diff -ruN --show-c-function --no-dereference configure configure
--- configure	2025-09-06 20:10:37.111901118 -0700
+++ configure	2025-09-06 19:58:25.486651882 -0700
@@ -10001,12 +10001,6 @@ then :
   printf "%s\n" "#define HAVE_LINUX_MAJOR_H 1" >>confdefs.h
 
 fi
-ac_fn_c_check_header_compile "$LINENO" "linux/ntsync.h" "ac_cv_header_linux_ntsync_h" "$ac_includes_default"
-if test "x$ac_cv_header_linux_ntsync_h" = xyes
-then :
-  printf "%s\n" "#define HAVE_LINUX_NTSYNC_H 1" >>confdefs.h
-
-fi
 ac_fn_c_check_header_compile "$LINENO" "linux/param.h" "ac_cv_header_linux_param_h" "$ac_includes_default"
 if test "x$ac_cv_header_linux_param_h" = xyes
 then :
@@ -10181,6 +10175,12 @@ then :
   printf "%s\n" "#define HAVE_SYS_EVENT_H 1" >>confdefs.h
 
 fi
+ac_fn_c_check_header_compile "$LINENO" "sys/eventfd.h" "ac_cv_header_sys_eventfd_h" "$ac_includes_default"
+if test "x$ac_cv_header_sys_eventfd_h" = xyes
+then :
+  printf "%s\n" "#define HAVE_SYS_EVENTFD_H 1" >>confdefs.h
+
+fi
 ac_fn_c_check_header_compile "$LINENO" "sys/extattr.h" "ac_cv_header_sys_extattr_h" "$ac_includes_default"
 if test "x$ac_cv_header_sys_extattr_h" = xyes
 then :
@@ -21198,6 +21198,12 @@ then :
   printf "%s\n" "#define HAVE_POSIX_FALLOCATE 1" >>confdefs.h
 
 fi
+ac_fn_c_check_func "$LINENO" "ppoll" "ac_cv_func_ppoll"
+if test "x$ac_cv_func_ppoll" = xyes
+then :
+  printf "%s\n" "#define HAVE_PPOLL 1" >>confdefs.h
+
+fi
 ac_fn_c_check_func "$LINENO" "prctl" "ac_cv_func_prctl"
 if test "x$ac_cv_func_prctl" = xyes
 then :
@@ -21329,6 +21335,80 @@ fi
 
 LIBS=$ac_save_LIBS
 
+ac_save_LIBS=$LIBS
+{ printf "%s\n" "$as_me:${as_lineno-$LINENO}: checking for library containing shm_open" >&5
+printf %s "checking for library containing shm_open... " >&6; }
+if test ${ac_cv_search_shm_open+y}
+then :
+  printf %s "(cached) " >&6
+else case e in #(
+  e) ac_func_search_save_LIBS=$LIBS
+cat confdefs.h - <<_ACEOF >conftest.$ac_ext
+/* end confdefs.h.  */
+
+/* Override any GCC internal prototype to avoid an error.
+   Use char because int might match the return type of a GCC
+   builtin and then its argument prototype would still apply.
+   The 'extern "C"' is for builds by C++ compilers;
+   although this is not generally supported in C code supporting it here
+   has little cost and some practical benefit (sr 110532).  */
+#ifdef __cplusplus
+extern "C"
+#endif
+char shm_open (void);
+int
+main (void)
+{
+return shm_open ();
+  ;
+  return 0;
+}
+_ACEOF
+for ac_lib in '' rt
+do
+  if test -z "$ac_lib"; then
+    ac_res="none required"
+  else
+    ac_res=-l$ac_lib
+    LIBS="-l$ac_lib  $ac_func_search_save_LIBS"
+  fi
+  if ac_fn_c_try_link "$LINENO"
+then :
+  ac_cv_search_shm_open=$ac_res
+fi
+rm -f core conftest.err conftest.$ac_objext conftest.beam \
+    conftest$ac_exeext
+  if test ${ac_cv_search_shm_open+y}
+then :
+  break
+fi
+done
+if test ${ac_cv_search_shm_open+y}
+then :
+
+else case e in #(
+  e) ac_cv_search_shm_open=no ;;
+esac
+fi
+rm conftest.$ac_ext
+LIBS=$ac_func_search_save_LIBS ;;
+esac
+fi
+{ printf "%s\n" "$as_me:${as_lineno-$LINENO}: result: $ac_cv_search_shm_open" >&5
+printf "%s\n" "$ac_cv_search_shm_open" >&6; }
+ac_res=$ac_cv_search_shm_open
+if test "$ac_res" != no
+then :
+  test "$ac_res" = "none required" || LIBS="$ac_res $LIBS"
+
+printf "%s\n" "#define HAVE_SHM_OPEN 1" >>confdefs.h
+
+                test "$ac_res" = "none required" || RT_LIBS="$ac_res"
+
+fi
+
+LIBS=$ac_save_LIBS
+
 { printf "%s\n" "$as_me:${as_lineno-$LINENO}: checking for sched_setaffinity" >&5
 printf %s "checking for sched_setaffinity... " >&6; }
 if test ${wine_cv_have_sched_setaffinity+y}
@@ -23427,7 +23507,7 @@ fi
 
 as_fn_append wine_rules "
 dlls/ntdll/unix/version.c: dummy
-	@version=\`(GIT_DIR=${wine_srcdir}.git git describe HEAD 2>/dev/null || echo \"wine-\$(PACKAGE_VERSION)\") | sed -n -e '\$\$s/\(.*\)/const char wine_build[] = \"\\1\";/p'\` && (echo \$\$version | cmp -s - \$@) || echo \$\$version >\$@ || (rm -f \$@ && exit 1)
+	@version=\`(echo \"wine-10.15\") | sed -n -e '\$\$s/\(.*\)/const char wine_build[] = \"\\1  ( FreeBSD TkG Esync )\";/p'\` && (echo \$\$version | cmp -s - \$@) || echo \$\$version >\$@ || (rm -f \$@ && exit 1)
 programs/winetest/build.rc: dummy
 	@build=\"STRINGTABLE { 1 \\\"\`GIT_DIR=${wine_srcdir}.git git rev-parse HEAD 2>/dev/null\`\\\" }\" && (echo \$\$build | cmp -s - \$@) || echo \$\$build >\$@ || (rm -f \$@ && exit 1)
 dlls/wineandroid.drv/wine-debug.apk: dlls/wineandroid.drv/build.gradle ${wine_srcdir}dlls/wineandroid.drv/AndroidManifest.xml ${wine_srcdir}dlls/wineandroid.drv/WineActivity.java ${wine_srcdir}dlls/wineandroid.drv/wine.svg
diff -ruN --show-c-function --no-dereference configure.ac configure.ac
--- configure.ac	2025-09-06 20:10:37.092090901 -0700
+++ configure.ac	2025-09-06 19:58:25.467557306 -0700
@@ -682,7 +682,6 @@ AC_CHECK_HEADERS(\
 	linux/input.h \
 	linux/ioctl.h \
 	linux/major.h \
-	linux/ntsync.h \
 	linux/param.h \
 	linux/serial.h \
 	linux/types.h \
@@ -712,6 +711,7 @@ AC_CHECK_HEADERS(\
 	sys/cdio.h \
 	sys/epoll.h \
 	sys/event.h \
+	sys/eventfd.h \
 	sys/extattr.h \
 	sys/filio.h \
 	sys/ipc.h \
@@ -2114,6 +2114,7 @@ AC_CHECK_FUNCS(\
 	port_create \
 	posix_fadvise \
 	posix_fallocate \
+	ppoll \
 	prctl \
 	sched_getcpu \
 	sched_yield \
@@ -2133,6 +2134,12 @@ AC_SEARCH_LIBS(clock_gettime, rt,
                 test "$ac_res" = "none required" || AC_SUBST(RT_LIBS,"$ac_res")])
 LIBS=$ac_save_LIBS
 
+ac_save_LIBS=$LIBS
+AC_SEARCH_LIBS(shm_open, rt,
+               [AC_DEFINE(HAVE_SHM_OPEN, 1, [Define to 1 if you have the `shm_open' function.])
+                test "$ac_res" = "none required" || AC_SUBST(RT_LIBS,"$ac_res")])
+LIBS=$ac_save_LIBS
+
 AC_CACHE_CHECK([for sched_setaffinity],wine_cv_have_sched_setaffinity,
                 AC_LINK_IFELSE([AC_LANG_PROGRAM(
 [[#include <sched.h>]], [[sched_setaffinity(0, 0, 0);]])],[wine_cv_have_sched_setaffinity=yes],[wine_cv_have_sched_setaffinity=no]))
@@ -3735,7 +3742,7 @@ dnl Rules for generated source files
 
 WINE_APPEND_RULE(
 [dlls/ntdll/unix/version.c: dummy
-	@version=\`(GIT_DIR=${wine_srcdir}.git git describe HEAD 2>/dev/null || echo \"wine-\$(PACKAGE_VERSION)\") | sed -n -e '\$\$s/\(.*\)/const char wine_build[[]] = \"\\1\";/p'\` && (echo \$\$version | cmp -s - \$[@]) || echo \$\$version >\$[@] || (rm -f \$[@] && exit 1)
+	@version=\`(echo \"wine-10.15\") | sed -n -e '\$\$s/\(.*\)/const char wine_build[] = \"\\1  ( FreeBSD TkG Esync )\";/p'\` && (echo \$\$version | cmp -s - \$@) || echo \$\$version >\$@ || (rm -f \$@ && exit 1)
 programs/winetest/build.rc: dummy
 	@build=\"STRINGTABLE { 1 \\\"\`GIT_DIR=${wine_srcdir}.git git rev-parse HEAD 2>/dev/null\`\\\" }\" && (echo \$\$build | cmp -s - \$[@]) || echo \$\$build >\$[@] || (rm -f \$[@] && exit 1)
 dlls/wineandroid.drv/wine-debug.apk: dlls/wineandroid.drv/build.gradle ${wine_srcdir}dlls/wineandroid.drv/AndroidManifest.xml ${wine_srcdir}dlls/wineandroid.drv/WineActivity.java ${wine_srcdir}dlls/wineandroid.drv/wine.svg
diff -ruN --show-c-function --no-dereference dlls/kernel32/tests/sync.c dlls/kernel32/tests/sync.c
--- dlls/kernel32/tests/sync.c	2025-09-06 20:10:25.249485030 -0700
+++ dlls/kernel32/tests/sync.c	2025-09-06 19:58:17.782306053 -0700
@@ -60,6 +60,7 @@ static DWORD (WINAPI *pQueueUserAPC2)(PA
 
 static NTSTATUS (WINAPI *pNtAllocateVirtualMemory)(HANDLE, PVOID *, ULONG_PTR, SIZE_T *, ULONG, ULONG);
 static NTSTATUS (WINAPI *pNtFreeVirtualMemory)(HANDLE, PVOID *, SIZE_T *, ULONG);
+static NTSTATUS (WINAPI *pNtQuerySystemTime)(LARGE_INTEGER *);
 static NTSTATUS (WINAPI *pNtWaitForSingleObject)(HANDLE, BOOLEAN, const LARGE_INTEGER *);
 static NTSTATUS (WINAPI *pNtWaitForMultipleObjects)(ULONG,const HANDLE*,BOOLEAN,BOOLEAN,const LARGE_INTEGER*);
 static PSLIST_ENTRY (__fastcall *pRtlInterlockedPushListSList)(PSLIST_HEADER list, PSLIST_ENTRY first,
@@ -292,7 +293,8 @@ static void test_mutex(void)
     SetLastError(0xdeadbeef);
     hOpened = OpenMutexA(GENERIC_READ | GENERIC_WRITE, FALSE, "WineTestMutex");
     ok(hOpened != NULL, "OpenMutex failed with error %ld\n", GetLastError());
-    wait_ret = WaitForSingleObject(hOpened, INFINITE);
+    wait_ret = WaitForSingleObject(hOpened, 0);
+todo_wine_if(getenv("WINEESYNC"))   /* XFAIL: validation is not implemented */
     ok(wait_ret == WAIT_FAILED, "WaitForSingleObject succeeded\n");
     CloseHandle(hOpened);
 
@@ -323,6 +325,7 @@ static void test_mutex(void)
 
     SetLastError(0xdeadbeef);
     ret = ReleaseMutex(hCreated);
+todo_wine_if(getenv("WINEESYNC"))   /* XFAIL: due to the above */
     ok(!ret && (GetLastError() == ERROR_NOT_OWNER),
         "ReleaseMutex should have failed with ERROR_NOT_OWNER instead of %ld\n", GetLastError());
 
@@ -572,12 +575,13 @@ static void test_slist(void)
 
 static void test_event(void)
 {
-    HANDLE handle, handle2;
+    HANDLE handle, handle2, handles[2];
     SECURITY_ATTRIBUTES sa;
     SECURITY_DESCRIPTOR sd;
     ACL acl;
     DWORD ret;
     BOOL val;
+    int i;
 
     /* no sd */
     handle = CreateEventA(NULL, FALSE, FALSE, __FILE__ ": Test Event");
@@ -681,11 +685,130 @@ static void test_event(void)
     ok( ret, "QueryMemoryResourceNotification failed err %lu\n", GetLastError() );
     ok( val == FALSE || val == TRUE, "wrong value %u\n", val );
     CloseHandle( handle );
+
+    handle = CreateEventA( NULL, TRUE, FALSE, NULL );
+    ok(!!handle, "got error %lu\n", GetLastError());
+
+    ret = WaitForSingleObject( handle, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    ret = SetEvent( handle );
+    ok(ret, "got error %lu\n", GetLastError());
+
+    ret = SetEvent( handle );
+    ok(ret, "got error %lu\n", GetLastError());
+
+    for (i = 0; i < 100; i++)
+    {
+        ret = WaitForSingleObject( handle, 0 );
+        ok(ret == 0, "got %lu\n", ret);
+    }
+
+    ret = ResetEvent( handle );
+    ok(ret, "got error %lu\n", GetLastError());
+
+    ret = ResetEvent( handle );
+    ok(ret, "got error %lu\n", GetLastError());
+
+    ret = WaitForSingleObject( handle, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    handle2 = CreateEventA( NULL, FALSE, TRUE, NULL );
+    ok(!!handle2, "got error %lu\n", GetLastError());
+
+    ret = WaitForSingleObject( handle2, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    ret = WaitForSingleObject( handle2, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    ret = SetEvent( handle2 );
+    ok(ret, "got error %lu\n", GetLastError());
+
+    ret = SetEvent( handle2 );
+    ok(ret, "got error %lu\n", GetLastError());
+
+    ret = ResetEvent( handle2 );
+    ok(ret, "got error %lu\n", GetLastError());
+
+    ret = ResetEvent( handle2 );
+    ok(ret, "got error %lu\n", GetLastError());
+
+    ret = WaitForSingleObject( handle2, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    handles[0] = handle;
+    handles[1] = handle2;
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    SetEvent( handle );
+    SetEvent( handle2 );
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    ret = WaitForSingleObject( handle2, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    ResetEvent( handle );
+    SetEvent( handle2 );
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == 1, "got %lu\n", ret);
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    SetEvent( handle );
+    SetEvent( handle2 );
+
+    ret = WaitForMultipleObjects( 2, handles, TRUE, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    ret = WaitForMultipleObjects( 2, handles, TRUE, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    SetEvent( handle2 );
+    ResetEvent( handle );
+
+    ret = WaitForMultipleObjects( 2, handles, TRUE, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    ret = WaitForSingleObject( handle2, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    handles[0] = handle2;
+    handles[1] = handle;
+    SetEvent( handle );
+    SetEvent( handle2 );
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == 1, "got %lu\n", ret);
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == 1, "got %lu\n", ret);
+
+    ret = CloseHandle( handle );
+    ok(ret, "got error %lu\n", GetLastError());
+
+    ret = CloseHandle( handle2 );
+    ok(ret, "got error %lu\n", GetLastError());
 }
 
 static void test_semaphore(void)
 {
-    HANDLE handle, handle2;
+    HANDLE handle, handle2, handles[2];
+    DWORD ret;
+    LONG prev;
+    int i;
 
     /* test case sensitivity */
 
@@ -727,6 +850,99 @@ static void test_semaphore(void)
     ok( GetLastError() == ERROR_INVALID_PARAMETER, "wrong error %lu\n", GetLastError());
 
     CloseHandle( handle );
+
+    handle = CreateSemaphoreA( NULL, 0, 5, NULL );
+    ok(!!handle, "CreateSemaphore failed: %lu\n", GetLastError());
+
+    ret = WaitForSingleObject( handle, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    ret = ReleaseSemaphore( handle, 1, &prev );
+    ok(ret, "got error %lu\n", GetLastError());
+    ok(prev == 0, "got prev %ld\n", prev);
+
+    ret = ReleaseSemaphore( handle, 1, &prev );
+    ok(ret, "got error %lu\n", GetLastError());
+    ok(prev == 1, "got prev %ld\n", prev);
+
+    ret = ReleaseSemaphore( handle, 5, &prev );
+    ok(!ret, "got %ld\n", ret);
+    ok(GetLastError() == ERROR_TOO_MANY_POSTS, "got error %lu\n", GetLastError());
+    ok(prev == 1, "got prev %ld\n", prev);
+
+    ret = ReleaseSemaphore( handle, 2, &prev );
+    ok(ret, "got error %lu\n", GetLastError());
+    ok(prev == 2, "got prev %ld\n", prev);
+
+    ret = ReleaseSemaphore( handle, 1, &prev );
+    ok(ret, "got error %lu\n", GetLastError());
+    ok(prev == 4, "got prev %ld\n", prev);
+
+    for (i = 0; i < 5; i++)
+    {
+        ret = WaitForSingleObject( handle, 0 );
+        ok(ret == 0, "got %lu\n", ret);
+    }
+
+    ret = WaitForSingleObject( handle, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    handle2 = CreateSemaphoreA( NULL, 3, 5, NULL );
+    ok(!!handle2, "CreateSemaphore failed: %lu\n", GetLastError());
+
+    ret = ReleaseSemaphore( handle2, 1, &prev );
+    ok(ret, "got error %lu\n", GetLastError());
+    ok(prev == 3, "got prev %ld\n", prev);
+
+    for (i = 0; i < 4; i++)
+    {
+        ret = WaitForSingleObject( handle2, 0 );
+        ok(ret == 0, "got %lu\n", ret);
+    }
+
+    ret = WaitForSingleObject( handle2, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    handles[0] = handle;
+    handles[1] = handle2;
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    ReleaseSemaphore( handle, 1, NULL );
+    ReleaseSemaphore( handle2, 1, NULL );
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == 1, "got %lu\n", ret);
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    ReleaseSemaphore( handle, 1, NULL );
+    ReleaseSemaphore( handle2, 1, NULL );
+
+    ret = WaitForMultipleObjects( 2, handles, TRUE, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    ReleaseSemaphore( handle, 1, NULL );
+
+    ret = WaitForMultipleObjects( 2, handles, TRUE, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    ret = WaitForSingleObject( handle, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    ret = CloseHandle( handle );
+    ok(ret, "got error %lu\n", ret);
+
+    ret = CloseHandle( handle2 );
+    ok(ret, "got error %lu\n", ret);
 }
 
 static void test_waitable_timer(void)
@@ -1281,11 +1497,15 @@ static HANDLE modify_handle(HANDLE handl
     return ULongToHandle(tmp);
 }
 
+#define TIMEOUT_INFINITE (((LONGLONG)0x7fffffff) << 32 | 0xffffffff)
+
 static void test_WaitForSingleObject(void)
 {
     HANDLE signaled, nonsignaled, invalid;
+    LARGE_INTEGER ntnow, ntthen;
     LARGE_INTEGER timeout;
     NTSTATUS status;
+    DWORD now, then;
     DWORD ret;
 
     signaled = CreateEventW(NULL, TRUE, TRUE, NULL);
@@ -1370,6 +1590,68 @@ static void test_WaitForSingleObject(voi
     status = pNtWaitForSingleObject(GetCurrentThread(), FALSE, &timeout);
     ok(status == STATUS_TIMEOUT, "expected STATUS_TIMEOUT, got %08lx\n", status);
 
+    ret = WaitForSingleObject( signaled, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    ret = WaitForSingleObject( nonsignaled, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    /* test that a timed wait actually does wait */
+    now = GetTickCount();
+    ret = WaitForSingleObject( nonsignaled, 100 );
+    then = GetTickCount();
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+    ok(abs((then - now) - 100) < 5, "got %lu ms\n", then - now);
+
+    now = GetTickCount();
+    ret = WaitForSingleObject( signaled, 100 );
+    then = GetTickCount();
+    ok(ret == 0, "got %lu\n", ret);
+    ok(abs(then - now) < 5, "got %lu ms\n", then - now);
+
+    ret = WaitForSingleObject( signaled, INFINITE );
+    ok(ret == 0, "got %lu\n", ret);
+
+    /* test NT timeouts */
+    pNtQuerySystemTime( &ntnow );
+    timeout.QuadPart = ntnow.QuadPart + 100 * 10000;
+    status = pNtWaitForSingleObject( nonsignaled, FALSE, &timeout );
+    pNtQuerySystemTime( &ntthen );
+    ok(status == STATUS_TIMEOUT, "got %#lx\n", status);
+    ok(abs(((ntthen.QuadPart - ntnow.QuadPart) / 10000) - 100) < 5, "got %s ns\n",
+        wine_dbgstr_longlong((ntthen.QuadPart - ntnow.QuadPart) * 100));
+
+    pNtQuerySystemTime( &ntnow );
+    timeout.QuadPart = -100 * 10000;
+    status = pNtWaitForSingleObject( nonsignaled, FALSE, &timeout );
+    pNtQuerySystemTime( &ntthen );
+    ok(status == STATUS_TIMEOUT, "got %#lx\n", status);
+    ok(abs(((ntthen.QuadPart - ntnow.QuadPart) / 10000) - 100) < 5, "got %s ns\n",
+        wine_dbgstr_longlong((ntthen.QuadPart - ntnow.QuadPart) * 100));
+
+    status = pNtWaitForSingleObject( signaled, FALSE, NULL );
+    ok(status == 0, "got %#lx\n", status);
+
+    timeout.QuadPart = TIMEOUT_INFINITE;
+    status = pNtWaitForSingleObject( signaled, FALSE, &timeout );
+    ok(status == 0, "got %#lx\n", status);
+
+    pNtQuerySystemTime( &ntnow );
+    timeout.QuadPart = ntnow.QuadPart;
+    status = pNtWaitForSingleObject( nonsignaled, FALSE, &timeout );
+    pNtQuerySystemTime( &ntthen );
+    ok(status == STATUS_TIMEOUT, "got %#lx\n", status);
+    ok(abs((ntthen.QuadPart - ntnow.QuadPart) / 10000) < 5, "got %s ns\n",
+        wine_dbgstr_longlong((ntthen.QuadPart - ntnow.QuadPart) * 100));
+
+    pNtQuerySystemTime( &ntnow );
+    timeout.QuadPart = ntnow.QuadPart - 100 * 10000;
+    status = pNtWaitForSingleObject( nonsignaled, FALSE, &timeout );
+    pNtQuerySystemTime( &ntthen );
+    ok(status == STATUS_TIMEOUT, "got %#lx\n", status);
+    ok(abs((ntthen.QuadPart - ntnow.QuadPart) / 10000) < 5, "got %s ns\n",
+        wine_dbgstr_longlong((ntthen.QuadPart - ntnow.QuadPart) * 100));
+
     CloseHandle(signaled);
     CloseHandle(nonsignaled);
 }
@@ -2992,6 +3274,84 @@ static void test_QueueUserAPC(void)
     }
 }
 
+static int zigzag_state, zigzag_count[2], zigzag_stop;
+
+static DWORD CALLBACK zigzag_event0(void *arg)
+{
+    HANDLE *events = arg;
+
+    while (!zigzag_stop)
+    {
+        WaitForSingleObject(events[0], INFINITE);
+        ResetEvent(events[0]);
+        ok(zigzag_state == 0, "got wrong state %d\n", zigzag_state);
+        zigzag_state++;
+        SetEvent(events[1]);
+        zigzag_count[0]++;
+    }
+    trace("thread 0 got done\n");
+    return 0;
+}
+
+static DWORD CALLBACK zigzag_event1(void *arg)
+{
+    HANDLE *events = arg;
+
+    while (!zigzag_stop)
+    {
+        WaitForSingleObject(events[1], INFINITE);
+        ResetEvent(events[1]);
+        ok(zigzag_state == 1, "got wrong state %d\n", zigzag_state);
+        zigzag_state--;
+        SetEvent(events[0]);
+        zigzag_count[1]++;
+    }
+    trace("thread 1 got done\n");
+    return 0;
+}
+
+static void test_zigzag_event(void)
+{
+    /* The basic idea is to test SetEvent/Wait back and forth between two
+     * threads. Each thread clears their own event, sets some common data,
+     * signals the other's, then waits on their own. We make sure the common
+     * data is always in the right state. We also print performance data. */
+
+    HANDLE threads[2], events[2];
+    BOOL ret;
+
+    events[0] = CreateEventA(NULL, FALSE, FALSE, NULL);
+    events[1] = CreateEventA(NULL, FALSE, FALSE, NULL);
+
+    threads[0] = CreateThread(NULL, 0, zigzag_event0, events, 0, NULL);
+    threads[1] = CreateThread(NULL, 0, zigzag_event1, events, 0, NULL);
+
+    zigzag_state = 0;
+    zigzag_count[0] = zigzag_count[1] = 0;
+    zigzag_stop = 0;
+
+    trace("starting zigzag test (events)\n");
+    SetEvent(events[0]);
+    Sleep(2000);
+    zigzag_stop = 1;
+    ret = WaitForMultipleObjects(2, threads, FALSE, INFINITE);
+    trace("%d\n", ret);
+    ok(ret == 0 || ret == 1, "wait failed: %u\n", ret);
+
+    ok(zigzag_count[0] == zigzag_count[1] || zigzag_count[0] == zigzag_count[1] + 1,
+        "count did not match: %d != %d\n", zigzag_count[0], zigzag_count[1]);
+
+    /* signal the other thread to finish, if it didn't already
+     * (in theory they both would at the same time, but there's a slight race on teardown if we get
+     * thread 1 SetEvent -> thread 0 ResetEvent -> thread 0 Wait -> thread 1 exits */
+    zigzag_state = 1-ret;
+    SetEvent(events[1-ret]);
+    ret = WaitForSingleObject(threads[1-ret], 1000);
+    ok(!ret, "wait failed: %u\n", ret);
+
+    trace("count: %d\n", zigzag_count[0]);
+}
+
 START_TEST(sync)
 {
     char **argv;
@@ -3019,6 +3379,7 @@ START_TEST(sync)
     pQueueUserAPC2 = (void *)GetProcAddress(hdll, "QueueUserAPC2");
     pNtAllocateVirtualMemory = (void *)GetProcAddress(hntdll, "NtAllocateVirtualMemory");
     pNtFreeVirtualMemory = (void *)GetProcAddress(hntdll, "NtFreeVirtualMemory");
+    pNtQuerySystemTime = (void *)GetProcAddress(hntdll, "NtQuerySystemTime");
     pNtWaitForSingleObject = (void *)GetProcAddress(hntdll, "NtWaitForSingleObject");
     pNtWaitForMultipleObjects = (void *)GetProcAddress(hntdll, "NtWaitForMultipleObjects");
     pRtlInterlockedPushListSList = (void *)GetProcAddress(hntdll, "RtlInterlockedPushListSList");
@@ -3063,5 +3424,6 @@ START_TEST(sync)
     test_srwlock_example();
     test_alertable_wait();
     test_apc_deadlock();
+    test_zigzag_event();
     test_crit_section();
 }
diff -ruN --show-c-function --no-dereference dlls/ntdll/Makefile.in dlls/ntdll/Makefile.in
--- dlls/ntdll/Makefile.in	2025-09-06 20:10:37.098256679 -0700
+++ dlls/ntdll/Makefile.in	2025-09-06 19:58:25.473464329 -0700
@@ -49,6 +49,7 @@ SOURCES = \
 	unix/cdrom.c \
 	unix/debug.c \
 	unix/env.c \
+	unix/esync.c \
 	unix/file.c \
 	unix/loader.c \
 	unix/loadorder.c \
diff -ruN --show-c-function --no-dereference dlls/ntdll/unix/esync.c dlls/ntdll/unix/esync.c
--- dlls/ntdll/unix/esync.c	1969-12-31 16:00:00.000000000 -0800
+++ dlls/ntdll/unix/esync.c	2025-09-06 19:58:17.788012985 -0700
@@ -0,0 +1,1325 @@
+/*
+ * eventfd-based synchronization objects
+ *
+ * Copyright (C) 2018 Zebediah Figura
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
+ */
+
+#if 0
+#pragma makedep unix
+#endif
+
+#include "config.h"
+
+#ifndef _GNU_SOURCE
+#define _GNU_SOURCE
+#endif
+
+#include <assert.h>
+#include <errno.h>
+#include <fcntl.h>
+#include <stdarg.h>
+#include <stdint.h>
+#include <stdlib.h>
+#include <sys/mman.h>
+#ifdef HAVE_SYS_STAT_H
+# include <sys/stat.h>
+#endif
+#include <poll.h>
+#include <sys/types.h>
+#include <unistd.h>
+
+#include "ntstatus.h"
+#define WIN32_NO_STATUS
+#include "windef.h"
+#include "winternl.h"
+#include "wine/server.h"
+#include "wine/debug.h"
+
+#include "unix_private.h"
+#include "esync.h"
+
+WINE_DEFAULT_DEBUG_CHANNEL(esync);
+
+int do_esync(void)
+{
+#ifdef HAVE_SYS_EVENTFD_H
+    static int do_esync_cached = -1;
+
+    if (do_esync_cached == -1)
+        do_esync_cached = getenv("WINEESYNC") && atoi(getenv("WINEESYNC"));
+
+    return do_esync_cached;
+#else
+    static int once;
+    if (!once++)
+        FIXME("eventfd not supported on this platform.\n");
+    return 0;
+#endif
+}
+
+struct esync
+{
+    LONG type;
+    int fd;
+    void *shm;
+};
+
+struct semaphore
+{
+    LONG max;
+    LONG count;
+};
+C_ASSERT(sizeof(struct semaphore) == 8);
+
+struct mutex
+{
+    LONG tid;
+    LONG count;    /* recursion count */
+};
+C_ASSERT(sizeof(struct mutex) == 8);
+
+struct event
+{
+    LONG signaled;
+    LONG locked;
+};
+C_ASSERT(sizeof(struct event) == 8);
+
+static char shm_name[29];
+static int shm_fd;
+static void **shm_addrs;
+static int shm_addrs_size;  /* length of the allocated shm_addrs array */
+static long pagesize;
+
+static pthread_mutex_t shm_addrs_mutex = PTHREAD_MUTEX_INITIALIZER;
+
+static void *get_shm( unsigned int idx )
+{
+    int entry  = (idx * 8) / pagesize;
+    int offset = (idx * 8) % pagesize;
+    void *ret;
+
+    pthread_mutex_lock( &shm_addrs_mutex );
+
+    if (entry >= shm_addrs_size)
+    {
+        int new_size = max(shm_addrs_size * 2, entry + 1);
+
+        if (!(shm_addrs = realloc( shm_addrs, new_size * sizeof(shm_addrs[0]) )))
+            ERR("Failed to grow shm_addrs array to size %d.\n", shm_addrs_size);
+        memset( shm_addrs + shm_addrs_size, 0, (new_size - shm_addrs_size) * sizeof(shm_addrs[0]) );
+        shm_addrs_size = new_size;
+    }
+
+    if (!shm_addrs[entry])
+    {
+        void *addr = mmap( NULL, pagesize, PROT_READ | PROT_WRITE, MAP_SHARED, shm_fd, entry * pagesize );
+        if (addr == (void *)-1)
+            ERR("Failed to map page %d (offset %#lx).\n", entry, entry * pagesize);
+
+        TRACE("Mapping page %d at %p.\n", entry, addr);
+
+        if (InterlockedCompareExchangePointer( &shm_addrs[entry], addr, 0 ))
+            munmap( addr, pagesize ); /* someone beat us to it */
+    }
+
+    ret = (void *)((unsigned long)shm_addrs[entry] + offset);
+
+    pthread_mutex_unlock( &shm_addrs_mutex );
+
+    return ret;
+}
+
+/* We'd like lookup to be fast. To that end, we use a static list indexed by handle.
+ * This is copied and adapted from the fd cache code. */
+
+#define ESYNC_LIST_BLOCK_SIZE  (65536 / sizeof(struct esync))
+#define ESYNC_LIST_ENTRIES     256
+
+static struct esync *esync_list[ESYNC_LIST_ENTRIES];
+static struct esync esync_list_initial_block[ESYNC_LIST_BLOCK_SIZE];
+
+static inline UINT_PTR handle_to_index( HANDLE handle, UINT_PTR *entry )
+{
+    UINT_PTR idx = (((UINT_PTR)handle) >> 2) - 1;
+    *entry = idx / ESYNC_LIST_BLOCK_SIZE;
+    return idx % ESYNC_LIST_BLOCK_SIZE;
+}
+
+static struct esync *add_to_list( HANDLE handle, enum esync_type type, int fd, void *shm )
+{
+    UINT_PTR entry, idx = handle_to_index( handle, &entry );
+
+    if (entry >= ESYNC_LIST_ENTRIES)
+    {
+        FIXME( "too many allocated handles, not caching %p\n", handle );
+        return FALSE;
+    }
+
+    if (!esync_list[entry])  /* do we need to allocate a new block of entries? */
+    {
+        if (!entry) esync_list[0] = esync_list_initial_block;
+        else
+        {
+            void *ptr = anon_mmap_alloc( ESYNC_LIST_BLOCK_SIZE * sizeof(struct esync),
+                                         PROT_READ | PROT_WRITE );
+            if (ptr == MAP_FAILED) return FALSE;
+            esync_list[entry] = ptr;
+        }
+    }
+
+    if (!InterlockedCompareExchange( &esync_list[entry][idx].type, type, 0 ))
+    {
+        esync_list[entry][idx].fd = fd;
+        esync_list[entry][idx].shm = shm;
+    }
+    return &esync_list[entry][idx];
+}
+
+static struct esync *get_cached_object( HANDLE handle )
+{
+    UINT_PTR entry, idx = handle_to_index( handle, &entry );
+
+    if (entry >= ESYNC_LIST_ENTRIES || !esync_list[entry]) return NULL;
+    if (!esync_list[entry][idx].type) return NULL;
+
+    return &esync_list[entry][idx];
+}
+
+/* Gets an object. This is either a proper esync object (i.e. an event,
+ * semaphore, etc. created using create_esync) or a generic synchronizable
+ * server-side object which the server will signal (e.g. a process, thread,
+ * message queue, etc.) */
+static NTSTATUS get_object( HANDLE handle, struct esync **obj )
+{
+    int ret = STATUS_SUCCESS;
+    enum esync_type type = 0;
+    unsigned int shm_idx = 0;
+    obj_handle_t fd_handle;
+    sigset_t sigset;
+    int fd = -1;
+
+    if ((*obj = get_cached_object( handle ))) return STATUS_SUCCESS;
+
+    if ((INT_PTR)handle < 0)
+    {
+        /* We can deal with pseudo-handles, but it's just easier this way */
+        return STATUS_NOT_IMPLEMENTED;
+    }
+
+    if (!handle)
+    {
+        /* Shadow of the Tomb Raider really likes passing in NULL handles to
+         * various functions. Concerning, but let's avoid a server call. */
+        return STATUS_INVALID_HANDLE;
+    }
+
+    /* We need to try grabbing it from the server. */
+    server_enter_uninterrupted_section( &fd_cache_mutex, &sigset );
+    if (!(*obj = get_cached_object( handle )))
+    {
+        SERVER_START_REQ( get_esync_fd )
+        {
+            req->handle = wine_server_obj_handle( handle );
+            if (!(ret = wine_server_call( req )))
+            {
+                type = reply->type;
+                shm_idx = reply->shm_idx;
+                fd = receive_fd( &fd_handle );
+                assert( wine_server_ptr_handle(fd_handle) == handle );
+            }
+        }
+        SERVER_END_REQ;
+    }
+    server_leave_uninterrupted_section( &fd_cache_mutex, &sigset );
+
+    if (*obj)
+    {
+        /* We managed to grab it while in the CS; return it. */
+        return STATUS_SUCCESS;
+    }
+
+    if (ret)
+    {
+        WARN("Failed to retrieve fd for handle %p, status %#x.\n", handle, ret);
+        *obj = NULL;
+        return ret;
+    }
+
+    TRACE("Got fd %d for handle %p.\n", fd, handle);
+
+    *obj = add_to_list( handle, type, fd, shm_idx ? get_shm( shm_idx ) : 0 );
+    return ret;
+}
+
+NTSTATUS esync_close( HANDLE handle )
+{
+    UINT_PTR entry, idx = handle_to_index( handle, &entry );
+
+    TRACE("%p.\n", handle);
+
+    if (entry < ESYNC_LIST_ENTRIES && esync_list[entry])
+    {
+        if (InterlockedExchange(&esync_list[entry][idx].type, 0))
+        {
+            close( esync_list[entry][idx].fd );
+            return STATUS_SUCCESS;
+        }
+    }
+
+    return STATUS_INVALID_HANDLE;
+}
+
+static NTSTATUS create_esync( enum esync_type type, HANDLE *handle, ACCESS_MASK access,
+                              const OBJECT_ATTRIBUTES *attr, int initval, int max )
+{
+    NTSTATUS ret;
+    data_size_t len;
+    struct object_attributes *objattr;
+    obj_handle_t fd_handle;
+    unsigned int shm_idx;
+    sigset_t sigset;
+    int fd;
+
+    if ((ret = alloc_object_attributes( attr, &objattr, &len ))) return ret;
+
+    /* We have to synchronize on the fd cache CS so that our calls to
+     * receive_fd don't race with theirs. */
+    server_enter_uninterrupted_section( &fd_cache_mutex, &sigset );
+    SERVER_START_REQ( create_esync )
+    {
+        req->access  = access;
+        req->initval = initval;
+        req->type    = type;
+        req->max     = max;
+        wine_server_add_data( req, objattr, len );
+        ret = wine_server_call( req );
+        if (!ret || ret == STATUS_OBJECT_NAME_EXISTS)
+        {
+            *handle = wine_server_ptr_handle( reply->handle );
+            type = reply->type;
+            shm_idx = reply->shm_idx;
+            fd = receive_fd( &fd_handle );
+            assert( wine_server_ptr_handle(fd_handle) == *handle );
+        }
+    }
+    SERVER_END_REQ;
+    server_leave_uninterrupted_section( &fd_cache_mutex, &sigset );
+
+    if (!ret || ret == STATUS_OBJECT_NAME_EXISTS)
+    {
+        add_to_list( *handle, type, fd, shm_idx ? get_shm( shm_idx ) : 0 );
+        TRACE("-> handle %p, fd %d.\n", *handle, fd);
+    }
+
+    free( objattr );
+    return ret;
+}
+
+static NTSTATUS open_esync( enum esync_type type, HANDLE *handle,
+    ACCESS_MASK access, const OBJECT_ATTRIBUTES *attr )
+{
+    NTSTATUS ret;
+    obj_handle_t fd_handle;
+    unsigned int shm_idx;
+    sigset_t sigset;
+    int fd;
+
+    server_enter_uninterrupted_section( &fd_cache_mutex, &sigset );
+    SERVER_START_REQ( open_esync )
+    {
+        req->access     = access;
+        req->attributes = attr->Attributes;
+        req->rootdir    = wine_server_obj_handle( attr->RootDirectory );
+        req->type       = type;
+        if (attr->ObjectName)
+            wine_server_add_data( req, attr->ObjectName->Buffer, attr->ObjectName->Length );
+        if (!(ret = wine_server_call( req )))
+        {
+            *handle = wine_server_ptr_handle( reply->handle );
+            type = reply->type;
+            shm_idx = reply->shm_idx;
+            fd = receive_fd( &fd_handle );
+            assert( wine_server_ptr_handle(fd_handle) == *handle );
+        }
+    }
+    SERVER_END_REQ;
+    server_leave_uninterrupted_section( &fd_cache_mutex, &sigset );
+
+    if (!ret)
+    {
+        add_to_list( *handle, type, fd, shm_idx ? get_shm( shm_idx ) : 0 );
+
+        TRACE("-> handle %p, fd %d.\n", *handle, fd);
+    }
+    return ret;
+}
+
+extern NTSTATUS esync_create_semaphore(HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr, int initial, int max)
+{
+    TRACE("name %s, initial %d, max %d.\n",
+        attr ? debugstr_us(attr->ObjectName) : "<no name>", initial, max);
+
+    return create_esync( ESYNC_SEMAPHORE, handle, access, attr, initial, max );
+}
+
+NTSTATUS esync_open_semaphore( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr )
+{
+    TRACE("name %s.\n", debugstr_us(attr->ObjectName));
+
+    return open_esync( ESYNC_SEMAPHORE, handle, access, attr );
+}
+
+NTSTATUS esync_release_semaphore( HANDLE handle, unsigned int count, ULONG *prev )
+{
+    struct esync *obj;
+    struct semaphore *semaphore;
+    uint64_t count64 = count;
+    ULONG current;
+    NTSTATUS ret;
+
+    TRACE("%p, %d, %p.\n", handle, count, prev);
+
+    if ((ret = get_object( handle, &obj))) return ret;
+    semaphore = obj->shm;
+
+    do
+    {
+        current = semaphore->count;
+
+        if (count + current > semaphore->max)
+            return STATUS_SEMAPHORE_LIMIT_EXCEEDED;
+    } while (InterlockedCompareExchange( &semaphore->count, count + current, current ) != current);
+
+    if (prev) *prev = current;
+
+    /* We don't have to worry about a race between increasing the count and
+     * write(). The fact that we were able to increase the count means that we
+     * have permission to actually write that many releases to the semaphore. */
+
+    if (write( obj->fd, &count64, sizeof(count64) ) == -1)
+        return errno_to_status( errno );
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS esync_query_semaphore( HANDLE handle, void *info, ULONG *ret_len )
+{
+    struct esync *obj;
+    struct semaphore *semaphore;
+    SEMAPHORE_BASIC_INFORMATION *out = info;
+    NTSTATUS ret;
+
+    TRACE("handle %p, info %p, ret_len %p.\n", handle, info, ret_len);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+    semaphore = obj->shm;
+
+    out->CurrentCount = semaphore->count;
+    out->MaximumCount = semaphore->max;
+    if (ret_len) *ret_len = sizeof(*out);
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS esync_create_event( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr, EVENT_TYPE event_type, BOOLEAN initial )
+{
+    enum esync_type type = (event_type == SynchronizationEvent ? ESYNC_AUTO_EVENT : ESYNC_MANUAL_EVENT);
+
+    TRACE("name %s, %s-reset, initial %d.\n",
+        attr ? debugstr_us(attr->ObjectName) : "<no name>",
+        event_type == NotificationEvent ? "manual" : "auto", initial);
+
+    return create_esync( type, handle, access, attr, initial, 0 );
+}
+
+NTSTATUS esync_open_event( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr )
+{
+    TRACE("name %s.\n", debugstr_us(attr->ObjectName));
+
+    return open_esync( ESYNC_AUTO_EVENT, handle, access, attr ); /* doesn't matter which */
+}
+
+static inline void small_pause(void)
+{
+#ifdef __i386__
+    __asm__ __volatile__( "rep;nop" : : : "memory" );
+#else
+    __asm__ __volatile__( "" : : : "memory" );
+#endif
+}
+
+/* Manual-reset events are actually racier than other objects in terms of shm
+ * state. With other objects, races don't matter, because we only treat the shm
+ * state as a hint that lets us skip poll()—we still have to read(). But with
+ * manual-reset events we don't, which means that the shm state can be out of
+ * sync with the actual state.
+ *
+ * In general we shouldn't have to worry about races between modifying the
+ * event and waiting on it. If the state changes while we're waiting, it's
+ * equally plausible that we caught it before or after the state changed.
+ * However, we can have races between SetEvent() and ResetEvent(), so that the
+ * event has inconsistent internal state.
+ *
+ * To solve this we have to use the other field to lock the event. Currently
+ * this is implemented as a spinlock, but I'm not sure if a futex might be
+ * better. I'm also not sure if it's possible to obviate locking by arranging
+ * writes and reads in a certain way.
+ *
+ * Note that we don't have to worry about locking in esync_wait_objects().
+ * There's only two general patterns:
+ *
+ * WaitFor()    SetEvent()
+ * -------------------------
+ * read()
+ * signaled = 0
+ *              signaled = 1
+ *              write()
+ * -------------------------
+ * read()
+ *              signaled = 1
+ * signaled = 0
+ *              <no write(), because it was already signaled>
+ * -------------------------
+ *
+ * That is, if SetEvent() tries to signal the event before WaitFor() resets its
+ * signaled state, it won't bother trying to write(), and then the signaled
+ * state will be reset, so the result is a consistent non-signaled event.
+ * There's several variations to this pattern but all of them are protected in
+ * the same way. Note however this is why we have to use interlocked_xchg()
+ * event inside of the lock.
+ */
+
+/* Removing this spinlock is harder than it looks. esync_wait_objects() can
+ * deal with inconsistent state well enough, and a race between SetEvent() and
+ * ResetEvent() gives us license to yield either result as long as we act
+ * consistently, but that's not enough. Notably, esync_wait_objects() should
+ * probably act like a fence, so that the second half of esync_set_event() does
+ * not seep past a subsequent reset. That's one problem, but no guarantee there
+ * aren't others. */
+
+NTSTATUS esync_set_event( HANDLE handle )
+{
+    static const uint64_t value = 1;
+    struct esync *obj;
+    struct event *event;
+    NTSTATUS ret;
+
+    TRACE("%p.\n", handle);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+    event = obj->shm;
+
+    if (obj->type == ESYNC_MANUAL_EVENT)
+    {
+        /* Acquire the spinlock. */
+        while (InterlockedCompareExchange( &event->locked, 1, 0 ))
+            small_pause();
+    }
+
+    /* For manual-reset events, as long as we're in a lock, we can take the
+     * optimization of only calling write() if the event wasn't already
+     * signaled.
+     *
+     * For auto-reset events, esync_wait_objects() must grab the kernel object.
+     * Thus if we got into a race so that the shm state is signaled but the
+     * eventfd is unsignaled (i.e. reset shm, set shm, set fd, reset fd), we
+     * *must* signal the fd now, or any waiting threads will never wake up. */
+
+    if (!InterlockedExchange( &event->signaled, 1 ) || obj->type == ESYNC_AUTO_EVENT)
+    {
+        if (write( obj->fd, &value, sizeof(value) ) == -1)
+            ERR("write: %s\n", strerror(errno));
+    }
+
+    if (obj->type == ESYNC_MANUAL_EVENT)
+    {
+        /* Release the spinlock. */
+        event->locked = 0;
+    }
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS esync_reset_event( HANDLE handle )
+{
+    uint64_t value;
+    struct esync *obj;
+    struct event *event;
+    NTSTATUS ret;
+
+    TRACE("%p.\n", handle);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+    event = obj->shm;
+
+    if (obj->type == ESYNC_MANUAL_EVENT)
+    {
+        /* Acquire the spinlock. */
+        while (InterlockedCompareExchange( &event->locked, 1, 0 ))
+            small_pause();
+    }
+
+    /* For manual-reset events, as long as we're in a lock, we can take the
+     * optimization of only calling read() if the event was already signaled.
+     *
+     * For auto-reset events, we have no guarantee that the previous "signaled"
+     * state is actually correct. We need to leave both states unsignaled after
+     * leaving this function, so we always have to read(). */
+    if (InterlockedExchange( &event->signaled, 0 ) || obj->type == ESYNC_AUTO_EVENT)
+    {
+        if (read( obj->fd, &value, sizeof(value) ) == -1 && errno != EWOULDBLOCK && errno != EAGAIN)
+        {
+            ERR("read: %s\n", strerror(errno));
+        }
+    }
+
+    if (obj->type == ESYNC_MANUAL_EVENT)
+    {
+        /* Release the spinlock. */
+        event->locked = 0;
+    }
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS esync_pulse_event( HANDLE handle )
+{
+    uint64_t value = 1;
+    struct esync *obj;
+    NTSTATUS ret;
+
+    TRACE("%p.\n", handle);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+
+    /* This isn't really correct; an application could miss the write.
+     * Unfortunately we can't really do much better. Fortunately this is rarely
+     * used (and publicly deprecated). */
+    if (write( obj->fd, &value, sizeof(value) ) == -1)
+        return errno_to_status( errno );
+
+    /* Try to give other threads a chance to wake up. Hopefully erring on this
+     * side is the better thing to do... */
+    NtYieldExecution();
+
+    read( obj->fd, &value, sizeof(value) );
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS esync_query_event( HANDLE handle, void *info, ULONG *ret_len )
+{
+    struct esync *obj;
+    EVENT_BASIC_INFORMATION *out = info;
+    struct pollfd fd;
+    NTSTATUS ret;
+
+    TRACE("handle %p, info %p, ret_len %p.\n", handle, info, ret_len);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+
+    fd.fd = obj->fd;
+    fd.events = POLLIN;
+    out->EventState = poll( &fd, 1, 0 );
+    out->EventType = (obj->type == ESYNC_AUTO_EVENT ? SynchronizationEvent : NotificationEvent);
+    if (ret_len) *ret_len = sizeof(*out);
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS esync_create_mutex( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr, BOOLEAN initial )
+{
+    TRACE("name %s, initial %d.\n",
+        attr ? debugstr_us(attr->ObjectName) : "<no name>", initial);
+
+    return create_esync( ESYNC_MUTEX, handle, access, attr, initial ? 0 : 1, 0 );
+}
+
+NTSTATUS esync_open_mutex( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr )
+{
+    TRACE("name %s.\n", debugstr_us(attr->ObjectName));
+
+    return open_esync( ESYNC_MUTEX, handle, access, attr );
+}
+
+NTSTATUS esync_release_mutex( HANDLE *handle, LONG *prev )
+{
+    struct esync *obj;
+    struct mutex *mutex;
+    static const uint64_t value = 1;
+    NTSTATUS ret;
+
+    TRACE("%p, %p.\n", handle, prev);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+    mutex = obj->shm;
+
+    /* This is thread-safe, because the only thread that can change the tid to
+     * or from our tid is ours. */
+    if (mutex->tid != GetCurrentThreadId()) return STATUS_MUTANT_NOT_OWNED;
+
+    if (prev) *prev = mutex->count;
+
+    mutex->count--;
+
+    if (!mutex->count)
+    {
+        /* This is also thread-safe, as long as signaling the file is the last
+         * thing we do. Other threads don't care about the tid if it isn't
+         * theirs. */
+        mutex->tid = 0;
+
+        if (write( obj->fd, &value, sizeof(value) ) == -1)
+            return errno_to_status( errno );
+    }
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS esync_query_mutex( HANDLE handle, void *info, ULONG *ret_len )
+{
+    struct esync *obj;
+    struct mutex *mutex;
+    MUTANT_BASIC_INFORMATION *out = info;
+    NTSTATUS ret;
+
+    TRACE("handle %p, info %p, ret_len %p.\n", handle, info, ret_len);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+    mutex = obj->shm;
+
+    out->CurrentCount = 1 - mutex->count;
+    out->OwnedByCaller = (mutex->tid == GetCurrentThreadId());
+    out->AbandonedState = (mutex->tid == ~0);
+    if (ret_len) *ret_len = sizeof(*out);
+
+    return STATUS_SUCCESS;
+}
+
+#define TICKSPERSEC        10000000
+#define TICKSPERMSEC       10000
+
+static LONGLONG update_timeout( ULONGLONG end )
+{
+    LARGE_INTEGER now;
+    LONGLONG timeleft;
+
+    NtQuerySystemTime( &now );
+    timeleft = end - now.QuadPart;
+    if (timeleft < 0) timeleft = 0;
+    return timeleft;
+}
+
+static int do_poll( struct pollfd *fds, nfds_t nfds, ULONGLONG *end )
+{
+    int ret;
+
+    do
+    {
+        if (end)
+        {
+            LONGLONG timeleft = update_timeout( *end );
+
+#ifdef HAVE_PPOLL
+            /* We use ppoll() if available since the time granularity is better. */
+            struct timespec tmo_p;
+            tmo_p.tv_sec = timeleft / (ULONGLONG)TICKSPERSEC;
+            tmo_p.tv_nsec = (timeleft % TICKSPERSEC) * 100;
+            ret = ppoll( fds, nfds, &tmo_p, NULL );
+#else
+            ret = poll( fds, nfds, timeleft / TICKSPERMSEC );
+#endif
+        }
+        else
+            ret = poll( fds, nfds, -1 );
+
+    /* If we receive EINTR we were probably suspended (SIGUSR1), possibly for a
+     * system APC. The right thing to do is just try again. */
+    } while (ret < 0 && errno == EINTR);
+
+    return ret;
+}
+
+/* Return TRUE if abandoned. */
+static BOOL update_grabbed_object( struct esync *obj )
+{
+    BOOL ret = FALSE;
+
+    if (obj->type == ESYNC_MUTEX)
+    {
+        struct mutex *mutex = obj->shm;
+        /* We don't have to worry about a race between this and read(); the
+         * fact that we grabbed it means the count is now zero, so nobody else
+         * can (and the only thread that can release it is us). */
+        if (mutex->tid == ~0)
+            ret = TRUE;
+        mutex->tid = GetCurrentThreadId();
+        mutex->count++;
+    }
+    else if (obj->type == ESYNC_SEMAPHORE)
+    {
+        struct semaphore *semaphore = obj->shm;
+        /* We don't have to worry about a race between this and read(); the
+         * fact that we were able to grab it at all means the count is nonzero,
+         * and if someone else grabbed it then the count must have been >= 2,
+         * etc. */
+        InterlockedExchangeAdd( &semaphore->count, -1 );
+    }
+    else if (obj->type == ESYNC_AUTO_EVENT)
+    {
+        struct event *event = obj->shm;
+        /* We don't have to worry about a race between this and read(), since
+         * this is just a hint, and the real state is in the kernel object.
+         * This might already be 0, but that's okay! */
+        event->signaled = 0;
+    }
+
+    return ret;
+}
+
+/* A value of STATUS_NOT_IMPLEMENTED returned from this function means that we
+ * need to delegate to server_select(). */
+static NTSTATUS __esync_wait_objects( unsigned int count, const HANDLE *handles, BOOLEAN wait_any,
+                             BOOLEAN alertable, const LARGE_INTEGER *timeout )
+{
+    static const LARGE_INTEGER zero;
+
+    struct esync *objs[MAXIMUM_WAIT_OBJECTS];
+    struct pollfd fds[MAXIMUM_WAIT_OBJECTS + 1];
+    int has_esync = 0, has_server = 0;
+    BOOL msgwait = FALSE;
+    LONGLONG timeleft;
+    LARGE_INTEGER now;
+    DWORD pollcount;
+    ULONGLONG end;
+    int64_t value;
+    ssize_t size;
+    int i, j, ret;
+
+    /* Grab the APC fd if we don't already have it. */
+    if (alertable && ntdll_get_thread_data()->esync_apc_fd == -1)
+    {
+        obj_handle_t fd_handle;
+        sigset_t sigset;
+        int fd = -1;
+
+        server_enter_uninterrupted_section( &fd_cache_mutex, &sigset );
+        SERVER_START_REQ( get_esync_apc_fd )
+        {
+            if (!(ret = wine_server_call( req )))
+            {
+                fd = receive_fd( &fd_handle );
+                assert( fd_handle == GetCurrentThreadId() );
+            }
+        }
+        SERVER_END_REQ;
+        server_leave_uninterrupted_section( &fd_cache_mutex, &sigset );
+
+        ntdll_get_thread_data()->esync_apc_fd = fd;
+    }
+
+    NtQuerySystemTime( &now );
+    if (timeout)
+    {
+        if (timeout->QuadPart == TIMEOUT_INFINITE)
+            timeout = NULL;
+        else if (timeout->QuadPart >= 0)
+            end = timeout->QuadPart;
+        else
+            end = now.QuadPart - timeout->QuadPart;
+    }
+
+    for (i = 0; i < count; i++)
+    {
+        ret = get_object( handles[i], &objs[i] );
+        if (ret == STATUS_SUCCESS)
+            has_esync = 1;
+        else if (ret == STATUS_NOT_IMPLEMENTED)
+            has_server = 1;
+        else
+            return ret;
+    }
+
+    if (objs[count - 1] && objs[count - 1]->type == ESYNC_QUEUE)
+        msgwait = TRUE;
+
+    if (has_esync && has_server)
+        FIXME("Can't wait on esync and server objects at the same time!\n");
+    else if (has_server)
+        return STATUS_NOT_IMPLEMENTED;
+
+    if (TRACE_ON(esync))
+    {
+        TRACE("Waiting for %s of %d handles:", wait_any ? "any" : "all", count);
+        for (i = 0; i < count; i++)
+            TRACE(" %p", handles[i]);
+
+        if (msgwait)
+            TRACE(" or driver events");
+        if (alertable)
+            TRACE(", alertable");
+
+        if (!timeout)
+            TRACE(", timeout = INFINITE.\n");
+        else
+        {
+            timeleft = update_timeout( end );
+            TRACE(", timeout = %ld.%07ld sec.\n",
+                (long) timeleft / TICKSPERSEC, (long) timeleft % TICKSPERSEC);
+        }
+    }
+
+    if (wait_any || count == 1)
+    {
+        /* Try to check objects now, so we can obviate poll() at least. */
+        for (i = 0; i < count; i++)
+        {
+            struct esync *obj = objs[i];
+
+            if (obj)
+            {
+                switch (obj->type)
+                {
+                case ESYNC_MUTEX:
+                {
+                    struct mutex *mutex = obj->shm;
+
+                    if (mutex->tid == GetCurrentThreadId())
+                    {
+                        TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                        mutex->count++;
+                        return i;
+                    }
+                    else if (!mutex->count)
+                    {
+                        if ((size = read( obj->fd, &value, sizeof(value) )) == sizeof(value))
+                        {
+                            if (mutex->tid == ~0)
+                            {
+                                TRACE("Woken up by abandoned mutex %p [%d].\n", handles[i], i);
+                                i += STATUS_ABANDONED_WAIT_0;
+                            }
+                            else
+                                TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                            mutex->tid = GetCurrentThreadId();
+                            mutex->count++;
+                            return i;
+                        }
+                    }
+                    break;
+                }
+                case ESYNC_SEMAPHORE:
+                {
+                    struct semaphore *semaphore = obj->shm;
+
+                    if (semaphore->count)
+                    {
+                        if ((size = read( obj->fd, &value, sizeof(value) )) == sizeof(value))
+                        {
+                            TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                            InterlockedDecrement( &semaphore->count );
+                            return i;
+                        }
+                    }
+                    break;
+                }
+                case ESYNC_AUTO_EVENT:
+                {
+                    struct event *event = obj->shm;
+
+                    if (event->signaled)
+                    {
+                        if ((size = read( obj->fd, &value, sizeof(value) )) == sizeof(value))
+                        {
+                            TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                            event->signaled = 0;
+                            return i;
+                        }
+                    }
+                    break;
+                }
+                case ESYNC_MANUAL_EVENT:
+                {
+                    struct event *event = obj->shm;
+
+                    if (event->signaled)
+                    {
+                        TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                        return i;
+                    }
+                    break;
+                }
+                case ESYNC_AUTO_SERVER:
+                case ESYNC_MANUAL_SERVER:
+                case ESYNC_QUEUE:
+                    /* We can't wait on any of these. Fortunately I don't think
+                     * they'll ever be uncontended anyway (at least, they won't be
+                     * performance-critical). */
+                    break;
+                }
+            }
+
+            fds[i].fd = obj ? obj->fd : -1;
+            fds[i].events = POLLIN;
+        }
+        if (alertable)
+        {
+            fds[i].fd = ntdll_get_thread_data()->esync_apc_fd;
+            fds[i].events = POLLIN;
+            i++;
+        }
+        pollcount = i;
+
+        while (1)
+        {
+            ret = do_poll( fds, pollcount, timeout ? &end : NULL );
+            if (ret > 0)
+            {
+                /* We must check this first! The server may set an event that
+                 * we're waiting on, but we need to return STATUS_USER_APC. */
+                if (alertable)
+                {
+                    if (fds[pollcount - 1].revents & POLLIN)
+                        goto userapc;
+                }
+
+                /* Find out which object triggered the wait. */
+                for (i = 0; i < count; i++)
+                {
+                    struct esync *obj = objs[i];
+
+                    if (fds[i].revents & (POLLERR | POLLHUP | POLLNVAL))
+                    {
+                        ERR("Polling on fd %d returned %#x.\n", fds[i].fd, fds[i].revents);
+                        return STATUS_INVALID_HANDLE;
+                    }
+
+                    if (obj)
+                    {
+                        if (obj->type == ESYNC_MANUAL_EVENT
+                                || obj->type == ESYNC_MANUAL_SERVER
+                                || obj->type == ESYNC_QUEUE)
+                        {
+                            /* Don't grab the object, just check if it's signaled. */
+                            if (fds[i].revents & POLLIN)
+                            {
+                                TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                                return i;
+                            }
+                        }
+                        else
+                        {
+                            if ((size = read( fds[i].fd, &value, sizeof(value) )) == sizeof(value))
+                            {
+                                /* We found our object. */
+                                TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                                if (update_grabbed_object( obj ))
+                                    return STATUS_ABANDONED_WAIT_0 + i;
+                                return i;
+                            }
+                        }
+                    }
+                }
+
+                /* If we got here, someone else stole (or reset, etc.) whatever
+                 * we were waiting for. So keep waiting. */
+                NtQuerySystemTime( &now );
+            }
+            else
+                goto err;
+        }
+    }
+    else
+    {
+        /* Wait-all is a little trickier to implement correctly. Fortunately,
+         * it's not as common.
+         *
+         * The idea is basically just to wait in sequence on every object in the
+         * set. Then when we're done, try to grab them all in a tight loop. If
+         * that fails, release any resources we've grabbed (and yes, we can
+         * reliably do this—it's just mutexes and semaphores that we have to
+         * put back, and in both cases we just put back 1), and if any of that
+         * fails we start over.
+         *
+         * What makes this inherently bad is that we might temporarily grab a
+         * resource incorrectly. Hopefully it'll be quick (and hey, it won't
+         * block on wineserver) so nobody will notice. Besides, consider: if
+         * object A becomes signaled but someone grabs it before we can grab it
+         * and everything else, then they could just as well have grabbed it
+         * before it became signaled. Similarly if object A was signaled and we
+         * were blocking on object B, then B becomes available and someone grabs
+         * A before we can, then they might have grabbed A before B became
+         * signaled. In either case anyone who tries to wait on A or B will be
+         * waiting for an instant while we put things back. */
+
+        while (1)
+        {
+tryagain:
+            /* First step: try to poll on each object in sequence. */
+            fds[0].events = POLLIN;
+            pollcount = 1;
+            if (alertable)
+            {
+                /* We also need to wait on APCs. */
+                fds[1].fd = ntdll_get_thread_data()->esync_apc_fd;
+                fds[1].events = POLLIN;
+                pollcount++;
+            }
+            for (i = 0; i < count; i++)
+            {
+                struct esync *obj = objs[i];
+
+                fds[0].fd = obj ? obj->fd : -1;
+
+                if (obj && obj->type == ESYNC_MUTEX)
+                {
+                    /* It might be ours. */
+                    struct mutex *mutex = obj->shm;
+
+                    if (mutex->tid == GetCurrentThreadId())
+                        continue;
+                }
+
+                ret = do_poll( fds, pollcount, timeout ? &end : NULL );
+                if (ret <= 0)
+                    goto err;
+                else if (alertable && (fds[1].revents & POLLIN))
+                    goto userapc;
+
+                if (fds[0].revents & (POLLHUP | POLLERR | POLLNVAL))
+                {
+                    ERR("Polling on fd %d returned %#x.\n", fds[0].fd, fds[0].revents);
+                    return STATUS_INVALID_HANDLE;
+                }
+            }
+
+            /* If we got here and we haven't timed out, that means all of the
+             * handles were signaled. Check to make sure they still are. */
+            for (i = 0; i < count; i++)
+            {
+                fds[i].fd = objs[i] ? objs[i]->fd : -1;
+                fds[i].events = POLLIN;
+            }
+            /* There's no reason to check for APCs here. */
+            pollcount = i;
+
+            /* Poll everything to see if they're still signaled. */
+            ret = poll( fds, pollcount, 0 );
+            if (ret == pollcount)
+            {
+                BOOL abandoned = FALSE;
+
+                /* Quick, grab everything. */
+                for (i = 0; i < count; i++)
+                {
+                    struct esync *obj = objs[i];
+
+                    switch (obj->type)
+                    {
+                    case ESYNC_MUTEX:
+                    {
+                        struct mutex *mutex = obj->shm;
+                        if (mutex->tid == GetCurrentThreadId())
+                            break;
+                        /* otherwise fall through */
+                    }
+                    case ESYNC_SEMAPHORE:
+                    case ESYNC_AUTO_EVENT:
+                        if ((size = read( fds[i].fd, &value, sizeof(value) )) != sizeof(value))
+                        {
+                            /* We were too slow. Put everything back. */
+                            value = 1;
+                            for (j = i; j >= 0; j--)
+                            {
+                                if (write( obj->fd, &value, sizeof(value) ) == -1)
+                                    return errno_to_status( errno );
+                            }
+
+                            goto tryagain;  /* break out of two loops and a switch */
+                        }
+                        break;
+                    default:
+                        /* If a manual-reset event changed between there and
+                         * here, it's shouldn't be a problem. */
+                        break;
+                    }
+                }
+
+                /* If we got here, we successfully waited on every object. */
+                /* Make sure to let ourselves know that we grabbed the mutexes
+                 * and semaphores. */
+                for (i = 0; i < count; i++)
+                    abandoned |= update_grabbed_object( objs[i] );
+
+                if (abandoned)
+                {
+                    TRACE("Wait successful, but some object(s) were abandoned.\n");
+                    return STATUS_ABANDONED;
+                }
+                TRACE("Wait successful.\n");
+                return STATUS_SUCCESS;
+            }
+
+            /* If we got here, ppoll() returned less than all of our objects.
+             * So loop back to the beginning and try again. */
+        } /* while(1) */
+    } /* else (wait-all) */
+
+err:
+    /* We should only get here if poll() failed. */
+
+    if (ret == 0)
+    {
+        TRACE("Wait timed out.\n");
+        return STATUS_TIMEOUT;
+    }
+    else
+    {
+        ERR("ppoll failed: %s\n", strerror(errno));
+        return errno_to_status( errno );
+    }
+
+userapc:
+    TRACE("Woken up by user APC.\n");
+
+    /* We have to make a server call anyway to get the APC to execute, so just
+     * delegate down to server_select(). */
+    ret = server_wait( NULL, 0, SELECT_INTERRUPTIBLE | SELECT_ALERTABLE, &zero );
+
+    /* This can happen if we received a system APC, and the APC fd was woken up
+     * before we got SIGUSR1. poll() doesn't return EINTR in that case. The
+     * right thing to do seems to be to return STATUS_USER_APC anyway. */
+    if (ret == STATUS_TIMEOUT) ret = STATUS_USER_APC;
+    return ret;
+}
+
+/* We need to let the server know when we are doing a message wait, and when we
+ * are done with one, so that all of the code surrounding hung queues works.
+ * We also need this for WaitForInputIdle(). */
+static void server_set_msgwait( int in_msgwait )
+{
+    SERVER_START_REQ( esync_msgwait )
+    {
+        req->in_msgwait = in_msgwait;
+        wine_server_call( req );
+    }
+    SERVER_END_REQ;
+}
+
+/* This is a very thin wrapper around the proper implementation above. The
+ * purpose is to make sure the server knows when we are doing a message wait.
+ * This is separated into a wrapper function since there are at least a dozen
+ * exit paths from esync_wait_objects(). */
+NTSTATUS esync_wait_objects( DWORD count, const HANDLE *handles, BOOLEAN wait_any,
+                             BOOLEAN alertable, const LARGE_INTEGER *timeout )
+{
+    BOOL msgwait = FALSE;
+    struct esync *obj;
+    NTSTATUS ret;
+
+    if (count && !get_object( handles[count - 1], &obj ) && obj->type == ESYNC_QUEUE)
+    {
+        msgwait = TRUE;
+        server_set_msgwait( 1 );
+    }
+
+    ret = __esync_wait_objects( count, handles, wait_any, alertable, timeout );
+
+    if (msgwait)
+        server_set_msgwait( 0 );
+
+    return ret;
+}
+
+NTSTATUS esync_signal_and_wait( HANDLE signal, HANDLE wait, BOOLEAN alertable,
+    const LARGE_INTEGER *timeout )
+{
+    struct esync *obj;
+    NTSTATUS ret;
+
+    if ((ret = get_object( signal, &obj ))) return ret;
+
+    switch (obj->type)
+    {
+    case ESYNC_SEMAPHORE:
+        ret = esync_release_semaphore( signal, 1, NULL );
+        break;
+    case ESYNC_AUTO_EVENT:
+    case ESYNC_MANUAL_EVENT:
+        ret = esync_set_event( signal );
+        break;
+    case ESYNC_MUTEX:
+        ret = esync_release_mutex( signal, NULL );
+        break;
+    default:
+        return STATUS_OBJECT_TYPE_MISMATCH;
+    }
+    if (ret) return ret;
+
+    return esync_wait_objects( 1, &wait, TRUE, alertable, timeout );
+}
+
+void esync_init(void)
+{
+    struct stat st;
+
+    if (!do_esync())
+    {
+        /* make sure the server isn't running with WINEESYNC */
+        HANDLE handle;
+        NTSTATUS ret;
+
+        ret = create_esync( 0, &handle, 0, NULL, 0, 0 );
+        if (ret != STATUS_NOT_IMPLEMENTED)
+        {
+            ERR("Server is running with WINEESYNC but this process is not, please enable WINEESYNC or restart wineserver.\n");
+            exit(1);
+        }
+
+        return;
+    }
+
+    if (stat( config_dir, &st ) == -1)
+        ERR("Cannot stat %s\n", config_dir);
+
+    if (st.st_ino != (unsigned long)st.st_ino)
+        sprintf( shm_name, "/wine-%lx%08lx-esync", (unsigned long)((unsigned long long)st.st_ino >> 32), (unsigned long)st.st_ino );
+    else
+        sprintf( shm_name, "/wine-%lx-esync", (unsigned long)st.st_ino );
+
+    if ((shm_fd = shm_open( shm_name, O_RDWR, 0644 )) == -1)
+    {
+        /* probably the server isn't running with WINEESYNC, tell the user and bail */
+        if (errno == ENOENT)
+            ERR("Failed to open esync shared memory file; make sure no stale wineserver instances are running without WINEESYNC.\n");
+        else
+            ERR("Failed to initialize shared memory: %s\n", strerror( errno ));
+        exit(1);
+    }
+
+    pagesize = sysconf( _SC_PAGESIZE );
+
+    shm_addrs = calloc( 128, sizeof(shm_addrs[0]) );
+    shm_addrs_size = 128;
+}
diff -ruN --show-c-function --no-dereference dlls/ntdll/unix/esync.h dlls/ntdll/unix/esync.h
--- dlls/ntdll/unix/esync.h	1969-12-31 16:00:00.000000000 -0800
+++ dlls/ntdll/unix/esync.h	2025-09-06 19:58:17.788165916 -0700
@@ -0,0 +1,61 @@
+/*
+ * eventfd-based synchronization objects
+ *
+ * Copyright (C) 2018 Zebediah Figura
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
+ */
+
+extern int do_esync(void);
+extern void esync_init(void);
+extern NTSTATUS esync_close( HANDLE handle );
+
+extern NTSTATUS esync_create_semaphore(HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr, int initial, int max);
+extern NTSTATUS esync_open_semaphore( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr );
+extern NTSTATUS esync_query_semaphore( HANDLE handle, void *info, ULONG *ret_len );
+extern NTSTATUS esync_release_semaphore( HANDLE handle, unsigned int count, ULONG *prev );
+
+extern NTSTATUS esync_create_event( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr, EVENT_TYPE type, BOOLEAN initial );
+extern NTSTATUS esync_open_event( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr );
+extern NTSTATUS esync_pulse_event( HANDLE handle );
+extern NTSTATUS esync_query_event( HANDLE handle, void *info, ULONG *ret_len );
+extern NTSTATUS esync_reset_event( HANDLE handle );
+extern NTSTATUS esync_set_event( HANDLE handle );
+
+extern NTSTATUS esync_create_mutex( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr, BOOLEAN initial );
+extern NTSTATUS esync_open_mutex( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr );
+extern NTSTATUS esync_query_mutex( HANDLE handle, void *info, ULONG *ret_len );
+extern NTSTATUS esync_release_mutex( HANDLE *handle, LONG *prev );
+
+extern NTSTATUS esync_wait_objects( DWORD count, const HANDLE *handles, BOOLEAN wait_any,
+                                    BOOLEAN alertable, const LARGE_INTEGER *timeout );
+extern NTSTATUS esync_signal_and_wait( HANDLE signal, HANDLE wait, BOOLEAN alertable,
+    const LARGE_INTEGER *timeout );
+
+
+/* We have to synchronize on the fd cache mutex so that our calls to receive_fd
+ * don't race with theirs. It looks weird, I know.
+ *
+ * If we weren't trying to avoid touching the code I'd rename the mutex to
+ * "server_fd_mutex" or something similar. */
+extern pthread_mutex_t fd_cache_mutex;
+
+extern int receive_fd( obj_handle_t *handle );
diff -ruN --show-c-function --no-dereference dlls/ntdll/unix/loader.c dlls/ntdll/unix/loader.c
--- dlls/ntdll/unix/loader.c	2025-09-06 20:10:25.390489988 -0700
+++ dlls/ntdll/unix/loader.c	2025-09-06 19:58:17.758141981 -0700
@@ -90,6 +90,7 @@
 #include "winioctl.h"
 #include "winternl.h"
 #include "unix_private.h"
+#include "esync.h"
 #include "wine/list.h"
 #include "ntsyscalls.h"
 #include "wine/debug.h"
@@ -1920,6 +1921,7 @@ static void start_main_thread(void)
     signal_alloc_thread( teb );
     dbg_init();
     startup_info_size = server_init_process();
+    esync_init();
     virtual_map_user_shared_data();
     init_cpu_info();
     init_files();
diff -ruN --show-c-function --no-dereference dlls/ntdll/unix/server.c dlls/ntdll/unix/server.c
--- dlls/ntdll/unix/server.c	2025-09-06 20:10:25.390489988 -0700
+++ dlls/ntdll/unix/server.c	2025-09-06 19:58:17.760204436 -0700
@@ -79,6 +79,7 @@
 #include "wine/server.h"
 #include "wine/debug.h"
 #include "unix_private.h"
+#include "esync.h"
 #include "ddk/wdm.h"
 
 WINE_DEFAULT_DEBUG_CHANNEL(server);
@@ -961,7 +962,7 @@ void wine_server_send_fd( int fd )
  *
  * Receive a file descriptor passed from the server.
  */
-int wine_server_receive_fd( obj_handle_t *handle )
+int receive_fd( obj_handle_t *handle )
 {
     struct iovec vec;
     struct msghdr msghdr;
@@ -1156,7 +1157,7 @@ int server_get_unix_fd( HANDLE handle, u
                 if (type) *type = reply->type;
                 if (options) *options = reply->options;
                 access = reply->access;
-                if ((fd = wine_server_receive_fd( &fd_handle )) != -1)
+                if ((fd = receive_fd( &fd_handle )) != -1)
                 {
                     assert( wine_server_ptr_handle(fd_handle) == handle );
                     *needs_close = (!reply->cacheable ||
@@ -1570,7 +1571,6 @@ size_t server_init_process(void)
 {
     const char *arch = getenv( "WINEARCH" );
     const char *env_socket = getenv( "WINESERVERSOCKET" );
-    struct ntdll_thread_data *data = ntdll_get_thread_data();
     obj_handle_t version;
     unsigned int i;
     int ret, reply_pipe;
@@ -1610,7 +1610,7 @@ size_t server_init_process(void)
     pthread_sigmask( SIG_BLOCK, &server_block_set, NULL );
 
     /* receive the first thread request fd on the main socket */
-    data->request_fd = wine_server_receive_fd( &version );
+    ntdll_get_thread_data()->request_fd = receive_fd( &version );
 
 #ifdef SO_PASSCRED
     /* now that we hopefully received the server_pid, disable SO_PASSCRED */
@@ -1645,24 +1645,16 @@ size_t server_init_process(void)
         req->unix_pid    = getpid();
         req->unix_tid    = get_unix_tid();
         req->reply_fd    = reply_pipe;
-        req->wait_fd     = data->wait_fd[1];
+        req->wait_fd     = ntdll_get_thread_data()->wait_fd[1];
         req->debug_level = (TRACE_ON(server) != 0);
         wine_server_set_reply( req, supported_machines, sizeof(supported_machines) );
-        if (!(ret = wine_server_call( req )))
-        {
-            obj_handle_t handle;
-            pid               = reply->pid;
-            tid               = reply->tid;
-            peb->SessionId    = reply->session_id;
-            info_size         = reply->info_size;
-            server_start_time = reply->server_start;
-            supported_machines_count = wine_server_reply_size( reply ) / sizeof(*supported_machines);
-            if (reply->inproc_device)
-            {
-                inproc_device_fd = wine_server_receive_fd( &handle );
-                assert( handle == reply->inproc_device );
-            }
-        }
+        ret = wine_server_call( req );
+        pid               = reply->pid;
+        tid               = reply->tid;
+        peb->SessionId    = reply->session_id;
+        info_size         = reply->info_size;
+        server_start_time = reply->server_start;
+        supported_machines_count = wine_server_reply_size( reply ) / sizeof(*supported_machines);
     }
     SERVER_END_REQ;
     close( reply_pipe );
@@ -1911,6 +1903,9 @@ NTSTATUS WINAPI NtClose( HANDLE handle )
      * retrieve it again */
     fd = remove_fd_from_cache( handle );
 
+    if (do_esync())
+        esync_close( handle );
+
     SERVER_START_REQ( close_handle )
     {
         req->handle = wine_server_obj_handle( handle );
diff -ruN --show-c-function --no-dereference dlls/ntdll/unix/sync.c dlls/ntdll/unix/sync.c
--- dlls/ntdll/unix/sync.c	2025-09-06 20:10:25.391490023 -0700
+++ dlls/ntdll/unix/sync.c	2025-09-06 19:58:17.786102448 -0700
@@ -57,9 +57,6 @@
 #ifdef HAVE_KQUEUE
 # include <sys/event.h>
 #endif
-#ifdef HAVE_LINUX_NTSYNC_H
-# include <linux/ntsync.h>
-#endif
 
 #include "ntstatus.h"
 #define WIN32_NO_STATUS
@@ -69,20 +66,18 @@
 #include "wine/server.h"
 #include "wine/debug.h"
 #include "unix_private.h"
+#include "esync.h"
 
 WINE_DEFAULT_DEBUG_CHANNEL(sync);
 
 HANDLE keyed_event = 0;
-int inproc_device_fd = -1;
 
 static const char *debugstr_timeout( const LARGE_INTEGER *timeout )
 {
     if (!timeout) return "(infinite)";
-    return wine_dbg_sprintf( "%lld.%07ld", (long long)(timeout->QuadPart / TICKSPERSEC),
-                             (long)(timeout->QuadPart % TICKSPERSEC) );
+    return wine_dbgstr_longlong( timeout->QuadPart );
 }
 
-
 /* return a monotonic time counter, in Win32 ticks */
 static inline ULONGLONG monotonic_counter(void)
 {
@@ -307,133 +302,6 @@ static unsigned int validate_open_object
 }
 
 
-struct inproc_sync
-{
-    int fd;
-    unsigned int access;
-    unsigned int type : 2;
-};
-
-static void release_inproc_sync( struct inproc_sync *sync )
-{
-    close( sync->fd );
-}
-
-static NTSTATUS get_inproc_sync( HANDLE handle, ACCESS_MASK desired_access, struct inproc_sync *sync )
-{
-    sigset_t sigset;
-    NTSTATUS ret;
-
-    /* We need to use fd_cache_mutex here to protect against races with
-     * other threads trying to receive fds for the fd cache,
-     * and we need to use an uninterrupted section to prevent reentrancy. */
-    server_enter_uninterrupted_section( &fd_cache_mutex, &sigset );
-
-    SERVER_START_REQ( get_inproc_sync_fd )
-    {
-        req->handle = wine_server_obj_handle( handle );
-        if (!(ret = wine_server_call( req )))
-        {
-            obj_handle_t fd_handle;
-            sync->fd = wine_server_receive_fd( &fd_handle );
-            assert( wine_server_ptr_handle(fd_handle) == handle );
-            sync->access = reply->access;
-            sync->type = reply->type;
-        }
-    }
-    SERVER_END_REQ;
-
-    server_leave_uninterrupted_section( &fd_cache_mutex, &sigset );
-
-    if (ret) return ret;
-    if ((sync->access & desired_access) != desired_access)
-    {
-        release_inproc_sync( sync );
-        return STATUS_ACCESS_DENIED;
-    }
-
-    return STATUS_SUCCESS;
-}
-
-static NTSTATUS inproc_release_semaphore( HANDLE handle, ULONG count, ULONG *prev_count )
-{
-    if (inproc_device_fd < 0) return STATUS_NOT_IMPLEMENTED;
-    return STATUS_NOT_IMPLEMENTED;
-}
-
-static NTSTATUS inproc_query_semaphore( HANDLE handle, SEMAPHORE_BASIC_INFORMATION *info )
-{
-    if (inproc_device_fd < 0) return STATUS_NOT_IMPLEMENTED;
-    return STATUS_NOT_IMPLEMENTED;
-}
-
-static NTSTATUS inproc_set_event( HANDLE handle, LONG *prev_state )
-{
-    if (inproc_device_fd < 0) return STATUS_NOT_IMPLEMENTED;
-    return STATUS_NOT_IMPLEMENTED;
-}
-
-static NTSTATUS inproc_reset_event( HANDLE handle, LONG *prev_state )
-{
-    if (inproc_device_fd < 0) return STATUS_NOT_IMPLEMENTED;
-    return STATUS_NOT_IMPLEMENTED;
-}
-
-static NTSTATUS inproc_pulse_event( HANDLE handle, LONG *prev_state )
-{
-    if (inproc_device_fd < 0) return STATUS_NOT_IMPLEMENTED;
-    return STATUS_NOT_IMPLEMENTED;
-}
-
-static NTSTATUS inproc_query_event( HANDLE handle, EVENT_BASIC_INFORMATION *info )
-{
-    if (inproc_device_fd < 0) return STATUS_NOT_IMPLEMENTED;
-    return STATUS_NOT_IMPLEMENTED;
-}
-
-static NTSTATUS inproc_release_mutex( HANDLE handle, LONG *prev_count )
-{
-    if (inproc_device_fd < 0) return STATUS_NOT_IMPLEMENTED;
-    return STATUS_NOT_IMPLEMENTED;
-}
-
-static NTSTATUS inproc_query_mutex( HANDLE handle, MUTANT_BASIC_INFORMATION *info )
-{
-    if (inproc_device_fd < 0) return STATUS_NOT_IMPLEMENTED;
-    return STATUS_NOT_IMPLEMENTED;
-}
-
-static NTSTATUS inproc_wait( DWORD count, const HANDLE *handles, BOOLEAN wait_any,
-                             BOOLEAN alertable, const LARGE_INTEGER *timeout )
-{
-    struct inproc_sync *syncs[64], stack[ARRAY_SIZE(syncs)];
-    NTSTATUS ret;
-
-    if (inproc_device_fd < 0) return STATUS_NOT_IMPLEMENTED;
-
-    assert( count <= ARRAY_SIZE(syncs) );
-    for (int i = 0; i < count; ++i)
-    {
-        if ((ret = get_inproc_sync( handles[i], SYNCHRONIZE, stack + i )))
-        {
-            while (i--) release_inproc_sync( syncs[i] );
-            return ret;
-        }
-        syncs[i] = stack + i;
-    }
-
-    while (count--) release_inproc_sync( syncs[count] );
-    return STATUS_NOT_IMPLEMENTED;
-}
-
-static NTSTATUS inproc_signal_and_wait( HANDLE signal, HANDLE wait,
-                                        BOOLEAN alertable, const LARGE_INTEGER *timeout )
-{
-    if (inproc_device_fd < 0) return STATUS_NOT_IMPLEMENTED;
-    return STATUS_NOT_IMPLEMENTED;
-}
-
-
 /******************************************************************************
  *              NtCreateSemaphore (NTDLL.@)
  */
@@ -444,13 +312,13 @@ NTSTATUS WINAPI NtCreateSemaphore( HANDL
     data_size_t len;
     struct object_attributes *objattr;
 
-    TRACE( "access %#x, name %s, initial %d, max %d\n", access,
-           attr ? debugstr_us(attr->ObjectName) : "(null)", initial, max );
-
     *handle = 0;
     if (max <= 0 || initial < 0 || initial > max) return STATUS_INVALID_PARAMETER;
     if ((ret = alloc_object_attributes( attr, &objattr, &len ))) return ret;
 
+    if (do_esync())
+        return esync_create_semaphore( handle, access, attr, initial, max );
+
     SERVER_START_REQ( create_semaphore )
     {
         req->access  = access;
@@ -474,9 +342,11 @@ NTSTATUS WINAPI NtOpenSemaphore( HANDLE
 {
     unsigned int ret;
 
-    TRACE( "access %#x, name %s\n", access, attr ? debugstr_us(attr->ObjectName) : "(null)" );
-
     *handle = 0;
+
+    if (do_esync())
+        return esync_open_semaphore( handle, access, attr );
+
     if ((ret = validate_open_object_attributes( attr ))) return ret;
 
     SERVER_START_REQ( open_semaphore )
@@ -513,11 +383,8 @@ NTSTATUS WINAPI NtQuerySemaphore( HANDLE
 
     if (len != sizeof(SEMAPHORE_BASIC_INFORMATION)) return STATUS_INFO_LENGTH_MISMATCH;
 
-    if ((ret = inproc_query_semaphore( handle, out )) != STATUS_NOT_IMPLEMENTED)
-    {
-        if (!ret && ret_len) *ret_len = sizeof(SEMAPHORE_BASIC_INFORMATION);
-        return ret;
-    }
+    if (do_esync())
+        return esync_query_semaphore( handle, info, ret_len );
 
     SERVER_START_REQ( query_semaphore )
     {
@@ -541,10 +408,8 @@ NTSTATUS WINAPI NtReleaseSemaphore( HAND
 {
     unsigned int ret;
 
-    TRACE( "handle %p, count %u, prev_count %p\n", handle, count, previous );
-
-    if ((ret = inproc_release_semaphore( handle, count, previous )) != STATUS_NOT_IMPLEMENTED)
-        return ret;
+    if (do_esync())
+        return esync_release_semaphore( handle, count, previous );
 
     SERVER_START_REQ( release_semaphore )
     {
@@ -570,11 +435,12 @@ NTSTATUS WINAPI NtCreateEvent( HANDLE *h
     data_size_t len;
     struct object_attributes *objattr;
 
-    TRACE( "access %#x, name %s, type %u, state %u\n", access,
-           attr ? debugstr_us(attr->ObjectName) : "(null)", type, state );
-
     *handle = 0;
     if (type != NotificationEvent && type != SynchronizationEvent) return STATUS_INVALID_PARAMETER;
+
+    if (do_esync())
+        return esync_create_event( handle, access, attr, type, state );
+
     if ((ret = alloc_object_attributes( attr, &objattr, &len ))) return ret;
 
     SERVER_START_REQ( create_event )
@@ -600,11 +466,12 @@ NTSTATUS WINAPI NtOpenEvent( HANDLE *han
 {
     unsigned int ret;
 
-    TRACE( "access %#x, name %s\n", access, attr ? debugstr_us(attr->ObjectName) : "(null)" );
-
     *handle = 0;
     if ((ret = validate_open_object_attributes( attr ))) return ret;
 
+    if (do_esync())
+        return esync_open_event( handle, access, attr );
+
     SERVER_START_REQ( open_event )
     {
         req->access     = access;
@@ -625,12 +492,11 @@ NTSTATUS WINAPI NtOpenEvent( HANDLE *han
  */
 NTSTATUS WINAPI NtSetEvent( HANDLE handle, LONG *prev_state )
 {
+    /* This comment is a dummy to make sure this patch applies in the right place. */
     unsigned int ret;
 
-    TRACE( "handle %p, prev_state %p\n", handle, prev_state );
-
-    if ((ret = inproc_set_event( handle, prev_state )) != STATUS_NOT_IMPLEMENTED)
-        return ret;
+    if (do_esync())
+        return esync_set_event( handle );
 
     SERVER_START_REQ( event_op )
     {
@@ -649,12 +515,12 @@ NTSTATUS WINAPI NtSetEvent( HANDLE handl
  */
 NTSTATUS WINAPI NtResetEvent( HANDLE handle, LONG *prev_state )
 {
+    /* This comment is a dummy to make sure this patch applies in the right place. */
     unsigned int ret;
 
-    TRACE( "handle %p, prev_state %p\n", handle, prev_state );
+    if (do_esync())
+        return esync_reset_event( handle );
 
-    if ((ret = inproc_reset_event( handle, prev_state )) != STATUS_NOT_IMPLEMENTED)
-        return ret;
 
     SERVER_START_REQ( event_op )
     {
@@ -685,10 +551,8 @@ NTSTATUS WINAPI NtPulseEvent( HANDLE han
 {
     unsigned int ret;
 
-    TRACE( "handle %p, prev_state %p\n", handle, prev_state );
-
-    if ((ret = inproc_pulse_event( handle, prev_state )) != STATUS_NOT_IMPLEMENTED)
-        return ret;
+    if (do_esync())
+        return esync_pulse_event( handle );
 
     SERVER_START_REQ( event_op )
     {
@@ -721,11 +585,8 @@ NTSTATUS WINAPI NtQueryEvent( HANDLE han
 
     if (len != sizeof(EVENT_BASIC_INFORMATION)) return STATUS_INFO_LENGTH_MISMATCH;
 
-    if ((ret = inproc_query_event( handle, out )) != STATUS_NOT_IMPLEMENTED)
-    {
-        if (!ret && ret_len) *ret_len = sizeof(EVENT_BASIC_INFORMATION);
-        return ret;
-    }
+    if (do_esync())
+        return esync_query_event( handle, info, ret_len );
 
     SERVER_START_REQ( query_event )
     {
@@ -752,10 +613,11 @@ NTSTATUS WINAPI NtCreateMutant( HANDLE *
     data_size_t len;
     struct object_attributes *objattr;
 
-    TRACE( "access %#x, name %s, owned %u\n", access,
-           attr ? debugstr_us(attr->ObjectName) : "(null)", owned );
-
     *handle = 0;
+
+    if (do_esync())
+        return esync_create_mutex( handle, access, attr, owned );
+
     if ((ret = alloc_object_attributes( attr, &objattr, &len ))) return ret;
 
     SERVER_START_REQ( create_mutex )
@@ -780,11 +642,12 @@ NTSTATUS WINAPI NtOpenMutant( HANDLE *ha
 {
     unsigned int ret;
 
-    TRACE( "access %#x, name %s\n", access, attr ? debugstr_us(attr->ObjectName) : "(null)" );
-
     *handle = 0;
     if ((ret = validate_open_object_attributes( attr ))) return ret;
 
+    if (do_esync())
+        return esync_open_mutex( handle, access, attr );
+
     SERVER_START_REQ( open_mutex )
     {
         req->access  = access;
@@ -807,10 +670,8 @@ NTSTATUS WINAPI NtReleaseMutant( HANDLE
 {
     unsigned int ret;
 
-    TRACE( "handle %p, prev_count %p\n", handle, prev_count );
-
-    if ((ret = inproc_release_mutex( handle, prev_count )) != STATUS_NOT_IMPLEMENTED)
-        return ret;
+    if (do_esync())
+        return esync_release_mutex( handle, prev_count );
 
     SERVER_START_REQ( release_mutex )
     {
@@ -842,11 +703,8 @@ NTSTATUS WINAPI NtQueryMutant( HANDLE ha
 
     if (len != sizeof(MUTANT_BASIC_INFORMATION)) return STATUS_INFO_LENGTH_MISMATCH;
 
-    if ((ret = inproc_query_mutex( handle, out )) != STATUS_NOT_IMPLEMENTED)
-    {
-        if (!ret && ret_len) *ret_len = sizeof(MUTANT_BASIC_INFORMATION);
-        return ret;
-    }
+    if (do_esync())
+        return esync_query_mutex( handle, info, ret_len );
 
     SERVER_START_REQ( query_mutex )
     {
@@ -1617,9 +1475,6 @@ NTSTATUS WINAPI NtCreateTimer( HANDLE *h
     data_size_t len;
     struct object_attributes *objattr;
 
-    TRACE( "access %#x, name %s, type %u\n", access,
-           attr ? debugstr_us(attr->ObjectName) : "(null)", type );
-
     *handle = 0;
     if (type != NotificationTimer && type != SynchronizationTimer) return STATUS_INVALID_PARAMETER;
     if ((ret = alloc_object_attributes( attr, &objattr, &len ))) return ret;
@@ -1647,8 +1502,6 @@ NTSTATUS WINAPI NtOpenTimer( HANDLE *han
 {
     unsigned int ret;
 
-    TRACE( "access %#x, name %s\n", access, attr ? debugstr_us(attr->ObjectName) : "(null)" );
-
     *handle = 0;
     if ((ret = validate_open_object_attributes( attr ))) return ret;
 
@@ -1702,8 +1555,6 @@ NTSTATUS WINAPI NtCancelTimer( HANDLE ha
 {
     unsigned int ret;
 
-    TRACE( "handle %p, state %p\n", handle, state );
-
     SERVER_START_REQ( cancel_timer )
     {
         req->handle = wine_server_obj_handle( handle );
@@ -1772,29 +1623,20 @@ NTSTATUS WINAPI NtWaitForMultipleObjects
 {
     union select_op select_op;
     UINT i, flags = SELECT_INTERRUPTIBLE;
-    unsigned int ret;
 
     if (!count || count > MAXIMUM_WAIT_OBJECTS) return STATUS_INVALID_PARAMETER_1;
 
-    if (TRACE_ON(sync))
+    if (do_esync())
     {
-        TRACE( "wait_any %u, alertable %u, handles {%p", wait_any, alertable, handles[0] );
-        for (i = 1; i < count; i++) TRACE( ", %p", handles[i] );
-        TRACE( "}, timeout %s\n", debugstr_timeout(timeout) );
-    }
-
-    if ((ret = inproc_wait( count, handles, wait_any, alertable, timeout )) != STATUS_NOT_IMPLEMENTED)
-    {
-        TRACE( "-> %#x\n", ret );
-        return ret;
+        NTSTATUS ret = esync_wait_objects( count, handles, wait_any, alertable, timeout );
+        if (ret != STATUS_NOT_IMPLEMENTED)
+            return ret;
     }
 
     if (alertable) flags |= SELECT_ALERTABLE;
     select_op.wait.op = wait_any ? SELECT_WAIT : SELECT_WAIT_ALL;
     for (i = 0; i < count; i++) select_op.wait.handles[i] = wine_server_obj_handle( handles[i] );
-    ret = server_wait( &select_op, offsetof( union select_op, wait.handles[count] ), flags, timeout );
-    TRACE( "-> %#x\n", ret );
-    return ret;
+    return server_wait( &select_op, offsetof( union select_op, wait.handles[count] ), flags, timeout );
 }
 
 
@@ -1815,15 +1657,12 @@ NTSTATUS WINAPI NtSignalAndWaitForSingle
 {
     union select_op select_op;
     UINT flags = SELECT_INTERRUPTIBLE;
-    NTSTATUS ret;
 
-    TRACE( "signal %p, wait %p, alertable %u, timeout %s\n", signal, wait, alertable, debugstr_timeout(timeout) );
+    if (do_esync())
+        return esync_signal_and_wait( signal, wait, alertable, timeout );
 
     if (!signal) return STATUS_INVALID_HANDLE;
 
-    if ((ret = inproc_signal_and_wait( signal, wait, alertable, timeout )) != STATUS_NOT_IMPLEMENTED)
-        return ret;
-
     if (alertable) flags |= SELECT_ALERTABLE;
     select_op.signal_and_wait.op = SELECT_SIGNAL_AND_WAIT;
     select_op.signal_and_wait.wait = wine_server_obj_handle( wait );
@@ -2066,9 +1905,6 @@ NTSTATUS WINAPI NtCreateKeyedEvent( HAND
     data_size_t len;
     struct object_attributes *objattr;
 
-    TRACE( "access %#x, name %s, flags %#x\n", access,
-           attr ? debugstr_us(attr->ObjectName) : "(null)", flags );
-
     *handle = 0;
     if ((ret = alloc_object_attributes( attr, &objattr, &len ))) return ret;
 
@@ -2093,8 +1929,6 @@ NTSTATUS WINAPI NtOpenKeyedEvent( HANDLE
 {
     unsigned int ret;
 
-    TRACE( "access %#x, name %s\n", access, attr ? debugstr_us(attr->ObjectName) : "(null)" );
-
     *handle = 0;
     if ((ret = validate_open_object_attributes( attr ))) return ret;
 
@@ -2121,8 +1955,6 @@ NTSTATUS WINAPI NtWaitForKeyedEvent( HAN
     union select_op select_op;
     UINT flags = SELECT_INTERRUPTIBLE;
 
-    TRACE( "handle %p, key %p, alertable %u, timeout %s\n", handle, key, alertable, debugstr_timeout(timeout) );
-
     if (!handle) handle = keyed_event;
     if ((ULONG_PTR)key & 1) return STATUS_INVALID_PARAMETER_1;
     if (alertable) flags |= SELECT_ALERTABLE;
@@ -2142,8 +1974,6 @@ NTSTATUS WINAPI NtReleaseKeyedEvent( HAN
     union select_op select_op;
     UINT flags = SELECT_INTERRUPTIBLE;
 
-    TRACE( "handle %p, key %p, alertable %u, timeout %s\n", handle, key, alertable, debugstr_timeout(timeout) );
-
     if (!handle) handle = keyed_event;
     if ((ULONG_PTR)key & 1) return STATUS_INVALID_PARAMETER_1;
     if (alertable) flags |= SELECT_ALERTABLE;
diff -ruN --show-c-function --no-dereference dlls/ntdll/unix/unix_private.h dlls/ntdll/unix/unix_private.h
--- dlls/ntdll/unix/unix_private.h	2025-09-06 20:10:25.392490058 -0700
+++ dlls/ntdll/unix/unix_private.h	2025-09-06 19:58:17.778900731 -0700
@@ -105,6 +105,7 @@ struct ntdll_thread_data
     SYSTEM_SERVICE_TABLE     *syscall_table; /* 214/0370 syscall table */
     struct syscall_frame     *syscall_frame; /* 218/0378 current syscall frame */
     int                       syscall_trace; /* 21c/0380 syscall trace flag */
+    int                       esync_apc_fd;  /* fd to wait on for user APCs */
     int                       request_fd;    /* fd for sending server requests */
     int                       reply_fd;      /* fd for receiving server replies */
     int                       wait_fd[2];    /* fd for sleeping server requests */
@@ -197,10 +198,8 @@ extern unsigned int supported_machines_c
 extern USHORT supported_machines[8];
 extern BOOL process_exiting;
 extern HANDLE keyed_event;
-extern int inproc_device_fd;
 extern timeout_t server_start_time;
 extern sigset_t server_block_set;
-extern pthread_mutex_t fd_cache_mutex;
 extern struct _KUSER_SHARED_DATA *user_shared_data;
 #ifdef __i386__
 extern struct ldt_copy __wine_ldt_copy;
@@ -235,7 +234,6 @@ extern unsigned int server_queue_process
 extern int server_get_unix_fd( HANDLE handle, unsigned int wanted_access, int *unix_fd,
                                int *needs_close, enum server_fd_type *type, unsigned int *options );
 extern void wine_server_send_fd( int fd );
-extern int wine_server_receive_fd( obj_handle_t *handle );
 extern void process_exit_wrapper( int status ) DECLSPEC_NORETURN;
 extern size_t server_init_process(void);
 extern void server_init_process_done(void);
diff -ruN --show-c-function --no-dereference dlls/ntdll/unix/virtual.c dlls/ntdll/unix/virtual.c
--- dlls/ntdll/unix/virtual.c	2025-09-06 20:10:25.392490058 -0700
+++ dlls/ntdll/unix/virtual.c	2025-09-06 19:58:17.779160726 -0700
@@ -4022,6 +4022,7 @@ static TEB *init_teb( void *ptr, BOOL is
     teb->StaticUnicodeString.Buffer = teb->StaticUnicodeBuffer;
     teb->StaticUnicodeString.MaximumLength = sizeof(teb->StaticUnicodeBuffer);
     thread_data = (struct ntdll_thread_data *)&teb->GdiTebBatch;
+    thread_data->esync_apc_fd = -1;
     thread_data->request_fd = -1;
     thread_data->reply_fd   = -1;
     thread_data->wait_fd[0] = -1;
diff -ruN --show-c-function --no-dereference dlls/rpcrt4/rpc_server.c dlls/rpcrt4/rpc_server.c
--- dlls/rpcrt4/rpc_server.c	2025-09-06 20:10:25.437491640 -0700
+++ dlls/rpcrt4/rpc_server.c	2025-09-06 19:58:17.772169009 -0700
@@ -701,10 +701,6 @@ static DWORD CALLBACK RPCRT4_server_thre
   }
   LeaveCriticalSection(&cps->cs);
 
-  EnterCriticalSection(&listen_cs);
-  CloseHandle(cps->server_thread);
-  cps->server_thread = NULL;
-  LeaveCriticalSection(&listen_cs);
   TRACE("done\n");
   return 0;
 }
@@ -1570,7 +1566,10 @@ RPC_STATUS WINAPI RpcMgmtWaitServerListe
       LIST_FOR_EACH_ENTRY(protseq, &protseqs, RpcServerProtseq, entry)
       {
           if ((wait_thread = protseq->server_thread))
+          {
+              protseq->server_thread = NULL;
               break;
+          }
       }
       LeaveCriticalSection(&server_cs);
       if (!wait_thread)
@@ -1579,6 +1578,7 @@ RPC_STATUS WINAPI RpcMgmtWaitServerListe
       TRACE("waiting for thread %lu\n", GetThreadId(wait_thread));
       LeaveCriticalSection(&listen_cs);
       WaitForSingleObject(wait_thread, INFINITE);
+      CloseHandle(wait_thread);
       EnterCriticalSection(&listen_cs);
   }
   if (listen_done_event == event)
diff -ruN --show-c-function --no-dereference include/config.h.in include/config.h.in
--- include/config.h.in	2025-09-06 20:10:36.772240877 -0700
+++ include/config.h.in	2025-09-06 19:58:25.135897398 -0700
@@ -198,9 +198,6 @@
 /* Define to 1 if you have the <linux/major.h> header file. */
 #undef HAVE_LINUX_MAJOR_H
 
-/* Define to 1 if you have the <linux/ntsync.h> header file. */
-#undef HAVE_LINUX_NTSYNC_H
-
 /* Define to 1 if you have the <linux/param.h> header file. */
 #undef HAVE_LINUX_PARAM_H
 
@@ -336,6 +333,9 @@
 /* Define to 1 if you have the 'posix_fallocate' function. */
 #undef HAVE_POSIX_FALLOCATE
 
+/* Define to 1 if you have the 'ppoll' function. */
+#undef HAVE_PPOLL
+
 /* Define to 1 if you have the 'prctl' function. */
 #undef HAVE_PRCTL
 
@@ -396,6 +396,9 @@
 /* Define to 1 if 'interface_id' is a member of 'sg_io_hdr_t'. */
 #undef HAVE_SG_IO_HDR_T_INTERFACE_ID
 
+/* Define to 1 if you have the `shm_open' function. */
+#undef HAVE_SHM_OPEN
+
 /* Define to 1 if 'si_fd' is a member of 'siginfo_t'. */
 #undef HAVE_SIGINFO_T_SI_FD
 
@@ -525,6 +528,9 @@
 /* Define to 1 if you have the <sys/epoll.h> header file. */
 #undef HAVE_SYS_EPOLL_H
 
+/* Define to 1 if you have the <sys/eventfd.h> header file. */
+#undef HAVE_SYS_EVENTFD_H
+
 /* Define to 1 if you have the <sys/event.h> header file. */
 #undef HAVE_SYS_EVENT_H
 
diff -ruN --show-c-function --no-dereference include/wine/server_protocol.h include/wine/server_protocol.h
--- include/wine/server_protocol.h	2025-09-06 20:10:25.644498919 -0700
+++ include/wine/server_protocol.h	2025-09-06 19:58:23.003351264 -0700
@@ -1148,10 +1148,8 @@ struct init_first_thread_reply
     thread_id_t  tid;
     timeout_t    server_start;
     unsigned int session_id;
-    obj_handle_t inproc_device;
     data_size_t  info_size;
     /* VARARG(machines,ushorts); */
-    char __pad_36[4];
 };
 
 
@@ -5939,6 +5937,78 @@ struct get_next_thread_reply
     char __pad_12[4];
 };
 
+enum esync_type
+{
+    ESYNC_SEMAPHORE = 1,
+    ESYNC_AUTO_EVENT,
+    ESYNC_MANUAL_EVENT,
+    ESYNC_MUTEX,
+    ESYNC_AUTO_SERVER,
+    ESYNC_MANUAL_SERVER,
+    ESYNC_QUEUE,
+};
+
+
+struct create_esync_request
+{
+    struct request_header __header;
+    unsigned int access;
+    int          initval;
+    int          type;
+    int          max;
+    /* VARARG(objattr,object_attributes); */
+    char __pad_28[4];
+};
+struct create_esync_reply
+{
+    struct reply_header __header;
+    obj_handle_t handle;
+    int          type;
+    unsigned int shm_idx;
+    char __pad_20[4];
+};
+
+struct open_esync_request
+{
+    struct request_header __header;
+    unsigned int access;
+    unsigned int attributes;
+    obj_handle_t rootdir;
+    int          type;
+    /* VARARG(name,unicode_str); */
+    char __pad_28[4];
+};
+struct open_esync_reply
+{
+    struct reply_header __header;
+    obj_handle_t handle;
+    int          type;
+    unsigned int shm_idx;
+    char __pad_20[4];
+};
+
+
+struct get_esync_fd_request
+{
+    struct request_header __header;
+    obj_handle_t handle;
+};
+struct get_esync_fd_reply
+{
+    struct reply_header __header;
+    int          type;
+    unsigned int shm_idx;
+};
+
+struct esync_msgwait_request
+{
+    struct request_header __header;
+    int          in_msgwait;
+};
+struct esync_msgwait_reply
+{
+    struct reply_header __header;
+};
 
 
 struct set_keyboard_repeat_request
@@ -5956,23 +6026,14 @@ struct set_keyboard_repeat_reply
 };
 
 
-enum inproc_sync_type
-{
-    INPROC_SYNC_UNKNOWN = 0,
-    INPROC_SYNC_EVENT = 1,
-};
-
-
-struct get_inproc_sync_fd_request
+struct get_esync_apc_fd_request
 {
     struct request_header __header;
-    obj_handle_t handle;
+    char __pad_12[4];
 };
-struct get_inproc_sync_fd_reply
+struct get_esync_apc_fd_reply
 {
     struct reply_header __header;
-    int           type;
-    unsigned int access;
 };
 
 
@@ -6274,8 +6335,12 @@ enum request
     REQ_resume_process,
     REQ_get_next_process,
     REQ_get_next_thread,
+    REQ_create_esync,
+    REQ_open_esync,
+    REQ_get_esync_fd,
+    REQ_esync_msgwait,
     REQ_set_keyboard_repeat,
-    REQ_get_inproc_sync_fd,
+    REQ_get_esync_apc_fd,
     REQ_NB_REQUESTS
 };
 
@@ -6579,8 +6644,12 @@ union generic_request
     struct resume_process_request resume_process_request;
     struct get_next_process_request get_next_process_request;
     struct get_next_thread_request get_next_thread_request;
+    struct create_esync_request create_esync_request;
+    struct open_esync_request open_esync_request;
+    struct get_esync_fd_request get_esync_fd_request;
+    struct esync_msgwait_request esync_msgwait_request;
     struct set_keyboard_repeat_request set_keyboard_repeat_request;
-    struct get_inproc_sync_fd_request get_inproc_sync_fd_request;
+    struct get_esync_apc_fd_request get_esync_apc_fd_request;
 };
 union generic_reply
 {
@@ -6882,10 +6951,14 @@ union generic_reply
     struct resume_process_reply resume_process_reply;
     struct get_next_process_reply get_next_process_reply;
     struct get_next_thread_reply get_next_thread_reply;
+    struct create_esync_reply create_esync_reply;
+    struct open_esync_reply open_esync_reply;
+    struct get_esync_fd_reply get_esync_fd_reply;
+    struct esync_msgwait_reply esync_msgwait_reply;
     struct set_keyboard_repeat_reply set_keyboard_repeat_reply;
-    struct get_inproc_sync_fd_reply get_inproc_sync_fd_reply;
+    struct get_esync_apc_fd_reply get_esync_apc_fd_reply;
 };
 
-#define SERVER_PROTOCOL_VERSION 893
+#define SERVER_PROTOCOL_VERSION 891
 
 #endif /* __WINE_WINE_SERVER_PROTOCOL_H */
diff -ruN --show-c-function --no-dereference README.esync README.esync
--- README.esync	1969-12-31 16:00:00.000000000 -0800
+++ README.esync	2025-09-06 19:58:17.786331614 -0700
@@ -0,0 +1,196 @@
+This is eventfd-based synchronization, or 'esync' for short. Turn it on with
+WINEESYNC=1; debug it with +esync.
+
+== BUGS AND LIMITATIONS ==
+
+Please let me know if you find any bugs. If you can, also attach a log with
++seh,+pid,+esync,+server,+timestamp.
+
+If you get something like "eventfd: Too many open files" and then things start
+crashing, you've probably run out of file descriptors. esync creates one
+eventfd descriptor for each synchronization object, and some games may use a
+large number of these.  Linux by default limits a process to 4096 file
+descriptors, which probably was reasonable back in the nineties but isn't
+really anymore. (Fortunately Debian and derivatives [Ubuntu, Mint] already
+have a reasonable limit.) To raise the limit you'll want to edit
+/etc/security/limits.conf and add a line like
+
+* hard nofile 1048576
+
+then restart your session.
+
+On distributions using systemd, the settings in `/etc/security/limits.conf`
+will be overridden by systemd's own settings. If you run `ulimit -Hn` and it
+returns a lower number than the one you've previously set, then you can set
+
+DefaultLimitNOFILE=1048576
+
+in both `/etc/systemd/system.conf` and `/etc/systemd/user.conf`. You can then
+execute `sudo systemctl daemon-reexec` and restart your session. Check again
+with `ulimit -Hn` that the limit is correct.
+
+Also note that if the wineserver has esync active, all clients also must, and
+vice versa. Otherwise things will probably crash quite badly.
+
+== EXPLANATION ==
+
+The aim is to execute all synchronization operations in "user-space", that is,
+without going through wineserver. We do this using Linux's eventfd
+facility. The main impetus to using eventfd is so that we can poll multiple
+objects at once; in particular we can't do this with futexes, or pthread
+semaphores, or the like. The only way I know of to wait on any of multiple
+objects is to use select/poll/epoll to wait on multiple fds, and eventfd gives
+us those fds in a quite usable way.
+
+Whenever a semaphore, event, or mutex is created, we have the server, instead
+of creating a traditional server-side event/semaphore/mutex, instead create an
+'esync' primitive. These live in esync.c and are very slim objects; in fact,
+they don't even know what type of primitive they are. The server is involved
+at all because we still need a way of creating named objects, passing handles
+to another process, etc.
+
+The server creates an eventfd file descriptor with the requested parameters
+and passes it back to ntdll. ntdll creates an object of the appropriate type,
+then caches it in a table. This table is copied almost wholesale from the fd
+cache code in server.c.
+
+Specific operations follow quite straightforwardly from eventfd:
+
+* To release an object, or set an event, we simply write() to it.
+* An object is signalled if read() succeeds on it. Notably, we create all
+  eventfd descriptors with O_NONBLOCK, so that we can atomically check if an
+  object is signalled and grab it if it is. This also lets us reset events.
+* For objects whose state should not be reset upon waiting—e.g. manual-reset
+  events—we simply check for the POLLIN flag instead of reading.
+* Semaphores are handled by the EFD_SEMAPHORE flag. This matches up quite well
+  (although with some difficulties; see below).
+* Mutexes store their owner thread locally. This isn't reliable information if
+  a different process's thread owns the mutex, but this doesn't matter—a
+  thread should only care whether it owns the mutex, so it knows whether to
+  try waiting on it or simply to increase the recursion count.
+
+The interesting part about esync is that (almost) all waits happen in ntdll,
+including those on server-bound objects. The idea here is that on the server
+side, for any waitable object, we create an eventfd file descriptor (not an
+esync primitive), and then pass it to ntdll if the program tries to wait on
+it. These are cached too, so only the first wait will require a round trip to
+the server. Then the server signals the file descriptor as appropriate, and
+thereby wakes up the client. So far this is implemented for processes,
+threads, message queues (difficult; see below), and device managers (necessary
+for drivers to work). All of these are necessarily server-bound, so we
+wouldn't really gain anything by signalling on the client side instead. Of
+course, except possibly for message queues, it's not likely that any program
+(cutting-edge D3D game or not) is going to be causing a great wineserver load
+by waiting on any of these objects; the motivation was rather to provide a way
+to wait on ntdll-bound and server-bound objects at the same time.
+
+Some cases are still passed to the server, and there's probably no reason not
+to keep them that way. Those that I noticed while testing include: async
+objects, which are internal to the file APIs and never exposed to userspace,
+startup_info objects, which are internal to the loader and signalled when a
+process starts, and keyed events, which are exposed through an ntdll API
+(although not through kernel32) but can't be mixed with other objects (you
+have to use NtWaitForKeyedEvent()). Other cases include: named pipes, debug
+events, sockets, and timers. It's unlikely we'll want to optimize debug events
+or sockets (or any of the other, rather rare, objects), but it is possible
+we'll want to optimize named pipes or timers.
+
+There were two sort of complications when working out the above. The first one
+was events. The trouble is that (1) the server actually creates some events by
+itself and (2) the server sometimes manipulates events passed by the
+client. Resolving the first case was easy enough, and merely entailed creating
+eventfd descriptors for the events the same way as for processes and threads
+(note that we don't really lose anything this way; the events include
+"LowMemoryCondition" and the event that signals system processes to shut
+down). For the second case I basically had to hook the server-side event
+functions to redirect to esync versions if the event was actually an esync
+primitive.
+
+The second complication was message queues. The difficulty here is that X11
+signals events by writing into a pipe (at least I think it's a pipe?), and so
+as a result wineserver has to poll on that descriptor. In theory we could just
+let wineserver do so and then signal us as appropriate, except that wineserver
+only polls on the pipe when the thread is waiting for events (otherwise we'd
+get e.g. keyboard input while the thread is doing something else, and spin
+forever trying to wake up a thread that doesn't care). The obvious solution is
+just to poll on that fd ourselves, and that's what I did—it's just that
+getting the fd from wineserver was kind of ugly, and the code for waiting was
+also kind of ugly basically because we have to wait on both X11's fd and the
+"normal" process/thread-style wineserver fd that we use to signal sent
+messages. The upshot about the whole thing was that races are basically
+impossible, since a thread can only wait on its own queue.
+
+System APCs already work, since the server will forcibly suspend a thread if
+it's not already waiting, and so we just need to check for EINTR from
+poll(). User APCs and alertable waits are implemented in a similar style to
+message queues (well, sort of): whenever someone executes an alertable wait,
+we add an additional eventfd to the list, which the server signals when an APC
+arrives. If that eventfd gets signaled, we hand it off to the server to take
+care of, and return STATUS_USER_APC.
+
+Originally I kept the volatile state of semaphores and mutexes inside a
+variable local to the handle, with the knowledge that this would break if
+someone tried to open the handle elsewhere or duplicate it. It did, and so now
+this state is stored inside shared memory. This is of the POSIX variety, is
+allocated by the server (but never mapped there) and lives under the path
+"/wine-esync".
+
+There are a couple things that this infrastructure can't handle, although
+surprisingly there aren't that many. In particular:
+* Implementing wait-all, i.e. WaitForMultipleObjects(..., TRUE, ...), is not
+  exactly possible the way we'd like it to be possible. In theory that
+  function should wait until it knows all objects are available, then grab
+  them all at once atomically. The server (like the kernel) can do this
+  because the server is single-threaded and can't race with itself. We can't
+  do this in ntdll, though. The approach I've taken I've laid out in great
+  detail in the relevant patch, but for a quick summary we poll on each object
+  until it's signaled (but don't grab it), check them all again, and if
+  they're all signaled we try to grab them all at once in a tight loop, and if
+  we fail on any of them we reset the count on whatever we shouldn't have
+  consumed. Such a blip would necessarily be very quick.
+* The whole patchset only works on Linux, where eventfd is available. However,
+  it should be possible to make it work on a Mac, since eventfd is just a
+  quicker, easier way to use pipes (i.e. instead of writing 1 to the fd you'd
+  write 1 byte; instead of reading a 64-bit value from the fd you'd read as
+  many bytes as you can carry, which is admittedly less than 2**64 but
+  can probably be something reasonable.) It's also possible, although I
+  haven't yet looked, to use some different kind of synchronization
+  primitives, but pipes would be easiest to tack onto this framework.
+* PulseEvent() can't work the way it's supposed to work. Fortunately it's rare
+  and deprecated. It's also explicitly mentioned on MSDN that a thread can
+  miss the notification for a kernel APC, so in a sense we're not necessarily
+  doing anything wrong.
+
+There are some things that are perfectly implementable but that I just haven't
+done yet:
+* Other synchronizable server primitives. It's unlikely we'll need any of
+  these, except perhaps named pipes (which would honestly be rather difficult)
+  and (maybe) timers.
+* Access masks. We'd need to store these inside ntdll, and validate them when
+  someone tries to execute esync operations.
+
+This patchset was inspired by Daniel Santos' "hybrid synchronization"
+patchset. My idea was to create a framework whereby even contended waits could
+be executed in userspace, eliminating a lot of the complexity that his
+synchronization primitives used. I do however owe some significant gratitude
+toward him for setting me on the right path.
+
+I've tried to maximize code separation, both to make any potential rebases
+easier and to ensure that esync is only active when configured. All code in
+existing source files is guarded with "if (do_esync())", and generally that
+condition is followed by "return esync_version_of_this_method(...);", where
+the latter lives in esync.c and is declared in esync.h. I've also tried to
+make the patchset very clear and readable—to write it as if I were going to
+submit it upstream. (Some intermediate patches do break things, which Wine is
+generally against, but I think it's for the better in this case.) I have cut
+some corners, though; there is some error checking missing, or implicit
+assumptions that the program is behaving correctly.
+
+I've tried to be careful about races. There are a lot of comments whose
+purpose are basically to assure me that races are impossible. In most cases we
+don't have to worry about races since all of the low-level synchronization is
+done by the kernel.
+
+Anyway, yeah, this is esync. Use it if you like.
+
+--Zebediah Figura
diff -ruN --show-c-function --no-dereference server/async.c server/async.c
--- server/async.c	2025-09-06 20:10:25.816738436 -0700
+++ server/async.c	2025-09-06 19:58:17.762784717 -0700
@@ -78,10 +78,10 @@ static const struct object_ops async_ops
     add_queue,                 /* add_queue */
     remove_queue,              /* remove_queue */
     async_signaled,            /* signaled */
+    NULL,                      /* get_esync_fd */
     async_satisfied,           /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
-    default_get_sync,          /* get_sync */
     default_map_access,        /* map_access */
     default_get_sd,            /* get_sd */
     default_set_sd,            /* set_sd */
@@ -700,10 +700,10 @@ static const struct object_ops iosb_ops
     no_add_queue,             /* add_queue */
     NULL,                     /* remove_queue */
     NULL,                     /* signaled */
+    NULL,                     /* get_esync_fd */
     NULL,                     /* satisfied */
     no_signal,                /* signal */
     no_get_fd,                /* get_fd */
-    default_get_sync,         /* get_sync */
     default_map_access,       /* map_access */
     default_get_sd,           /* get_sd */
     default_set_sd,           /* set_sd */
diff -ruN --show-c-function --no-dereference server/atom.c server/atom.c
--- server/atom.c	2025-09-06 20:10:25.816738436 -0700
+++ server/atom.c	2025-09-06 19:58:17.762972004 -0700
@@ -78,10 +78,10 @@ static const struct object_ops atom_tabl
     no_add_queue,                 /* add_queue */
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
+    NULL,                         /* get_esync_fd */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-    default_get_sync,             /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
diff -ruN --show-c-function --no-dereference server/change.c server/change.c
--- server/change.c	2025-09-06 20:10:25.816738436 -0700
+++ server/change.c	2025-09-06 19:58:17.786461822 -0700
@@ -109,13 +109,13 @@ static const struct object_ops dir_ops =
     sizeof(struct dir),       /* size */
     &file_type,               /* type */
     dir_dump,                 /* dump */
-    NULL,                     /* add_queue */
-    NULL,                     /* remove_queue */
-    NULL,                     /* signaled */
-    NULL,                     /* satisfied */
+    add_queue,                /* add_queue */
+    remove_queue,             /* remove_queue */
+    default_fd_signaled,      /* signaled */
+    default_fd_get_esync_fd,  /* get_esync_fd */
+    no_satisfied,             /* satisfied */
     no_signal,                /* signal */
     dir_get_fd,               /* get_fd */
-    default_fd_get_sync,      /* get_sync */
     default_map_access,       /* map_access */
     dir_get_sd,               /* get_sd */
     dir_set_sd,               /* set_sd */
diff -ruN --show-c-function --no-dereference server/clipboard.c server/clipboard.c
--- server/clipboard.c	2025-09-06 20:10:25.816738436 -0700
+++ server/clipboard.c	2025-09-06 19:58:17.763191562 -0700
@@ -76,10 +76,10 @@ static const struct object_ops clipboard
     no_add_queue,                 /* add_queue */
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
+    NULL,                         /* get_esync_fd */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-    default_get_sync,             /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
diff -ruN --show-c-function --no-dereference server/completion.c server/completion.c
--- server/completion.c	2025-09-06 20:10:25.816738436 -0700
+++ server/completion.c	2025-09-06 19:58:17.763359141 -0700
@@ -72,11 +72,11 @@ struct completion_wait
 
 struct completion
 {
-    struct object       obj;
-    struct event_sync  *sync;
-    struct list         queue;
-    struct list         wait_queue;
-    unsigned int        depth;
+    struct object  obj;
+    struct list    queue;
+    struct list    wait_queue;
+    unsigned int   depth;
+    int            closed;
 };
 
 static void completion_wait_dump( struct object*, int );
@@ -92,10 +92,10 @@ static const struct object_ops completio
     add_queue,                      /* add_queue */
     remove_queue,                   /* remove_queue */
     completion_wait_signaled,       /* signaled */
+    NULL,                           /* get_esync_fd */
     completion_wait_satisfied,      /* satisfied */
     no_signal,                      /* signal */
     no_get_fd,                      /* get_fd */
-    default_get_sync,               /* get_sync */
     default_map_access,             /* map_access */
     default_get_sd,                 /* get_sd */
     default_set_sd,                 /* set_sd */
@@ -155,7 +155,7 @@ static void completion_wait_satisfied( s
 }
 
 static void completion_dump( struct object*, int );
-static struct object *completion_get_sync( struct object * );
+static int completion_signaled( struct object *obj, struct wait_queue_entry *entry );
 static int completion_close_handle( struct object *obj, struct process *process, obj_handle_t handle );
 static void completion_destroy( struct object * );
 
@@ -164,13 +164,13 @@ static const struct object_ops completio
     sizeof(struct completion), /* size */
     &completion_type,          /* type */
     completion_dump,           /* dump */
-    NULL,                      /* add_queue */
-    NULL,                      /* remove_queue */
-    NULL,                      /* signaled */
-    NULL,                      /* satisfied */
+    add_queue,                 /* add_queue */
+    remove_queue,              /* remove_queue */
+    completion_signaled,       /* signaled */
+    NULL,                      /* get_esync_fd */
+    no_satisfied,              /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
-    completion_get_sync,       /* get_sync */
     default_map_access,        /* map_access */
     default_get_sd,            /* get_sd */
     default_set_sd,            /* set_sd */
@@ -193,8 +193,6 @@ static void completion_destroy( struct o
     {
         free( tmp );
     }
-
-    if (completion->sync) release_object( completion->sync );
 }
 
 static void completion_dump( struct object *obj, int verbose )
@@ -205,11 +203,11 @@ static void completion_dump( struct obje
     fprintf( stderr, "Completion depth=%u\n", completion->depth );
 }
 
-static struct object *completion_get_sync( struct object *obj )
+static int completion_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct completion *completion = (struct completion *)obj;
-    assert( obj->ops == &completion_ops );
-    return grab_object( completion->sync );
+
+    return !list_empty( &completion->queue ) || completion->closed;
 }
 
 static int completion_close_handle( struct object *obj, struct process *process, obj_handle_t handle )
@@ -230,7 +228,8 @@ static int completion_close_handle( stru
             cleanup_thread_completion( wait->thread );
         }
     }
-    signal_sync( completion->sync );
+    completion->closed = 1;
+    wake_up( obj, 0 );
     return 1;
 }
 
@@ -274,16 +273,10 @@ static struct completion *create_complet
     {
         if (get_error() != STATUS_OBJECT_NAME_EXISTS)
         {
-            completion->sync = NULL;
             list_init( &completion->queue );
             list_init( &completion->wait_queue );
             completion->depth = 0;
-
-            if (!(completion->sync = create_event_sync( 1, 0 )))
-            {
-                release_object( completion );
-                return NULL;
-            }
+            completion->closed = 0;
         }
     }
 
@@ -316,7 +309,7 @@ void add_completion( struct completion *
         wake_up( &wait->obj, 1 );
         if (list_empty( &completion->queue )) return;
     }
-    if (!list_empty( &completion->queue )) signal_sync( completion->sync );
+    if (!list_empty( &completion->queue )) wake_up( &completion->obj, 0 );
 }
 
 /* create a completion */
@@ -417,7 +410,6 @@ DECL_HANDLER(remove_completion)
         reply->information = msg->information;
         free( msg );
         reply->wait_handle = 0;
-        if (list_empty( &completion->queue )) reset_sync( completion->sync );
     }
 
     release_object( completion );
diff -ruN --show-c-function --no-dereference server/console.c server/console.c
--- server/console.c	2025-09-06 20:10:25.816738436 -0700
+++ server/console.c	2025-09-06 19:58:17.787740346 -0700
@@ -41,6 +41,7 @@
 #include "wincon.h"
 #include "winternl.h"
 #include "wine/condrv.h"
+#include "esync.h"
 
 struct screen_buffer;
 
@@ -53,7 +54,7 @@ struct history_line
 struct console
 {
     struct object                obj;           /* object header */
-    struct event_sync           *sync;          /* sync object for wait/signal */
+    int                          signaled;      /* is console signaled */
     struct thread               *renderer;      /* console renderer thread */
     struct screen_buffer        *active;        /* active screen buffer */
     struct console_server       *server;        /* console server object */
@@ -68,25 +69,26 @@ struct console
 
 static void console_dump( struct object *obj, int verbose );
 static void console_destroy( struct object *obj );
+static int console_signaled( struct object *obj, struct wait_queue_entry *entry );
 static struct fd *console_get_fd( struct object *obj );
-static struct object *console_get_sync( struct object *obj );
 static struct object *console_lookup_name( struct object *obj, struct unicode_str *name,
                                            unsigned int attr, struct object *root );
 static struct object *console_open_file( struct object *obj, unsigned int access,
                                          unsigned int sharing, unsigned int options );
+static int console_add_queue( struct object *obj, struct wait_queue_entry *entry );
 
 static const struct object_ops console_ops =
 {
     sizeof(struct console),           /* size */
     &file_type,                       /* type */
     console_dump,                     /* dump */
-    NULL,                             /* add_queue */
-    NULL,                             /* remove_queue */
-    NULL,                             /* signaled */
-    NULL,                             /* satisfied */
+    console_add_queue,                /* add_queue */
+    remove_queue,                     /* remove_queue */
+    console_signaled,                 /* signaled */
+    NULL,                             /* get_esync_fd */
+    no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     console_get_fd,                   /* get_fd */
-    console_get_sync,                 /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -133,22 +135,23 @@ struct console_host_ioctl
 
 struct console_server
 {
-    struct object         obj;            /* object header */
-    struct event_sync    *sync;           /* sync object for wait/signal */
-    struct fd            *fd;             /* pseudo-fd for ioctls */
-    struct console       *console;        /* attached console */
-    struct list           queue;          /* ioctl queue */
-    struct list           read_queue;     /* blocking read queue */
+    struct object         obj;         /* object header */
+    struct fd            *fd;          /* pseudo-fd for ioctls */
+    struct console       *console;     /* attached console */
+    struct list           queue;       /* ioctl queue */
+    struct list           read_queue;  /* blocking read queue */
     unsigned int          busy : 1;       /* flag if server processing an ioctl */
     unsigned int          once_input : 1; /* flag if input thread has already been requested */
-    int                   term_fd;        /* UNIX terminal fd */
-    struct termios        termios;        /* original termios */
+    int                   term_fd;     /* UNIX terminal fd */
+    struct termios        termios;     /* original termios */
+    int                   esync_fd;
 };
 
 static void console_server_dump( struct object *obj, int verbose );
 static void console_server_destroy( struct object *obj );
+static int console_server_signaled( struct object *obj, struct wait_queue_entry *entry );
+static int console_server_get_esync_fd( struct object *obj, enum esync_type *type );
 static struct fd *console_server_get_fd( struct object *obj );
-static struct object *console_server_get_sync( struct object *obj );
 static struct object *console_server_lookup_name( struct object *obj, struct unicode_str *name,
                                                 unsigned int attr, struct object *root );
 static struct object *console_server_open_file( struct object *obj, unsigned int access,
@@ -159,13 +162,13 @@ static const struct object_ops console_s
     sizeof(struct console_server),    /* size */
     &file_type,                       /* type */
     console_server_dump,              /* dump */
-    NULL,                             /* add_queue */
-    NULL,                             /* remove_queue */
-    NULL,                             /* signaled */
-    NULL,                             /* satisfied */
+    add_queue,                        /* add_queue */
+    remove_queue,                     /* remove_queue */
+    console_server_signaled,          /* signaled */
+    console_server_get_esync_fd,      /* get_esync_fd */
+    no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     console_server_get_fd,            /* get_fd */
-    console_server_get_sync,          /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -210,7 +213,6 @@ struct font_info
 struct screen_buffer
 {
     struct object         obj;           /* object header */
-    struct event_sync    *sync;          /* sync object for wait/signal */
     struct list           entry;         /* entry in list of all screen buffers */
     struct console       *input;         /* associated console input */
     unsigned int          id;            /* buffer id */
@@ -220,8 +222,8 @@ struct screen_buffer
 
 static void screen_buffer_dump( struct object *obj, int verbose );
 static void screen_buffer_destroy( struct object *obj );
+static int screen_buffer_signaled( struct object *obj, struct wait_queue_entry *entry );
 static struct fd *screen_buffer_get_fd( struct object *obj );
-static struct object *screen_buffer_get_sync( struct object *obj );
 static struct object *screen_buffer_open_file( struct object *obj, unsigned int access,
                                                unsigned int sharing, unsigned int options );
 
@@ -230,13 +232,13 @@ static const struct object_ops screen_bu
     sizeof(struct screen_buffer),     /* size */
     &file_type,                       /* type */
     screen_buffer_dump,               /* dump */
-    NULL,                             /* add_queue */
-    NULL,                             /* remove_queue */
-    NULL,                             /* signaled */
-    NULL,                             /* satisfied */
+    add_queue,                        /* add_queue */
+    remove_queue,                     /* remove_queue */
+    screen_buffer_signaled,           /* signaled */
+    NULL,                             /* get_esync_fd */
+    no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     screen_buffer_get_fd,             /* get_fd */
-    screen_buffer_get_sync,           /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -283,10 +285,10 @@ static const struct object_ops console_d
     no_add_queue,                     /* add_queue */
     NULL,                             /* remove_queue */
     NULL,                             /* signaled */
+    NULL,                             /* get_esync_fd */
     no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     no_get_fd,                        /* get_fd */
-    default_get_sync,                 /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -303,17 +305,16 @@ static const struct object_ops console_d
 struct console_input
 {
     struct object         obj;         /* object header */
-    struct event_sync    *sync;        /* sync object for wait/signal */
     struct fd            *fd;          /* pseudo-fd */
     struct list           entry;       /* entry in console->inputs */
     struct console       *console;     /* associated console at creation time */
 };
 
 static void console_input_dump( struct object *obj, int verbose );
+static int console_input_signaled( struct object *obj, struct wait_queue_entry *entry );
 static struct object *console_input_open_file( struct object *obj, unsigned int access,
                                                unsigned int sharing, unsigned int options );
 static struct fd *console_input_get_fd( struct object *obj );
-static struct object *console_input_get_sync( struct object *obj );
 static void console_input_destroy( struct object *obj );
 
 static const struct object_ops console_input_ops =
@@ -321,13 +322,13 @@ static const struct object_ops console_i
     sizeof(struct console_input),     /* size */
     &device_type,                     /* type */
     console_input_dump,               /* dump */
-    NULL,                             /* add_queue */
-    NULL,                             /* remove_queue */
-    NULL,                             /* signaled */
-    NULL,                             /* satisfied */
+    add_queue,                        /* add_queue */
+    remove_queue,                     /* remove_queue */
+    console_input_signaled,           /* signaled */
+    NULL,                             /* get_esync_fd */
+    no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     console_input_get_fd,             /* get_fd */
-    console_input_get_sync,           /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -364,15 +365,14 @@ static const struct fd_ops console_input
 struct console_output
 {
     struct object         obj;         /* object header */
-    struct event_sync    *sync;        /* sync object for wait/signal */
     struct fd            *fd;          /* pseudo-fd */
     struct list           entry;       /* entry in console->outputs */
     struct console       *console;     /* associated console at creation time */
 };
 
 static void console_output_dump( struct object *obj, int verbose );
+static int console_output_signaled( struct object *obj, struct wait_queue_entry *entry );
 static struct fd *console_output_get_fd( struct object *obj );
-static struct object *console_output_get_sync( struct object *obj );
 static struct object *console_output_open_file( struct object *obj, unsigned int access,
                                                 unsigned int sharing, unsigned int options );
 static void console_output_destroy( struct object *obj );
@@ -382,13 +382,13 @@ static const struct object_ops console_o
     sizeof(struct console_output),    /* size */
     &device_type,                     /* type */
     console_output_dump,              /* dump */
-    NULL,                             /* add_queue */
-    NULL,                             /* remove_queue */
-    NULL,                             /* signaled */
-    NULL,                             /* satisfied */
+    add_queue,                        /* add_queue */
+    remove_queue,                     /* remove_queue */
+    console_output_signaled,          /* signaled */
+    NULL,                             /* get_esync_fd */
+    no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     console_output_get_fd,            /* get_fd */
-    console_output_get_sync,          /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -444,10 +444,10 @@ static const struct object_ops console_c
     no_add_queue,                     /* add_queue */
     NULL,                             /* remove_queue */
     NULL,                             /* signaled */
+    NULL,                             /* get_esync_fd */
     no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     console_connection_get_fd,        /* get_fd */
-    default_get_sync,                 /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -482,18 +482,10 @@ static const struct fd_ops console_conne
 static int queue_host_ioctl( struct console_server *server, unsigned int code, unsigned int output,
                              struct async *async, struct async_queue *queue );
 
-static struct fd *console_get_fd( struct object *obj )
-{
-    struct console *console = (struct console *)obj;
-    assert( obj->ops == &console_ops );
-    return (struct fd *)grab_object( console->fd );
-}
-
-static struct object *console_get_sync( struct object *obj )
+static int console_add_queue( struct object *obj, struct wait_queue_entry *entry )
 {
-    struct console *console = (struct console *)obj;
+    struct console *console = (struct console*)obj;
     assert( obj->ops == &console_ops );
-
     /* before waiting, ensure conhost's input thread has been started */
     if (console->server && !console->server->once_input)
     {
@@ -501,8 +493,20 @@ static struct object *console_get_sync(
         if (console->server->term_fd == -1)
             queue_host_ioctl( console->server, IOCTL_CONDRV_PEEK, 0, NULL, NULL );
     }
+    return add_queue( &console->obj, entry );
+}
+
+static int console_signaled( struct object *obj, struct wait_queue_entry *entry )
+{
+    struct console *console = (struct console*)obj;
+    return console->signaled;
+}
 
-    return grab_object( console->sync );
+static struct fd *console_get_fd( struct object *obj )
+{
+    struct console *console = (struct console *)obj;
+    assert( obj->ops == &console_ops );
+    return (struct fd *)grab_object( console->fd );
 }
 
 static enum server_fd_type console_get_fd_type( struct fd *fd )
@@ -541,9 +545,11 @@ static struct object *create_console(voi
 {
     struct console *console;
 
-    if (!(console = alloc_object( &console_ops ))) return NULL;
-    console->sync          = NULL;
+    if (!(console = alloc_object( &console_ops )))
+        return NULL;
+
     console->renderer      = NULL;
+    console->signaled      = 0;
     console->active        = NULL;
     console->server        = NULL;
     console->fd            = NULL;
@@ -554,14 +560,14 @@ static struct object *create_console(voi
     init_async_queue( &console->ioctl_q );
     init_async_queue( &console->read_q );
 
-    if (!(console->sync = create_event_sync( 1, 0 ))) goto error;
-    if (!(console->fd = alloc_pseudo_fd( &console_fd_ops, &console->obj, FILE_SYNCHRONOUS_IO_NONALERT ))) goto error;
+    console->fd = alloc_pseudo_fd( &console_fd_ops, &console->obj, FILE_SYNCHRONOUS_IO_NONALERT );
+    if (!console->fd)
+    {
+        release_object( console );
+        return NULL;
+    }
     allow_fd_caching( console->fd );
     return &console->obj;
-
-error:
-    release_object( console );
-    return NULL;
 }
 
 static void console_host_ioctl_terminate( struct console_host_ioctl *call, unsigned int status )
@@ -589,7 +595,7 @@ static int queue_host_ioctl( struct cons
         queue_async( queue, async );
     }
     list_add_tail( &server->queue, &ioctl->entry );
-    signal_sync( server->sync );
+    wake_up( &server->obj, 0 );
     if (async) set_error( STATUS_PENDING );
     return 1;
 }
@@ -602,6 +608,8 @@ static void disconnect_console_server( s
         list_remove( &call->entry );
         console_host_ioctl_terminate( call, STATUS_CANCELLED );
     }
+    if (do_esync())
+        esync_clear( server->esync_fd );
     while (!list_empty( &server->read_queue ))
     {
         struct console_host_ioctl *call = LIST_ENTRY( list_head( &server->read_queue ), struct console_host_ioctl, entry );
@@ -621,7 +629,7 @@ static void disconnect_console_server( s
         assert( server->console->server == server );
         server->console->server = NULL;
         server->console = NULL;
-        signal_sync( server->sync );
+        wake_up( &server->obj, 0 );
     }
 }
 
@@ -645,8 +653,9 @@ static struct object *create_screen_buff
         return NULL;
     }
 
-    if (!(screen_buffer = alloc_object( &screen_buffer_ops ))) return NULL;
-    screen_buffer->sync  = (struct event_sync *)grab_object( console->sync );
+    if (!(screen_buffer = alloc_object( &screen_buffer_ops )))
+        return NULL;
+
     screen_buffer->id    = ++console->last_id;
     screen_buffer->input = console;
     init_async_queue( &screen_buffer->ioctl_q );
@@ -777,12 +786,6 @@ static void console_destroy( struct obje
     LIST_FOR_EACH_ENTRY( output, &console->outputs, struct console_output, entry )
         output->console = NULL;
 
-    if (console->sync)
-    {
-        reset_sync( console->sync );
-        release_object( console->sync );
-    }
-
     free_async_queue( &console->ioctl_q );
     free_async_queue( &console->read_q );
     if (console->fd)
@@ -862,10 +865,17 @@ static void screen_buffer_destroy( struc
                               screen_buffer->id, NULL, NULL );
     }
     free_async_queue( &screen_buffer->ioctl_q );
-    if (screen_buffer->sync) release_object( screen_buffer->sync );
     if (screen_buffer->fd) release_object( screen_buffer->fd );
 }
 
+static int screen_buffer_signaled( struct object *obj, struct wait_queue_entry *entry )
+{
+    struct screen_buffer *screen_buffer = (struct screen_buffer *)obj;
+    assert( obj->ops == &screen_buffer_ops );
+    if (!screen_buffer->input) return 0;
+    return screen_buffer->input->signaled;
+}
+
 static struct object *screen_buffer_open_file( struct object *obj, unsigned int access,
                                                unsigned int sharing, unsigned int options )
 {
@@ -882,13 +892,6 @@ static struct fd *screen_buffer_get_fd(
     return NULL;
 }
 
-static struct object *screen_buffer_get_sync( struct object *obj )
-{
-    struct screen_buffer *screen_buffer = (struct screen_buffer *)obj;
-    assert( obj->ops == &screen_buffer_ops );
-    return grab_object( screen_buffer->sync );
-}
-
 static void console_server_dump( struct object *obj, int verbose )
 {
     assert( obj->ops == &console_server_ops );
@@ -900,8 +903,8 @@ static void console_server_destroy( stru
     struct console_server *server = (struct console_server *)obj;
     assert( obj->ops == &console_server_ops );
     disconnect_console_server( server );
-    if (server->sync) release_object( server->sync );
     if (server->fd) release_object( server->fd );
+    if (do_esync()) close( server->esync_fd );
 }
 
 static struct object *console_server_lookup_name( struct object *obj, struct unicode_str *name,
@@ -936,25 +939,31 @@ static struct object *console_server_loo
         release_object( screen_buffer );
         server->console->server = server;
 
-        if (list_empty( &server->queue )) reset_sync( server->sync );
         return &server->console->obj;
     }
 
     return NULL;
 }
 
-static struct fd *console_server_get_fd( struct object* obj )
+static int console_server_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct console_server *server = (struct console_server*)obj;
     assert( obj->ops == &console_server_ops );
-    return (struct fd *)grab_object( server->fd );
+    return !server->console || !list_empty( &server->queue );
 }
 
-static struct object *console_server_get_sync( struct object *obj )
+static int console_server_get_esync_fd( struct object *obj, enum esync_type *type )
 {
-    struct console_server *server = (struct console_server *)obj;
+    struct console_server *server = (struct console_server*)obj;
+    *type = ESYNC_MANUAL_SERVER;
+    return server->esync_fd;
+}
+
+static struct fd *console_server_get_fd( struct object* obj )
+{
+    struct console_server *server = (struct console_server*)obj;
     assert( obj->ops == &console_server_ops );
-    return grab_object( server->sync );
+    return (struct fd *)grab_object( server->fd );
 }
 
 static struct object *console_server_open_file( struct object *obj, unsigned int access,
@@ -968,23 +977,25 @@ static struct object *create_console_ser
     struct console_server *server;
 
     if (!(server = alloc_object( &console_server_ops ))) return NULL;
-    server->sync       = NULL;
-    server->fd         = NULL;
     server->console    = NULL;
     server->busy       = 0;
     server->once_input = 0;
     server->term_fd    = -1;
     list_init( &server->queue );
     list_init( &server->read_queue );
-
-    if (!(server->sync = create_event_sync( 1, 1 ))) goto error;
-    if (!(server->fd = alloc_pseudo_fd( &console_server_fd_ops, &server->obj, FILE_SYNCHRONOUS_IO_NONALERT ))) goto error;
+    server->fd = alloc_pseudo_fd( &console_server_fd_ops, &server->obj, FILE_SYNCHRONOUS_IO_NONALERT );
+    if (!server->fd)
+    {
+        release_object( server );
+        return NULL;
+    }
     allow_fd_caching(server->fd);
-    return &server->obj;
+    server->esync_fd = -1;
 
-error:
-    release_object( server );
-    return NULL;
+    if (do_esync())
+        server->esync_fd = esync_create_fd( 0, 0 );
+
+    return &server->obj;
 }
 
 static int is_blocking_read_ioctl( unsigned int code )
@@ -1350,7 +1361,6 @@ static struct object *console_device_loo
 
         name->len = 0;
         if (!(console_input = alloc_object( &console_input_ops ))) return NULL;
-        console_input->sync = (struct event_sync *)grab_object( current->process->console->sync );
         console_input->fd = alloc_pseudo_fd( &console_input_fd_ops, &console_input->obj,
                                              FILE_SYNCHRONOUS_IO_NONALERT );
         if (!console_input->fd)
@@ -1375,7 +1385,6 @@ static struct object *console_device_loo
 
         name->len = 0;
         if (!(console_output = alloc_object( &console_output_ops ))) return NULL;
-        console_output->sync = (struct event_sync *)grab_object( current->process->console->sync );
         console_output->fd = alloc_pseudo_fd( &console_output_fd_ops, &console_output->obj,
                                              FILE_SYNCHRONOUS_IO_NONALERT );
         if (!console_output->fd)
@@ -1438,18 +1447,19 @@ static void console_input_dump( struct o
     fputs( "console Input device\n", stderr );
 }
 
-static struct fd *console_input_get_fd( struct object *obj )
+static int console_input_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct console_input *console_input = (struct console_input *)obj;
     assert( obj->ops == &console_input_ops );
-    return (struct fd *)grab_object( console_input->fd );
+    if (!console_input->console) return 0;
+    return console_input->console->signaled;
 }
 
-static struct object *console_input_get_sync( struct object *obj )
+static struct fd *console_input_get_fd( struct object *obj )
 {
     struct console_input *console_input = (struct console_input *)obj;
     assert( obj->ops == &console_input_ops );
-    return grab_object( console_input->sync );
+    return (struct fd *)grab_object( console_input->fd );
 }
 
 static struct object *console_input_open_file( struct object *obj, unsigned int access,
@@ -1465,7 +1475,6 @@ static void console_input_destroy( struc
     assert( obj->ops == &console_input_ops );
     if (console_input->fd) release_object( console_input->fd );
     if (console_input->console) list_remove( &console_input->entry );
-    if (console_input->sync) release_object( console_input->sync );
 }
 
 static void console_input_ioctl( struct fd *fd, ioctl_code_t code, struct async *async )
@@ -1509,18 +1518,19 @@ static void console_output_dump( struct
     fputs( "console Output device\n", stderr );
 }
 
-static struct fd *console_output_get_fd( struct object *obj )
+static int console_output_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct console_output *console_output = (struct console_output *)obj;
     assert( obj->ops == &console_output_ops );
-    return (struct fd *)grab_object( console_output->fd );
+    if (!console_output->console) return 0;
+    return console_output->console->signaled;
 }
 
-static struct object *console_output_get_sync( struct object *obj )
+static struct fd *console_output_get_fd( struct object *obj )
 {
     struct console_output *console_output = (struct console_output *)obj;
     assert( obj->ops == &console_output_ops );
-    return grab_object( console_output->sync );
+    return (struct fd *)grab_object( console_output->fd );
 }
 
 static struct object *console_output_open_file( struct object *obj, unsigned int access,
@@ -1536,7 +1546,6 @@ static void console_output_destroy( stru
     assert( obj->ops == &console_output_ops );
     if (console_output->fd) release_object( console_output->fd );
     if (console_output->console) list_remove( &console_output->entry );
-    if (console_output->sync) release_object( console_output->sync );
 }
 
 static void console_output_ioctl( struct fd *fd, ioctl_code_t code, struct async *async )
@@ -1573,7 +1582,10 @@ struct object *create_console_device( st
 DECL_HANDLER(get_next_console_request)
 {
     struct console_host_ioctl *ioctl = NULL, *next;
+    struct screen_buffer *screen_buffer;
     struct console_server *server;
+    struct console_output *output;
+    struct console_input *input;
     struct iosb *iosb = NULL;
 
     server = (struct console_server *)get_handle_obj( current->process, req->handle, 0, &console_server_ops );
@@ -1588,8 +1600,18 @@ DECL_HANDLER(get_next_console_request)
 
     if (!server->console->renderer) server->console->renderer = current;
 
-    if (!req->signal) reset_sync( server->console->sync );
-    else signal_sync( server->console->sync );
+    if (!req->signal) server->console->signaled = 0;
+    else if (!server->console->signaled)
+    {
+        server->console->signaled = 1;
+        wake_up( &server->console->obj, 0 );
+        LIST_FOR_EACH_ENTRY( screen_buffer, &server->console->screen_buffers, struct screen_buffer, entry )
+            wake_up( &screen_buffer->obj, 0 );
+        LIST_FOR_EACH_ENTRY( input, &server->console->inputs, struct console_input, entry )
+            wake_up( &input->obj, 0 );
+        LIST_FOR_EACH_ENTRY( output, &server->console->outputs, struct console_output, entry )
+            wake_up( &output->obj, 0 );
+    }
 
     if (req->read)
     {
@@ -1610,6 +1632,8 @@ DECL_HANDLER(get_next_console_request)
         /* set result of previous ioctl */
         ioctl = LIST_ENTRY( list_head( &server->queue ), struct console_host_ioctl, entry );
         list_remove( &ioctl->entry );
+        if (do_esync() && list_empty( &server->queue ))
+            esync_clear( server->esync_fd );
     }
 
     if (ioctl)
@@ -1633,7 +1657,11 @@ DECL_HANDLER(get_next_console_request)
         free( ioctl );
         if (iosb) release_object( iosb );
 
-        if (req->read) goto done;
+        if (req->read)
+        {
+            release_object( server );
+            return;
+        }
         server->busy = 0;
     }
 
@@ -1691,8 +1719,8 @@ DECL_HANDLER(get_next_console_request)
     {
         set_error( STATUS_PENDING );
     }
+    if (do_esync() && list_empty( &server->queue ))
+        esync_clear( server->esync_fd );
 
-done:
-    if (list_empty( &server->queue )) reset_sync( server->sync );
     release_object( server );
 }
diff -ruN --show-c-function --no-dereference server/debugger.c server/debugger.c
--- server/debugger.c	2025-09-06 20:10:25.816738436 -0700
+++ server/debugger.c	2025-09-06 19:58:17.763702564 -0700
@@ -43,7 +43,6 @@ enum debug_event_state { EVENT_QUEUED, E
 struct debug_event
 {
     struct object          obj;       /* object header */
-    struct event_sync     *sync;      /* sync object for wait/signal */
     struct list            entry;     /* entry in event queue */
     struct thread         *sender;    /* thread which sent this event */
     struct file           *file;      /* file object for events that need one */
@@ -70,14 +69,13 @@ struct type_descr debug_obj_type =
 struct debug_obj
 {
     struct object        obj;         /* object header */
-    struct event_sync   *sync;       /* sync object for wait/signal */
     struct list          event_queue; /* pending events queue */
     unsigned int         flags;       /* debug flags */
 };
 
 
 static void debug_event_dump( struct object *obj, int verbose );
-static struct object *debug_event_get_sync( struct object *obj );
+static int debug_event_signaled( struct object *obj, struct wait_queue_entry *entry );
 static void debug_event_destroy( struct object *obj );
 
 static const struct object_ops debug_event_ops =
@@ -85,13 +83,13 @@ static const struct object_ops debug_eve
     sizeof(struct debug_event),    /* size */
     &no_type,                      /* type */
     debug_event_dump,              /* dump */
-    NULL,                          /* add_queue */
-    NULL,                          /* remove_queue */
-    NULL,                          /* signaled */
-    NULL,                          /* satisfied */
+    add_queue,                     /* add_queue */
+    remove_queue,                  /* remove_queue */
+    debug_event_signaled,          /* signaled */
+    NULL,                          /* get_esync_fd */
+    no_satisfied,                  /* satisfied */
     no_signal,                     /* signal */
     no_get_fd,                     /* get_fd */
-    debug_event_get_sync,          /* get_sync */
     default_map_access,            /* map_access */
     default_get_sd,                /* get_sd */
     default_set_sd,                /* set_sd */
@@ -106,7 +104,7 @@ static const struct object_ops debug_eve
 };
 
 static void debug_obj_dump( struct object *obj, int verbose );
-static struct object *debug_obj_get_sync( struct object *obj );
+static int debug_obj_signaled( struct object *obj, struct wait_queue_entry *entry );
 static void debug_obj_destroy( struct object *obj );
 
 static const struct object_ops debug_obj_ops =
@@ -114,13 +112,13 @@ static const struct object_ops debug_obj
     sizeof(struct debug_obj),      /* size */
     &debug_obj_type,               /* type */
     debug_obj_dump,                /* dump */
-    NULL,                          /* add_queue */
-    NULL,                          /* remove_queue */
-    NULL,                          /* signaled */
-    NULL,                          /* satisfied */
+    add_queue,                     /* add_queue */
+    remove_queue,                  /* remove_queue */
+    debug_obj_signaled,            /* signaled */
+    NULL,                          /* get_esync_fd */
+    no_satisfied,                  /* satisfied */
     no_signal,                     /* signal */
     no_get_fd,                     /* get_fd */
-    debug_obj_get_sync,            /* get_sync */
     default_map_access,            /* map_access */
     default_get_sd,                /* get_sd */
     default_set_sd,                /* set_sd */
@@ -256,7 +254,7 @@ static void link_event( struct debug_obj
     {
         /* grab reference since debugger could be killed while trying to wake up */
         grab_object( debug_obj );
-        signal_sync( debug_obj->sync );
+        wake_up( &debug_obj->obj, 0 );
         release_object( debug_obj );
     }
 }
@@ -265,11 +263,10 @@ static void link_event( struct debug_obj
 static void resume_event( struct debug_obj *debug_obj, struct debug_event *event )
 {
     event->state = EVENT_QUEUED;
-    reset_sync( event->sync );
     if (!event->sender->process->debug_event)
     {
         grab_object( debug_obj );
-        signal_sync( debug_obj->sync );
+        wake_up( &debug_obj->obj, 0 );
         release_object( debug_obj );
     }
 }
@@ -278,7 +275,6 @@ static void resume_event( struct debug_o
 static void delay_event( struct debug_obj *debug_obj, struct debug_event *event )
 {
     event->state = EVENT_DELAYED;
-    reset_sync( event->sync );
     if (event->sender->process->debug_event == event) event->sender->process->debug_event = NULL;
 }
 
@@ -305,11 +301,11 @@ static void debug_event_dump( struct obj
              debug_event->sender, debug_event->data.code, debug_event->state );
 }
 
-static struct object *debug_event_get_sync( struct object *obj )
+static int debug_event_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct debug_event *debug_event = (struct debug_event *)obj;
     assert( obj->ops == &debug_event_ops );
-    return grab_object( debug_event->sync );
+    return debug_event->state == EVENT_CONTINUED;
 }
 
 static void debug_event_destroy( struct object *obj )
@@ -317,7 +313,6 @@ static void debug_event_destroy( struct
     struct debug_event *event = (struct debug_event *)obj;
     assert( obj->ops == &debug_event_ops );
 
-    if (event->sync) release_object( event->sync );
     if (event->file) release_object( event->file );
     release_object( event->sender );
 }
@@ -330,11 +325,11 @@ static void debug_obj_dump( struct objec
              debug_obj->event_queue.next, debug_obj->event_queue.prev );
 }
 
-static struct object *debug_obj_get_sync( struct object *obj )
+static int debug_obj_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct debug_obj *debug_obj = (struct debug_obj *)obj;
     assert( obj->ops == &debug_obj_ops );
-    return grab_object( debug_obj->sync );
+    return find_event_to_send( debug_obj ) != NULL;
 }
 
 static void debug_obj_destroy( struct object *obj )
@@ -349,8 +344,6 @@ static void debug_obj_destroy( struct ob
     /* free all pending events */
     while ((ptr = list_head( &debug_obj->event_queue )))
         unlink_event( debug_obj, LIST_ENTRY( ptr, struct debug_event, entry ));
-
-    if (debug_obj->sync) release_object( debug_obj->sync );
 }
 
 struct debug_obj *get_debug_obj( struct process *process, obj_handle_t handle, unsigned int access )
@@ -368,15 +361,8 @@ static struct debug_obj *create_debug_ob
     {
         if (get_error() != STATUS_OBJECT_NAME_EXISTS)
         {
-            debug_obj->sync  = NULL;
             debug_obj->flags = flags;
             list_init( &debug_obj->event_queue );
-
-            if (!(debug_obj->sync = create_event_sync( 1, 0 )))
-            {
-                release_object( debug_obj );
-                return NULL;
-            }
         }
     }
     return debug_obj;
@@ -422,7 +408,7 @@ static int continue_debug_event( struct
                 assert( event->sender->process->debug_event == event );
                 event->status = status;
                 event->state  = EVENT_CONTINUED;
-                signal_sync( event->sync );
+                wake_up( &event->obj, 0 );
                 unlink_event( debug_obj, event );
                 resume_process( process );
                 return 1;
@@ -443,20 +429,12 @@ static struct debug_event *alloc_debug_e
 
     /* build the event */
     if (!(event = alloc_object( &debug_event_ops ))) return NULL;
-    event->sync      = NULL;
     event->state     = EVENT_QUEUED;
     event->sender    = (struct thread *)grab_object( thread );
     event->file      = NULL;
     memset( &event->data, 0, sizeof(event->data) );
     fill_debug_event[code - DbgCreateThreadStateChange]( event, arg );
     event->data.code = code;
-
-    if (!(event->sync = create_event_sync( 1, 0 )))
-    {
-        release_object( event );
-        return NULL;
-    }
-
     return event;
 }
 
@@ -542,7 +520,7 @@ void debugger_detach( struct process *pr
         assert( event->state != EVENT_CONTINUED );
         event->status = DBG_CONTINUE;
         event->state  = EVENT_CONTINUED;
-        signal_sync( event->sync );
+        wake_up( &event->obj, 0 );
         unlink_event( debug_obj, event );
         /* from queued debug event */
         resume_process( process );
@@ -588,13 +566,11 @@ DECL_HANDLER(wait_debug_event)
     if ((event = find_event_to_send( debug_obj )))
     {
         event->state = EVENT_SENT;
-        reset_sync( event->sync );
         event->sender->process->debug_event = event;
         reply->pid = get_process_id( event->sender->process );
         reply->tid = get_thread_id( event->sender );
         alloc_event_handles( event, current->process );
         set_reply_data( &event->data, min( get_reply_max_size(), sizeof(event->data) ));
-        if (!find_event_to_send( debug_obj )) reset_sync( debug_obj->sync );
     }
     else
     {
diff -ruN --show-c-function --no-dereference server/device.c server/device.c
--- server/device.c	2025-09-06 20:10:25.816738436 -0700
+++ server/device.c	2025-09-06 19:58:17.773995114 -0700
@@ -38,6 +38,7 @@
 #include "handle.h"
 #include "request.h"
 #include "process.h"
+#include "esync.h"
 
 /* IRP object */
 
@@ -66,10 +67,10 @@ static const struct object_ops irp_call_
     no_add_queue,                     /* add_queue */
     NULL,                             /* remove_queue */
     NULL,                             /* signaled */
+    NULL,                             /* get_esync_fd */
     NULL,                             /* satisfied */
     no_signal,                        /* signal */
     no_get_fd,                        /* get_fd */
-    default_get_sync,                 /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -89,15 +90,16 @@ static const struct object_ops irp_call_
 struct device_manager
 {
     struct object          obj;            /* object header */
-    struct event_sync     *sync;           /* sync object for wait/signal */
     struct list            devices;        /* list of devices */
     struct list            requests;       /* list of pending irps across all devices */
     struct irp_call       *current_call;   /* call currently executed on client side */
     struct wine_rb_tree    kernel_objects; /* map of objects that have client side pointer associated */
+    int                    esync_fd;       /* esync file descriptor */
 };
 
 static void device_manager_dump( struct object *obj, int verbose );
-static struct object *device_manager_get_sync( struct object *obj );
+static int device_manager_signaled( struct object *obj, struct wait_queue_entry *entry );
+static int device_manager_get_esync_fd( struct object *obj, enum esync_type *type );
 static void device_manager_destroy( struct object *obj );
 
 static const struct object_ops device_manager_ops =
@@ -105,13 +107,13 @@ static const struct object_ops device_ma
     sizeof(struct device_manager),    /* size */
     &no_type,                         /* type */
     device_manager_dump,              /* dump */
-    NULL,                             /* add_queue */
-    NULL,                             /* remove_queue */
-    NULL,                             /* signaled */
-    NULL,                             /* satisfied */
+    add_queue,                        /* add_queue */
+    remove_queue,                     /* remove_queue */
+    device_manager_signaled,          /* signaled */
+    device_manager_get_esync_fd,      /* get_esync_fd */
+    no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     no_get_fd,                        /* get_fd */
-    device_manager_get_sync,          /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -166,10 +168,10 @@ static const struct object_ops device_op
     no_add_queue,                     /* add_queue */
     NULL,                             /* remove_queue */
     NULL,                             /* signaled */
+    NULL,                             /* get_esync_fd */
     no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     no_get_fd,                        /* get_fd */
-    default_get_sync,                 /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -216,13 +218,13 @@ static const struct object_ops device_fi
     sizeof(struct device_file),       /* size */
     &file_type,                       /* type */
     device_file_dump,                 /* dump */
-    NULL,                             /* add_queue */
-    NULL,                             /* remove_queue */
-    NULL,                             /* signaled */
-    NULL,                             /* satisfied */
+    add_queue,                        /* add_queue */
+    remove_queue,                     /* remove_queue */
+    default_fd_signaled,              /* signaled */
+    NULL,                             /* get_esync_fd */
+    no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     device_file_get_fd,               /* get_fd */
-    default_fd_get_sync,              /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -423,7 +425,7 @@ static void add_irp_to_queue( struct dev
     irp->thread = thread ? (struct thread *)grab_object( thread ) : NULL;
     if (irp->file) list_add_tail( &irp->file->requests, &irp->dev_entry );
     list_add_tail( &manager->requests, &irp->mgr_entry );
-    if (list_head( &manager->requests ) == &irp->mgr_entry) signal_sync( manager->sync );
+    if (list_head( &manager->requests ) == &irp->mgr_entry) wake_up( &manager->obj, 0 );  /* first one */
 }
 
 static struct object *device_open_file( struct object *obj, unsigned int access,
@@ -753,7 +755,6 @@ struct object *create_unix_device( struc
 /* terminate requests when the underlying device is deleted */
 static void delete_file( struct device_file *file )
 {
-    struct device_manager *manager = file->device->manager;
     struct irp_call *irp, *next;
 
     /* the pending requests may be the only thing holding a reference to the file */
@@ -762,11 +763,13 @@ static void delete_file( struct device_f
     /* terminate all pending requests */
     LIST_FOR_EACH_ENTRY_SAFE( irp, next, &file->requests, struct irp_call, dev_entry )
     {
+        if (do_esync() && file->device->manager && list_empty( &file->device->manager->requests ))
+            esync_clear( file->device->manager->esync_fd );
+
         list_remove( &irp->mgr_entry );
         set_irp_result( irp, STATUS_FILE_DELETED, NULL, 0, 0 );
     }
 
-    if (list_empty( &manager->requests )) reset_sync( manager->sync );
     release_object( file );
 }
 
@@ -791,11 +794,18 @@ static void device_manager_dump( struct
     fprintf( stderr, "Device manager\n" );
 }
 
-static struct object *device_manager_get_sync( struct object *obj )
+static int device_manager_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct device_manager *manager = (struct device_manager *)obj;
-    assert( obj->ops == &device_manager_ops );
-    return grab_object( manager->sync );
+
+    return !list_empty( &manager->requests );
+}
+
+static int device_manager_get_esync_fd( struct object *obj, enum esync_type *type )
+{
+    struct device_manager *manager = (struct device_manager *)obj;
+    *type = ESYNC_MANUAL_SERVER;
+    return manager->esync_fd;
 }
 
 static void device_manager_destroy( struct object *obj )
@@ -833,7 +843,8 @@ static void device_manager_destroy( stru
         release_object( irp );
     }
 
-    if (manager->sync) release_object( manager->sync );
+    if (do_esync())
+        close( manager->esync_fd );
 }
 
 static struct device_manager *create_device_manager(void)
@@ -842,17 +853,13 @@ static struct device_manager *create_dev
 
     if ((manager = alloc_object( &device_manager_ops )))
     {
-        manager->sync         = NULL;
         manager->current_call = NULL;
         list_init( &manager->devices );
         list_init( &manager->requests );
         wine_rb_init( &manager->kernel_objects, compare_kernel_object );
 
-        if (!(manager->sync = create_event_sync( 1, 0 )))
-        {
-            release_object( manager );
-            return NULL;
-        }
+        if (do_esync())
+            manager->esync_fd = esync_create_fd( 0, 0 );
     }
     return manager;
 }
@@ -1039,11 +1046,12 @@ DECL_HANDLER(get_next_device_request)
                 }
                 list_remove( &irp->mgr_entry );
                 list_init( &irp->mgr_entry );
-                if (list_empty( &manager->requests )) reset_sync( manager->sync );
-
                 /* we already own the object if it's only on manager queue */
                 if (irp->file) grab_object( irp );
                 manager->current_call = irp;
+
+                if (do_esync() && list_empty( &manager->requests ))
+                    esync_clear( manager->esync_fd );
             }
             else close_handle( current->process, reply->next );
         }
diff -ruN --show-c-function --no-dereference server/directory.c server/directory.c
--- server/directory.c	2025-09-06 20:10:25.816738436 -0700
+++ server/directory.c	2025-09-06 19:58:17.764005020 -0700
@@ -69,10 +69,10 @@ static const struct object_ops object_ty
     no_add_queue,                 /* add_queue */
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
+    NULL,                         /* get_esync_fd */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-    default_get_sync,             /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
@@ -120,10 +120,10 @@ static const struct object_ops directory
     no_add_queue,                 /* add_queue */
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
+    NULL,                         /* get_esync_fd */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-    default_get_sync,             /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
diff -ruN --show-c-function --no-dereference server/esync.c server/esync.c
--- server/esync.c	1969-12-31 16:00:00.000000000 -0800
+++ server/esync.c	2025-09-06 19:58:17.787193415 -0700
@@ -0,0 +1,588 @@
+/*
+ * eventfd-based synchronization objects
+ *
+ * Copyright (C) 2018 Zebediah Figura
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
+ */
+
+#include "config.h"
+
+
+#include <fcntl.h>
+#include <stdio.h>
+#include <stdarg.h>
+#ifdef HAVE_SYS_EVENTFD_H
+# include <sys/eventfd.h>
+#endif
+#include <sys/mman.h>
+#ifdef HAVE_SYS_STAT_H
+# include <sys/stat.h>
+#endif
+#include <unistd.h>
+
+#include "ntstatus.h"
+#define WIN32_NO_STATUS
+#include "windef.h"
+#include "winternl.h"
+
+#include "handle.h"
+#include "request.h"
+#include "file.h"
+#include "esync.h"
+
+int do_esync(void)
+{
+#ifdef HAVE_SYS_EVENTFD_H
+    static int do_esync_cached = -1;
+
+    if (do_esync_cached == -1)
+        do_esync_cached = getenv("WINEESYNC") && atoi(getenv("WINEESYNC"));
+
+    return do_esync_cached;
+#else
+    return 0;
+#endif
+}
+
+static char shm_name[29];
+static int shm_fd;
+static off_t shm_size;
+static void **shm_addrs;
+static int shm_addrs_size;  /* length of the allocated shm_addrs array */
+static long pagesize;
+
+static void shm_cleanup(void)
+{
+    close( shm_fd );
+    if (shm_unlink( shm_name ) == -1)
+        perror( "shm_unlink" );
+}
+
+void esync_init(void)
+{
+    struct stat st;
+
+    if (fstat( config_dir_fd, &st ) == -1)
+        fatal_error( "cannot stat config dir\n" );
+
+    if (st.st_ino != (unsigned long)st.st_ino)
+        sprintf( shm_name, "/wine-%lx%08lx-esync", (unsigned long)((unsigned long long)st.st_ino >> 32), (unsigned long)st.st_ino );
+    else
+        sprintf( shm_name, "/wine-%lx-esync", (unsigned long)st.st_ino );
+
+    shm_unlink( shm_name );
+
+    shm_fd = shm_open( shm_name, O_RDWR | O_CREAT | O_EXCL, 0644 );
+    if (shm_fd == -1)
+        perror( "shm_open" );
+
+    pagesize = sysconf( _SC_PAGESIZE );
+
+    shm_addrs = calloc( 128, sizeof(shm_addrs[0]) );
+    shm_addrs_size = 128;
+
+    shm_size = pagesize;
+    if (ftruncate( shm_fd, shm_size ) == -1)
+        perror( "ftruncate" );
+
+    fprintf( stderr, "esync: up and running.\n" );
+
+    atexit( shm_cleanup );
+}
+
+static struct list mutex_list = LIST_INIT(mutex_list);
+
+struct esync
+{
+    struct object   obj;            /* object header */
+    int             fd;             /* eventfd file descriptor */
+    enum esync_type type;
+    unsigned int    shm_idx;        /* index into the shared memory section */
+    struct list     mutex_entry;    /* entry in the mutex list (if applicable) */
+};
+
+static void esync_dump( struct object *obj, int verbose );
+static int esync_get_esync_fd( struct object *obj, enum esync_type *type );
+static unsigned int esync_map_access( struct object *obj, unsigned int access );
+static void esync_destroy( struct object *obj );
+
+const struct object_ops esync_ops =
+{
+    sizeof(struct esync),      /* size */
+    &no_type,                  /* type */
+    esync_dump,                /* dump */
+    no_add_queue,              /* add_queue */
+    NULL,                      /* remove_queue */
+    NULL,                      /* signaled */
+    esync_get_esync_fd,        /* get_esync_fd */
+    NULL,                      /* satisfied */
+    no_signal,                 /* signal */
+    no_get_fd,                 /* get_fd */
+    esync_map_access,          /* map_access */
+    default_get_sd,            /* get_sd */
+    default_set_sd,            /* set_sd */
+    default_get_full_name,     /* get_full_name */
+    no_lookup_name,            /* lookup_name */
+    directory_link_name,       /* link_name */
+    default_unlink_name,       /* unlink_name */
+    no_open_file,              /* open_file */
+    no_kernel_obj_list,        /* get_kernel_obj_list */
+    no_close_handle,           /* close_handle */
+    esync_destroy              /* destroy */
+};
+
+static void esync_dump( struct object *obj, int verbose )
+{
+    struct esync *esync = (struct esync *)obj;
+    assert( obj->ops == &esync_ops );
+    fprintf( stderr, "esync fd=%d\n", esync->fd );
+}
+
+static int esync_get_esync_fd( struct object *obj, enum esync_type *type )
+{
+    struct esync *esync = (struct esync *)obj;
+    *type = esync->type;
+    return esync->fd;
+}
+
+static unsigned int esync_map_access( struct object *obj, unsigned int access )
+{
+    /* Sync objects have the same flags. */
+    if (access & GENERIC_READ)    access |= STANDARD_RIGHTS_READ | EVENT_QUERY_STATE;
+    if (access & GENERIC_WRITE)   access |= STANDARD_RIGHTS_WRITE | EVENT_MODIFY_STATE;
+    if (access & GENERIC_EXECUTE) access |= STANDARD_RIGHTS_EXECUTE | SYNCHRONIZE;
+    if (access & GENERIC_ALL)     access |= STANDARD_RIGHTS_ALL | EVENT_QUERY_STATE | EVENT_MODIFY_STATE;
+    return access & ~(GENERIC_READ | GENERIC_WRITE | GENERIC_EXECUTE | GENERIC_ALL);
+}
+
+static void esync_destroy( struct object *obj )
+{
+    struct esync *esync = (struct esync *)obj;
+    if (esync->type == ESYNC_MUTEX)
+        list_remove( &esync->mutex_entry );
+    close( esync->fd );
+}
+
+static int type_matches( enum esync_type type1, enum esync_type type2 )
+{
+    return (type1 == type2) ||
+           ((type1 == ESYNC_AUTO_EVENT || type1 == ESYNC_MANUAL_EVENT) &&
+            (type2 == ESYNC_AUTO_EVENT || type2 == ESYNC_MANUAL_EVENT));
+}
+
+static void *get_shm( unsigned int idx )
+{
+    int entry  = (idx * 8) / pagesize;
+    int offset = (idx * 8) % pagesize;
+
+    if (entry >= shm_addrs_size)
+    {
+        int new_size = max(shm_addrs_size * 2, entry + 1);
+
+        if (!(shm_addrs = realloc( shm_addrs, new_size * sizeof(shm_addrs[0]) )))
+            fprintf( stderr, "esync: couldn't expand shm_addrs array to size %d\n", entry + 1 );
+
+        memset( shm_addrs + shm_addrs_size, 0, (new_size - shm_addrs_size) * sizeof(shm_addrs[0]) );
+
+        shm_addrs_size = new_size;
+    }
+
+    if (!shm_addrs[entry])
+    {
+        void *addr = mmap( NULL, pagesize, PROT_READ | PROT_WRITE, MAP_SHARED, shm_fd, entry * pagesize );
+        if (addr == (void *)-1)
+        {
+            fprintf( stderr, "esync: failed to map page %d (offset %#lx): ", entry, entry * pagesize );
+            perror( "mmap" );
+        }
+
+        if (debug_level)
+            fprintf( stderr, "esync: Mapping page %d at %p.\n", entry, addr );
+
+        if (__sync_val_compare_and_swap( &shm_addrs[entry], 0, addr ))
+            munmap( addr, pagesize ); /* someone beat us to it */
+    }
+
+    return (void *)((unsigned long)shm_addrs[entry] + offset);
+}
+
+struct semaphore
+{
+    int max;
+    int count;
+};
+C_ASSERT(sizeof(struct semaphore) == 8);
+
+struct mutex
+{
+    DWORD tid;
+    int count;    /* recursion count */
+};
+C_ASSERT(sizeof(struct mutex) == 8);
+
+struct event
+{
+    int signaled;
+    int locked;
+};
+C_ASSERT(sizeof(struct event) == 8);
+
+struct esync *create_esync( struct object *root, const struct unicode_str *name,
+                            unsigned int attr, int initval, int max, enum esync_type type,
+                            const struct security_descriptor *sd )
+{
+#ifdef HAVE_SYS_EVENTFD_H
+    struct esync *esync;
+
+    if ((esync = create_named_object( root, &esync_ops, name, attr, sd )))
+    {
+        if (get_error() != STATUS_OBJECT_NAME_EXISTS)
+        {
+            int flags = EFD_CLOEXEC | EFD_NONBLOCK;
+
+            if (type == ESYNC_SEMAPHORE)
+                flags |= EFD_SEMAPHORE;
+
+            /* initialize it if it didn't already exist */
+            esync->fd = eventfd( initval, flags );
+            if (esync->fd == -1)
+            {
+                perror( "eventfd" );
+                file_set_error();
+                release_object( esync );
+                return NULL;
+            }
+            esync->type = type;
+
+            /* Use the fd as index, since that'll be unique across all
+             * processes, but should hopefully end up also allowing reuse. */
+            esync->shm_idx = esync->fd + 1; /* we keep index 0 reserved */
+            while (esync->shm_idx * 8 >= shm_size)
+            {
+                /* Better expand the shm section. */
+                shm_size += pagesize;
+                if (ftruncate( shm_fd, shm_size ) == -1)
+                {
+                    fprintf( stderr, "esync: couldn't expand %s to size %ld: ",
+                             shm_name, (long)shm_size );
+                    perror( "ftruncate" );
+                }
+            }
+
+            /* Initialize the shared memory portion. We want to do this on the
+             * server side to avoid a potential though unlikely race whereby
+             * the same object is opened and used between the time it's created
+             * and the time its shared memory portion is initialized. */
+            switch (type)
+            {
+            case ESYNC_SEMAPHORE:
+            {
+                struct semaphore *semaphore = get_shm( esync->shm_idx );
+                semaphore->max = max;
+                semaphore->count = initval;
+                break;
+            }
+            case ESYNC_AUTO_EVENT:
+            case ESYNC_MANUAL_EVENT:
+            {
+                struct event *event = get_shm( esync->shm_idx );
+                event->signaled = initval ? 1 : 0;
+                event->locked = 0;
+                break;
+            }
+            case ESYNC_MUTEX:
+            {
+                struct mutex *mutex = get_shm( esync->shm_idx );
+                mutex->tid = initval ? 0 : current->id;
+                mutex->count = initval ? 0 : 1;
+                list_add_tail( &mutex_list, &esync->mutex_entry );
+                break;
+            }
+            default:
+                assert( 0 );
+            }
+        }
+        else
+        {
+            /* validate the type */
+            if (!type_matches( type, esync->type ))
+            {
+                release_object( &esync->obj );
+                set_error( STATUS_OBJECT_TYPE_MISMATCH );
+                return NULL;
+            }
+        }
+    }
+    return esync;
+#else
+    /* FIXME: Provide a fallback implementation using pipe(). */
+    set_error( STATUS_NOT_IMPLEMENTED );
+    return NULL;
+#endif
+}
+
+/* Create a file descriptor for an existing handle.
+ * Caller must close the handle when it's done; it's not linked to an esync
+ * server object in any way. */
+int esync_create_fd( int initval, int flags )
+{
+#ifdef HAVE_SYS_EVENTFD_H
+    int fd;
+
+    fd = eventfd( initval, flags | EFD_CLOEXEC | EFD_NONBLOCK );
+    if (fd == -1)
+        perror( "eventfd" );
+
+    return fd;
+#else
+    return -1;
+#endif
+}
+
+/* Wake up a specific fd. */
+void esync_wake_fd( int fd )
+{
+    static const uint64_t value = 1;
+
+    if (write( fd, &value, sizeof(value) ) == -1)
+        perror( "esync: write" );
+}
+
+/* Wake up a server-side esync object. */
+void esync_wake_up( struct object *obj )
+{
+    enum esync_type dummy;
+    int fd;
+
+    if (obj->ops->get_esync_fd)
+    {
+        fd = obj->ops->get_esync_fd( obj, &dummy );
+        esync_wake_fd( fd );
+    }
+}
+
+void esync_clear( int fd )
+{
+    uint64_t value;
+
+    /* we don't care about the return value */
+    read( fd, &value, sizeof(value) );
+}
+
+static inline void small_pause(void)
+{
+#ifdef __i386__
+    __asm__ __volatile__( "rep;nop" : : : "memory" );
+#else
+    __asm__ __volatile__( "" : : : "memory" );
+#endif
+}
+
+/* Server-side event support. */
+void esync_set_event( struct esync *esync )
+{
+    static const uint64_t value = 1;
+    struct event *event = get_shm( esync->shm_idx );
+
+    assert( esync->obj.ops == &esync_ops );
+    assert( event != NULL );
+
+    if (debug_level)
+        fprintf( stderr, "esync_set_event() fd=%d\n", esync->fd );
+
+    if (esync->type == ESYNC_MANUAL_EVENT)
+    {
+        /* Acquire the spinlock. */
+        while (__sync_val_compare_and_swap( &event->locked, 0, 1 ))
+            small_pause();
+    }
+
+    if (!__atomic_exchange_n( &event->signaled, 1, __ATOMIC_SEQ_CST ))
+    {
+        if (write( esync->fd, &value, sizeof(value) ) == -1)
+            perror( "esync: write" );
+    }
+
+    if (esync->type == ESYNC_MANUAL_EVENT)
+    {
+        /* Release the spinlock. */
+        event->locked = 0;
+    }
+}
+
+void esync_reset_event( struct esync *esync )
+{
+    static uint64_t value = 1;
+    struct event *event = get_shm( esync->shm_idx );
+
+    assert( esync->obj.ops == &esync_ops );
+    assert( event != NULL );
+
+    if (debug_level)
+        fprintf( stderr, "esync_reset_event() fd=%d\n", esync->fd );
+
+    if (esync->type == ESYNC_MANUAL_EVENT)
+    {
+        /* Acquire the spinlock. */
+        while (__sync_val_compare_and_swap( &event->locked, 0, 1 ))
+            small_pause();
+    }
+
+    /* Only bother signaling the fd if we weren't already signaled. */
+    if (__atomic_exchange_n( &event->signaled, 0, __ATOMIC_SEQ_CST ))
+    {
+        /* we don't care about the return value */
+        read( esync->fd, &value, sizeof(value) );
+    }
+
+    if (esync->type == ESYNC_MANUAL_EVENT)
+    {
+        /* Release the spinlock. */
+        event->locked = 0;
+    }
+}
+
+void esync_abandon_mutexes( struct thread *thread )
+{
+    struct esync *esync;
+
+    LIST_FOR_EACH_ENTRY( esync, &mutex_list, struct esync, mutex_entry )
+    {
+        struct mutex *mutex = get_shm( esync->shm_idx );
+
+        if (mutex->tid == thread->id)
+        {
+            if (debug_level)
+                fprintf( stderr, "esync_abandon_mutexes() fd=%d\n", esync->fd );
+            mutex->tid = ~0;
+            mutex->count = 0;
+            esync_wake_fd( esync->fd );
+        }
+    }
+}
+
+DECL_HANDLER(create_esync)
+{
+    struct esync *esync;
+    struct unicode_str name;
+    struct object *root;
+    const struct security_descriptor *sd;
+    const struct object_attributes *objattr = get_req_object_attributes( &sd, &name, &root );
+
+    if (!do_esync())
+    {
+        set_error( STATUS_NOT_IMPLEMENTED );
+        return;
+    }
+
+    if (!req->type)
+    {
+        set_error( STATUS_INVALID_PARAMETER );
+        return;
+    }
+
+    if (!objattr) return;
+
+    if ((esync = create_esync( root, &name, objattr->attributes, req->initval, req->max, req->type, sd )))
+    {
+        if (get_error() == STATUS_OBJECT_NAME_EXISTS)
+            reply->handle = alloc_handle( current->process, esync, req->access, objattr->attributes );
+        else
+            reply->handle = alloc_handle_no_access_check( current->process, esync,
+                                                          req->access, objattr->attributes );
+
+        reply->type = esync->type;
+        reply->shm_idx = esync->shm_idx;
+        send_client_fd( current->process, esync->fd, reply->handle );
+        release_object( esync );
+    }
+
+    if (root) release_object( root );
+}
+
+DECL_HANDLER(open_esync)
+{
+    struct unicode_str name = get_req_unicode_str();
+
+    reply->handle = open_object( current->process, req->rootdir, req->access,
+                                 &esync_ops, &name, req->attributes );
+
+    /* send over the fd */
+    if (reply->handle)
+    {
+        struct esync *esync;
+
+        if (!(esync = (struct esync *)get_handle_obj( current->process, reply->handle,
+                                                      0, &esync_ops )))
+            return;
+
+        if (!type_matches( req->type, esync->type ))
+        {
+            set_error( STATUS_OBJECT_TYPE_MISMATCH );
+            release_object( esync );
+            return;
+        }
+
+        reply->type = esync->type;
+        reply->shm_idx = esync->shm_idx;
+
+        send_client_fd( current->process, esync->fd, reply->handle );
+        release_object( esync );
+    }
+}
+
+/* Retrieve a file descriptor for an esync object which will be signaled by the
+ * server. The client should only read from (i.e. wait on) this object. */
+DECL_HANDLER(get_esync_fd)
+{
+    struct object *obj;
+    enum esync_type type;
+    int fd;
+
+    if (!(obj = get_handle_obj( current->process, req->handle, SYNCHRONIZE, NULL )))
+        return;
+
+    if (obj->ops->get_esync_fd)
+    {
+        fd = obj->ops->get_esync_fd( obj, &type );
+        reply->type = type;
+        if (obj->ops == &esync_ops)
+        {
+            struct esync *esync = (struct esync *)obj;
+            reply->shm_idx = esync->shm_idx;
+        }
+        else
+            reply->shm_idx = 0;
+        send_client_fd( current->process, fd, req->handle );
+    }
+    else
+    {
+        if (debug_level)
+        {
+            fprintf( stderr, "%04x: esync: can't wait on object: ", current->id );
+            obj->ops->dump( obj, 0 );
+        }
+        set_error( STATUS_NOT_IMPLEMENTED );
+    }
+
+    release_object( obj );
+}
+
+/* Return the fd used for waiting on user APCs. */
+DECL_HANDLER(get_esync_apc_fd)
+{
+    send_client_fd( current->process, current->esync_apc_fd, current->id );
+}
diff -ruN --show-c-function --no-dereference server/esync.h server/esync.h
--- server/esync.h	1969-12-31 16:00:00.000000000 -0800
+++ server/esync.h	2025-09-06 19:58:17.787337679 -0700
@@ -0,0 +1,35 @@
+/*
+ * eventfd-based synchronization objects
+ *
+ * Copyright (C) 2018 Zebediah Figura
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
+ */
+
+#include <unistd.h>
+
+extern int do_esync(void);
+void esync_init(void);
+int esync_create_fd( int initval, int flags );
+void esync_wake_fd( int fd );
+void esync_wake_up( struct object *obj );
+void esync_clear( int fd );
+
+struct esync;
+
+extern const struct object_ops esync_ops;
+void esync_set_event( struct esync *esync );
+void esync_reset_event( struct esync *esync );
+void esync_abandon_mutexes( struct thread *thread );
diff -ruN --show-c-function --no-dereference server/event.c server/event.c
--- server/event.c	2025-09-06 20:10:25.816738436 -0700
+++ server/event.c	2025-09-06 19:58:17.771548137 -0700
@@ -35,6 +35,7 @@
 #include "thread.h"
 #include "request.h"
 #include "security.h"
+#include "esync.h"
 
 static const WCHAR event_name[] = {'E','v','e','n','t'};
 
@@ -50,106 +51,19 @@ struct type_descr event_type =
     },
 };
 
-struct event_sync
-{
-    struct object  obj;             /* object header */
-    unsigned int   manual : 1;      /* is it a manual reset event? */
-    unsigned int   signaled : 1;    /* event has been signaled */
-};
-
-static void event_sync_dump( struct object *obj, int verbose );
-static int event_sync_signaled( struct object *obj, struct wait_queue_entry *entry );
-static void event_sync_satisfied( struct object *obj, struct wait_queue_entry *entry );
-static int event_sync_signal( struct object *obj, unsigned int access );
-
-static const struct object_ops event_sync_ops =
-{
-    sizeof(struct event_sync), /* size */
-    &no_type,                  /* type */
-    event_sync_dump,           /* dump */
-    add_queue,                 /* add_queue */
-    remove_queue,              /* remove_queue */
-    event_sync_signaled,       /* signaled */
-    event_sync_satisfied,      /* satisfied */
-    event_sync_signal,         /* signal */
-    no_get_fd,                 /* get_fd */
-    default_get_sync,          /* get_sync */
-    default_map_access,        /* map_access */
-    default_get_sd,            /* get_sd */
-    default_set_sd,            /* set_sd */
-    default_get_full_name,     /* get_full_name */
-    no_lookup_name,            /* lookup_name */
-    directory_link_name,       /* link_name */
-    default_unlink_name,       /* unlink_name */
-    no_open_file,              /* open_file */
-    no_kernel_obj_list,        /* get_kernel_obj_list */
-    no_close_handle,           /* close_handle */
-    no_destroy                 /* destroy */
-};
-
-struct event_sync *create_event_sync( int manual, int signaled )
-{
-    struct event_sync *event;
-
-    if (!(event = alloc_object( &event_sync_ops ))) return NULL;
-    event->manual   = manual;
-    event->signaled = signaled;
-
-    return event;
-}
-
-static void event_sync_dump( struct object *obj, int verbose )
-{
-    struct event_sync *event = (struct event_sync *)obj;
-    assert( obj->ops == &event_sync_ops );
-    fprintf( stderr, "Event manual=%d signaled=%d\n",
-             event->manual, event->signaled );
-}
-
-static int event_sync_signaled( struct object *obj, struct wait_queue_entry *entry )
-{
-    struct event_sync *event = (struct event_sync *)obj;
-    assert( obj->ops == &event_sync_ops );
-    return event->signaled;
-}
-
-void signal_sync( struct event_sync *event )
-{
-    event->signaled = 1;
-    /* wake up all waiters if manual reset, a single one otherwise */
-    wake_up( &event->obj, !event->manual );
-}
-
-void reset_sync( struct event_sync *event )
-{
-    event->signaled = 0;
-}
-
-static void event_sync_satisfied( struct object *obj, struct wait_queue_entry *entry )
-{
-    struct event_sync *event = (struct event_sync *)obj;
-    assert( obj->ops == &event_sync_ops );
-    /* Reset if it's an auto-reset event */
-    if (!event->manual) reset_sync( event );
-}
-
-static int event_sync_signal( struct object *obj, unsigned int access )
-{
-    struct event_sync *event = (struct event_sync *)obj;
-    assert( obj->ops == &event_sync_ops );
-    signal_sync( event );
-    return 1;
-}
-
 struct event
 {
-    struct object      obj;             /* object header */
-    struct event_sync *sync;            /* event sync object */
-    struct list        kernel_object;   /* list of kernel object pointers */
+    struct object  obj;             /* object header */
+    struct list    kernel_object;   /* list of kernel object pointers */
+    int            manual_reset;    /* is it a manual reset event? */
+    int            signaled;        /* event has been signaled */
+    int            esync_fd;        /* esync file descriptor */
 };
 
 static void event_dump( struct object *obj, int verbose );
-static struct object *event_get_sync( struct object *obj );
+static int event_signaled( struct object *obj, struct wait_queue_entry *entry );
+static void event_satisfied( struct object *obj, struct wait_queue_entry *entry );
+static int event_get_esync_fd( struct object *obj, enum esync_type *type );
 static int event_signal( struct object *obj, unsigned int access);
 static struct list *event_get_kernel_obj_list( struct object *obj );
 static void event_destroy( struct object *obj );
@@ -159,13 +73,13 @@ static const struct object_ops event_ops
     sizeof(struct event),      /* size */
     &event_type,               /* type */
     event_dump,                /* dump */
-    NULL,                      /* add_queue */
-    NULL,                      /* remove_queue */
-    NULL,                      /* signaled */
-    NULL,                      /* satisfied */
+    add_queue,                 /* add_queue */
+    remove_queue,              /* remove_queue */
+    event_signaled,            /* signaled */
+    event_get_esync_fd,        /* get_esync_fd */
+    event_satisfied,           /* satisfied */
     event_signal,              /* signal */
     no_get_fd,                 /* get_fd */
-    event_get_sync,            /* get_sync */
     default_map_access,        /* map_access */
     default_get_sd,            /* get_sd */
     default_set_sd,            /* set_sd */
@@ -176,7 +90,7 @@ static const struct object_ops event_ops
     no_open_file,              /* open_file */
     event_get_kernel_obj_list, /* get_kernel_obj_list */
     no_close_handle,           /* close_handle */
-    event_destroy,             /* destroy */
+    event_destroy              /* destroy */
 };
 
 
@@ -210,10 +124,10 @@ static const struct object_ops keyed_eve
     add_queue,                   /* add_queue */
     remove_queue,                /* remove_queue */
     keyed_event_signaled,        /* signaled */
+    NULL,                        /* get_esync_fd */
     no_satisfied,                /* satisfied */
     no_signal,                   /* signal */
     no_get_fd,                   /* get_fd */
-    default_get_sync,            /* get_sync */
     default_map_access,          /* map_access */
     default_get_sd,              /* get_sd */
     default_set_sd,              /* set_sd */
@@ -239,14 +153,12 @@ struct event *create_event( struct objec
         if (get_error() != STATUS_OBJECT_NAME_EXISTS)
         {
             /* initialize it if it didn't already exist */
-            event->sync = NULL;
             list_init( &event->kernel_object );
+            event->manual_reset = manual_reset;
+            event->signaled     = initial_state;
 
-            if (!(event->sync = create_event_sync( manual_reset, initial_state )))
-            {
-                release_object( event );
-                return NULL;
-            }
+            if (do_esync())
+                event->esync_fd = esync_create_fd( initial_state, 0 );
         }
     }
     return event;
@@ -254,31 +166,75 @@ struct event *create_event( struct objec
 
 struct event *get_event_obj( struct process *process, obj_handle_t handle, unsigned int access )
 {
+    struct object *obj;
+    if (do_esync() && (obj = get_handle_obj( process, handle, access, &esync_ops)))
+        return (struct event *)obj; /* even though it's not an event */
+
     return (struct event *)get_handle_obj( process, handle, access, &event_ops );
 }
 
+static void pulse_event( struct event *event )
+{
+    event->signaled = 1;
+    /* wake up all waiters if manual reset, a single one otherwise */
+    wake_up( &event->obj, !event->manual_reset );
+    event->signaled = 0;
+}
+
 void set_event( struct event *event )
 {
-    signal_sync( event->sync );
+    if (do_esync() && event->obj.ops == &esync_ops)
+    {
+        esync_set_event( (struct esync *)event );
+        return;
+    }
+
+    event->signaled = 1;
+    /* wake up all waiters if manual reset, a single one otherwise */
+    wake_up( &event->obj, !event->manual_reset );
 }
 
 void reset_event( struct event *event )
 {
-    reset_sync( event->sync );
+    if (do_esync() && event->obj.ops == &esync_ops)
+    {
+        esync_reset_event( (struct esync *)event );
+        return;
+    }
+    event->signaled = 0;
+
+    if (do_esync())
+        esync_clear( event->esync_fd );
 }
 
 static void event_dump( struct object *obj, int verbose )
 {
     struct event *event = (struct event *)obj;
     assert( obj->ops == &event_ops );
-    event->sync->obj.ops->dump( &event->sync->obj, verbose );
+    fprintf( stderr, "Event manual=%d signaled=%d\n",
+             event->manual_reset, event->signaled );
 }
 
-static struct object *event_get_sync( struct object *obj )
+static int event_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct event *event = (struct event *)obj;
     assert( obj->ops == &event_ops );
-    return grab_object( event->sync );
+    return event->signaled;
+}
+
+static int event_get_esync_fd( struct object *obj, enum esync_type *type )
+{
+    struct event *event = (struct event *)obj;
+    *type = event->manual_reset ? ESYNC_MANUAL_SERVER : ESYNC_AUTO_SERVER;
+    return event->esync_fd;
+}
+
+static void event_satisfied( struct object *obj, struct wait_queue_entry *entry )
+{
+    struct event *event = (struct event *)obj;
+    assert( obj->ops == &event_ops );
+    /* Reset if it's an auto-reset event */
+    if (!event->manual_reset) event->signaled = 0;
 }
 
 static int event_signal( struct object *obj, unsigned int access )
@@ -304,9 +260,9 @@ static struct list *event_get_kernel_obj
 static void event_destroy( struct object *obj )
 {
     struct event *event = (struct event *)obj;
-    assert( obj->ops == &event_ops );
 
-    if (event->sync) release_object( event->sync );
+    if (do_esync())
+        close( event->esync_fd );
 }
 
 struct keyed_event *create_keyed_event( struct object *root, const struct unicode_str *name,
@@ -402,13 +358,11 @@ DECL_HANDLER(event_op)
     struct event *event;
 
     if (!(event = get_event_obj( current->process, req->handle, EVENT_MODIFY_STATE ))) return;
-
-    reply->state = event->sync->signaled;
+    reply->state = event->signaled;
     switch(req->op)
     {
     case PULSE_EVENT:
-        set_event( event );
-        reset_event( event );
+        pulse_event( event );
         break;
     case SET_EVENT:
         set_event( event );
@@ -430,8 +384,8 @@ DECL_HANDLER(query_event)
 
     if (!(event = get_event_obj( current->process, req->handle, EVENT_QUERY_STATE ))) return;
 
-    reply->manual_reset = event->sync->manual;
-    reply->state = event->sync->signaled;
+    reply->manual_reset = event->manual_reset;
+    reply->state = event->signaled;
 
     release_object( event );
 }
diff -ruN --show-c-function --no-dereference server/fd.c server/fd.c
--- server/fd.c	2025-09-06 20:10:25.817505002 -0700
+++ server/fd.c	2025-09-06 19:58:17.786695918 -0700
@@ -94,6 +94,7 @@
 #include "handle.h"
 #include "process.h"
 #include "request.h"
+#include "esync.h"
 
 #include "winternl.h"
 #include "winioctl.h"
@@ -129,7 +130,6 @@ struct fd
 {
     struct object        obj;         /* object header */
     const struct fd_ops *fd_ops;      /* file descriptor operations */
-    struct event_sync   *sync;        /* sync object for wait/signal */
     struct inode        *inode;       /* inode that this fd belongs to */
     struct list          inode_entry; /* entry in inode fd list */
     struct closed_fd    *closed;      /* structure to store the unix fd at destroy time */
@@ -146,6 +146,7 @@ struct fd
     int                  unix_fd;     /* unix file descriptor */
     unsigned int         no_fd_status;/* status to return when unix_fd is -1 */
     unsigned int         cacheable :1;/* can the fd be cached on the client side? */
+    unsigned int         signaled :1; /* is the fd signaled? */
     unsigned int         fs_locks :1; /* can we use filesystem locks for this fd? */
     int                  poll_index;  /* index of fd in poll array */
     struct async_queue   read_q;      /* async readers of this fd */
@@ -154,10 +155,10 @@ struct fd
     struct completion   *completion;  /* completion object attached to this fd */
     apc_param_t          comp_key;    /* completion key to set in completion events */
     unsigned int         comp_flags;  /* completion flags */
+    int                  esync_fd;    /* esync file descriptor */
 };
 
 static void fd_dump( struct object *obj, int verbose );
-static struct object *fd_get_sync( struct object *obj );
 static void fd_destroy( struct object *obj );
 
 static const struct object_ops fd_ops =
@@ -165,13 +166,13 @@ static const struct object_ops fd_ops =
     sizeof(struct fd),        /* size */
     &no_type,                 /* type */
     fd_dump,                  /* dump */
-    NULL,                     /* add_queue */
+    no_add_queue,             /* add_queue */
     NULL,                     /* remove_queue */
     NULL,                     /* signaled */
+    NULL,                     /* get_esync_fd */
     NULL,                     /* satisfied */
     no_signal,                /* signal */
     no_get_fd,                /* get_fd */
-    fd_get_sync,              /* get_sync */
     default_map_access,       /* map_access */
     default_get_sd,           /* get_sd */
     default_set_sd,           /* set_sd */
@@ -210,10 +211,10 @@ static const struct object_ops device_op
     no_add_queue,             /* add_queue */
     NULL,                     /* remove_queue */
     NULL,                     /* signaled */
+    NULL,                     /* get_esync_fd */
     NULL,                     /* satisfied */
     no_signal,                /* signal */
     no_get_fd,                /* get_fd */
-    default_get_sync,         /* get_sync */
     default_map_access,       /* map_access */
     default_get_sd,           /* get_sd */
     default_set_sd,           /* set_sd */
@@ -251,10 +252,10 @@ static const struct object_ops inode_ops
     no_add_queue,             /* add_queue */
     NULL,                     /* remove_queue */
     NULL,                     /* signaled */
+    NULL,                     /* get_esync_fd */
     NULL,                     /* satisfied */
     no_signal,                /* signal */
     no_get_fd,                /* get_fd */
-    default_get_sync,         /* get_sync */
     default_map_access,       /* map_access */
     default_get_sd,           /* get_sd */
     default_set_sd,           /* set_sd */
@@ -273,7 +274,6 @@ static const struct object_ops inode_ops
 struct file_lock
 {
     struct object       obj;         /* object header */
-    struct event_sync  *sync;        /* sync object for wait/signal */
     struct fd          *fd;          /* fd owning this lock */
     struct list         fd_entry;    /* entry in list of locks on a given fd */
     struct list         inode_entry; /* entry in inode list of locks */
@@ -285,21 +285,20 @@ struct file_lock
 };
 
 static void file_lock_dump( struct object *obj, int verbose );
-static struct object *file_lock_get_sync( struct object *obj );
-static void file_lock_destroy( struct object *obj );
+static int file_lock_signaled( struct object *obj, struct wait_queue_entry *entry );
 
 static const struct object_ops file_lock_ops =
 {
     sizeof(struct file_lock),   /* size */
     &no_type,                   /* type */
     file_lock_dump,             /* dump */
-    NULL,                       /* add_queue */
-    NULL,                       /* remove_queue */
-    NULL,                       /* signaled */
-    NULL,                       /* satisfied */
+    add_queue,                  /* add_queue */
+    remove_queue,               /* remove_queue */
+    file_lock_signaled,         /* signaled */
+    NULL,                       /* get_esync_fd */
+    no_satisfied,               /* satisfied */
     no_signal,                  /* signal */
     no_get_fd,                  /* get_fd */
-    file_lock_get_sync,         /* get_sync */
     default_map_access,         /* map_access */
     default_get_sd,             /* get_sd */
     default_set_sd,             /* set_sd */
@@ -310,7 +309,7 @@ static const struct object_ops file_lock
     no_open_file,               /* open_file */
     no_kernel_obj_list,         /* get_kernel_obj_list */
     no_close_handle,            /* close_handle */
-    file_lock_destroy,          /* destroy */
+    no_destroy                  /* destroy */
 };
 
 
@@ -1243,18 +1242,11 @@ static void file_lock_dump( struct objec
     fprintf( stderr, "\n" );
 }
 
-static struct object *file_lock_get_sync( struct object *obj )
-{
-    struct file_lock *lock = (struct file_lock *)obj;
-    assert( obj->ops == &file_lock_ops );
-    return grab_object( lock->sync );
-}
-
-static void file_lock_destroy( struct object *obj )
+static int file_lock_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct file_lock *lock = (struct file_lock *)obj;
-    assert( obj->ops == &file_lock_ops );
-    if (lock->sync) release_object( lock->sync );
+    /* lock is signaled if it has lost its owner */
+    return !lock->process;
 }
 
 /* set (or remove) a Unix lock if possible for the given range */
@@ -1434,24 +1426,22 @@ static struct file_lock *add_lock( struc
     struct file_lock *lock;
 
     if (!(lock = alloc_object( &file_lock_ops ))) return NULL;
-    lock->sync    = NULL;
     lock->shared  = shared;
     lock->start   = start;
     lock->end     = end;
     lock->fd      = fd;
     lock->process = current->process;
 
-    if (!(lock->sync = create_event_sync( 1, 0 ))) goto error;
     /* now try to set a Unix lock */
-    if (!set_unix_lock( lock->fd, lock->start, lock->end, lock->shared ? F_RDLCK : F_WRLCK )) goto error;
+    if (!set_unix_lock( lock->fd, lock->start, lock->end, lock->shared ? F_RDLCK : F_WRLCK ))
+    {
+        release_object( lock );
+        return NULL;
+    }
     list_add_tail( &fd->locks, &lock->fd_entry );
     list_add_tail( &fd->inode->locks, &lock->inode_entry );
     list_add_tail( &lock->process->locks, &lock->proc_entry );
     return lock;
-
-error:
-    release_object( lock );
-    return NULL;
 }
 
 /* remove an existing lock */
@@ -1465,7 +1455,7 @@ static void remove_lock( struct file_loc
     if (remove_unix) remove_unix_locks( lock->fd, lock->start, lock->end );
     if (list_empty( &inode->locks )) inode_close_pending( inode, 1 );
     lock->process = NULL;
-    signal_sync( lock->sync );
+    wake_up( &lock->obj, 0 );
     release_object( lock );
 }
 
@@ -1572,12 +1562,6 @@ static void fd_dump( struct object *obj,
     fprintf( stderr, "\n" );
 }
 
-static struct object *fd_get_sync( struct object *obj )
-{
-    struct fd *fd = (struct fd *)obj;
-    return grab_object( fd->sync );
-}
-
 static void fd_destroy( struct object *obj )
 {
     struct fd *fd = (struct fd *)obj;
@@ -1602,7 +1586,9 @@ static void fd_destroy( struct object *o
         if (fd->unix_fd != -1) close( fd->unix_fd );
         free( fd->unix_name );
     }
-    if (fd->sync) release_object( fd->sync );
+
+    if (do_esync())
+        close( fd->esync_fd );
 }
 
 /* check if the desired access is possible without violating */
@@ -1700,7 +1686,6 @@ static struct fd *alloc_fd_object(void)
     if (!fd) return NULL;
 
     fd->fd_ops     = NULL;
-    fd->sync       = NULL;
     fd->user       = NULL;
     fd->inode      = NULL;
     fd->closed     = NULL;
@@ -1714,24 +1699,27 @@ static struct fd *alloc_fd_object(void)
     fd->nt_name    = NULL;
     fd->nt_namelen = 0;
     fd->cacheable  = 0;
+    fd->signaled   = 1;
     fd->fs_locks   = 1;
     fd->poll_index = -1;
     fd->completion = NULL;
     fd->comp_flags = 0;
+    fd->esync_fd   = -1;
     init_async_queue( &fd->read_q );
     init_async_queue( &fd->write_q );
     init_async_queue( &fd->wait_q );
     list_init( &fd->inode_entry );
     list_init( &fd->locks );
 
-    if (!(fd->sync = create_event_sync( 1, 1 ))) goto error;
-    if ((fd->poll_index = add_poll_user( fd )) == -1) goto error;
+    if (do_esync())
+        fd->esync_fd = esync_create_fd( 1, 0 );
 
+    if ((fd->poll_index = add_poll_user( fd )) == -1)
+    {
+        release_object( fd );
+        return NULL;
+    }
     return fd;
-
-error:
-    release_object( fd );
-    return NULL;
 }
 
 /* allocate a pseudo fd object, for objects that need to behave like files but don't have a unix fd */
@@ -1742,7 +1730,6 @@ struct fd *alloc_pseudo_fd( const struct
     if (!fd) return NULL;
 
     fd->fd_ops     = fd_user_ops;
-    fd->sync       = NULL;
     fd->user       = user;
     fd->inode      = NULL;
     fd->closed     = NULL;
@@ -1756,22 +1743,21 @@ struct fd *alloc_pseudo_fd( const struct
     fd->nt_namelen = 0;
     fd->unix_fd    = -1;
     fd->cacheable  = 0;
+    fd->signaled   = 1;
     fd->fs_locks   = 0;
     fd->poll_index = -1;
     fd->completion = NULL;
     fd->comp_flags = 0;
     fd->no_fd_status = STATUS_BAD_DEVICE_TYPE;
+    fd->esync_fd   = -1;
     init_async_queue( &fd->read_q );
     init_async_queue( &fd->write_q );
     init_async_queue( &fd->wait_q );
     list_init( &fd->inode_entry );
     list_init( &fd->locks );
 
-    if (!(fd->sync = create_event_sync( 1, 1 )))
-    {
-        release_object( fd );
-        return NULL;
-    }
+    if (do_esync())
+        fd->esync_fd = esync_create_fd( 0, 0 );
     return fd;
 }
 
@@ -2175,8 +2161,11 @@ int is_fd_removable( struct fd *fd )
 void set_fd_signaled( struct fd *fd, int signaled )
 {
     if (fd->comp_flags & FILE_SKIP_SET_EVENT_ON_HANDLE) return;
-    if (signaled) signal_sync( fd->sync );
-    else reset_sync( fd->sync );
+    fd->signaled = signaled;
+    if (signaled) wake_up( fd->user, 0 );
+
+    if (do_esync() && !signaled)
+        esync_clear( fd->esync_fd );
 }
 
 /* check if events are pending and if yes return which one(s) */
@@ -2193,13 +2182,13 @@ int check_fd_events( struct fd *fd, int
     return pfd.revents;
 }
 
-/* default get_sync() routine for objects that poll() on an fd */
-struct object *default_fd_get_sync( struct object *obj )
+/* default signaled() routine for objects that poll() on an fd */
+int default_fd_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct fd *fd = get_obj_fd( obj );
-    struct object *sync = get_obj_sync( &fd->obj );
+    int ret = fd->signaled;
     release_object( fd );
-    return sync;
+    return ret;
 }
 
 /* default get_full_name() routine for objects with an fd */
@@ -2218,6 +2207,15 @@ WCHAR *default_fd_get_full_name( struct
     return ret;
 }
 
+int default_fd_get_esync_fd( struct object *obj, enum esync_type *type )
+{
+    struct fd *fd = get_obj_fd( obj );
+    int ret = fd->esync_fd;
+    *type = ESYNC_MANUAL_SERVER;
+    release_object( fd );
+    return ret;
+}
+
 int default_fd_get_poll_events( struct fd *fd )
 {
     int events = 0;
diff -ruN --show-c-function --no-dereference server/file.c server/file.c
--- server/file.c	2025-09-06 20:10:25.817505002 -0700
+++ server/file.c	2025-09-06 19:58:17.764689623 -0700
@@ -91,13 +91,13 @@ static const struct object_ops file_ops
     sizeof(struct file),          /* size */
     &file_type,                   /* type */
     file_dump,                    /* dump */
-    NULL,                         /* add_queue */
-    NULL,                         /* remove_queue */
-    NULL,                         /* signaled */
-    NULL,                         /* satisfied */
+    add_queue,                    /* add_queue */
+    remove_queue,                 /* remove_queue */
+    default_fd_signaled,          /* signaled */
+    NULL,                         /* get_esync_fd */
+    no_satisfied,                 /* satisfied */
     no_signal,                    /* signal */
     file_get_fd,                  /* get_fd */
-    default_fd_get_sync,          /* get_sync */
     default_map_access,           /* map_access */
     file_get_sd,                  /* get_sd */
     file_set_sd,                  /* set_sd */
diff -ruN --show-c-function --no-dereference server/file.h server/file.h
--- server/file.h	2025-09-06 20:10:25.817505002 -0700
+++ server/file.h	2025-09-06 19:58:17.784612442 -0700
@@ -108,7 +108,8 @@ extern void set_fd_signaled( struct fd *
 extern char *dup_fd_name( struct fd *root, const char *name ) __WINE_DEALLOC(free) __WINE_MALLOC;
 extern void get_nt_name( struct fd *fd, struct unicode_str *name );
 
-extern struct object *default_fd_get_sync( struct object *obj );
+extern int default_fd_signaled( struct object *obj, struct wait_queue_entry *entry );
+extern int default_fd_get_esync_fd( struct object *obj, enum esync_type *type );
 extern WCHAR *default_fd_get_full_name( struct object *obj, data_size_t max, data_size_t *ret_len );
 extern int default_fd_get_poll_events( struct fd *fd );
 extern void default_poll_event( struct fd *fd, int event );
diff -ruN --show-c-function --no-dereference server/handle.c server/handle.c
--- server/handle.c	2025-09-06 20:10:25.817505002 -0700
+++ server/handle.c	2025-09-06 19:58:17.764825341 -0700
@@ -126,10 +126,10 @@ static const struct object_ops handle_ta
     no_add_queue,                    /* add_queue */
     NULL,                            /* remove_queue */
     NULL,                            /* signaled */
+    NULL,                            /* get_esync_fd */
     NULL,                            /* satisfied */
     no_signal,                       /* signal */
     no_get_fd,                       /* get_fd */
-    default_get_sync,                /* get_sync */
     default_map_access,              /* map_access */
     default_get_sd,                  /* get_sd */
     default_set_sd,                  /* set_sd */
diff -ruN --show-c-function --no-dereference server/hook.c server/hook.c
--- server/hook.c	2025-09-06 20:10:25.817505002 -0700
+++ server/hook.c	2025-09-06 19:58:17.764968654 -0700
@@ -80,10 +80,10 @@ static const struct object_ops hook_tabl
     no_add_queue,                 /* add_queue */
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
+    NULL,                         /* get_esync_fd */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-    default_get_sync,             /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
diff -ruN --show-c-function --no-dereference server/inproc_sync.c server/inproc_sync.c
--- server/inproc_sync.c	2025-09-06 20:10:25.817505002 -0700
+++ server/inproc_sync.c	1969-12-31 16:00:00.000000000 -0800
@@ -1,190 +0,0 @@
-/*
- * In-process synchronization primitives
- *
- * Copyright (C) 2021-2022 Elizabeth Figura for CodeWeavers
- *
- * This library is free software; you can redistribute it and/or
- * modify it under the terms of the GNU Lesser General Public
- * License as published by the Free Software Foundation; either
- * version 2.1 of the License, or (at your option) any later version.
- *
- * This library is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * Lesser General Public License for more details.
- *
- * You should have received a copy of the GNU Lesser General Public
- * License along with this library; if not, write to the Free Software
- * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
- */
-
-#include "config.h"
-
-#include <assert.h>
-#include <stdint.h>
-#include <stdio.h>
-
-#include "ntstatus.h"
-#define WIN32_NO_STATUS
-#include "winternl.h"
-
-#include "file.h"
-#include "handle.h"
-#include "request.h"
-#include "thread.h"
-#include "user.h"
-
-#ifdef HAVE_LINUX_NTSYNC_H
-# include <linux/ntsync.h>
-#endif
-
-#ifdef NTSYNC_IOC_EVENT_READ
-
-#include <fcntl.h>
-#include <sys/ioctl.h>
-#include <sys/stat.h>
-#include <unistd.h>
-
-int get_inproc_device_fd(void)
-{
-    static int fd = -2;
-    if (fd == -2) fd = open( "/dev/ntsync", O_CLOEXEC | O_RDONLY );
-    return fd;
-}
-
-struct inproc_sync
-{
-    struct object          obj;  /* object header */
-    enum inproc_sync_type  type;
-    int                    fd;
-};
-
-static void inproc_sync_dump( struct object *obj, int verbose );
-static void inproc_sync_destroy( struct object *obj );
-
-static const struct object_ops inproc_sync_ops =
-{
-    sizeof(struct inproc_sync), /* size */
-    &no_type,                   /* type */
-    inproc_sync_dump,           /* dump */
-    no_add_queue,               /* add_queue */
-    NULL,                       /* remove_queue */
-    NULL,                       /* signaled */
-    NULL,                       /* satisfied */
-    no_signal,                  /* signal */
-    no_get_fd,                  /* get_fd */
-    default_get_sync,           /* get_sync */
-    default_map_access,         /* map_access */
-    default_get_sd,             /* get_sd */
-    default_set_sd,             /* set_sd */
-    default_get_full_name,      /* get_full_name */
-    no_lookup_name,             /* lookup_name */
-    directory_link_name,        /* link_name */
-    default_unlink_name,        /* unlink_name */
-    no_open_file,               /* open_file */
-    no_kernel_obj_list,         /* get_kernel_obj_list */
-    no_close_handle,            /* close_handle */
-    inproc_sync_destroy,        /* destroy */
-};
-
-struct inproc_sync *create_inproc_event_sync( int manual, int signaled )
-{
-    struct ntsync_event_args args = {.signaled = signaled, .manual = manual};
-    struct inproc_sync *event;
-
-    if (!(event = alloc_object( &inproc_sync_ops ))) return NULL;
-    event->type = INPROC_SYNC_EVENT;
-    event->fd = ioctl( get_inproc_device_fd(), NTSYNC_IOC_CREATE_EVENT, &args );
-
-    return event;
-}
-
-static void inproc_sync_dump( struct object *obj, int verbose )
-{
-    struct inproc_sync *sync = (struct inproc_sync *)obj;
-    assert( obj->ops == &inproc_sync_ops );
-    fprintf( stderr, "Inproc sync type=%d, fd=%d\n", sync->type, sync->fd );
-}
-
-void signal_inproc_sync( struct inproc_sync *sync )
-{
-    __u32 count;
-    if (debug_level) fprintf( stderr, "set_inproc_event %d\n", sync->fd );
-    ioctl( sync->fd, NTSYNC_IOC_EVENT_SET, &count );
-}
-
-void reset_inproc_sync( struct inproc_sync *sync )
-{
-    __u32 count;
-    if (debug_level) fprintf( stderr, "reset_inproc_event %d\n", sync->fd );
-    ioctl( sync->fd, NTSYNC_IOC_EVENT_RESET, &count );
-}
-
-static void inproc_sync_destroy( struct object *obj )
-{
-    struct inproc_sync *sync = (struct inproc_sync *)obj;
-    assert( obj->ops == &inproc_sync_ops );
-    close( sync->fd );
-}
-
-static int get_inproc_sync_fd( struct object *obj, int *type )
-{
-    struct object *sync;
-    int fd = -1;
-
-    if (obj != (struct object *)current->queue) sync = get_obj_sync( obj );
-    else sync = thread_queue_inproc_sync( current );
-    if (!sync) return -1;
-
-    if (sync->ops == &inproc_sync_ops)
-    {
-        struct inproc_sync *inproc = (struct inproc_sync *)sync;
-        *type = inproc->type;
-        fd = inproc->fd;
-    }
-
-    release_object( sync );
-    return fd;
-}
-
-#else /* NTSYNC_IOC_EVENT_READ */
-
-int get_inproc_device_fd(void)
-{
-    return -1;
-}
-
-struct inproc_sync *create_inproc_event_sync( int manual, int signaled )
-{
-    return NULL;
-}
-
-void signal_inproc_sync( struct inproc_sync *sync )
-{
-}
-
-void reset_inproc_sync( struct inproc_sync *sync )
-{
-}
-
-static int get_inproc_sync_fd( struct object *obj, int *type )
-{
-    return -1;
-}
-
-#endif /* NTSYNC_IOC_EVENT_READ */
-
-DECL_HANDLER(get_inproc_sync_fd)
-{
-    struct object *obj;
-    int fd;
-
-    if (!(obj = get_handle_obj( current->process, req->handle, 0, NULL ))) return;
-
-    reply->access = get_handle_access( current->process, req->handle );
-
-    if ((fd = get_inproc_sync_fd( obj, &reply->type )) < 0) set_error( STATUS_NOT_IMPLEMENTED );
-    else send_client_fd( current->process, fd, req->handle );
-
-    release_object( obj );
-}
diff -ruN --show-c-function --no-dereference server/mailslot.c server/mailslot.c
--- server/mailslot.c	2025-09-06 20:10:25.817505002 -0700
+++ server/mailslot.c	2025-09-06 19:58:17.765099733 -0700
@@ -79,13 +79,13 @@ static const struct object_ops mailslot_
     sizeof(struct mailslot),   /* size */
     &file_type,                /* type */
     mailslot_dump,             /* dump */
-    NULL,                      /* add_queue */
-    NULL,                      /* remove_queue */
-    NULL,                      /* signaled */
-    NULL,                      /* satisfied */
+    add_queue,                 /* add_queue */
+    remove_queue,              /* remove_queue */
+    default_fd_signaled,       /* signaled */
+    NULL,                      /* get_esync_fd */
+    no_satisfied,              /* satisfied */
     no_signal,                 /* signal */
     mailslot_get_fd,           /* get_fd */
-    default_fd_get_sync,       /* get_sync */
     mailslot_map_access,       /* map_access */
     default_get_sd,            /* get_sd */
     default_set_sd,            /* set_sd */
@@ -144,10 +144,10 @@ static const struct object_ops mail_writ
     no_add_queue,               /* add_queue */
     NULL,                       /* remove_queue */
     NULL,                       /* signaled */
+    NULL,                       /* get_esync_fd */
     NULL,                       /* satisfied */
     no_signal,                  /* signal */
     mail_writer_get_fd,         /* get_fd */
-    default_get_sync,           /* get_sync */
     mail_writer_map_access,     /* map_access */
     default_get_sd,             /* get_sd */
     default_set_sd,             /* set_sd */
@@ -210,10 +210,10 @@ static const struct object_ops mailslot_
     no_add_queue,                   /* add_queue */
     NULL,                           /* remove_queue */
     NULL,                           /* signaled */
+    NULL,                           /* get_esync_fd */
     no_satisfied,                   /* satisfied */
     no_signal,                      /* signal */
     no_get_fd,                      /* get_fd */
-    default_get_sync,               /* get_sync */
     default_map_access,             /* map_access */
     default_get_sd,                 /* get_sd */
     default_set_sd,                 /* set_sd */
@@ -238,13 +238,13 @@ static const struct object_ops mailslot_
     sizeof(struct mailslot_device_file),    /* size */
     &file_type,                             /* type */
     mailslot_device_file_dump,              /* dump */
-    NULL,                                   /* add_queue */
-    NULL,                                   /* remove_queue */
-    NULL,                                   /* signaled */
-    NULL,                                   /* satisfied */
+    add_queue,                              /* add_queue */
+    remove_queue,                           /* remove_queue */
+    default_fd_signaled,                    /* signaled */
+    NULL,                                   /* get_esync_fd */
+    no_satisfied,                           /* satisfied */
     no_signal,                              /* signal */
     mailslot_device_file_get_fd,            /* get_fd */
-    default_fd_get_sync,                    /* get_sync */
     default_map_access,                     /* map_access */
     default_get_sd,                         /* get_sd */
     default_set_sd,                         /* set_sd */
diff -ruN --show-c-function --no-dereference server/main.c server/main.c
--- server/main.c	2025-09-06 20:10:25.817505002 -0700
+++ server/main.c	2025-09-06 19:58:17.757426088 -0700
@@ -34,6 +34,7 @@
 #include "thread.h"
 #include "request.h"
 #include "unicode.h"
+#include "esync.h"
 
 /* command-line options */
 int debug_level = 0;
@@ -229,6 +230,9 @@ int main( int argc, char *argv[] )
     sock_init();
     open_master_socket();
 
+    if (do_esync())
+        esync_init();
+
     if (debug_level) fprintf( stderr, "wineserver: starting (pid=%ld)\n", (long) getpid() );
     set_current_time();
     init_signals();
diff -ruN --show-c-function --no-dereference server/Makefile.in server/Makefile.in
--- server/Makefile.in	2025-09-06 20:10:25.816504967 -0700
+++ server/Makefile.in	2025-09-06 19:58:17.757223422 -0700
@@ -11,12 +11,12 @@ SOURCES = \
 	debugger.c \
 	device.c \
 	directory.c \
+	esync.c \
 	event.c \
 	fd.c \
 	file.c \
 	handle.c \
 	hook.c \
-	inproc_sync.c \
 	mach.c \
 	mailslot.c \
 	main.c \
diff -ruN --show-c-function --no-dereference server/mapping.c server/mapping.c
--- server/mapping.c	2025-09-06 20:10:25.817505002 -0700
+++ server/mapping.c	2025-09-06 19:58:17.765288072 -0700
@@ -67,10 +67,10 @@ static const struct object_ops ranges_op
     no_add_queue,              /* add_queue */
     NULL,                      /* remove_queue */
     NULL,                      /* signaled */
+    NULL,                      /* get_esync_fd */
     NULL,                      /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
-    default_get_sync,          /* get_sync */
     default_map_access,        /* map_access */
     default_get_sd,            /* get_sd */
     default_set_sd,            /* set_sd */
@@ -104,10 +104,10 @@ static const struct object_ops shared_ma
     no_add_queue,              /* add_queue */
     NULL,                      /* remove_queue */
     NULL,                      /* signaled */
+    NULL,                      /* get_esync_fd */
     NULL,                      /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
-    default_get_sync,          /* get_sync */
     default_map_access,        /* map_access */
     default_get_sd,            /* get_sd */
     default_set_sd,            /* set_sd */
@@ -178,10 +178,10 @@ static const struct object_ops mapping_o
     no_add_queue,                /* add_queue */
     NULL,                        /* remove_queue */
     NULL,                        /* signaled */
+    NULL,                        /* get_esync_fd */
     NULL,                        /* satisfied */
     no_signal,                   /* signal */
     mapping_get_fd,              /* get_fd */
-    default_get_sync,            /* get_sync */
     default_map_access,          /* map_access */
     default_get_sd,              /* get_sd */
     default_set_sd,              /* set_sd */
diff -ruN --show-c-function --no-dereference server/mutex.c server/mutex.c
--- server/mutex.c	2025-09-06 20:10:25.817505002 -0700
+++ server/mutex.c	2025-09-06 19:58:17.765461382 -0700
@@ -50,32 +50,33 @@ struct type_descr mutex_type =
     },
 };
 
-struct mutex_sync
+struct mutex
 {
-    struct object       obj;                /* object header */
-    struct thread      *owner;              /* mutex owner */
-    unsigned int        count;              /* recursion count */
-    int                 abandoned;          /* has it been abandoned? */
-    struct list         entry;              /* entry in owner thread mutex list */
+    struct object  obj;             /* object header */
+    struct thread *owner;           /* mutex owner */
+    unsigned int   count;           /* recursion count */
+    int            abandoned;       /* has it been abandoned? */
+    struct list    entry;           /* entry in owner thread mutex list */
 };
 
-static void mutex_sync_dump( struct object *obj, int verbose );
-static int mutex_sync_signaled( struct object *obj, struct wait_queue_entry *entry );
-static void mutex_sync_satisfied( struct object *obj, struct wait_queue_entry *entry );
-static void mutex_sync_destroy( struct object *obj );
-
-static const struct object_ops mutex_sync_ops =
-{
-    sizeof(struct mutex_sync), /* size */
-    &no_type,                  /* type */
-    mutex_sync_dump,           /* dump */
+static void mutex_dump( struct object *obj, int verbose );
+static int mutex_signaled( struct object *obj, struct wait_queue_entry *entry );
+static void mutex_satisfied( struct object *obj, struct wait_queue_entry *entry );
+static void mutex_destroy( struct object *obj );
+static int mutex_signal( struct object *obj, unsigned int access );
+
+static const struct object_ops mutex_ops =
+{
+    sizeof(struct mutex),      /* size */
+    &mutex_type,               /* type */
+    mutex_dump,                /* dump */
     add_queue,                 /* add_queue */
     remove_queue,              /* remove_queue */
-    mutex_sync_signaled,       /* signaled */
-    mutex_sync_satisfied,      /* satisfied */
-    no_signal,                 /* signal */
+    mutex_signaled,            /* signaled */
+    NULL,                      /* get_esync_fd */
+    mutex_satisfied,           /* satisfied */
+    mutex_signal,              /* signal */
     no_get_fd,                 /* get_fd */
-    default_get_sync,          /* get_sync */
     default_map_access,        /* map_access */
     default_get_sd,            /* get_sd */
     default_set_sd,            /* set_sd */
@@ -86,11 +87,12 @@ static const struct object_ops mutex_syn
     no_open_file,              /* open_file */
     no_kernel_obj_list,        /* get_kernel_obj_list */
     no_close_handle,           /* close_handle */
-    mutex_sync_destroy,        /* destroy */
+    mutex_destroy              /* destroy */
 };
 
+
 /* grab a mutex for a given thread */
-static void do_grab( struct mutex_sync *mutex, struct thread *thread )
+static void do_grab( struct mutex *mutex, struct thread *thread )
 {
     assert( !mutex->count || (mutex->owner == thread) );
 
@@ -104,104 +106,15 @@ static void do_grab( struct mutex_sync *
 }
 
 /* release a mutex once the recursion count is 0 */
-static int do_release( struct mutex_sync *mutex, struct thread *thread, int count )
-{
-    if (!mutex->count || (mutex->owner != thread))
-    {
-        set_error( STATUS_MUTANT_NOT_OWNED );
-        return 0;
-    }
-    if (!(mutex->count -= count))
-    {
-        /* remove the mutex from the thread list of owned mutexes */
-        list_remove( &mutex->entry );
-        mutex->owner = NULL;
-        wake_up( &mutex->obj, 0 );
-        release_object( mutex );
-    }
-    return 1;
-}
-
-static void mutex_sync_dump( struct object *obj, int verbose )
-{
-    struct mutex_sync *mutex = (struct mutex_sync *)obj;
-    assert( obj->ops == &mutex_sync_ops );
-    fprintf( stderr, "Mutex count=%u owner=%p\n", mutex->count, mutex->owner );
-}
-
-static void mutex_sync_destroy( struct object *obj )
+static void do_release( struct mutex *mutex )
 {
-    struct mutex_sync *mutex = (struct mutex_sync *)obj;
-    assert( obj->ops == &mutex_sync_ops );
     assert( !mutex->count );
-}
-
-static int mutex_sync_signaled( struct object *obj, struct wait_queue_entry *entry )
-{
-    struct mutex_sync *mutex = (struct mutex_sync *)obj;
-    assert( obj->ops == &mutex_sync_ops );
-    return (!mutex->count || (mutex->owner == get_wait_queue_thread( entry )));
-}
-
-static void mutex_sync_satisfied( struct object *obj, struct wait_queue_entry *entry )
-{
-    struct mutex_sync *mutex = (struct mutex_sync *)obj;
-    assert( obj->ops == &mutex_sync_ops );
-
-    do_grab( mutex, get_wait_queue_thread( entry ));
-    if (mutex->abandoned) make_wait_abandoned( entry );
-    mutex->abandoned = 0;
-}
-
-static struct mutex_sync *create_mutex_sync( int owned )
-{
-    struct mutex_sync *mutex;
-
-    if (!(mutex = alloc_object( &mutex_sync_ops ))) return NULL;
-    mutex->count = 0;
+    /* remove the mutex from the thread list of owned mutexes */
+    list_remove( &mutex->entry );
     mutex->owner = NULL;
-    mutex->abandoned = 0;
-    if (owned) do_grab( mutex, current );
-
-    return mutex;
+    wake_up( &mutex->obj, 0 );
 }
 
-struct mutex
-{
-    struct object       obj;             /* object header */
-    struct mutex_sync  *sync;            /* mutex sync object */
-};
-
-static void mutex_dump( struct object *obj, int verbose );
-static struct object *mutex_get_sync( struct object *obj );
-static int mutex_signal( struct object *obj, unsigned int access );
-static void mutex_destroy( struct object *obj );
-
-static const struct object_ops mutex_ops =
-{
-    sizeof(struct mutex),      /* size */
-    &mutex_type,               /* type */
-    mutex_dump,                /* dump */
-    NULL,                      /* add_queue */
-    NULL,                      /* remove_queue */
-    NULL,                      /* signaled */
-    NULL,                      /* satisfied */
-    mutex_signal,              /* signal */
-    no_get_fd,                 /* get_fd */
-    mutex_get_sync,            /* get_sync */
-    default_map_access,        /* map_access */
-    default_get_sd,            /* get_sd */
-    default_set_sd,            /* set_sd */
-    default_get_full_name,     /* get_full_name */
-    no_lookup_name,            /* lookup_name */
-    directory_link_name,       /* link_name */
-    default_unlink_name,       /* unlink_name */
-    no_open_file,              /* open_file */
-    no_kernel_obj_list,        /* get_kernel_obj_list */
-    no_close_handle,           /* close_handle */
-    mutex_destroy,             /* destroy */
-};
-
 static struct mutex *create_mutex( struct object *root, const struct unicode_str *name,
                                    unsigned int attr, int owned, const struct security_descriptor *sd )
 {
@@ -212,13 +125,10 @@ static struct mutex *create_mutex( struc
         if (get_error() != STATUS_OBJECT_NAME_EXISTS)
         {
             /* initialize it if it didn't already exist */
-            mutex->sync = NULL;
-
-            if (!(mutex->sync = create_mutex_sync( owned )))
-            {
-                release_object( mutex );
-                return NULL;
-            }
+            mutex->count = 0;
+            mutex->owner = NULL;
+            mutex->abandoned = 0;
+            if (owned) do_grab( mutex, current );
         }
     }
     return mutex;
@@ -230,10 +140,11 @@ void abandon_mutexes( struct thread *thr
 
     while ((ptr = list_head( &thread->mutex_list )) != NULL)
     {
-        struct mutex_sync *mutex = LIST_ENTRY( ptr, struct mutex_sync, entry );
+        struct mutex *mutex = LIST_ENTRY( ptr, struct mutex, entry );
         assert( mutex->owner == thread );
+        mutex->count = 0;
         mutex->abandoned = 1;
-        do_release( mutex, thread, mutex->count );
+        do_release( mutex );
     }
 }
 
@@ -241,14 +152,24 @@ static void mutex_dump( struct object *o
 {
     struct mutex *mutex = (struct mutex *)obj;
     assert( obj->ops == &mutex_ops );
-    mutex->sync->obj.ops->dump( &mutex->sync->obj, verbose );
+    fprintf( stderr, "Mutex count=%u owner=%p\n", mutex->count, mutex->owner );
 }
 
-static struct object *mutex_get_sync( struct object *obj )
+static int mutex_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct mutex *mutex = (struct mutex *)obj;
     assert( obj->ops == &mutex_ops );
-    return grab_object( mutex->sync );
+    return (!mutex->count || (mutex->owner == get_wait_queue_thread( entry )));
+}
+
+static void mutex_satisfied( struct object *obj, struct wait_queue_entry *entry )
+{
+    struct mutex *mutex = (struct mutex *)obj;
+    assert( obj->ops == &mutex_ops );
+
+    do_grab( mutex, get_wait_queue_thread( entry ));
+    if (mutex->abandoned) make_wait_abandoned( entry );
+    mutex->abandoned = 0;
 }
 
 static int mutex_signal( struct object *obj, unsigned int access )
@@ -261,14 +182,23 @@ static int mutex_signal( struct object *
         set_error( STATUS_ACCESS_DENIED );
         return 0;
     }
-    return do_release( mutex->sync, current, 1 );
+    if (!mutex->count || (mutex->owner != current))
+    {
+        set_error( STATUS_MUTANT_NOT_OWNED );
+        return 0;
+    }
+    if (!--mutex->count) do_release( mutex );
+    return 1;
 }
 
 static void mutex_destroy( struct object *obj )
 {
     struct mutex *mutex = (struct mutex *)obj;
     assert( obj->ops == &mutex_ops );
-    if (mutex->sync) release_object( mutex->sync );
+
+    if (!mutex->count) return;
+    mutex->count = 0;
+    do_release( mutex );
 }
 
 /* create a mutex */
@@ -312,8 +242,12 @@ DECL_HANDLER(release_mutex)
     if ((mutex = (struct mutex *)get_handle_obj( current->process, req->handle,
                                                  0, &mutex_ops )))
     {
-        reply->prev_count = mutex->sync->count;
-        do_release( mutex->sync, current, 1 );
+        if (!mutex->count || (mutex->owner != current)) set_error( STATUS_MUTANT_NOT_OWNED );
+        else
+        {
+            reply->prev_count = mutex->count;
+            if (!--mutex->count) do_release( mutex );
+        }
         release_object( mutex );
     }
 }
@@ -326,9 +260,9 @@ DECL_HANDLER(query_mutex)
     if ((mutex = (struct mutex *)get_handle_obj( current->process, req->handle,
                                                  MUTANT_QUERY_STATE, &mutex_ops )))
     {
-        reply->count = mutex->sync->count;
-        reply->owned = (mutex->sync->owner == current);
-        reply->abandoned = mutex->sync->abandoned;
+        reply->count = mutex->count;
+        reply->owned = (mutex->owner == current);
+        reply->abandoned = mutex->abandoned;
 
         release_object( mutex );
     }
diff -ruN --show-c-function --no-dereference server/named_pipe.c server/named_pipe.c
--- server/named_pipe.c	2025-09-06 20:10:25.817505002 -0700
+++ server/named_pipe.c	2025-09-06 19:58:17.784760755 -0700
@@ -119,10 +119,10 @@ static const struct object_ops named_pip
     no_add_queue,                 /* add_queue */
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
+    NULL,                         /* get_esync_fd */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-    default_get_sync,             /* get_sync */
     named_pipe_map_access,        /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
@@ -165,13 +165,13 @@ static const struct object_ops pipe_serv
     sizeof(struct pipe_server),   /* size */
     &file_type,                   /* type */
     pipe_server_dump,             /* dump */
-    NULL,                         /* add_queue */
-    NULL,                         /* remove_queue */
-    NULL,                         /* signaled */
-    NULL,                         /* satisfied */
+    add_queue,                    /* add_queue */
+    remove_queue,                 /* remove_queue */
+    default_fd_signaled,          /* signaled */
+    default_fd_get_esync_fd,      /* get_esync_fd */
+    no_satisfied,                 /* satisfied */
     no_signal,                    /* signal */
     pipe_end_get_fd,              /* get_fd */
-    default_fd_get_sync,          /* get_sync */
     default_map_access,           /* map_access */
     pipe_end_get_sd,              /* get_sd */
     pipe_end_set_sd,              /* set_sd */
@@ -210,13 +210,13 @@ static const struct object_ops pipe_clie
     sizeof(struct pipe_end),      /* size */
     &file_type,                   /* type */
     pipe_client_dump,             /* dump */
-    NULL,                         /* add_queue */
-    NULL,                         /* remove_queue */
-    NULL,                         /* signaled */
-    NULL,                         /* satisfied */
+    add_queue,                    /* add_queue */
+    remove_queue,                 /* remove_queue */
+    default_fd_signaled,          /* signaled */
+    default_fd_get_esync_fd,      /* get_esync_fd */
+    no_satisfied,                 /* satisfied */
     no_signal,                    /* signal */
     pipe_end_get_fd,              /* get_fd */
-    default_fd_get_sync,          /* get_sync */
     default_map_access,           /* map_access */
     pipe_end_get_sd,              /* get_sd */
     pipe_end_set_sd,              /* set_sd */
@@ -262,10 +262,10 @@ static const struct object_ops named_pip
     no_add_queue,                     /* add_queue */
     NULL,                             /* remove_queue */
     NULL,                             /* signaled */
+    NULL,                             /* get_esync_fd */
     no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     no_get_fd,                        /* get_fd */
-    default_get_sync,                 /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -291,13 +291,13 @@ static const struct object_ops named_pip
     sizeof(struct named_pipe_device_file),   /* size */
     &file_type,                              /* type */
     named_pipe_device_file_dump,             /* dump */
-    NULL,                                    /* add_queue */
-    NULL,                                    /* remove_queue */
-    NULL,                                    /* signaled */
-    NULL,                                    /* satisfied */
+    add_queue,                               /* add_queue */
+    remove_queue,                            /* remove_queue */
+    default_fd_signaled,                     /* signaled */
+    NULL,                                    /* get_esync_fd */
+    no_satisfied,                            /* satisfied */
     no_signal,                               /* signal */
     named_pipe_device_file_get_fd,           /* get_fd */
-    default_fd_get_sync,                     /* get_sync */
     default_map_access,                      /* map_access */
     default_get_sd,                          /* get_sd */
     default_set_sd,                          /* set_sd */
@@ -342,13 +342,13 @@ static const struct object_ops named_pip
     sizeof(struct named_pipe_device_file),   /* size */
     &file_type,                              /* type */
     named_pipe_dir_dump,                     /* dump */
-    NULL,                                    /* add_queue */
-    NULL,                                    /* remove_queue */
-    NULL,                                    /* signaled */
-    NULL,                                    /* satisfied */
+    add_queue,                               /* add_queue */
+    remove_queue,                            /* remove_queue */
+    default_fd_signaled,                     /* signaled */
+    NULL,                                    /* get_esync_fd */
+    no_satisfied,                            /* satisfied */
     no_signal,                               /* signal */
     named_pipe_dir_get_fd,                   /* get_fd */
-    default_fd_get_sync,                     /* get_sync */
     default_map_access,                      /* map_access */
     default_get_sd,                          /* get_sd */
     default_set_sd,                          /* set_sd */
diff -ruN --show-c-function --no-dereference server/object.c server/object.c
--- server/object.c	2025-09-06 20:10:25.817505002 -0700
+++ server/object.c	2025-09-06 19:58:17.765846435 -0700
@@ -109,10 +109,10 @@ static const struct object_ops apc_reser
     no_add_queue,               /* add_queue */
     NULL,                       /* remove_queue */
     NULL,                       /* signaled */
+    NULL,                       /* get_esync_fd */
     no_satisfied,               /* satisfied */
     no_signal,                  /* signal */
     no_get_fd,                  /* get_fd */
-    default_get_sync,           /* get_sync */
     default_map_access,         /* map_access */
     default_get_sd,             /* get_sd */
     default_set_sd,             /* set_sd */
@@ -134,10 +134,10 @@ static const struct object_ops completio
     no_add_queue,              /* add_queue */
     NULL,                      /* remove_queue */
     NULL,                      /* signaled */
+    NULL,                      /* get_esync_fd */
     no_satisfied,              /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
-    default_get_sync,          /* get_sync */
     default_map_access,        /* map_access */
     default_get_sd,            /* get_sd */
     default_set_sd,            /* set_sd */
@@ -642,11 +642,6 @@ struct fd *no_get_fd( struct object *obj
     return NULL;
 }
 
-struct object *default_get_sync( struct object *obj )
-{
-    return grab_object( obj );
-}
-
 unsigned int default_map_access( struct object *obj, unsigned int access )
 {
     return map_access( access, &obj->ops->type->mapping );
diff -ruN --show-c-function --no-dereference server/object.h server/object.h
--- server/object.h	2025-09-06 20:10:25.817505002 -0700
+++ server/object.h	2025-09-06 19:58:17.765980209 -0700
@@ -78,14 +78,14 @@ struct object_ops
     void (*remove_queue)(struct object *,struct wait_queue_entry *);
     /* is object signaled? */
     int  (*signaled)(struct object *,struct wait_queue_entry *);
+    /* return the esync fd for this object */
+    int (*get_esync_fd)(struct object *, enum esync_type *type);
     /* wait satisfied */
     void (*satisfied)(struct object *,struct wait_queue_entry *);
     /* signal an object */
     int  (*signal)(struct object *, unsigned int);
     /* return an fd object that can be used to read/write from the object */
     struct fd *(*get_fd)(struct object *);
-    /* return a sync that can be used to wait/signal the object */
-    struct object *(*get_sync)(struct object *);
     /* map access rights to the specific rights for this object */
     unsigned int (*map_access)(struct object *, unsigned int);
     /* returns the security descriptor of the object */
@@ -172,8 +172,6 @@ extern int no_add_queue( struct object *
 extern void no_satisfied( struct object *obj, struct wait_queue_entry *entry );
 extern int no_signal( struct object *obj, unsigned int access );
 extern struct fd *no_get_fd( struct object *obj );
-extern struct object *default_get_sync( struct object *obj );
-static inline struct object *get_obj_sync( struct object *obj ) { return obj->ops->get_sync( obj ); }
 extern unsigned int default_map_access( struct object *obj, unsigned int access );
 extern struct security_descriptor *default_get_sd( struct object *obj );
 extern int default_set_sd( struct object *obj, const struct security_descriptor *sd, unsigned int set_info );
@@ -218,14 +216,9 @@ static inline void *mem_append( void *pt
 
 /* event functions */
 
-struct event_sync;
 struct event;
 struct keyed_event;
 
-extern struct event_sync *create_event_sync( int manual, int signaled );
-extern void signal_sync( struct event_sync *sync );
-extern void reset_sync( struct event_sync *sync );
-
 extern struct event *create_event( struct object *root, const struct unicode_str *name,
                                    unsigned int attr, int manual_reset, int initial_state,
                                    const struct security_descriptor *sd );
@@ -240,14 +233,6 @@ extern void reset_event( struct event *e
 
 extern void abandon_mutexes( struct thread *thread );
 
-/* in-process synchronization functions */
-
-struct inproc_sync;
-extern int get_inproc_device_fd(void);
-extern struct inproc_sync *create_inproc_event_sync( int manual, int signaled );
-extern void signal_inproc_sync( struct inproc_sync *sync );
-extern void reset_inproc_sync( struct inproc_sync *sync );
-
 /* serial functions */
 
 int get_serial_async_timeout(struct object *obj, int type, int count);
diff -ruN --show-c-function --no-dereference server/process.c server/process.c
--- server/process.c	2025-09-06 20:10:25.817505002 -0700
+++ server/process.c	2025-09-06 19:58:17.769835898 -0700
@@ -64,6 +64,7 @@
 #include "request.h"
 #include "user.h"
 #include "security.h"
+#include "esync.h"
 
 /* process object */
 
@@ -90,12 +91,13 @@ struct type_descr process_type =
 };
 
 static void process_dump( struct object *obj, int verbose );
-static struct object *process_get_sync( struct object *obj );
+static int process_signaled( struct object *obj, struct wait_queue_entry *entry );
 static unsigned int process_map_access( struct object *obj, unsigned int access );
 static struct security_descriptor *process_get_sd( struct object *obj );
 static void process_poll_event( struct fd *fd, int event );
 static struct list *process_get_kernel_obj_list( struct object *obj );
 static void process_destroy( struct object *obj );
+static int process_get_esync_fd( struct object *obj, enum esync_type *type );
 static void terminate_process( struct process *process, struct thread *skip, int exit_code );
 
 static const struct object_ops process_ops =
@@ -103,13 +105,13 @@ static const struct object_ops process_o
     sizeof(struct process),      /* size */
     &process_type,               /* type */
     process_dump,                /* dump */
-    NULL,                        /* add_queue */
-    NULL,                        /* remove_queue */
-    NULL,                        /* signaled */
-    NULL,                        /* satisfied */
+    add_queue,                   /* add_queue */
+    remove_queue,                /* remove_queue */
+    process_signaled,            /* signaled */
+    process_get_esync_fd,        /* get_esync_fd */
+    no_satisfied,                /* satisfied */
     no_signal,                   /* signal */
     no_get_fd,                   /* get_fd */
-    process_get_sync,            /* get_sync */
     process_map_access,          /* map_access */
     process_get_sd,              /* get_sd */
     default_set_sd,              /* set_sd */
@@ -139,16 +141,15 @@ static const struct fd_ops process_fd_op
 
 struct startup_info
 {
-    struct object               obj;            /* object header */
-    struct event_sync          *sync;           /* sync object for wait/signal */
-    struct process             *process;        /* created process */
-    data_size_t                 info_size;      /* size of startup info */
-    data_size_t                 data_size;      /* size of whole startup data */
-    struct startup_info_data   *data;           /* data for startup info */
+    struct object       obj;          /* object header */
+    struct process     *process;      /* created process */
+    data_size_t         info_size;    /* size of startup info */
+    data_size_t         data_size;    /* size of whole startup data */
+    struct startup_info_data *data;   /* data for startup info */
 };
 
 static void startup_info_dump( struct object *obj, int verbose );
-static struct object *startup_info_get_sync( struct object *obj );
+static int startup_info_signaled( struct object *obj, struct wait_queue_entry *entry );
 static void startup_info_destroy( struct object *obj );
 
 static const struct object_ops startup_info_ops =
@@ -156,13 +157,13 @@ static const struct object_ops startup_i
     sizeof(struct startup_info),   /* size */
     &no_type,                      /* type */
     startup_info_dump,             /* dump */
-    NULL,                          /* add_queue */
-    NULL,                          /* remove_queue */
-    NULL,                          /* signaled */
-    NULL,                          /* satisfied */
+    add_queue,                     /* add_queue */
+    remove_queue,                  /* remove_queue */
+    startup_info_signaled,         /* signaled */
+    NULL,                          /* get_esync_fd */
+    no_satisfied,                  /* satisfied */
     no_signal,                     /* signal */
     no_get_fd,                     /* get_fd */
-    startup_info_get_sync,         /* get_sync */
     default_map_access,            /* map_access */
     default_get_sd,                /* get_sd */
     default_set_sd,                /* set_sd */
@@ -193,24 +194,24 @@ struct type_descr job_type =
 };
 
 static void job_dump( struct object *obj, int verbose );
-static struct object *job_get_sync( struct object *obj );
+static int job_signaled( struct object *obj, struct wait_queue_entry *entry );
 static int job_close_handle( struct object *obj, struct process *process, obj_handle_t handle );
 static void job_destroy( struct object *obj );
 
 struct job
 {
-    struct object        obj;               /* object header */
-    struct event_sync   *sync;              /* sync object for wait/signal */
-    struct list          process_list;      /* list of processes */
-    int                  num_processes;     /* count of running processes */
-    int                  total_processes;   /* count of processes which have been assigned */
-    unsigned int         limit_flags;       /* limit flags */
-    int                  terminating;       /* job is terminating */
-    struct completion   *completion_port;   /* associated completion port */
-    apc_param_t          completion_key;    /* key to send with completion messages */
-    struct job          *parent;
-    struct list          parent_job_entry;  /* list entry for parent job */
-    struct list          child_job_list;    /* list of child jobs */
+    struct object obj;             /* object header */
+    struct list process_list;      /* list of processes */
+    int num_processes;             /* count of running processes */
+    int total_processes;           /* count of processes which have been assigned */
+    unsigned int limit_flags;      /* limit flags */
+    int terminating;               /* job is terminating */
+    int signaled;                  /* job is signaled */
+    struct completion *completion_port; /* associated completion port */
+    apc_param_t completion_key;    /* key to send with completion messages */
+    struct job *parent;
+    struct list parent_job_entry;  /* list entry for parent job */
+    struct list child_job_list;    /* list of child jobs */
 };
 
 static const struct object_ops job_ops =
@@ -218,13 +219,13 @@ static const struct object_ops job_ops =
     sizeof(struct job),            /* size */
     &job_type,                     /* type */
     job_dump,                      /* dump */
-    NULL,                          /* add_queue */
-    NULL,                          /* remove_queue */
-    NULL,                          /* signaled */
-    NULL,                          /* satisfied */
+    add_queue,                     /* add_queue */
+    remove_queue,                  /* remove_queue */
+    job_signaled,                  /* signaled */
+    NULL,                          /* get_esync_fd */
+    no_satisfied,                  /* satisfied */
     no_signal,                     /* signal */
     no_get_fd,                     /* get_fd */
-    job_get_sync,                  /* get_sync */
     default_map_access,            /* map_access */
     default_get_sd,                /* get_sd */
     default_set_sd,                /* set_sd */
@@ -248,22 +249,16 @@ static struct job *create_job_object( st
         if (get_error() != STATUS_OBJECT_NAME_EXISTS)
         {
             /* initialize it if it didn't already exist */
-            job->sync = NULL;
             list_init( &job->process_list );
             list_init( &job->child_job_list );
             job->num_processes = 0;
             job->total_processes = 0;
             job->limit_flags = 0;
             job->terminating = 0;
+            job->signaled = 0;
             job->completion_port = NULL;
             job->completion_key = 0;
             job->parent = NULL;
-
-            if (!(job->sync = create_event_sync( 1, 0 )))
-            {
-                release_object( job );
-                return NULL;
-            }
         }
     }
     return job;
@@ -418,7 +413,8 @@ static void terminate_job( struct job *j
         if (process->running_threads) terminate_process( process, NULL, exit_code );
     }
     job->terminating = 0;
-    signal_sync( job->sync );
+    job->signaled = 1;
+    wake_up( &job->obj, 0 );
 }
 
 static int job_close_handle( struct object *obj, struct process *process, obj_handle_t handle )
@@ -449,8 +445,6 @@ static void job_destroy( struct object *
         list_remove( &job->parent_job_entry );
         release_object( job->parent );
     }
-
-    if (job->sync) release_object( job->sync );
 }
 
 static void job_dump( struct object *obj, int verbose )
@@ -461,11 +455,10 @@ static void job_dump( struct object *obj
              list_count(&job->process_list), list_count(&job->child_job_list), job->parent );
 }
 
-static struct object *job_get_sync( struct object *obj )
+static int job_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct job *job = (struct job *)obj;
-    assert( obj->ops == &job_ops );
-    return grab_object( job->sync );
+    return job->signaled;
 }
 
 struct ptid_entry
@@ -564,7 +557,7 @@ static void set_process_startup_state( s
     if (process->startup_state == STARTUP_IN_PROGRESS) process->startup_state = state;
     if (process->startup_info)
     {
-        signal_sync( process->startup_info->sync );
+        wake_up( &process->startup_info->obj, 0 );
         release_object( process->startup_info );
         process->startup_info = NULL;
     }
@@ -663,7 +656,6 @@ struct process *create_process( int fd,
         close( fd );
         goto error;
     }
-    process->sync            = NULL;
     process->parent_id       = 0;
     process->debug_obj       = NULL;
     process->debug_event     = NULL;
@@ -702,6 +694,7 @@ struct process *create_process( int fd,
     process->rawinput_kbd    = NULL;
     memset( &process->image_info, 0, sizeof(process->image_info) );
     list_init( &process->rawinput_entry );
+    process->esync_fd        = -1;
     list_init( &process->kernel_object );
     list_init( &process->thread_list );
     list_init( &process->locks );
@@ -723,7 +716,6 @@ struct process *create_process( int fd,
         goto error;
     }
     if (!(process->msg_fd = create_anonymous_fd( &process_fd_ops, fd, &process->obj, 0 ))) goto error;
-    if (!(process->sync = create_event_sync( 1, 0 ))) goto error;
 
     /* create the handle table */
     if (!parent)
@@ -753,6 +745,9 @@ struct process *create_process( int fd,
     if (!process->handles || !process->token) goto error;
     process->session_id = token_get_session_id( process->token );
 
+    if (do_esync())
+        process->esync_fd = esync_create_fd( 0, 0 );
+
     set_fd_events( process->msg_fd, POLLIN );  /* start listening to events */
     return process;
 
@@ -797,11 +792,11 @@ static void process_destroy( struct obje
     if (process->idle_event) release_object( process->idle_event );
     if (process->id) free_ptid( process->id );
     if (process->token) release_object( process->token );
-    if (process->sync) release_object( process->sync );
     list_remove( &process->rawinput_entry );
     free( process->rawinput_devices );
     free( process->dir_cache );
     free( process->image );
+    if (do_esync()) close( process->esync_fd );
 }
 
 /* dump a process on stdout for debugging purposes */
@@ -813,11 +808,17 @@ static void process_dump( struct object
     fprintf( stderr, "Process id=%04x handles=%p\n", process->id, process->handles );
 }
 
-static struct object *process_get_sync( struct object *obj )
+static int process_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct process *process = (struct process *)obj;
-    assert( obj->ops == &process_ops );
-    return grab_object( process->sync );
+    return !process->running_threads;
+}
+
+static int process_get_esync_fd( struct object *obj, enum esync_type *type )
+{
+    struct process *process = (struct process *)obj;
+    *type = ESYNC_MANUAL_SERVER;
+    return process->esync_fd;
 }
 
 static unsigned int process_map_access( struct object *obj, unsigned int access )
@@ -890,7 +891,6 @@ static void startup_info_destroy( struct
     assert( obj->ops == &startup_info_ops );
     free( info->data );
     if (info->process) release_object( info->process );
-    if (info->sync) release_object( info->sync );
 }
 
 static void startup_info_dump( struct object *obj, int verbose )
@@ -905,11 +905,10 @@ static void startup_info_dump( struct ob
     fputc( '\n', stderr );
 }
 
-static struct object *startup_info_get_sync( struct object *obj )
+static int startup_info_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct startup_info *info = (struct startup_info *)obj;
-    assert( obj->ops == &startup_info_ops );
-    return grab_object( info->sync );
+    return info->process && info->process->startup_state != STARTUP_IN_PROGRESS;
 }
 
 /* get a process from an id (and increment the refcount) */
@@ -1001,7 +1000,7 @@ static void process_killed( struct proce
     finish_process_tracing( process );
     release_job_process( process );
     start_sigkill_timer( process );
-    signal_sync( process->sync );
+    wake_up( &process->obj, 0 );
 }
 
 /* add a thread to a process running threads list */
@@ -1219,16 +1218,9 @@ DECL_HANDLER(new_process)
         release_object( parent );
         return;
     }
-    info->sync     = NULL;
     info->process  = NULL;
     info->data     = NULL;
 
-    if (!(info->sync = create_event_sync( 1, 0 )))
-    {
-        close( socket_fd );
-        goto done;
-    }
-
     info_ptr = get_req_data_after_objattr( objattr, &info->data_size );
 
     if ((req->handles_size & 3) || req->handles_size > info->data_size)
diff -ruN --show-c-function --no-dereference server/process.h server/process.h
--- server/process.h	2025-09-06 20:10:25.818505038 -0700
+++ server/process.h	2025-09-06 19:58:17.770061467 -0700
@@ -36,7 +36,6 @@ enum startup_state { STARTUP_IN_PROGRESS
 struct process
 {
     struct object        obj;             /* object header */
-    struct event_sync   *sync;            /* sync object for wait/signal */
     struct list          entry;           /* entry in system-wide process list */
     process_id_t         parent_id;       /* parent process id (at the time of creation) */
     struct list          thread_list;     /* thread list */
@@ -89,6 +88,7 @@ struct process
     struct list          rawinput_entry;  /* entry in the rawinput process list */
     struct list          kernel_object;   /* list of kernel object pointers */
     struct pe_image_info image_info;      /* main exe image info */
+    int                  esync_fd;        /* esync file descriptor (signaled on exit) */
 };
 
 /* process functions */
diff -ruN --show-c-function --no-dereference server/protocol.def server/protocol.def
--- server/protocol.def	2025-09-06 20:10:25.818505038 -0700
+++ server/protocol.def	2025-09-06 19:58:17.779895645 -0700
@@ -1126,7 +1126,6 @@ struct obj_locator
     thread_id_t  tid;          /* thread id of the new thread */
     timeout_t    server_start; /* server start time */
     unsigned int session_id;   /* process session id */
-    obj_handle_t inproc_device;/* inproc device fd in flight with this handle */
     data_size_t  info_size;    /* total size of startup info */
     VARARG(machines,ushorts);  /* array of supported machines */
 @END
@@ -4092,7 +4091,7 @@ struct handle_info
     obj_handle_t handle;       /* process handle */
 @END
 
-/* Iterate processes using global process list */
+/* Itererate processes using global process list */
 @REQ(get_next_process)
     obj_handle_t last;         /* process handle to start with */
     unsigned int access;       /* desired access for returned handle */
@@ -4113,6 +4112,53 @@ struct handle_info
     obj_handle_t handle;       /* next thread handle */
 @END
 
+enum esync_type
+{
+    ESYNC_SEMAPHORE = 1,
+    ESYNC_AUTO_EVENT,
+    ESYNC_MANUAL_EVENT,
+    ESYNC_MUTEX,
+    ESYNC_AUTO_SERVER,
+    ESYNC_MANUAL_SERVER,
+    ESYNC_QUEUE,
+};
+
+/* Create a new eventfd-based synchronization object */
+@REQ(create_esync)
+    unsigned int access;        /* wanted access rights */
+    int          initval;       /* initial value */
+    int          type;          /* type of esync object */
+    int          max;           /* maximum count on a semaphore */
+    VARARG(objattr,object_attributes); /* object attributes */
+@REPLY
+    obj_handle_t handle;        /* handle to the object */
+    int          type;          /* actual type (may be different for events) */
+    unsigned int shm_idx;
+@END
+
+@REQ(open_esync)
+    unsigned int access;        /* wanted access rights */
+    unsigned int attributes;    /* object attributes */
+    obj_handle_t rootdir;       /* root directory */
+    int          type;          /* type of esync object (above) */
+    VARARG(name,unicode_str);   /* object name */
+@REPLY
+    obj_handle_t handle;        /* handle to the event */
+    int          type;          /* type of esync object (above) */
+    unsigned int shm_idx;       /* this object's index into the shm section */
+@END
+
+/* Retrieve the esync fd for an object. */
+@REQ(get_esync_fd)
+    obj_handle_t handle;        /* handle to the object */
+@REPLY
+    int          type;
+    unsigned int shm_idx;
+@END
+
+@REQ(esync_msgwait)
+    int          in_msgwait;    /* are we in a message wait? */
+@END
 
 /* Setup keyboard auto-repeat */
 @REQ(set_keyboard_repeat)
@@ -4123,17 +4169,6 @@ struct handle_info
     int enable;                /* previous state of auto-repeat enable */
 @END
 
-
-enum inproc_sync_type
-{
-    INPROC_SYNC_UNKNOWN = 0,
-    INPROC_SYNC_EVENT = 1,
-};
-
-/* Get the in-process synchronization fd associated with the waitable handle */
-@REQ(get_inproc_sync_fd)
-    obj_handle_t handle;        /* handle to the object */
-@REPLY
-    int           type;         /* inproc sync type */
-    unsigned int access;        /* handle access rights */
+/* Retrieve the fd to wait on for user APCs. */
+@REQ(get_esync_apc_fd)
 @END
diff -ruN --show-c-function --no-dereference server/queue.c server/queue.c
--- server/queue.c	2025-09-06 20:10:25.818505038 -0700
+++ server/queue.c	2025-09-06 19:58:17.773435300 -0700
@@ -45,6 +45,7 @@
 #include "process.h"
 #include "request.h"
 #include "user.h"
+#include "esync.h"
 
 #define WM_NCMOUSEFIRST WM_NCMOUSEMOVE
 #define WM_NCMOUSELAST  (WM_NCMOUSEFIRST+(WM_MOUSELAST-WM_MOUSEFIRST))
@@ -116,8 +117,6 @@ struct msg_queue
 {
     struct object          obj;             /* object header */
     struct fd             *fd;              /* optional file descriptor to poll */
-    struct inproc_sync    *inproc_sync;     /* inproc sync for client-side waits */
-    int                    signaled;        /* queue is signaled from fd POLLIN or masks */
     int                    paint_count;     /* pending paint messages count */
     int                    hotkey_count;    /* pending hotkey messages count */
     int                    quit_message;    /* is there a pending quit message? */
@@ -135,8 +134,9 @@ struct msg_queue
     struct hook_table     *hooks;           /* hook table */
     timeout_t              last_get_msg;    /* time of last get message call */
     int                    keystate_lock;   /* owns an input keystate lock */
-    int                    waiting;         /* is thread waiting on queue */
     queue_shm_t           *shared;          /* queue in session shared memory */
+    int                    esync_fd;        /* esync file descriptor (signalled on message) */
+    int                    esync_in_msgwait; /* our thread is currently waiting on us */
 };
 
 struct hotkey
@@ -153,6 +153,7 @@ static void msg_queue_dump( struct objec
 static int msg_queue_add_queue( struct object *obj, struct wait_queue_entry *entry );
 static void msg_queue_remove_queue( struct object *obj, struct wait_queue_entry *entry );
 static int msg_queue_signaled( struct object *obj, struct wait_queue_entry *entry );
+static int msg_queue_get_esync_fd( struct object *obj, enum esync_type *type );
 static void msg_queue_satisfied( struct object *obj, struct wait_queue_entry *entry );
 static void msg_queue_destroy( struct object *obj );
 static void msg_queue_poll_event( struct fd *fd, int event );
@@ -168,10 +169,10 @@ static const struct object_ops msg_queue
     msg_queue_add_queue,       /* add_queue */
     msg_queue_remove_queue,    /* remove_queue */
     msg_queue_signaled,        /* signaled */
+    msg_queue_get_esync_fd,    /* get_esync_fd */
     msg_queue_satisfied,       /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
-    default_get_sync,          /* get_sync */
     default_map_access,        /* map_access */
     default_get_sd,            /* get_sd */
     default_set_sd,            /* set_sd */
@@ -206,10 +207,10 @@ static const struct object_ops thread_in
     no_add_queue,                 /* add_queue */
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
+    NULL,                         /* get_esync_fd */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-    default_get_sync,             /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
@@ -308,8 +309,6 @@ static struct msg_queue *create_msg_queu
     if ((queue = alloc_object( &msg_queue_ops )))
     {
         queue->fd              = NULL;
-        queue->inproc_sync     = NULL;
-        queue->signaled        = 0;
         queue->paint_count     = 0;
         queue->hotkey_count    = 0;
         queue->quit_message    = 0;
@@ -321,15 +320,19 @@ static struct msg_queue *create_msg_queu
         queue->hooks           = NULL;
         queue->last_get_msg    = current_time;
         queue->keystate_lock   = 0;
-        queue->waiting         = 0;
+        queue->esync_fd        = -1;
+        queue->esync_in_msgwait = 0;
         list_init( &queue->send_result );
         list_init( &queue->callback_result );
         list_init( &queue->pending_timers );
         list_init( &queue->expired_timers );
         for (i = 0; i < NB_MSG_KINDS; i++) list_init( &queue->msg_list[i] );
 
-        if (get_inproc_device_fd() >= 0 && !(queue->inproc_sync = create_inproc_event_sync( 1, 0 ))) goto error;
-        if (!(queue->shared = alloc_shared_object())) goto error;
+        if (!(queue->shared = alloc_shared_object()))
+        {
+            release_object( queue );
+            return NULL;
+        }
 
         SHARED_WRITE_BEGIN( queue->shared, queue_shm_t )
         {
@@ -341,6 +344,9 @@ static struct msg_queue *create_msg_queu
         }
         SHARED_WRITE_END;
 
+        if (do_esync())
+            queue->esync_fd = esync_create_fd( 0, 0 );
+
         thread->queue = queue;
 
         if ((desktop = get_thread_desktop( thread, 0 )))
@@ -351,10 +357,6 @@ static struct msg_queue *create_msg_queu
     }
     if (new_input) release_object( new_input );
     return queue;
-
-error:
-    release_object( queue );
-    return NULL;
 }
 
 /* free the message queue of a thread at thread exit */
@@ -714,20 +716,6 @@ void add_queue_hook_count( struct thread
     assert( thread->queue->shared->hooks_count[index] >= 0 );
 }
 
-static void signal_queue_sync( struct msg_queue *queue )
-{
-    if (queue->signaled) return;
-    queue->signaled = 1;
-    wake_up( &queue->obj, 0 );
-    if (queue->inproc_sync) signal_inproc_sync( queue->inproc_sync );
-}
-
-static void reset_queue_sync( struct msg_queue *queue )
-{
-    queue->signaled = 0;
-    if (queue->inproc_sync) reset_inproc_sync( queue->inproc_sync );
-}
-
 /* check the queue status */
 static inline int is_signaled( struct msg_queue *queue )
 {
@@ -754,7 +742,7 @@ static inline void set_queue_bits( struc
     }
     SHARED_WRITE_END;
 
-    if (is_signaled( queue )) signal_queue_sync( queue );
+    if (is_signaled( queue )) wake_up( &queue->obj, 0 );
 }
 
 /* clear some queue bits */
@@ -774,7 +762,9 @@ static inline void clear_queue_bits( str
         if (queue->keystate_lock) unlock_input_keystate( queue->input );
         queue->keystate_lock = 0;
     }
-    if (!is_signaled( queue )) reset_queue_sync( queue );
+
+    if (do_esync() && !is_signaled( queue ))
+        esync_clear( queue->esync_fd );
 }
 
 /* check if message is matched by the filter */
@@ -1284,25 +1274,20 @@ static void cleanup_results( struct msg_
 /* check if the thread owning the queue is hung (not checking for messages) */
 static int is_queue_hung( struct msg_queue *queue )
 {
+    struct wait_queue_entry *entry;
+
     if (current_time - queue->last_get_msg <= 5 * TICKS_PER_SEC)
         return 0;  /* less than 5 seconds since last get message -> not hung */
-    return !queue->waiting;
-}
 
-static int msg_queue_select( struct msg_queue *queue, int events )
-{
-    if (queue->waiting == !!events)
+    LIST_FOR_EACH_ENTRY( entry, &queue->obj.wait_queue, struct wait_queue_entry, entry )
     {
-        set_error( STATUS_ACCESS_DENIED );
-        return 0;
+        if (get_wait_queue_thread(entry)->queue == queue)
+            return 0;  /* thread is waiting on queue -> not hung */
     }
-    queue->waiting = !!events;
 
-    if (queue->fd)
-    {
-        if (events && check_fd_events( queue->fd, POLLIN )) signal_queue_sync( queue );
-        else set_fd_events( queue->fd, events );
-    }
+    if (do_esync() && queue->esync_in_msgwait)
+        return 0;   /* thread is waiting on queue in absentia -> not hung */
+
     return 1;
 }
 
@@ -1317,7 +1302,8 @@ static int msg_queue_add_queue( struct o
         return 0;
     }
 
-    if (!msg_queue_select( queue, POLLIN )) return 0;
+    if (queue->fd && list_empty( &obj->wait_queue ))  /* first on the queue */
+        set_fd_events( queue->fd, POLLIN );
     add_queue( obj, entry );
     return 1;
 }
@@ -1327,7 +1313,8 @@ static void msg_queue_remove_queue(struc
     struct msg_queue *queue = (struct msg_queue *)obj;
 
     remove_queue( obj, entry );
-    msg_queue_select( queue, 0 );
+    if (queue->fd && list_empty( &obj->wait_queue ))  /* last on the queue is gone */
+        set_fd_events( queue->fd, 0 );
 }
 
 static void msg_queue_dump( struct object *obj, int verbose )
@@ -1341,8 +1328,25 @@ static void msg_queue_dump( struct objec
 static int msg_queue_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct msg_queue *queue = (struct msg_queue *)obj;
-    assert( obj->ops == &msg_queue_ops );
-    return queue->signaled;
+    int ret = 0;
+
+    if (queue->fd)
+    {
+        if ((ret = check_fd_events( queue->fd, POLLIN )))
+            /* stop waiting on select() if we are signaled */
+            set_fd_events( queue->fd, 0 );
+        else if (!list_empty( &obj->wait_queue ))
+            /* restart waiting on poll() if we are no longer signaled */
+            set_fd_events( queue->fd, POLLIN );
+    }
+    return ret || is_signaled( queue );
+}
+
+static int msg_queue_get_esync_fd( struct object *obj, enum esync_type *type )
+{
+    struct msg_queue *queue = (struct msg_queue *)obj;
+    *type = ESYNC_QUEUE;
+    return queue->esync_fd;
 }
 
 static void msg_queue_satisfied( struct object *obj, struct wait_queue_entry *entry )
@@ -1356,7 +1360,6 @@ static void msg_queue_satisfied( struct
         shared->changed_mask = 0;
     }
     SHARED_WRITE_END;
-    reset_queue_sync( queue );
 }
 
 static void msg_queue_destroy( struct object *obj )
@@ -1402,7 +1405,7 @@ static void msg_queue_destroy( struct ob
     if (queue->hooks) release_object( queue->hooks );
     if (queue->fd) release_object( queue->fd );
     if (queue->shared) free_shared_object( queue->shared );
-    if (queue->inproc_sync) release_object( queue->inproc_sync );
+    if (do_esync()) close( queue->esync_fd );
 }
 
 static void msg_queue_poll_event( struct fd *fd, int event )
@@ -1412,7 +1415,7 @@ static void msg_queue_poll_event( struct
 
     if (event & (POLLERR | POLLHUP)) set_fd_events( fd, -1 );
     else set_fd_events( queue->fd, 0 );
-    signal_queue_sync( queue );
+    wake_up( &queue->obj, 0 );
 }
 
 static void thread_input_dump( struct object *obj, int verbose )
@@ -1492,12 +1495,6 @@ int init_thread_queue( struct thread *th
     return (create_msg_queue( thread, NULL ) != NULL);
 }
 
-struct object *thread_queue_inproc_sync( struct thread *thread )
-{
-    if (!thread->queue) return NULL;
-    return grab_object( thread->queue->inproc_sync );
-}
-
 /* attach two thread input data structures */
 int attach_thread_input( struct thread *thread_from, struct thread *thread_to )
 {
@@ -3178,9 +3175,23 @@ DECL_HANDLER(set_queue_mask)
         reply->wake_bits    = queue_shm->wake_bits;
         reply->changed_bits = queue_shm->changed_bits;
 
-        if (!is_signaled( queue )) reset_queue_sync( queue );
-        else if (!req->skip_wait) signal_queue_sync( queue );
-        else msg_queue_satisfied( &queue->obj, NULL );
+        if (is_signaled( queue ))
+        {
+            /* if skip wait is set, do what would have been done in the subsequent wait */
+            if (req->skip_wait)
+            {
+                SHARED_WRITE_BEGIN( queue_shm, queue_shm_t )
+                {
+                    shared->wake_mask = 0;
+                    shared->changed_mask = 0;
+                }
+                SHARED_WRITE_END;
+            }
+            else wake_up( &queue->obj, 0 );
+        }
+
+        if (do_esync() && !is_signaled( queue ))
+            esync_clear( queue->esync_fd );
     }
 }
 
@@ -3202,7 +3213,8 @@ DECL_HANDLER(get_queue_status)
         }
         SHARED_WRITE_END;
 
-        if (!is_signaled( queue )) reset_queue_sync( queue );
+        if (do_esync() && !is_signaled( queue ))
+            esync_clear( queue->esync_fd );
     }
     else reply->wake_bits = reply->changed_bits = 0;
 }
@@ -3400,8 +3412,6 @@ DECL_HANDLER(get_message)
     }
     SHARED_WRITE_END;
 
-    if (!is_signaled( queue )) reset_queue_sync( queue );
-
     /* then check for posted messages */
     if ((filter & QS_POSTMESSAGE) &&
         get_posted_message( queue, get_win, req->get_first, req->get_last, req->flags, reply ))
@@ -3461,8 +3471,11 @@ DECL_HANDLER(get_message)
     }
     SHARED_WRITE_END;
 
-    reset_queue_sync( queue );
     set_error( STATUS_PENDING );  /* FIXME */
+
+    if (do_esync() && !is_signaled( queue ))
+        esync_clear( queue->esync_fd );
+
 }
 
 
@@ -4239,6 +4252,23 @@ DECL_HANDLER(update_rawinput_devices)
     }
 }
 
+DECL_HANDLER(esync_msgwait)
+{
+    struct msg_queue *queue = get_current_queue();
+    const queue_shm_t *queue_shm;
+
+    if (!queue) return;
+    queue_shm = queue->shared;
+    queue->esync_in_msgwait = req->in_msgwait;
+
+    if (current->process->idle_event && !(queue_shm->wake_mask & QS_SMRESULT))
+        set_event( current->process->idle_event );
+
+    /* and start/stop waiting on the driver */
+    if (queue->fd)
+        set_fd_events( queue->fd, req->in_msgwait ? POLLIN : 0 );
+}
+
 DECL_HANDLER(set_keyboard_repeat)
 {
     struct desktop *desktop;
@@ -4257,3 +4287,4 @@ DECL_HANDLER(set_keyboard_repeat)
 
     release_object( desktop );
 }
+
diff -ruN --show-c-function --no-dereference server/registry.c server/registry.c
--- server/registry.c	2025-09-06 20:10:25.818505038 -0700
+++ server/registry.c	2025-09-06 19:58:17.766818986 -0700
@@ -180,10 +180,10 @@ static const struct object_ops key_ops =
     no_add_queue,            /* add_queue */
     NULL,                    /* remove_queue */
     NULL,                    /* signaled */
+    NULL,                    /* get_esync_fd */
     NULL,                    /* satisfied */
     no_signal,               /* signal */
     no_get_fd,               /* get_fd */
-    default_get_sync,        /* get_sync */
     key_map_access,          /* map_access */
     key_get_sd,              /* get_sd */
     default_set_sd,          /* set_sd */
diff -ruN --show-c-function --no-dereference server/request.c server/request.c
--- server/request.c	2025-09-06 20:10:25.818505038 -0700
+++ server/request.c	2025-09-06 19:58:17.767040878 -0700
@@ -89,10 +89,10 @@ static const struct object_ops master_so
     no_add_queue,                  /* add_queue */
     NULL,                          /* remove_queue */
     NULL,                          /* signaled */
+    NULL,                          /* get_esync_fd */
     NULL,                          /* satisfied */
     no_signal,                     /* signal */
     no_get_fd,                     /* get_fd */
-    default_get_sync,              /* get_sync */
     default_map_access,            /* map_access */
     default_get_sd,                /* get_sd */
     default_set_sd,                /* set_sd */
diff -ruN --show-c-function --no-dereference server/request_handlers.h server/request_handlers.h
--- server/request_handlers.h	2025-09-06 20:10:25.819505073 -0700
+++ server/request_handlers.h	2025-09-06 19:58:23.009895058 -0700
@@ -303,8 +303,12 @@ DECL_HANDLER(suspend_process);
 DECL_HANDLER(resume_process);
 DECL_HANDLER(get_next_process);
 DECL_HANDLER(get_next_thread);
+DECL_HANDLER(create_esync);
+DECL_HANDLER(open_esync);
+DECL_HANDLER(get_esync_fd);
+DECL_HANDLER(esync_msgwait);
 DECL_HANDLER(set_keyboard_repeat);
-DECL_HANDLER(get_inproc_sync_fd);
+DECL_HANDLER(get_esync_apc_fd);
 
 typedef void (*req_handler)( const void *req, void *reply );
 static const req_handler req_handlers[REQ_NB_REQUESTS] =
@@ -605,8 +609,12 @@ static const req_handler req_handlers[RE
     (req_handler)req_resume_process,
     (req_handler)req_get_next_process,
     (req_handler)req_get_next_thread,
+    (req_handler)req_create_esync,
+    (req_handler)req_open_esync,
+    (req_handler)req_get_esync_fd,
+    (req_handler)req_esync_msgwait,
     (req_handler)req_set_keyboard_repeat,
-    (req_handler)req_get_inproc_sync_fd,
+    (req_handler)req_get_esync_apc_fd,
 };
 
 C_ASSERT( sizeof(abstime_t) == 8 );
@@ -709,9 +717,8 @@ C_ASSERT( offsetof(struct init_first_thr
 C_ASSERT( offsetof(struct init_first_thread_reply, tid) == 12 );
 C_ASSERT( offsetof(struct init_first_thread_reply, server_start) == 16 );
 C_ASSERT( offsetof(struct init_first_thread_reply, session_id) == 24 );
-C_ASSERT( offsetof(struct init_first_thread_reply, inproc_device) == 28 );
-C_ASSERT( offsetof(struct init_first_thread_reply, info_size) == 32 );
-C_ASSERT( sizeof(struct init_first_thread_reply) == 40 );
+C_ASSERT( offsetof(struct init_first_thread_reply, info_size) == 28 );
+C_ASSERT( sizeof(struct init_first_thread_reply) == 32 );
 C_ASSERT( offsetof(struct init_thread_request, unix_tid) == 12 );
 C_ASSERT( offsetof(struct init_thread_request, reply_fd) == 16 );
 C_ASSERT( offsetof(struct init_thread_request, wait_fd) == 20 );
@@ -2288,14 +2295,35 @@ C_ASSERT( offsetof(struct get_next_threa
 C_ASSERT( sizeof(struct get_next_thread_request) == 32 );
 C_ASSERT( offsetof(struct get_next_thread_reply, handle) == 8 );
 C_ASSERT( sizeof(struct get_next_thread_reply) == 16 );
+C_ASSERT( offsetof(struct create_esync_request, access) == 12 );
+C_ASSERT( offsetof(struct create_esync_request, initval) == 16 );
+C_ASSERT( offsetof(struct create_esync_request, type) == 20 );
+C_ASSERT( offsetof(struct create_esync_request, max) == 24 );
+C_ASSERT( sizeof(struct create_esync_request) == 32 );
+C_ASSERT( offsetof(struct create_esync_reply, handle) == 8 );
+C_ASSERT( offsetof(struct create_esync_reply, type) == 12 );
+C_ASSERT( offsetof(struct create_esync_reply, shm_idx) == 16 );
+C_ASSERT( sizeof(struct create_esync_reply) == 24 );
+C_ASSERT( offsetof(struct open_esync_request, access) == 12 );
+C_ASSERT( offsetof(struct open_esync_request, attributes) == 16 );
+C_ASSERT( offsetof(struct open_esync_request, rootdir) == 20 );
+C_ASSERT( offsetof(struct open_esync_request, type) == 24 );
+C_ASSERT( sizeof(struct open_esync_request) == 32 );
+C_ASSERT( offsetof(struct open_esync_reply, handle) == 8 );
+C_ASSERT( offsetof(struct open_esync_reply, type) == 12 );
+C_ASSERT( offsetof(struct open_esync_reply, shm_idx) == 16 );
+C_ASSERT( sizeof(struct open_esync_reply) == 24 );
+C_ASSERT( offsetof(struct get_esync_fd_request, handle) == 12 );
+C_ASSERT( sizeof(struct get_esync_fd_request) == 16 );
+C_ASSERT( offsetof(struct get_esync_fd_reply, type) == 8 );
+C_ASSERT( offsetof(struct get_esync_fd_reply, shm_idx) == 12 );
+C_ASSERT( sizeof(struct get_esync_fd_reply) == 16 );
+C_ASSERT( offsetof(struct esync_msgwait_request, in_msgwait) == 12 );
+C_ASSERT( sizeof(struct esync_msgwait_request) == 16 );
 C_ASSERT( offsetof(struct set_keyboard_repeat_request, enable) == 12 );
 C_ASSERT( offsetof(struct set_keyboard_repeat_request, delay) == 16 );
 C_ASSERT( offsetof(struct set_keyboard_repeat_request, period) == 20 );
 C_ASSERT( sizeof(struct set_keyboard_repeat_request) == 24 );
 C_ASSERT( offsetof(struct set_keyboard_repeat_reply, enable) == 8 );
 C_ASSERT( sizeof(struct set_keyboard_repeat_reply) == 16 );
-C_ASSERT( offsetof(struct get_inproc_sync_fd_request, handle) == 12 );
-C_ASSERT( sizeof(struct get_inproc_sync_fd_request) == 16 );
-C_ASSERT( offsetof(struct get_inproc_sync_fd_reply, type) == 8 );
-C_ASSERT( offsetof(struct get_inproc_sync_fd_reply, access) == 12 );
-C_ASSERT( sizeof(struct get_inproc_sync_fd_reply) == 16 );
+C_ASSERT( sizeof(struct get_esync_apc_fd_request) == 16 );
diff -ruN --show-c-function --no-dereference server/request_trace.h server/request_trace.h
--- server/request_trace.h	2025-09-06 20:10:25.819505073 -0700
+++ server/request_trace.h	2025-09-06 19:58:23.006995960 -0700
@@ -148,7 +148,6 @@ static void dump_init_first_thread_reply
     fprintf( stderr, ", tid=%04x", req->tid );
     dump_timeout( ", server_start=", &req->server_start );
     fprintf( stderr, ", session_id=%08x", req->session_id );
-    fprintf( stderr, ", inproc_device=%04x", req->inproc_device );
     fprintf( stderr, ", info_size=%u", req->info_size );
     dump_varargs_ushorts( ", machines=", cur_size );
 }
@@ -3372,6 +3371,54 @@ static void dump_get_next_thread_reply(
     fprintf( stderr, " handle=%04x", req->handle );
 }
 
+static void dump_create_esync_request( const struct create_esync_request *req )
+{
+    fprintf( stderr, " access=%08x", req->access );
+    fprintf( stderr, ", initval=%d", req->initval );
+    fprintf( stderr, ", type=%d", req->type );
+    fprintf( stderr, ", max=%d", req->max );
+    dump_varargs_object_attributes( ", objattr=", cur_size );
+}
+
+static void dump_create_esync_reply( const struct create_esync_reply *req )
+{
+    fprintf( stderr, " handle=%04x", req->handle );
+    fprintf( stderr, ", type=%d", req->type );
+    fprintf( stderr, ", shm_idx=%08x", req->shm_idx );
+}
+
+static void dump_open_esync_request( const struct open_esync_request *req )
+{
+    fprintf( stderr, " access=%08x", req->access );
+    fprintf( stderr, ", attributes=%08x", req->attributes );
+    fprintf( stderr, ", rootdir=%04x", req->rootdir );
+    fprintf( stderr, ", type=%d", req->type );
+    dump_varargs_unicode_str( ", name=", cur_size );
+}
+
+static void dump_open_esync_reply( const struct open_esync_reply *req )
+{
+    fprintf( stderr, " handle=%04x", req->handle );
+    fprintf( stderr, ", type=%d", req->type );
+    fprintf( stderr, ", shm_idx=%08x", req->shm_idx );
+}
+
+static void dump_get_esync_fd_request( const struct get_esync_fd_request *req )
+{
+    fprintf( stderr, " handle=%04x", req->handle );
+}
+
+static void dump_get_esync_fd_reply( const struct get_esync_fd_reply *req )
+{
+    fprintf( stderr, " type=%d", req->type );
+    fprintf( stderr, ", shm_idx=%08x", req->shm_idx );
+}
+
+static void dump_esync_msgwait_request( const struct esync_msgwait_request *req )
+{
+    fprintf( stderr, " in_msgwait=%d", req->in_msgwait );
+}
+
 static void dump_set_keyboard_repeat_request( const struct set_keyboard_repeat_request *req )
 {
     fprintf( stderr, " enable=%d", req->enable );
@@ -3384,15 +3431,8 @@ static void dump_set_keyboard_repeat_rep
     fprintf( stderr, " enable=%d", req->enable );
 }
 
-static void dump_get_inproc_sync_fd_request( const struct get_inproc_sync_fd_request *req )
-{
-    fprintf( stderr, " handle=%04x", req->handle );
-}
-
-static void dump_get_inproc_sync_fd_reply( const struct get_inproc_sync_fd_reply *req )
+static void dump_get_esync_apc_fd_request( const struct get_esync_apc_fd_request *req )
 {
-    fprintf( stderr, " type=%d", req->type );
-    fprintf( stderr, ", access=%08x", req->access );
 }
 
 typedef void (*dump_func)( const void *req );
@@ -3695,8 +3735,12 @@ static const dump_func req_dumpers[REQ_N
     (dump_func)dump_resume_process_request,
     (dump_func)dump_get_next_process_request,
     (dump_func)dump_get_next_thread_request,
+    (dump_func)dump_create_esync_request,
+    (dump_func)dump_open_esync_request,
+    (dump_func)dump_get_esync_fd_request,
+    (dump_func)dump_esync_msgwait_request,
     (dump_func)dump_set_keyboard_repeat_request,
-    (dump_func)dump_get_inproc_sync_fd_request,
+    (dump_func)dump_get_esync_apc_fd_request,
 };
 
 static const dump_func reply_dumpers[REQ_NB_REQUESTS] =
@@ -3997,8 +4041,12 @@ static const dump_func reply_dumpers[REQ
     NULL,
     (dump_func)dump_get_next_process_reply,
     (dump_func)dump_get_next_thread_reply,
+    (dump_func)dump_create_esync_reply,
+    (dump_func)dump_open_esync_reply,
+    (dump_func)dump_get_esync_fd_reply,
+    NULL,
     (dump_func)dump_set_keyboard_repeat_reply,
-    (dump_func)dump_get_inproc_sync_fd_reply,
+    NULL,
 };
 
 static const char * const req_names[REQ_NB_REQUESTS] =
@@ -4299,8 +4347,12 @@ static const char * const req_names[REQ_
     "resume_process",
     "get_next_process",
     "get_next_thread",
+    "create_esync",
+    "open_esync",
+    "get_esync_fd",
+    "esync_msgwait",
     "set_keyboard_repeat",
-    "get_inproc_sync_fd",
+    "get_esync_apc_fd",
 };
 
 static const struct
diff -ruN --show-c-function --no-dereference server/semaphore.c server/semaphore.c
--- server/semaphore.c	2025-09-06 20:10:25.819505073 -0700
+++ server/semaphore.c	2025-09-06 19:58:17.767172158 -0700
@@ -50,119 +50,30 @@ struct type_descr semaphore_type =
     },
 };
 
-struct semaphore_sync
-{
-    struct object       obj;                /* object header */
-    unsigned int        count;              /* current count */
-    unsigned int        max;                /* maximum possible count */
-};
-
-static void semaphore_sync_dump( struct object *obj, int verbose );
-static int semaphore_sync_signaled( struct object *obj, struct wait_queue_entry *entry );
-static void semaphore_sync_satisfied( struct object *obj, struct wait_queue_entry *entry );
-
-static const struct object_ops semaphore_sync_ops =
-{
-    sizeof(struct semaphore_sync), /* size */
-    &no_type,                      /* type */
-    semaphore_sync_dump,           /* dump */
-    add_queue,                     /* add_queue */
-    remove_queue,                  /* remove_queue */
-    semaphore_sync_signaled,       /* signaled */
-    semaphore_sync_satisfied,      /* satisfied */
-    no_signal,                     /* signal */
-    no_get_fd,                     /* get_fd */
-    default_get_sync,              /* get_sync */
-    default_map_access,            /* map_access */
-    default_get_sd,                /* get_sd */
-    default_set_sd,                /* set_sd */
-    default_get_full_name,         /* get_full_name */
-    no_lookup_name,                /* lookup_name */
-    directory_link_name,           /* link_name */
-    default_unlink_name,           /* unlink_name */
-    no_open_file,                  /* open_file */
-    no_kernel_obj_list,            /* get_kernel_obj_list */
-    no_close_handle,               /* close_handle */
-    no_destroy                     /* destroy */
-};
-
-static int release_semaphore( struct semaphore_sync *sem, unsigned int count,
-                              unsigned int *prev )
-{
-    if (prev) *prev = sem->count;
-    if (sem->count + count < sem->count || sem->count + count > sem->max)
-    {
-        set_error( STATUS_SEMAPHORE_LIMIT_EXCEEDED );
-        return 0;
-    }
-    else if (sem->count)
-    {
-        /* there cannot be any thread to wake up if the count is != 0 */
-        sem->count += count;
-    }
-    else
-    {
-        sem->count = count;
-        wake_up( &sem->obj, count );
-    }
-    return 1;
-}
-
-static void semaphore_sync_dump( struct object *obj, int verbose )
-{
-    struct semaphore_sync *sem = (struct semaphore_sync *)obj;
-    assert( obj->ops == &semaphore_sync_ops );
-    fprintf( stderr, "Semaphore count=%d max=%d\n", sem->count, sem->max );
-}
-
-static int semaphore_sync_signaled( struct object *obj, struct wait_queue_entry *entry )
-{
-    struct semaphore_sync *sem = (struct semaphore_sync *)obj;
-    assert( obj->ops == &semaphore_sync_ops );
-    return (sem->count > 0);
-}
-
-static void semaphore_sync_satisfied( struct object *obj, struct wait_queue_entry *entry )
-{
-    struct semaphore_sync *sem = (struct semaphore_sync *)obj;
-    assert( obj->ops == &semaphore_sync_ops );
-    assert( sem->count );
-    sem->count--;
-}
-
-static struct semaphore_sync *create_semaphore_sync( unsigned int initial, unsigned int max )
-{
-    struct semaphore_sync *sem;
-
-    if (!(sem = alloc_object( &semaphore_sync_ops ))) return NULL;
-    sem->count = initial;
-    sem->max   = max;
-    return sem;
-}
-
 struct semaphore
 {
-    struct object          obj;    /* object header */
-    struct semaphore_sync *sync;   /* semaphore sync object */
+    struct object  obj;    /* object header */
+    unsigned int   count;  /* current count */
+    unsigned int   max;    /* maximum possible count */
 };
 
 static void semaphore_dump( struct object *obj, int verbose );
-static struct object *semaphore_get_sync( struct object *obj );
+static int semaphore_signaled( struct object *obj, struct wait_queue_entry *entry );
+static void semaphore_satisfied( struct object *obj, struct wait_queue_entry *entry );
 static int semaphore_signal( struct object *obj, unsigned int access );
-static void semaphore_destroy( struct object *obj );
 
 static const struct object_ops semaphore_ops =
 {
     sizeof(struct semaphore),      /* size */
     &semaphore_type,               /* type */
     semaphore_dump,                /* dump */
-    NULL,                          /* add_queue */
-    NULL,                          /* remove_queue */
-    NULL,                          /* signaled */
-    NULL,                          /* satisfied */
+    add_queue,                     /* add_queue */
+    remove_queue,                  /* remove_queue */
+    semaphore_signaled,            /* signaled */
+    NULL,                          /* get_esync_fd */
+    semaphore_satisfied,           /* satisfied */
     semaphore_signal,              /* signal */
     no_get_fd,                     /* get_fd */
-    semaphore_get_sync,            /* get_sync */
     default_map_access,            /* map_access */
     default_get_sd,                /* get_sd */
     default_set_sd,                /* set_sd */
@@ -173,9 +84,10 @@ static const struct object_ops semaphore
     no_open_file,                  /* open_file */
     no_kernel_obj_list,            /* get_kernel_obj_list */
     no_close_handle,               /* close_handle */
-    semaphore_destroy,             /* destroy */
+    no_destroy                     /* destroy */
 };
 
+
 static struct semaphore *create_semaphore( struct object *root, const struct unicode_str *name,
                                            unsigned int attr, unsigned int initial, unsigned int max,
                                            const struct security_descriptor *sd )
@@ -192,30 +104,55 @@ static struct semaphore *create_semaphor
         if (get_error() != STATUS_OBJECT_NAME_EXISTS)
         {
             /* initialize it if it didn't already exist */
-            sem->sync = NULL;
-
-            if (!(sem->sync = create_semaphore_sync( initial, max )))
-            {
-                release_object( sem );
-                return NULL;
-            }
+            sem->count = initial;
+            sem->max   = max;
         }
     }
     return sem;
 }
 
+static int release_semaphore( struct semaphore *sem, unsigned int count,
+                              unsigned int *prev )
+{
+    if (prev) *prev = sem->count;
+    if (sem->count + count < sem->count || sem->count + count > sem->max)
+    {
+        set_error( STATUS_SEMAPHORE_LIMIT_EXCEEDED );
+        return 0;
+    }
+    else if (sem->count)
+    {
+        /* there cannot be any thread to wake up if the count is != 0 */
+        sem->count += count;
+    }
+    else
+    {
+        sem->count = count;
+        wake_up( &sem->obj, count );
+    }
+    return 1;
+}
+
 static void semaphore_dump( struct object *obj, int verbose )
 {
     struct semaphore *sem = (struct semaphore *)obj;
     assert( obj->ops == &semaphore_ops );
-    sem->sync->obj.ops->dump( &sem->sync->obj, verbose );
+    fprintf( stderr, "Semaphore count=%d max=%d\n", sem->count, sem->max );
+}
+
+static int semaphore_signaled( struct object *obj, struct wait_queue_entry *entry )
+{
+    struct semaphore *sem = (struct semaphore *)obj;
+    assert( obj->ops == &semaphore_ops );
+    return (sem->count > 0);
 }
 
-static struct object *semaphore_get_sync( struct object *obj )
+static void semaphore_satisfied( struct object *obj, struct wait_queue_entry *entry )
 {
     struct semaphore *sem = (struct semaphore *)obj;
     assert( obj->ops == &semaphore_ops );
-    return grab_object( sem->sync );
+    assert( sem->count );
+    sem->count--;
 }
 
 static int semaphore_signal( struct object *obj, unsigned int access )
@@ -228,14 +165,7 @@ static int semaphore_signal( struct obje
         set_error( STATUS_ACCESS_DENIED );
         return 0;
     }
-    return release_semaphore( sem->sync, 1, NULL );
-}
-
-static void semaphore_destroy( struct object *obj )
-{
-    struct semaphore *sem = (struct semaphore *)obj;
-    assert( obj->ops == &semaphore_ops );
-    if (sem->sync) release_object( sem->sync );
+    return release_semaphore( sem, 1, NULL );
 }
 
 /* create a semaphore */
@@ -279,7 +209,7 @@ DECL_HANDLER(release_semaphore)
     if ((sem = (struct semaphore *)get_handle_obj( current->process, req->handle,
                                                    SEMAPHORE_MODIFY_STATE, &semaphore_ops )))
     {
-        release_semaphore( sem->sync, req->count, &reply->prev_count );
+        release_semaphore( sem, req->count, &reply->prev_count );
         release_object( sem );
     }
 }
@@ -292,8 +222,8 @@ DECL_HANDLER(query_semaphore)
     if ((sem = (struct semaphore *)get_handle_obj( current->process, req->handle,
                                                    SEMAPHORE_QUERY_STATE, &semaphore_ops )))
     {
-        reply->current = sem->sync->count;
-        reply->max = sem->sync->max;
+        reply->current = sem->count;
+        reply->max = sem->max;
         release_object( sem );
     }
 }
diff -ruN --show-c-function --no-dereference server/serial.c server/serial.c
--- server/serial.c	2025-09-06 20:10:25.819505073 -0700
+++ server/serial.c	2025-09-06 19:58:17.767270615 -0700
@@ -88,13 +88,13 @@ static const struct object_ops serial_op
     sizeof(struct serial),        /* size */
     &file_type,                   /* type */
     serial_dump,                  /* dump */
-    NULL,                         /* add_queue */
-    NULL,                         /* remove_queue */
-    NULL,                         /* signaled */
-    NULL,                         /* satisfied */
+    add_queue,                    /* add_queue */
+    remove_queue,                 /* remove_queue */
+    default_fd_signaled,          /* signaled */
+    NULL,                         /* get_esync_fd */
+    no_satisfied,                 /* satisfied */
     no_signal,                    /* signal */
     serial_get_fd,                /* get_fd */
-    default_fd_get_sync,          /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
diff -ruN --show-c-function --no-dereference server/signal.c server/signal.c
--- server/signal.c	2025-09-06 20:10:25.819505073 -0700
+++ server/signal.c	2025-09-06 19:58:17.767375114 -0700
@@ -62,10 +62,10 @@ static const struct object_ops handler_o
     no_add_queue,             /* add_queue */
     NULL,                     /* remove_queue */
     NULL,                     /* signaled */
+    NULL,                     /* get_esync_fd */
     NULL,                     /* satisfied */
     no_signal,                /* signal */
     no_get_fd,                /* get_fd */
-    default_get_sync,         /* get_sync */
     default_map_access,       /* map_access */
     default_get_sd,           /* get_sd */
     default_set_sd,           /* set_sd */
diff -ruN --show-c-function --no-dereference server/sock.c server/sock.c
--- server/sock.c	2025-09-06 20:10:25.819505073 -0700
+++ server/sock.c	2025-09-06 19:58:17.767565968 -0700
@@ -483,13 +483,13 @@ static const struct object_ops sock_ops
     sizeof(struct sock),          /* size */
     &file_type,                   /* type */
     sock_dump,                    /* dump */
-    NULL,                         /* add_queue */
-    NULL,                         /* remove_queue */
-    NULL,                         /* signaled */
-    NULL,                         /* satisfied */
+    add_queue,                    /* add_queue */
+    remove_queue,                 /* remove_queue */
+    default_fd_signaled,          /* signaled */
+    NULL,                         /* get_esync_fd */
+    no_satisfied,                 /* satisfied */
     no_signal,                    /* signal */
     sock_get_fd,                  /* get_fd */
-    default_fd_get_sync,          /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
@@ -3706,10 +3706,10 @@ static const struct object_ops ifchange_
     no_add_queue,            /* add_queue */
     NULL,                    /* remove_queue */
     NULL,                    /* signaled */
+    NULL,                    /* get_esync_fd */
     no_satisfied,            /* satisfied */
     no_signal,               /* signal */
     ifchange_get_fd,         /* get_fd */
-    default_get_sync,        /* get_sync */
     default_map_access,      /* map_access */
     default_get_sd,          /* get_sd */
     default_set_sd,          /* set_sd */
@@ -3928,10 +3928,10 @@ static const struct object_ops socket_de
     no_add_queue,               /* add_queue */
     NULL,                       /* remove_queue */
     NULL,                       /* signaled */
+    NULL,                       /* get_esync_fd */
     no_satisfied,               /* satisfied */
     no_signal,                  /* signal */
     no_get_fd,                  /* get_fd */
-    default_get_sync,           /* get_sync */
     default_map_access,         /* map_access */
     default_get_sd,             /* get_sd */
     default_set_sd,             /* set_sd */
diff -ruN --show-c-function --no-dereference server/symlink.c server/symlink.c
--- server/symlink.c	2025-09-06 20:10:25.819505073 -0700
+++ server/symlink.c	2025-09-06 19:58:17.767904782 -0700
@@ -71,10 +71,10 @@ static const struct object_ops symlink_o
     no_add_queue,                 /* add_queue */
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
+    NULL,                         /* get_esync_fd */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-    default_get_sync,             /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
diff -ruN --show-c-function --no-dereference server/thread.c server/thread.c
--- server/thread.c	2025-09-06 20:10:25.819505073 -0700
+++ server/thread.c	2025-09-06 19:58:17.787477686 -0700
@@ -60,6 +60,7 @@
 #include "request.h"
 #include "user.h"
 #include "security.h"
+#include "esync.h"
 
 
 /* thread queues */
@@ -85,7 +86,6 @@ struct thread_wait
 struct thread_apc
 {
     struct object       obj;      /* object header */
-    struct event_sync  *sync;     /* sync object for wait/signal */
     struct list         entry;    /* queue linked list */
     struct thread      *caller;   /* thread that queued this apc */
     struct object      *owner;    /* object that queued this apc */
@@ -96,7 +96,7 @@ struct thread_apc
 };
 
 static void dump_thread_apc( struct object *obj, int verbose );
-static struct object *thread_apc_get_sync( struct object *obj );
+static int thread_apc_signaled( struct object *obj, struct wait_queue_entry *entry );
 static void thread_apc_destroy( struct object *obj );
 static void clear_apc_queue( struct list *queue );
 
@@ -105,13 +105,13 @@ static const struct object_ops thread_ap
     sizeof(struct thread_apc),  /* size */
     &no_type,                   /* type */
     dump_thread_apc,            /* dump */
-    NULL,                       /* add_queue */
-    NULL,                       /* remove_queue */
-    NULL,                       /* signaled */
-    NULL,                       /* satisfied */
+    add_queue,                  /* add_queue */
+    remove_queue,               /* remove_queue */
+    thread_apc_signaled,        /* signaled */
+    NULL,                       /* get_esync_fd */
+    no_satisfied,               /* satisfied */
     no_signal,                  /* signal */
     no_get_fd,                  /* get_fd */
-    thread_apc_get_sync,        /* get_sync */
     default_map_access,         /* map_access */
     default_get_sd,             /* get_sd */
     default_set_sd,             /* set_sd */
@@ -130,10 +130,9 @@ static const struct object_ops thread_ap
 
 struct context
 {
-    struct object           obj;        /* object header */
-    struct event_sync      *sync;       /* sync object for wait/signal */
-    unsigned int            status;     /* status of the context */
-    struct context_data     regs[2];    /* context data */
+    struct object   obj;        /* object header */
+    unsigned int    status;     /* status of the context */
+    struct context_data regs[2];/* context data */
 };
 #define CTX_NATIVE  0  /* context for native machine */
 #define CTX_WOW     1  /* context if thread is inside WoW */
@@ -142,21 +141,20 @@ struct context
 static const unsigned int system_flags = SERVER_CTX_DEBUG_REGISTERS;
 
 static void dump_context( struct object *obj, int verbose );
-static struct object *context_get_sync( struct object *obj );
-static void context_destroy( struct object *obj );
+static int context_signaled( struct object *obj, struct wait_queue_entry *entry );
 
 static const struct object_ops context_ops =
 {
     sizeof(struct context),     /* size */
     &no_type,                   /* type */
     dump_context,               /* dump */
-    NULL,                       /* add_queue */
-    NULL,                       /* remove_queue */
-    NULL,                       /* signaled */
-    NULL,                       /* satisfied */
+    add_queue,                  /* add_queue */
+    remove_queue,               /* remove_queue */
+    context_signaled,           /* signaled */
+    NULL,                       /* get_esync_fd */
+    no_satisfied,               /* satisfied */
     no_signal,                  /* signal */
     no_get_fd,                  /* get_fd */
-    context_get_sync,           /* get_sync */
     default_map_access,         /* map_access */
     default_get_sd,             /* get_sd */
     default_set_sd,             /* set_sd */
@@ -167,7 +165,7 @@ static const struct object_ops context_o
     no_open_file,               /* open_file */
     no_kernel_obj_list,         /* get_kernel_obj_list */
     no_close_handle,            /* close_handle */
-    context_destroy,            /* destroy */
+    no_destroy                  /* destroy */
 };
 
 
@@ -189,7 +187,8 @@ struct type_descr thread_type =
 };
 
 static void dump_thread( struct object *obj, int verbose );
-static struct object *thread_get_sync( struct object *obj );
+static int thread_signaled( struct object *obj, struct wait_queue_entry *entry );
+static int thread_get_esync_fd( struct object *obj, enum esync_type *type );
 static unsigned int thread_map_access( struct object *obj, unsigned int access );
 static void thread_poll_event( struct fd *fd, int event );
 static struct list *thread_get_kernel_obj_list( struct object *obj );
@@ -200,13 +199,13 @@ static const struct object_ops thread_op
     sizeof(struct thread),      /* size */
     &thread_type,               /* type */
     dump_thread,                /* dump */
-    NULL,                       /* add_queue */
-    NULL,                       /* remove_queue */
-    NULL,                       /* signaled */
-    NULL,                       /* satisfied */
+    add_queue,                  /* add_queue */
+    remove_queue,               /* remove_queue */
+    thread_signaled,            /* signaled */
+    thread_get_esync_fd,        /* get_esync_fd */
+    no_satisfied,               /* satisfied */
     no_signal,                  /* signal */
     no_get_fd,                  /* get_fd */
-    thread_get_sync,            /* get_sync */
     thread_map_access,          /* map_access */
     default_get_sd,             /* get_sd */
     default_set_sd,             /* set_sd */
@@ -396,12 +395,13 @@ static inline void init_thread_structure
 {
     int i;
 
-    thread->sync            = NULL;
     thread->unix_pid        = -1;  /* not known yet */
     thread->unix_tid        = -1;  /* not known yet */
     thread->context         = NULL;
     thread->teb             = 0;
     thread->entry_point     = 0;
+    thread->esync_fd        = -1;
+    thread->esync_apc_fd    = -1;
     thread->system_regs     = 0;
     thread->queue           = NULL;
     thread->wait            = NULL;
@@ -463,35 +463,20 @@ static void dump_context( struct object
 }
 
 
-static struct object *context_get_sync( struct object *obj )
+static int context_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct context *context = (struct context *)obj;
-    assert( obj->ops == &context_ops );
-    return grab_object( context->sync );
+    return context->status != STATUS_PENDING;
 }
 
-static void context_destroy( struct object *obj )
-{
-    struct context *context = (struct context *)obj;
-    assert( obj->ops == &context_ops );
-    if (context->sync) release_object( context->sync );
-}
 
 static struct context *create_thread_context( struct thread *thread )
 {
     struct context *context;
     if (!(context = alloc_object( &context_ops ))) return NULL;
-    context->sync   = NULL;
     context->status = STATUS_PENDING;
     memset( &context->regs, 0, sizeof(context->regs) );
     context->regs[CTX_NATIVE].machine = native_machine;
-
-    if (!(context->sync = create_event_sync( 1, 0 )))
-    {
-        release_object( context );
-        return NULL;
-    }
-
     return context;
 }
 
@@ -558,8 +543,11 @@ struct thread *create_thread( int fd, st
         release_object( thread );
         return NULL;
     }
-    if (!(thread->request_fd = create_anonymous_fd( &thread_fd_ops, fd, &thread->obj, 0 ))) goto error;
-    if (!(thread->sync = create_event_sync( 1, 0 ))) goto error;
+    if (!(thread->request_fd = create_anonymous_fd( &thread_fd_ops, fd, &thread->obj, 0 )))
+    {
+        release_object( thread );
+        return NULL;
+    }
 
     if (process->desktop)
     {
@@ -571,13 +559,15 @@ struct thread *create_thread( int fd, st
         }
     }
 
+    if (do_esync())
+    {
+        thread->esync_fd = esync_create_fd( 0, 0 );
+        thread->esync_apc_fd = esync_create_fd( 0, 0 );
+    }
+
     set_fd_events( thread->request_fd, POLLIN );  /* start listening to events */
     add_process_thread( thread->process, thread );
     return thread;
-
-error:
-    release_object( thread );
-    return NULL;
 }
 
 /* handle a client event */
@@ -609,7 +599,7 @@ static void cleanup_thread( struct threa
     if (thread->context)
     {
         thread->context->status = STATUS_ACCESS_DENIED;
-        signal_sync( thread->context->sync );
+        wake_up( &thread->context->obj, 0 );
         release_object( thread->context );
         thread->context = NULL;
     }
@@ -654,7 +644,9 @@ static void destroy_thread( struct objec
     release_object( thread->process );
     if (thread->id) free_ptid( thread->id );
     if (thread->token) release_object( thread->token );
-    if (thread->sync) release_object( thread->sync );
+
+    if (do_esync())
+        close( thread->esync_fd );
 }
 
 /* dump a thread on stdout for debugging purposes */
@@ -667,11 +659,17 @@ static void dump_thread( struct object *
              thread->id, thread->unix_pid, thread->unix_tid, thread->state );
 }
 
-static struct object *thread_get_sync( struct object *obj )
+static int thread_signaled( struct object *obj, struct wait_queue_entry *entry )
+{
+    struct thread *mythread = (struct thread *)obj;
+    return (mythread->state == TERMINATED);
+}
+
+static int thread_get_esync_fd( struct object *obj, enum esync_type *type )
 {
     struct thread *thread = (struct thread *)obj;
-    assert( obj->ops == &thread_ops );
-    return grab_object( thread->sync );
+    *type = ESYNC_MANUAL_SERVER;
+    return thread->esync_fd;
 }
 
 static unsigned int thread_map_access( struct object *obj, unsigned int access )
@@ -690,11 +688,10 @@ static void dump_thread_apc( struct obje
     fprintf( stderr, "APC owner=%p type=%u\n", apc->owner, apc->call.type );
 }
 
-static struct object *thread_apc_get_sync( struct object *obj )
+static int thread_apc_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct thread_apc *apc = (struct thread_apc *)obj;
-    assert( obj->ops == &thread_apc_ops );
-    return grab_object( apc->sync );
+    return apc->executed;
 }
 
 static void thread_apc_destroy( struct object *obj )
@@ -710,7 +707,6 @@ static void thread_apc_destroy( struct o
             async_set_result( apc->owner, apc->call.async_io.status, 0 );
         release_object( apc->owner );
     }
-    if (apc->sync) release_object( apc->sync );
     reserve_obj_unbind( apc->reserve );
 }
 
@@ -721,7 +717,6 @@ static struct thread_apc *create_apc( st
 
     if ((apc = alloc_object( &thread_apc_ops )))
     {
-        apc->sync        = NULL;
         if (call_data) apc->call = *call_data;
         else apc->call.type = APC_NONE;
         apc->caller      = NULL;
@@ -730,12 +725,6 @@ static struct thread_apc *create_apc( st
         apc->executed    = 0;
         apc->result.type = APC_NONE;
         if (owner) grab_object( owner );
-
-        if (!(apc->sync = create_event_sync( 1, 0 )))
-        {
-            release_object( apc );
-            return NULL;
-        }
     }
     return apc;
 }
@@ -963,6 +952,8 @@ int resume_thread( struct thread *thread
 /* add a thread to an object wait queue; return 1 if OK, 0 on error */
 int add_queue( struct object *obj, struct wait_queue_entry *entry )
 {
+    grab_object( obj );
+    entry->obj = obj;
     list_add_tail( &obj->wait_queue, &entry->entry );
     return 1;
 }
@@ -971,6 +962,7 @@ int add_queue( struct object *obj, struc
 void remove_queue( struct object *obj, struct wait_queue_entry *entry )
 {
     list_remove( &entry->entry );
+    release_object( obj );
 }
 
 struct thread *get_wait_queue_thread( struct wait_queue_entry *entry )
@@ -998,36 +990,6 @@ void set_wait_status( struct wait_queue_
     entry->wait->status = status;
 }
 
-static void object_sync_satisfied( struct object *obj, struct wait_queue_entry *entry )
-{
-    struct object *sync = get_obj_sync( obj );
-    sync->ops->satisfied( sync, entry );
-    release_object( sync );
-}
-
-static void object_sync_remove_queue( struct object *obj, struct wait_queue_entry *entry )
-{
-    struct object *sync = get_obj_sync( obj );
-    sync->ops->remove_queue( sync, entry );
-    release_object( sync );
-}
-
-static int object_sync_add_queue( struct object *obj, struct wait_queue_entry *entry )
-{
-    struct object *sync = get_obj_sync( obj );
-    int ret = sync->ops->add_queue( sync, entry );
-    release_object( sync );
-    return ret;
-}
-
-static int object_sync_signaled( struct object *obj, struct wait_queue_entry *entry )
-{
-    struct object *sync = get_obj_sync( obj );
-    int ret = sync->ops->signaled( sync, entry );
-    release_object( sync );
-    return ret;
-}
-
 /* finish waiting */
 static unsigned int end_wait( struct thread *thread, unsigned int status )
 {
@@ -1044,22 +1006,18 @@ static unsigned int end_wait( struct thr
         if (wait->select == SELECT_WAIT_ALL)
         {
             for (i = 0, entry = wait->queues; i < wait->count; i++, entry++)
-                object_sync_satisfied( entry->obj, entry );
+                entry->obj->ops->satisfied( entry->obj, entry );
         }
         else
         {
             entry = wait->queues + status;
-            object_sync_satisfied( entry->obj, entry );
+            entry->obj->ops->satisfied( entry->obj, entry );
         }
         status = wait->status;
         if (wait->abandoned) status += STATUS_ABANDONED_WAIT_0;
     }
     for (i = 0, entry = wait->queues; i < wait->count; i++, entry++)
-    {
-        object_sync_remove_queue( entry->obj, entry );
-        release_object( entry->obj );
-        entry->obj = NULL;
-    }
+        entry->obj->ops->remove_queue( entry->obj, entry );
     if (wait->user) remove_timeout_user( wait->user );
     free( wait );
     return status;
@@ -1089,14 +1047,13 @@ static int wait_on( const union select_o
     {
         struct object *obj = objects[i];
         entry->wait = wait;
-        if (!object_sync_add_queue( obj, entry ))
+        if (!obj->ops->add_queue( obj, entry ))
         {
             wait->count = i;
             end_wait( current, get_error() );
             return 0;
         }
 
-        entry->obj = grab_object( obj );
         if (obj == (struct object *)current->queue) idle = 1;
     }
 
@@ -1144,13 +1101,13 @@ static int check_wait( struct thread *th
         /* Note: we must check them all anyway, as some objects may
          * want to do something when signaled, even if others are not */
         for (i = 0, entry = wait->queues; i < wait->count; i++, entry++)
-            not_ok |= !object_sync_signaled( entry->obj, entry );
+            not_ok |= !entry->obj->ops->signaled( entry->obj, entry );
         if (!not_ok) return STATUS_WAIT_0;
     }
     else
     {
         for (i = 0, entry = wait->queues; i < wait->count; i++, entry++)
-            if (object_sync_signaled( entry->obj, entry )) return i;
+            if (entry->obj->ops->signaled( entry->obj, entry )) return i;
     }
 
     if ((wait->flags & SELECT_ALERTABLE) && !list_empty(&thread->user_apc)) return STATUS_USER_APC;
@@ -1357,6 +1314,9 @@ void wake_up( struct object *obj, int ma
     struct list *ptr;
     int ret;
 
+    if (do_esync())
+        esync_wake_up( obj );
+
     LIST_FOR_EACH( ptr, &obj->wait_queue )
     {
         struct wait_queue_entry *entry = LIST_ENTRY( ptr, struct wait_queue_entry, entry );
@@ -1440,8 +1400,13 @@ static int queue_apc( struct process *pr
     grab_object( apc );
     list_add_tail( queue, &apc->entry );
     if (!list_prev( queue, &apc->entry ))  /* first one */
+    {
         wake_thread( thread );
 
+        if (do_esync() && queue == &thread->user_apc)
+            esync_wake_fd( thread->esync_apc_fd );
+    }
+
     return 1;
 }
 
@@ -1470,7 +1435,7 @@ void thread_cancel_apc( struct thread *t
         if (apc->owner != owner) continue;
         list_remove( &apc->entry );
         apc->executed = 1;
-        signal_sync( apc->sync );
+        wake_up( &apc->obj, 0 );
         release_object( apc );
         return;
     }
@@ -1487,6 +1452,10 @@ static struct thread_apc *thread_dequeue
         apc = LIST_ENTRY( ptr, struct thread_apc, entry );
         list_remove( ptr );
     }
+
+    if (do_esync() && list_empty( &thread->system_apc ) && list_empty( &thread->user_apc ))
+        esync_clear( thread->esync_apc_fd );
+
     return apc;
 }
 
@@ -1500,7 +1469,7 @@ static void clear_apc_queue( struct list
         struct thread_apc *apc = LIST_ENTRY( ptr, struct thread_apc, entry );
         list_remove( &apc->entry );
         apc->executed = 1;
-        signal_sync( apc->sync );
+        wake_up( &apc->obj, 0 );
         release_object( apc );
     }
 }
@@ -1582,7 +1551,9 @@ void kill_thread( struct thread *thread,
     }
     kill_console_processes( thread, 0 );
     abandon_mutexes( thread );
-    signal_sync( thread->sync );
+    wake_up( &thread->obj, 0 );
+    if (do_esync())
+        esync_abandon_mutexes( thread );
     if (violent_death) send_thread_signal( thread, SIGQUIT );
     cleanup_thread( thread );
     remove_process_thread( thread->process, thread );
@@ -1709,7 +1680,6 @@ static int init_thread( struct thread *t
 DECL_HANDLER(init_first_thread)
 {
     struct process *process = current->process;
-    int fd;
 
     if (!init_thread( current, req->reply_fd, req->wait_fd )) return;
 
@@ -1732,12 +1702,6 @@ DECL_HANDLER(init_first_thread)
     reply->server_start = server_start_time;
     set_reply_data( supported_machines,
                     min( supported_machines_count * sizeof(unsigned short), get_reply_max_size() ));
-
-    if ((fd = get_inproc_device_fd()) >= 0)
-    {
-        reply->inproc_device = get_process_id( process ) | 1;
-        send_client_fd( process, fd, reply->inproc_device );
-    }
 }
 
 /* initialize a new thread */
@@ -1946,7 +1910,7 @@ DECL_HANDLER(select)
         }
         ctx->status = STATUS_SUCCESS;
         current->suspend_cookie = req->cookie;
-        signal_sync( ctx->sync );
+        wake_up( &ctx->obj, 0 );
     }
 
     if (!req->cookie) goto invalid_param;
@@ -1970,7 +1934,7 @@ DECL_HANDLER(select)
             apc->result.create_thread.handle = handle;
             clear_error();  /* ignore errors from the above calls */
         }
-        signal_sync( apc->sync );
+        wake_up( &apc->obj, 0 );
         close_handle( current->process, req->prev_apc );
         release_object( apc );
     }
@@ -1993,7 +1957,7 @@ DECL_HANDLER(select)
         else
         {
             apc->executed = 1;
-            signal_sync( apc->sync );
+            wake_up( &apc->obj, 0 );
         }
         release_object( apc );
     }
diff -ruN --show-c-function --no-dereference server/thread.h server/thread.h
--- server/thread.h	2025-09-06 20:10:25.819505073 -0700
+++ server/thread.h	2025-09-06 19:58:17.780493713 -0700
@@ -50,13 +50,14 @@ struct inflight_fd
 struct thread
 {
     struct object          obj;           /* object header */
-    struct event_sync     *sync;          /* sync object for wait/signal */
     struct list            entry;         /* entry in system-wide thread list */
     struct list            proc_entry;    /* entry in per-process thread list */
     struct list            desktop_entry; /* entry in per-desktop thread list */
     struct process        *process;
     thread_id_t            id;            /* thread id */
     struct list            mutex_list;    /* list of currently owned mutexes */
+    int                    esync_fd;      /* esync file descriptor (signalled on exit) */
+    int                    esync_apc_fd;  /* esync apc fd (signalled when APCs are present) */
     unsigned int           system_regs;   /* which system regs have been set */
     struct msg_queue      *queue;         /* message queue */
     struct thread_wait    *wait;          /* current wait condition if sleeping */
diff -ruN --show-c-function --no-dereference server/timer.c server/timer.c
--- server/timer.c	2025-09-06 20:10:25.819505073 -0700
+++ server/timer.c	2025-09-06 19:58:17.778634204 -0700
@@ -35,6 +35,7 @@
 #include "file.h"
 #include "handle.h"
 #include "request.h"
+#include "esync.h"
 
 static const WCHAR timer_name[] = {'T','i','m','e','r'};
 
@@ -53,7 +54,6 @@ struct type_descr timer_type =
 struct timer
 {
     struct object        obj;       /* object header */
-    struct event_sync   *sync;      /* sync object for wait/signal */
     int                  manual;    /* manual reset */
     int                  signaled;  /* current signaled state */
     unsigned int         period;    /* timer period in ms */
@@ -62,10 +62,13 @@ struct timer
     struct thread       *thread;    /* thread that set the APC function */
     client_ptr_t         callback;  /* callback APC function */
     client_ptr_t         arg;       /* callback argument */
+    int                  esync_fd;  /* esync file descriptor */
 };
 
 static void timer_dump( struct object *obj, int verbose );
-static struct object *timer_get_sync( struct object *obj );
+static int timer_signaled( struct object *obj, struct wait_queue_entry *entry );
+static int timer_get_esync_fd( struct object *obj, enum esync_type *type );
+static void timer_satisfied( struct object *obj, struct wait_queue_entry *entry );
 static void timer_destroy( struct object *obj );
 
 static const struct object_ops timer_ops =
@@ -73,13 +76,13 @@ static const struct object_ops timer_ops
     sizeof(struct timer),      /* size */
     &timer_type,               /* type */
     timer_dump,                /* dump */
-    NULL,                      /* add_queue */
-    NULL,                      /* remove_queue */
-    NULL,                      /* signaled */
-    NULL,                      /* satisfied */
+    add_queue,                 /* add_queue */
+    remove_queue,              /* remove_queue */
+    timer_signaled,            /* signaled */
+    timer_get_esync_fd,        /* get_esync_fd */
+    timer_satisfied,           /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
-    timer_get_sync,            /* get_sync */
     default_map_access,        /* map_access */
     default_get_sd,            /* get_sd */
     default_set_sd,            /* set_sd */
@@ -105,19 +108,16 @@ static struct timer *create_timer( struc
         if (get_error() != STATUS_OBJECT_NAME_EXISTS)
         {
             /* initialize it if it didn't already exist */
-            timer->sync     = NULL;
             timer->manual   = manual;
             timer->signaled = 0;
             timer->when     = 0;
             timer->period   = 0;
             timer->timeout  = NULL;
             timer->thread   = NULL;
+            timer->esync_fd = -1;
 
-            if (!(timer->sync = create_event_sync( manual, 0 )))
-            {
-                release_object( timer );
-                return NULL;
-            }
+            if (do_esync())
+                timer->esync_fd = esync_create_fd( 0, 0 );
         }
     }
     return timer;
@@ -157,8 +157,9 @@ static void timer_callback( void *privat
     }
     else timer->timeout = NULL;
 
+    /* wake up waiters */
     timer->signaled = 1;
-    signal_sync( timer->sync );
+    wake_up( &timer->obj, 0 );
 }
 
 /* cancel a running timer */
@@ -189,7 +190,9 @@ static int set_timer( struct timer *time
     {
         period = 0;  /* period doesn't make any sense for a manual timer */
         timer->signaled = 0;
-        reset_sync( timer->sync );
+
+        if (do_esync())
+            esync_clear( timer->esync_fd );
     }
     timer->when     = (expire <= 0) ? expire - monotonic_time : max( expire, current_time );
     timer->period   = period;
@@ -210,11 +213,25 @@ static void timer_dump( struct object *o
              timer->manual, get_timeout_str(timeout), timer->period );
 }
 
-static struct object *timer_get_sync( struct object *obj )
+static int timer_signaled( struct object *obj, struct wait_queue_entry *entry )
+{
+    struct timer *timer = (struct timer *)obj;
+    assert( obj->ops == &timer_ops );
+    return timer->signaled;
+}
+
+static int timer_get_esync_fd( struct object *obj, enum esync_type *type )
+{
+    struct timer *timer = (struct timer *)obj;
+    *type = timer->manual ? ESYNC_MANUAL_SERVER : ESYNC_AUTO_SERVER;
+    return timer->esync_fd;
+}
+
+static void timer_satisfied( struct object *obj, struct wait_queue_entry *entry )
 {
     struct timer *timer = (struct timer *)obj;
     assert( obj->ops == &timer_ops );
-    return grab_object( timer->sync );
+    if (!timer->manual) timer->signaled = 0;
 }
 
 static void timer_destroy( struct object *obj )
@@ -224,7 +241,7 @@ static void timer_destroy( struct object
 
     if (timer->timeout) remove_timeout_user( timer->timeout );
     if (timer->thread) release_object( timer->thread );
-    if (timer->sync) release_object( timer->sync );
+    if (do_esync()) close( timer->esync_fd );
 }
 
 /* create a timer */
diff -ruN --show-c-function --no-dereference server/token.c server/token.c
--- server/token.c	2025-09-06 20:10:25.820505108 -0700
+++ server/token.c	2025-09-06 19:58:17.768421776 -0700
@@ -145,10 +145,10 @@ static const struct object_ops token_ops
     no_add_queue,              /* add_queue */
     NULL,                      /* remove_queue */
     NULL,                      /* signaled */
+    NULL,                      /* get_esync_fd */
     NULL,                      /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
-    default_get_sync,          /* get_sync */
     default_map_access,        /* map_access */
     default_get_sd,            /* get_sd */
     token_set_sd,              /* set_sd */
diff -ruN --show-c-function --no-dereference server/user.h server/user.h
--- server/user.h	2025-09-06 20:10:25.820505108 -0700
+++ server/user.h	2025-09-06 19:58:17.745242870 -0700
@@ -120,7 +120,6 @@ extern void inc_queue_paint_count( struc
 extern void queue_cleanup_window( struct thread *thread, user_handle_t win );
 extern int init_thread_queue( struct thread *thread );
 extern void check_thread_queue_idle( struct thread *thread );
-extern struct object *thread_queue_inproc_sync( struct thread *thread );
 extern int attach_thread_input( struct thread *thread_from, struct thread *thread_to );
 extern void detach_thread_input( struct thread *thread_from );
 extern void set_clip_rectangle( struct desktop *desktop, const struct rectangle *rect,
diff -ruN --show-c-function --no-dereference server/window.c server/window.c
--- server/window.c	2025-09-06 20:10:25.820505108 -0700
+++ server/window.c	2025-09-06 19:58:17.768662314 -0700
@@ -108,10 +108,10 @@ static const struct object_ops window_op
     no_add_queue,             /* add_queue */
     NULL,                     /* remove_queue */
     NULL,                     /* signaled */
+    NULL,                     /* get_esync_fd */
     NULL,                     /* satisfied */
     no_signal,                /* signal */
     no_get_fd,                /* get_fd */
-    default_get_sync,         /* get_sync */
     default_map_access,       /* map_access */
     default_get_sd,           /* get_sd */
     default_set_sd,           /* set_sd */
diff -ruN --show-c-function --no-dereference server/winstation.c server/winstation.c
--- server/winstation.c	2025-09-06 20:10:25.820505108 -0700
+++ server/winstation.c	2025-09-06 19:58:17.768943119 -0700
@@ -76,10 +76,10 @@ static const struct object_ops winstatio
     no_add_queue,                 /* add_queue */
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
+    NULL,                         /* get_esync_fd */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-    default_get_sync,             /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
@@ -117,10 +117,10 @@ static const struct object_ops desktop_o
     no_add_queue,                 /* add_queue */
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
+    NULL,                         /* get_esync_fd */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-    default_get_sync,             /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
