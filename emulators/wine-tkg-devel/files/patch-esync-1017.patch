diff -ruN --show-c-function configure configure
--- configure	2025-10-21 17:44:47.290026993 -0700
+++ configure	2025-10-24 16:11:51.058644622 -0700
@@ -10023,12 +10023,6 @@ then :
   printf "%s\n" "#define HAVE_LINUX_MAJOR_H 1" >>confdefs.h
 
 fi
-ac_fn_c_check_header_compile "$LINENO" "linux/ntsync.h" "ac_cv_header_linux_ntsync_h" "$ac_includes_default"
-if test "x$ac_cv_header_linux_ntsync_h" = xyes
-then :
-  printf "%s\n" "#define HAVE_LINUX_NTSYNC_H 1" >>confdefs.h
-
-fi
 ac_fn_c_check_header_compile "$LINENO" "linux/param.h" "ac_cv_header_linux_param_h" "$ac_includes_default"
 if test "x$ac_cv_header_linux_param_h" = xyes
 then :
@@ -10203,6 +10197,12 @@ then :
   printf "%s\n" "#define HAVE_SYS_EVENT_H 1" >>confdefs.h
 
 fi
+ac_fn_c_check_header_compile "$LINENO" "sys/eventfd.h" "ac_cv_header_sys_eventfd_h" "$ac_includes_default"
+if test "x$ac_cv_header_sys_eventfd_h" = xyes
+then :
+  printf "%s\n" "#define HAVE_SYS_EVENTFD_H 1" >>confdefs.h
+
+fi
 ac_fn_c_check_header_compile "$LINENO" "sys/extattr.h" "ac_cv_header_sys_extattr_h" "$ac_includes_default"
 if test "x$ac_cv_header_sys_extattr_h" = xyes
 then :
@@ -21314,6 +21314,12 @@ then :
   printf "%s\n" "#define HAVE_POSIX_FALLOCATE 1" >>confdefs.h
 
 fi
+ac_fn_c_check_func "$LINENO" "ppoll" "ac_cv_func_ppoll"
+if test "x$ac_cv_func_ppoll" = xyes
+then :
+  printf "%s\n" "#define HAVE_PPOLL 1" >>confdefs.h
+
+fi
 ac_fn_c_check_func "$LINENO" "prctl" "ac_cv_func_prctl"
 if test "x$ac_cv_func_prctl" = xyes
 then :
@@ -21445,6 +21451,80 @@ fi
 
 LIBS=$ac_save_LIBS
 
+ac_save_LIBS=$LIBS
+{ printf "%s\n" "$as_me:${as_lineno-$LINENO}: checking for library containing shm_open" >&5
+printf %s "checking for library containing shm_open... " >&6; }
+if test ${ac_cv_search_shm_open+y}
+then :
+  printf %s "(cached) " >&6
+else case e in #(
+  e) ac_func_search_save_LIBS=$LIBS
+cat confdefs.h - <<_ACEOF >conftest.$ac_ext
+/* end confdefs.h.  */
+
+/* Override any GCC internal prototype to avoid an error.
+   Use char because int might match the return type of a GCC
+   builtin and then its argument prototype would still apply.
+   The 'extern "C"' is for builds by C++ compilers;
+   although this is not generally supported in C code supporting it here
+   has little cost and some practical benefit (sr 110532).  */
+#ifdef __cplusplus
+extern "C"
+#endif
+char shm_open (void);
+int
+main (void)
+{
+return shm_open ();
+  ;
+  return 0;
+}
+_ACEOF
+for ac_lib in '' rt
+do
+  if test -z "$ac_lib"; then
+    ac_res="none required"
+  else
+    ac_res=-l$ac_lib
+    LIBS="-l$ac_lib  $ac_func_search_save_LIBS"
+  fi
+  if ac_fn_c_try_link "$LINENO"
+then :
+  ac_cv_search_shm_open=$ac_res
+fi
+rm -f core conftest.err conftest.$ac_objext conftest.beam \
+    conftest$ac_exeext
+  if test ${ac_cv_search_shm_open+y}
+then :
+  break
+fi
+done
+if test ${ac_cv_search_shm_open+y}
+then :
+
+else case e in #(
+  e) ac_cv_search_shm_open=no ;;
+esac
+fi
+rm conftest.$ac_ext
+LIBS=$ac_func_search_save_LIBS ;;
+esac
+fi
+{ printf "%s\n" "$as_me:${as_lineno-$LINENO}: result: $ac_cv_search_shm_open" >&5
+printf "%s\n" "$ac_cv_search_shm_open" >&6; }
+ac_res=$ac_cv_search_shm_open
+if test "$ac_res" != no
+then :
+  test "$ac_res" = "none required" || LIBS="$ac_res $LIBS"
+
+printf "%s\n" "#define HAVE_SHM_OPEN 1" >>confdefs.h
+
+                test "$ac_res" = "none required" || RT_LIBS="$ac_res"
+
+fi
+
+LIBS=$ac_save_LIBS
+
 { printf "%s\n" "$as_me:${as_lineno-$LINENO}: checking for sched_setaffinity" >&5
 printf %s "checking for sched_setaffinity... " >&6; }
 if test ${wine_cv_have_sched_setaffinity+y}
@@ -23549,7 +23629,7 @@ fi
 
 as_fn_append wine_rules "
 dlls/ntdll/unix/version.c: dummy
-	@version=\`(GIT_DIR=${wine_srcdir}.git git describe HEAD 2>/dev/null || echo \"wine-\$(PACKAGE_VERSION)\") | sed -n -e '\$\$s/\(.*\)/const char wine_build[] = \"\\1\";/p'\` && (echo \$\$version | cmp -s - \$@) || echo \$\$version >\$@ || (rm -f \$@ && exit 1)
+	@version=\`(echo \"wine-10.17\") | sed -n -e '\$\$s/\(.*\)/const char wine_build[] = \"\\1  ( FreeBSD TkG Esync )\";/p'\` && (echo \$\$version | cmp -s - \$@) || echo \$\$version >\$@ || (rm -f \$@ && exit 1)
 programs/winetest/build.rc: dummy
 	@build=\"STRINGTABLE { 1 \\\"\`GIT_DIR=${wine_srcdir}.git git rev-parse HEAD 2>/dev/null\`\\\" }\" && (echo \$\$build | cmp -s - \$@) || echo \$\$build >\$@ || (rm -f \$@ && exit 1)
 dlls/wineandroid.drv/wine-debug.apk: dlls/wineandroid.drv/build.gradle ${wine_srcdir}dlls/wineandroid.drv/AndroidManifest.xml ${wine_srcdir}dlls/wineandroid.drv/WineActivity.java ${wine_srcdir}dlls/wineandroid.drv/wine.svg
diff -ruN --show-c-function configure.ac configure.ac
--- configure.ac	2025-10-21 20:56:16.464249113 -0700
+++ configure.ac	2025-10-24 16:11:51.038644167 -0700
@@ -683,7 +683,6 @@ AC_CHECK_HEADERS(\
 	linux/input.h \
 	linux/ioctl.h \
 	linux/major.h \
-	linux/ntsync.h \
 	linux/param.h \
 	linux/serial.h \
 	linux/types.h \
@@ -713,6 +712,7 @@ AC_CHECK_HEADERS(\
 	sys/cdio.h \
 	sys/epoll.h \
 	sys/event.h \
+	sys/eventfd.h \
 	sys/extattr.h \
 	sys/filio.h \
 	sys/ipc.h \
@@ -2131,6 +2131,7 @@ AC_CHECK_FUNCS(\
 	port_create \
 	posix_fadvise \
 	posix_fallocate \
+	ppoll \
 	prctl \
 	sched_getcpu \
 	sched_yield \
@@ -2150,6 +2151,12 @@ AC_SEARCH_LIBS(clock_gettime, rt,
                 test "$ac_res" = "none required" || AC_SUBST(RT_LIBS,"$ac_res")])
 LIBS=$ac_save_LIBS
 
+ac_save_LIBS=$LIBS
+AC_SEARCH_LIBS(shm_open, rt,
+               [AC_DEFINE(HAVE_SHM_OPEN, 1, [Define to 1 if you have the `shm_open' function.])
+                test "$ac_res" = "none required" || AC_SUBST(RT_LIBS,"$ac_res")])
+LIBS=$ac_save_LIBS
+
 AC_CACHE_CHECK([for sched_setaffinity],wine_cv_have_sched_setaffinity,
                 AC_LINK_IFELSE([AC_LANG_PROGRAM(
 [[#include <sched.h>]], [[sched_setaffinity(0, 0, 0);]])],[wine_cv_have_sched_setaffinity=yes],[wine_cv_have_sched_setaffinity=no]))
@@ -3758,7 +3765,7 @@ dnl Rules for generated source files
 
 WINE_APPEND_RULE(
 [dlls/ntdll/unix/version.c: dummy
-	@version=\`(GIT_DIR=${wine_srcdir}.git git describe HEAD 2>/dev/null || echo \"wine-\$(PACKAGE_VERSION)\") | sed -n -e '\$\$s/\(.*\)/const char wine_build[[]] = \"\\1\";/p'\` && (echo \$\$version | cmp -s - \$[@]) || echo \$\$version >\$[@] || (rm -f \$[@] && exit 1)
+	@version=\`(echo \"wine-10.17\") | sed -n -e '\$\$s/\(.*\)/const char wine_build[] = \"\\1  ( FreeBSD TkG Esync )\";/p'\` && (echo \$\$version | cmp -s - \$@) || echo \$\$version >\$@ || (rm -f \$@ && exit 1)
 programs/winetest/build.rc: dummy
 	@build=\"STRINGTABLE { 1 \\\"\`GIT_DIR=${wine_srcdir}.git git rev-parse HEAD 2>/dev/null\`\\\" }\" && (echo \$\$build | cmp -s - \$[@]) || echo \$\$build >\$[@] || (rm -f \$[@] && exit 1)
 dlls/wineandroid.drv/wine-debug.apk: dlls/wineandroid.drv/build.gradle ${wine_srcdir}dlls/wineandroid.drv/AndroidManifest.xml ${wine_srcdir}dlls/wineandroid.drv/WineActivity.java ${wine_srcdir}dlls/wineandroid.drv/wine.svg
diff -ruN --show-c-function dlls/kernel32/tests/sync.c dlls/kernel32/tests/sync.c
--- dlls/kernel32/tests/sync.c	2025-10-21 17:44:36.784790897 -0700
+++ dlls/kernel32/tests/sync.c	2025-10-24 16:11:42.416109741 -0700
@@ -60,6 +60,7 @@ static DWORD (WINAPI *pQueueUserAPC2)(PA
 
 static NTSTATUS (WINAPI *pNtAllocateVirtualMemory)(HANDLE, PVOID *, ULONG_PTR, SIZE_T *, ULONG, ULONG);
 static NTSTATUS (WINAPI *pNtFreeVirtualMemory)(HANDLE, PVOID *, SIZE_T *, ULONG);
+static NTSTATUS (WINAPI *pNtQuerySystemTime)(LARGE_INTEGER *);
 static NTSTATUS (WINAPI *pNtWaitForSingleObject)(HANDLE, BOOLEAN, const LARGE_INTEGER *);
 static NTSTATUS (WINAPI *pNtWaitForMultipleObjects)(ULONG,const HANDLE*,BOOLEAN,BOOLEAN,const LARGE_INTEGER*);
 static PSLIST_ENTRY (__fastcall *pRtlInterlockedPushListSList)(PSLIST_HEADER list, PSLIST_ENTRY first,
@@ -292,7 +293,8 @@ static void test_mutex(void)
     SetLastError(0xdeadbeef);
     hOpened = OpenMutexA(GENERIC_READ | GENERIC_WRITE, FALSE, "WineTestMutex");
     ok(hOpened != NULL, "OpenMutex failed with error %ld\n", GetLastError());
-    wait_ret = WaitForSingleObject(hOpened, INFINITE);
+    wait_ret = WaitForSingleObject(hOpened, 0);
+todo_wine_if(getenv("WINEESYNC"))   /* XFAIL: validation is not implemented */
     ok(wait_ret == WAIT_FAILED, "WaitForSingleObject succeeded\n");
     CloseHandle(hOpened);
 
@@ -323,6 +325,7 @@ static void test_mutex(void)
 
     SetLastError(0xdeadbeef);
     ret = ReleaseMutex(hCreated);
+todo_wine_if(getenv("WINEESYNC"))   /* XFAIL: due to the above */
     ok(!ret && (GetLastError() == ERROR_NOT_OWNER),
         "ReleaseMutex should have failed with ERROR_NOT_OWNER instead of %ld\n", GetLastError());
 
@@ -572,12 +575,13 @@ static void test_slist(void)
 
 static void test_event(void)
 {
-    HANDLE handle, handle2;
+    HANDLE handle, handle2, handles[2];
     SECURITY_ATTRIBUTES sa;
     SECURITY_DESCRIPTOR sd;
     ACL acl;
     DWORD ret;
     BOOL val;
+    int i;
 
     /* no sd */
     handle = CreateEventA(NULL, FALSE, FALSE, __FILE__ ": Test Event");
@@ -681,11 +685,130 @@ static void test_event(void)
     ok( ret, "QueryMemoryResourceNotification failed err %lu\n", GetLastError() );
     ok( val == FALSE || val == TRUE, "wrong value %u\n", val );
     CloseHandle( handle );
+
+    handle = CreateEventA( NULL, TRUE, FALSE, NULL );
+    ok(!!handle, "got error %lu\n", GetLastError());
+
+    ret = WaitForSingleObject( handle, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    ret = SetEvent( handle );
+    ok(ret, "got error %lu\n", GetLastError());
+
+    ret = SetEvent( handle );
+    ok(ret, "got error %lu\n", GetLastError());
+
+    for (i = 0; i < 100; i++)
+    {
+        ret = WaitForSingleObject( handle, 0 );
+        ok(ret == 0, "got %lu\n", ret);
+    }
+
+    ret = ResetEvent( handle );
+    ok(ret, "got error %lu\n", GetLastError());
+
+    ret = ResetEvent( handle );
+    ok(ret, "got error %lu\n", GetLastError());
+
+    ret = WaitForSingleObject( handle, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    handle2 = CreateEventA( NULL, FALSE, TRUE, NULL );
+    ok(!!handle2, "got error %lu\n", GetLastError());
+
+    ret = WaitForSingleObject( handle2, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    ret = WaitForSingleObject( handle2, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    ret = SetEvent( handle2 );
+    ok(ret, "got error %lu\n", GetLastError());
+
+    ret = SetEvent( handle2 );
+    ok(ret, "got error %lu\n", GetLastError());
+
+    ret = ResetEvent( handle2 );
+    ok(ret, "got error %lu\n", GetLastError());
+
+    ret = ResetEvent( handle2 );
+    ok(ret, "got error %lu\n", GetLastError());
+
+    ret = WaitForSingleObject( handle2, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    handles[0] = handle;
+    handles[1] = handle2;
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    SetEvent( handle );
+    SetEvent( handle2 );
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    ret = WaitForSingleObject( handle2, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    ResetEvent( handle );
+    SetEvent( handle2 );
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == 1, "got %lu\n", ret);
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    SetEvent( handle );
+    SetEvent( handle2 );
+
+    ret = WaitForMultipleObjects( 2, handles, TRUE, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    ret = WaitForMultipleObjects( 2, handles, TRUE, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    SetEvent( handle2 );
+    ResetEvent( handle );
+
+    ret = WaitForMultipleObjects( 2, handles, TRUE, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    ret = WaitForSingleObject( handle2, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    handles[0] = handle2;
+    handles[1] = handle;
+    SetEvent( handle );
+    SetEvent( handle2 );
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == 1, "got %lu\n", ret);
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == 1, "got %lu\n", ret);
+
+    ret = CloseHandle( handle );
+    ok(ret, "got error %lu\n", GetLastError());
+
+    ret = CloseHandle( handle2 );
+    ok(ret, "got error %lu\n", GetLastError());
 }
 
 static void test_semaphore(void)
 {
-    HANDLE handle, handle2;
+    HANDLE handle, handle2, handles[2];
+    DWORD ret;
+    LONG prev;
+    int i;
 
     /* test case sensitivity */
 
@@ -727,6 +850,99 @@ static void test_semaphore(void)
     ok( GetLastError() == ERROR_INVALID_PARAMETER, "wrong error %lu\n", GetLastError());
 
     CloseHandle( handle );
+
+    handle = CreateSemaphoreA( NULL, 0, 5, NULL );
+    ok(!!handle, "CreateSemaphore failed: %lu\n", GetLastError());
+
+    ret = WaitForSingleObject( handle, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    ret = ReleaseSemaphore( handle, 1, &prev );
+    ok(ret, "got error %lu\n", GetLastError());
+    ok(prev == 0, "got prev %ld\n", prev);
+
+    ret = ReleaseSemaphore( handle, 1, &prev );
+    ok(ret, "got error %lu\n", GetLastError());
+    ok(prev == 1, "got prev %ld\n", prev);
+
+    ret = ReleaseSemaphore( handle, 5, &prev );
+    ok(!ret, "got %ld\n", ret);
+    ok(GetLastError() == ERROR_TOO_MANY_POSTS, "got error %lu\n", GetLastError());
+    ok(prev == 1, "got prev %ld\n", prev);
+
+    ret = ReleaseSemaphore( handle, 2, &prev );
+    ok(ret, "got error %lu\n", GetLastError());
+    ok(prev == 2, "got prev %ld\n", prev);
+
+    ret = ReleaseSemaphore( handle, 1, &prev );
+    ok(ret, "got error %lu\n", GetLastError());
+    ok(prev == 4, "got prev %ld\n", prev);
+
+    for (i = 0; i < 5; i++)
+    {
+        ret = WaitForSingleObject( handle, 0 );
+        ok(ret == 0, "got %lu\n", ret);
+    }
+
+    ret = WaitForSingleObject( handle, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    handle2 = CreateSemaphoreA( NULL, 3, 5, NULL );
+    ok(!!handle2, "CreateSemaphore failed: %lu\n", GetLastError());
+
+    ret = ReleaseSemaphore( handle2, 1, &prev );
+    ok(ret, "got error %lu\n", GetLastError());
+    ok(prev == 3, "got prev %ld\n", prev);
+
+    for (i = 0; i < 4; i++)
+    {
+        ret = WaitForSingleObject( handle2, 0 );
+        ok(ret == 0, "got %lu\n", ret);
+    }
+
+    ret = WaitForSingleObject( handle2, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    handles[0] = handle;
+    handles[1] = handle2;
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    ReleaseSemaphore( handle, 1, NULL );
+    ReleaseSemaphore( handle2, 1, NULL );
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == 1, "got %lu\n", ret);
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    ReleaseSemaphore( handle, 1, NULL );
+    ReleaseSemaphore( handle2, 1, NULL );
+
+    ret = WaitForMultipleObjects( 2, handles, TRUE, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    ret = WaitForMultipleObjects( 2, handles, FALSE, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    ReleaseSemaphore( handle, 1, NULL );
+
+    ret = WaitForMultipleObjects( 2, handles, TRUE, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    ret = WaitForSingleObject( handle, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    ret = CloseHandle( handle );
+    ok(ret, "got error %lu\n", ret);
+
+    ret = CloseHandle( handle2 );
+    ok(ret, "got error %lu\n", ret);
 }
 
 static void test_waitable_timer(void)
@@ -1281,11 +1497,15 @@ static HANDLE modify_handle(HANDLE handl
     return ULongToHandle(tmp);
 }
 
+#define TIMEOUT_INFINITE (((LONGLONG)0x7fffffff) << 32 | 0xffffffff)
+
 static void test_WaitForSingleObject(void)
 {
     HANDLE signaled, nonsignaled, invalid;
+    LARGE_INTEGER ntnow, ntthen;
     LARGE_INTEGER timeout;
     NTSTATUS status;
+    DWORD now, then;
     DWORD ret;
 
     signaled = CreateEventW(NULL, TRUE, TRUE, NULL);
@@ -1370,6 +1590,68 @@ static void test_WaitForSingleObject(voi
     status = pNtWaitForSingleObject(GetCurrentThread(), FALSE, &timeout);
     ok(status == STATUS_TIMEOUT, "expected STATUS_TIMEOUT, got %08lx\n", status);
 
+    ret = WaitForSingleObject( signaled, 0 );
+    ok(ret == 0, "got %lu\n", ret);
+
+    ret = WaitForSingleObject( nonsignaled, 0 );
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+
+    /* test that a timed wait actually does wait */
+    now = GetTickCount();
+    ret = WaitForSingleObject( nonsignaled, 100 );
+    then = GetTickCount();
+    ok(ret == WAIT_TIMEOUT, "got %lu\n", ret);
+    ok(abs((then - now) - 100) < 5, "got %lu ms\n", then - now);
+
+    now = GetTickCount();
+    ret = WaitForSingleObject( signaled, 100 );
+    then = GetTickCount();
+    ok(ret == 0, "got %lu\n", ret);
+    ok(abs(then - now) < 5, "got %lu ms\n", then - now);
+
+    ret = WaitForSingleObject( signaled, INFINITE );
+    ok(ret == 0, "got %lu\n", ret);
+
+    /* test NT timeouts */
+    pNtQuerySystemTime( &ntnow );
+    timeout.QuadPart = ntnow.QuadPart + 100 * 10000;
+    status = pNtWaitForSingleObject( nonsignaled, FALSE, &timeout );
+    pNtQuerySystemTime( &ntthen );
+    ok(status == STATUS_TIMEOUT, "got %#lx\n", status);
+    ok(abs(((ntthen.QuadPart - ntnow.QuadPart) / 10000) - 100) < 5, "got %s ns\n",
+        wine_dbgstr_longlong((ntthen.QuadPart - ntnow.QuadPart) * 100));
+
+    pNtQuerySystemTime( &ntnow );
+    timeout.QuadPart = -100 * 10000;
+    status = pNtWaitForSingleObject( nonsignaled, FALSE, &timeout );
+    pNtQuerySystemTime( &ntthen );
+    ok(status == STATUS_TIMEOUT, "got %#lx\n", status);
+    ok(abs(((ntthen.QuadPart - ntnow.QuadPart) / 10000) - 100) < 5, "got %s ns\n",
+        wine_dbgstr_longlong((ntthen.QuadPart - ntnow.QuadPart) * 100));
+
+    status = pNtWaitForSingleObject( signaled, FALSE, NULL );
+    ok(status == 0, "got %#lx\n", status);
+
+    timeout.QuadPart = TIMEOUT_INFINITE;
+    status = pNtWaitForSingleObject( signaled, FALSE, &timeout );
+    ok(status == 0, "got %#lx\n", status);
+
+    pNtQuerySystemTime( &ntnow );
+    timeout.QuadPart = ntnow.QuadPart;
+    status = pNtWaitForSingleObject( nonsignaled, FALSE, &timeout );
+    pNtQuerySystemTime( &ntthen );
+    ok(status == STATUS_TIMEOUT, "got %#lx\n", status);
+    ok(abs((ntthen.QuadPart - ntnow.QuadPart) / 10000) < 5, "got %s ns\n",
+        wine_dbgstr_longlong((ntthen.QuadPart - ntnow.QuadPart) * 100));
+
+    pNtQuerySystemTime( &ntnow );
+    timeout.QuadPart = ntnow.QuadPart - 100 * 10000;
+    status = pNtWaitForSingleObject( nonsignaled, FALSE, &timeout );
+    pNtQuerySystemTime( &ntthen );
+    ok(status == STATUS_TIMEOUT, "got %#lx\n", status);
+    ok(abs((ntthen.QuadPart - ntnow.QuadPart) / 10000) < 5, "got %s ns\n",
+        wine_dbgstr_longlong((ntthen.QuadPart - ntnow.QuadPart) * 100));
+
     CloseHandle(signaled);
     CloseHandle(nonsignaled);
 }
@@ -2992,6 +3274,84 @@ static void test_QueueUserAPC(void)
     }
 }
 
+static int zigzag_state, zigzag_count[2], zigzag_stop;
+
+static DWORD CALLBACK zigzag_event0(void *arg)
+{
+    HANDLE *events = arg;
+
+    while (!zigzag_stop)
+    {
+        WaitForSingleObject(events[0], INFINITE);
+        ResetEvent(events[0]);
+        ok(zigzag_state == 0, "got wrong state %d\n", zigzag_state);
+        zigzag_state++;
+        SetEvent(events[1]);
+        zigzag_count[0]++;
+    }
+    trace("thread 0 got done\n");
+    return 0;
+}
+
+static DWORD CALLBACK zigzag_event1(void *arg)
+{
+    HANDLE *events = arg;
+
+    while (!zigzag_stop)
+    {
+        WaitForSingleObject(events[1], INFINITE);
+        ResetEvent(events[1]);
+        ok(zigzag_state == 1, "got wrong state %d\n", zigzag_state);
+        zigzag_state--;
+        SetEvent(events[0]);
+        zigzag_count[1]++;
+    }
+    trace("thread 1 got done\n");
+    return 0;
+}
+
+static void test_zigzag_event(void)
+{
+    /* The basic idea is to test SetEvent/Wait back and forth between two
+     * threads. Each thread clears their own event, sets some common data,
+     * signals the other's, then waits on their own. We make sure the common
+     * data is always in the right state. We also print performance data. */
+
+    HANDLE threads[2], events[2];
+    BOOL ret;
+
+    events[0] = CreateEventA(NULL, FALSE, FALSE, NULL);
+    events[1] = CreateEventA(NULL, FALSE, FALSE, NULL);
+
+    threads[0] = CreateThread(NULL, 0, zigzag_event0, events, 0, NULL);
+    threads[1] = CreateThread(NULL, 0, zigzag_event1, events, 0, NULL);
+
+    zigzag_state = 0;
+    zigzag_count[0] = zigzag_count[1] = 0;
+    zigzag_stop = 0;
+
+    trace("starting zigzag test (events)\n");
+    SetEvent(events[0]);
+    Sleep(2000);
+    zigzag_stop = 1;
+    ret = WaitForMultipleObjects(2, threads, FALSE, INFINITE);
+    trace("%d\n", ret);
+    ok(ret == 0 || ret == 1, "wait failed: %u\n", ret);
+
+    ok(zigzag_count[0] == zigzag_count[1] || zigzag_count[0] == zigzag_count[1] + 1,
+        "count did not match: %d != %d\n", zigzag_count[0], zigzag_count[1]);
+
+    /* signal the other thread to finish, if it didn't already
+     * (in theory they both would at the same time, but there's a slight race on teardown if we get
+     * thread 1 SetEvent -> thread 0 ResetEvent -> thread 0 Wait -> thread 1 exits */
+    zigzag_state = 1-ret;
+    SetEvent(events[1-ret]);
+    ret = WaitForSingleObject(threads[1-ret], 1000);
+    ok(!ret, "wait failed: %u\n", ret);
+
+    trace("count: %d\n", zigzag_count[0]);
+}
+
 START_TEST(sync)
 {
     char **argv;
@@ -3019,6 +3379,7 @@ START_TEST(sync)
     pQueueUserAPC2 = (void *)GetProcAddress(hdll, "QueueUserAPC2");
     pNtAllocateVirtualMemory = (void *)GetProcAddress(hntdll, "NtAllocateVirtualMemory");
     pNtFreeVirtualMemory = (void *)GetProcAddress(hntdll, "NtFreeVirtualMemory");
+    pNtQuerySystemTime = (void *)GetProcAddress(hntdll, "NtQuerySystemTime");
     pNtWaitForSingleObject = (void *)GetProcAddress(hntdll, "NtWaitForSingleObject");
     pNtWaitForMultipleObjects = (void *)GetProcAddress(hntdll, "NtWaitForMultipleObjects");
     pRtlInterlockedPushListSList = (void *)GetProcAddress(hntdll, "RtlInterlockedPushListSList");
@@ -3063,5 +3424,6 @@ START_TEST(sync)
     test_srwlock_example();
     test_alertable_wait();
     test_apc_deadlock();
+    test_zigzag_event();
     test_crit_section();
 }
diff -ruN --show-c-function dlls/ntdll/Makefile.in dlls/ntdll/Makefile.in
--- dlls/ntdll/Makefile.in	2025-10-21 17:44:47.276229433 -0700
+++ dlls/ntdll/Makefile.in	2025-10-24 16:11:51.044633670 -0700
@@ -49,6 +49,7 @@ SOURCES = \
 	unix/cdrom.c \
 	unix/debug.c \
 	unix/env.c \
+	unix/esync.c \
 	unix/file.c \
 	unix/loader.c \
 	unix/loadorder.c \
diff -ruN --show-c-function dlls/ntdll/unix/esync.c dlls/ntdll/unix/esync.c
--- dlls/ntdll/unix/esync.c	1969-12-31 16:00:00.000000000 -0800
+++ dlls/ntdll/unix/esync.c	2025-10-24 16:11:42.421728195 -0700
@@ -0,0 +1,1325 @@
+/*
+ * eventfd-based synchronization objects
+ *
+ * Copyright (C) 2018 Zebediah Figura
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
+ */
+
+#if 0
+#pragma makedep unix
+#endif
+
+#include "config.h"
+
+#ifndef _GNU_SOURCE
+#define _GNU_SOURCE
+#endif
+
+#include <assert.h>
+#include <errno.h>
+#include <fcntl.h>
+#include <stdarg.h>
+#include <stdint.h>
+#include <stdlib.h>
+#include <sys/mman.h>
+#ifdef HAVE_SYS_STAT_H
+# include <sys/stat.h>
+#endif
+#include <poll.h>
+#include <sys/types.h>
+#include <unistd.h>
+
+#include "ntstatus.h"
+#define WIN32_NO_STATUS
+#include "windef.h"
+#include "winternl.h"
+#include "wine/server.h"
+#include "wine/debug.h"
+
+#include "unix_private.h"
+#include "esync.h"
+
+WINE_DEFAULT_DEBUG_CHANNEL(esync);
+
+int do_esync(void)
+{
+#ifdef HAVE_SYS_EVENTFD_H
+    static int do_esync_cached = -1;
+
+    if (do_esync_cached == -1)
+        do_esync_cached = getenv("WINEESYNC") && atoi(getenv("WINEESYNC"));
+
+    return do_esync_cached;
+#else
+    static int once;
+    if (!once++)
+        FIXME("eventfd not supported on this platform.\n");
+    return 0;
+#endif
+}
+
+struct esync
+{
+    LONG type;
+    int fd;
+    void *shm;
+};
+
+struct semaphore
+{
+    LONG max;
+    LONG count;
+};
+C_ASSERT(sizeof(struct semaphore) == 8);
+
+struct mutex
+{
+    LONG tid;
+    LONG count;    /* recursion count */
+};
+C_ASSERT(sizeof(struct mutex) == 8);
+
+struct event
+{
+    LONG signaled;
+    LONG locked;
+};
+C_ASSERT(sizeof(struct event) == 8);
+
+static char shm_name[29];
+static int shm_fd;
+static void **shm_addrs;
+static int shm_addrs_size;  /* length of the allocated shm_addrs array */
+static long pagesize;
+
+static pthread_mutex_t shm_addrs_mutex = PTHREAD_MUTEX_INITIALIZER;
+
+static void *get_shm( unsigned int idx )
+{
+    int entry  = (idx * 8) / pagesize;
+    int offset = (idx * 8) % pagesize;
+    void *ret;
+
+    pthread_mutex_lock( &shm_addrs_mutex );
+
+    if (entry >= shm_addrs_size)
+    {
+        int new_size = max(shm_addrs_size * 2, entry + 1);
+
+        if (!(shm_addrs = realloc( shm_addrs, new_size * sizeof(shm_addrs[0]) )))
+            ERR("Failed to grow shm_addrs array to size %d.\n", shm_addrs_size);
+        memset( shm_addrs + shm_addrs_size, 0, (new_size - shm_addrs_size) * sizeof(shm_addrs[0]) );
+        shm_addrs_size = new_size;
+    }
+
+    if (!shm_addrs[entry])
+    {
+        void *addr = mmap( NULL, pagesize, PROT_READ | PROT_WRITE, MAP_SHARED, shm_fd, entry * pagesize );
+        if (addr == (void *)-1)
+            ERR("Failed to map page %d (offset %#lx).\n", entry, entry * pagesize);
+
+        TRACE("Mapping page %d at %p.\n", entry, addr);
+
+        if (InterlockedCompareExchangePointer( &shm_addrs[entry], addr, 0 ))
+            munmap( addr, pagesize ); /* someone beat us to it */
+    }
+
+    ret = (void *)((unsigned long)shm_addrs[entry] + offset);
+
+    pthread_mutex_unlock( &shm_addrs_mutex );
+
+    return ret;
+}
+
+/* We'd like lookup to be fast. To that end, we use a static list indexed by handle.
+ * This is copied and adapted from the fd cache code. */
+
+#define ESYNC_LIST_BLOCK_SIZE  (65536 / sizeof(struct esync))
+#define ESYNC_LIST_ENTRIES     256
+
+static struct esync *esync_list[ESYNC_LIST_ENTRIES];
+static struct esync esync_list_initial_block[ESYNC_LIST_BLOCK_SIZE];
+
+static inline UINT_PTR handle_to_index( HANDLE handle, UINT_PTR *entry )
+{
+    UINT_PTR idx = (((UINT_PTR)handle) >> 2) - 1;
+    *entry = idx / ESYNC_LIST_BLOCK_SIZE;
+    return idx % ESYNC_LIST_BLOCK_SIZE;
+}
+
+static struct esync *add_to_list( HANDLE handle, enum esync_type type, int fd, void *shm )
+{
+    UINT_PTR entry, idx = handle_to_index( handle, &entry );
+
+    if (entry >= ESYNC_LIST_ENTRIES)
+    {
+        FIXME( "too many allocated handles, not caching %p\n", handle );
+        return FALSE;
+    }
+
+    if (!esync_list[entry])  /* do we need to allocate a new block of entries? */
+    {
+        if (!entry) esync_list[0] = esync_list_initial_block;
+        else
+        {
+            void *ptr = anon_mmap_alloc( ESYNC_LIST_BLOCK_SIZE * sizeof(struct esync),
+                                         PROT_READ | PROT_WRITE );
+            if (ptr == MAP_FAILED) return FALSE;
+            esync_list[entry] = ptr;
+        }
+    }
+
+    if (!InterlockedCompareExchange( &esync_list[entry][idx].type, type, 0 ))
+    {
+        esync_list[entry][idx].fd = fd;
+        esync_list[entry][idx].shm = shm;
+    }
+    return &esync_list[entry][idx];
+}
+
+static struct esync *get_cached_object( HANDLE handle )
+{
+    UINT_PTR entry, idx = handle_to_index( handle, &entry );
+
+    if (entry >= ESYNC_LIST_ENTRIES || !esync_list[entry]) return NULL;
+    if (!esync_list[entry][idx].type) return NULL;
+
+    return &esync_list[entry][idx];
+}
+
+/* Gets an object. This is either a proper esync object (i.e. an event,
+ * semaphore, etc. created using create_esync) or a generic synchronizable
+ * server-side object which the server will signal (e.g. a process, thread,
+ * message queue, etc.) */
+static NTSTATUS get_object( HANDLE handle, struct esync **obj )
+{
+    int ret = STATUS_SUCCESS;
+    enum esync_type type = 0;
+    unsigned int shm_idx = 0;
+    obj_handle_t fd_handle;
+    sigset_t sigset;
+    int fd = -1;
+
+    if ((*obj = get_cached_object( handle ))) return STATUS_SUCCESS;
+
+    if ((INT_PTR)handle < 0)
+    {
+        /* We can deal with pseudo-handles, but it's just easier this way */
+        return STATUS_NOT_IMPLEMENTED;
+    }
+
+    if (!handle)
+    {
+        /* Shadow of the Tomb Raider really likes passing in NULL handles to
+         * various functions. Concerning, but let's avoid a server call. */
+        return STATUS_INVALID_HANDLE;
+    }
+
+    /* We need to try grabbing it from the server. */
+    server_enter_uninterrupted_section( &fd_cache_mutex, &sigset );
+    if (!(*obj = get_cached_object( handle )))
+    {
+        SERVER_START_REQ( get_esync_fd )
+        {
+            req->handle = wine_server_obj_handle( handle );
+            if (!(ret = wine_server_call( req )))
+            {
+                type = reply->type;
+                shm_idx = reply->shm_idx;
+                fd = receive_fd( &fd_handle );
+                assert( wine_server_ptr_handle(fd_handle) == handle );
+            }
+        }
+        SERVER_END_REQ;
+    }
+    server_leave_uninterrupted_section( &fd_cache_mutex, &sigset );
+
+    if (*obj)
+    {
+        /* We managed to grab it while in the CS; return it. */
+        return STATUS_SUCCESS;
+    }
+
+    if (ret)
+    {
+        WARN("Failed to retrieve fd for handle %p, status %#x.\n", handle, ret);
+        *obj = NULL;
+        return ret;
+    }
+
+    TRACE("Got fd %d for handle %p.\n", fd, handle);
+
+    *obj = add_to_list( handle, type, fd, shm_idx ? get_shm( shm_idx ) : 0 );
+    return ret;
+}
+
+NTSTATUS esync_close( HANDLE handle )
+{
+    UINT_PTR entry, idx = handle_to_index( handle, &entry );
+
+    TRACE("%p.\n", handle);
+
+    if (entry < ESYNC_LIST_ENTRIES && esync_list[entry])
+    {
+        if (InterlockedExchange(&esync_list[entry][idx].type, 0))
+        {
+            close( esync_list[entry][idx].fd );
+            return STATUS_SUCCESS;
+        }
+    }
+
+    return STATUS_INVALID_HANDLE;
+}
+
+static NTSTATUS create_esync( enum esync_type type, HANDLE *handle, ACCESS_MASK access,
+                              const OBJECT_ATTRIBUTES *attr, int initval, int max )
+{
+    NTSTATUS ret;
+    data_size_t len;
+    struct object_attributes *objattr;
+    obj_handle_t fd_handle;
+    unsigned int shm_idx;
+    sigset_t sigset;
+    int fd;
+
+    if ((ret = alloc_object_attributes( attr, &objattr, &len ))) return ret;
+
+    /* We have to synchronize on the fd cache CS so that our calls to
+     * receive_fd don't race with theirs. */
+    server_enter_uninterrupted_section( &fd_cache_mutex, &sigset );
+    SERVER_START_REQ( create_esync )
+    {
+        req->access  = access;
+        req->initval = initval;
+        req->type    = type;
+        req->max     = max;
+        wine_server_add_data( req, objattr, len );
+        ret = wine_server_call( req );
+        if (!ret || ret == STATUS_OBJECT_NAME_EXISTS)
+        {
+            *handle = wine_server_ptr_handle( reply->handle );
+            type = reply->type;
+            shm_idx = reply->shm_idx;
+            fd = receive_fd( &fd_handle );
+            assert( wine_server_ptr_handle(fd_handle) == *handle );
+        }
+    }
+    SERVER_END_REQ;
+    server_leave_uninterrupted_section( &fd_cache_mutex, &sigset );
+
+    if (!ret || ret == STATUS_OBJECT_NAME_EXISTS)
+    {
+        add_to_list( *handle, type, fd, shm_idx ? get_shm( shm_idx ) : 0 );
+        TRACE("-> handle %p, fd %d.\n", *handle, fd);
+    }
+
+    free( objattr );
+    return ret;
+}
+
+static NTSTATUS open_esync( enum esync_type type, HANDLE *handle,
+    ACCESS_MASK access, const OBJECT_ATTRIBUTES *attr )
+{
+    NTSTATUS ret;
+    obj_handle_t fd_handle;
+    unsigned int shm_idx;
+    sigset_t sigset;
+    int fd;
+
+    server_enter_uninterrupted_section( &fd_cache_mutex, &sigset );
+    SERVER_START_REQ( open_esync )
+    {
+        req->access     = access;
+        req->attributes = attr->Attributes;
+        req->rootdir    = wine_server_obj_handle( attr->RootDirectory );
+        req->type       = type;
+        if (attr->ObjectName)
+            wine_server_add_data( req, attr->ObjectName->Buffer, attr->ObjectName->Length );
+        if (!(ret = wine_server_call( req )))
+        {
+            *handle = wine_server_ptr_handle( reply->handle );
+            type = reply->type;
+            shm_idx = reply->shm_idx;
+            fd = receive_fd( &fd_handle );
+            assert( wine_server_ptr_handle(fd_handle) == *handle );
+        }
+    }
+    SERVER_END_REQ;
+    server_leave_uninterrupted_section( &fd_cache_mutex, &sigset );
+
+    if (!ret)
+    {
+        add_to_list( *handle, type, fd, shm_idx ? get_shm( shm_idx ) : 0 );
+
+        TRACE("-> handle %p, fd %d.\n", *handle, fd);
+    }
+    return ret;
+}
+
+extern NTSTATUS esync_create_semaphore(HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr, int initial, int max)
+{
+    TRACE("name %s, initial %d, max %d.\n",
+        attr ? debugstr_us(attr->ObjectName) : "<no name>", initial, max);
+
+    return create_esync( ESYNC_SEMAPHORE, handle, access, attr, initial, max );
+}
+
+NTSTATUS esync_open_semaphore( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr )
+{
+    TRACE("name %s.\n", debugstr_us(attr->ObjectName));
+
+    return open_esync( ESYNC_SEMAPHORE, handle, access, attr );
+}
+
+NTSTATUS esync_release_semaphore( HANDLE handle, unsigned int count, ULONG *prev )
+{
+    struct esync *obj;
+    struct semaphore *semaphore;
+    uint64_t count64 = count;
+    ULONG current;
+    NTSTATUS ret;
+
+    TRACE("%p, %d, %p.\n", handle, count, prev);
+
+    if ((ret = get_object( handle, &obj))) return ret;
+    semaphore = obj->shm;
+
+    do
+    {
+        current = semaphore->count;
+
+        if (count + current > semaphore->max)
+            return STATUS_SEMAPHORE_LIMIT_EXCEEDED;
+    } while (InterlockedCompareExchange( &semaphore->count, count + current, current ) != current);
+
+    if (prev) *prev = current;
+
+    /* We don't have to worry about a race between increasing the count and
+     * write(). The fact that we were able to increase the count means that we
+     * have permission to actually write that many releases to the semaphore. */
+
+    if (write( obj->fd, &count64, sizeof(count64) ) == -1)
+        return errno_to_status( errno );
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS esync_query_semaphore( HANDLE handle, void *info, ULONG *ret_len )
+{
+    struct esync *obj;
+    struct semaphore *semaphore;
+    SEMAPHORE_BASIC_INFORMATION *out = info;
+    NTSTATUS ret;
+
+    TRACE("handle %p, info %p, ret_len %p.\n", handle, info, ret_len);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+    semaphore = obj->shm;
+
+    out->CurrentCount = semaphore->count;
+    out->MaximumCount = semaphore->max;
+    if (ret_len) *ret_len = sizeof(*out);
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS esync_create_event( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr, EVENT_TYPE event_type, BOOLEAN initial )
+{
+    enum esync_type type = (event_type == SynchronizationEvent ? ESYNC_AUTO_EVENT : ESYNC_MANUAL_EVENT);
+
+    TRACE("name %s, %s-reset, initial %d.\n",
+        attr ? debugstr_us(attr->ObjectName) : "<no name>",
+        event_type == NotificationEvent ? "manual" : "auto", initial);
+
+    return create_esync( type, handle, access, attr, initial, 0 );
+}
+
+NTSTATUS esync_open_event( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr )
+{
+    TRACE("name %s.\n", debugstr_us(attr->ObjectName));
+
+    return open_esync( ESYNC_AUTO_EVENT, handle, access, attr ); /* doesn't matter which */
+}
+
+static inline void small_pause(void)
+{
+#ifdef __i386__
+    __asm__ __volatile__( "rep;nop" : : : "memory" );
+#else
+    __asm__ __volatile__( "" : : : "memory" );
+#endif
+}
+
+/* Manual-reset events are actually racier than other objects in terms of shm
+ * state. With other objects, races don't matter, because we only treat the shm
+ * state as a hint that lets us skip poll()—we still have to read(). But with
+ * manual-reset events we don't, which means that the shm state can be out of
+ * sync with the actual state.
+ *
+ * In general we shouldn't have to worry about races between modifying the
+ * event and waiting on it. If the state changes while we're waiting, it's
+ * equally plausible that we caught it before or after the state changed.
+ * However, we can have races between SetEvent() and ResetEvent(), so that the
+ * event has inconsistent internal state.
+ *
+ * To solve this we have to use the other field to lock the event. Currently
+ * this is implemented as a spinlock, but I'm not sure if a futex might be
+ * better. I'm also not sure if it's possible to obviate locking by arranging
+ * writes and reads in a certain way.
+ *
+ * Note that we don't have to worry about locking in esync_wait_objects().
+ * There's only two general patterns:
+ *
+ * WaitFor()    SetEvent()
+ * -------------------------
+ * read()
+ * signaled = 0
+ *              signaled = 1
+ *              write()
+ * -------------------------
+ * read()
+ *              signaled = 1
+ * signaled = 0
+ *              <no write(), because it was already signaled>
+ * -------------------------
+ *
+ * That is, if SetEvent() tries to signal the event before WaitFor() resets its
+ * signaled state, it won't bother trying to write(), and then the signaled
+ * state will be reset, so the result is a consistent non-signaled event.
+ * There's several variations to this pattern but all of them are protected in
+ * the same way. Note however this is why we have to use interlocked_xchg()
+ * event inside of the lock.
+ */
+
+/* Removing this spinlock is harder than it looks. esync_wait_objects() can
+ * deal with inconsistent state well enough, and a race between SetEvent() and
+ * ResetEvent() gives us license to yield either result as long as we act
+ * consistently, but that's not enough. Notably, esync_wait_objects() should
+ * probably act like a fence, so that the second half of esync_set_event() does
+ * not seep past a subsequent reset. That's one problem, but no guarantee there
+ * aren't others. */
+
+NTSTATUS esync_set_event( HANDLE handle )
+{
+    static const uint64_t value = 1;
+    struct esync *obj;
+    struct event *event;
+    NTSTATUS ret;
+
+    TRACE("%p.\n", handle);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+    event = obj->shm;
+
+    if (obj->type == ESYNC_MANUAL_EVENT)
+    {
+        /* Acquire the spinlock. */
+        while (InterlockedCompareExchange( &event->locked, 1, 0 ))
+            small_pause();
+    }
+
+    /* For manual-reset events, as long as we're in a lock, we can take the
+     * optimization of only calling write() if the event wasn't already
+     * signaled.
+     *
+     * For auto-reset events, esync_wait_objects() must grab the kernel object.
+     * Thus if we got into a race so that the shm state is signaled but the
+     * eventfd is unsignaled (i.e. reset shm, set shm, set fd, reset fd), we
+     * *must* signal the fd now, or any waiting threads will never wake up. */
+
+    if (!InterlockedExchange( &event->signaled, 1 ) || obj->type == ESYNC_AUTO_EVENT)
+    {
+        if (write( obj->fd, &value, sizeof(value) ) == -1)
+            ERR("write: %s\n", strerror(errno));
+    }
+
+    if (obj->type == ESYNC_MANUAL_EVENT)
+    {
+        /* Release the spinlock. */
+        event->locked = 0;
+    }
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS esync_reset_event( HANDLE handle )
+{
+    uint64_t value;
+    struct esync *obj;
+    struct event *event;
+    NTSTATUS ret;
+
+    TRACE("%p.\n", handle);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+    event = obj->shm;
+
+    if (obj->type == ESYNC_MANUAL_EVENT)
+    {
+        /* Acquire the spinlock. */
+        while (InterlockedCompareExchange( &event->locked, 1, 0 ))
+            small_pause();
+    }
+
+    /* For manual-reset events, as long as we're in a lock, we can take the
+     * optimization of only calling read() if the event was already signaled.
+     *
+     * For auto-reset events, we have no guarantee that the previous "signaled"
+     * state is actually correct. We need to leave both states unsignaled after
+     * leaving this function, so we always have to read(). */
+    if (InterlockedExchange( &event->signaled, 0 ) || obj->type == ESYNC_AUTO_EVENT)
+    {
+        if (read( obj->fd, &value, sizeof(value) ) == -1 && errno != EWOULDBLOCK && errno != EAGAIN)
+        {
+            ERR("read: %s\n", strerror(errno));
+        }
+    }
+
+    if (obj->type == ESYNC_MANUAL_EVENT)
+    {
+        /* Release the spinlock. */
+        event->locked = 0;
+    }
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS esync_pulse_event( HANDLE handle )
+{
+    uint64_t value = 1;
+    struct esync *obj;
+    NTSTATUS ret;
+
+    TRACE("%p.\n", handle);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+
+    /* This isn't really correct; an application could miss the write.
+     * Unfortunately we can't really do much better. Fortunately this is rarely
+     * used (and publicly deprecated). */
+    if (write( obj->fd, &value, sizeof(value) ) == -1)
+        return errno_to_status( errno );
+
+    /* Try to give other threads a chance to wake up. Hopefully erring on this
+     * side is the better thing to do... */
+    NtYieldExecution();
+
+    read( obj->fd, &value, sizeof(value) );
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS esync_query_event( HANDLE handle, void *info, ULONG *ret_len )
+{
+    struct esync *obj;
+    EVENT_BASIC_INFORMATION *out = info;
+    struct pollfd fd;
+    NTSTATUS ret;
+
+    TRACE("handle %p, info %p, ret_len %p.\n", handle, info, ret_len);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+
+    fd.fd = obj->fd;
+    fd.events = POLLIN;
+    out->EventState = poll( &fd, 1, 0 );
+    out->EventType = (obj->type == ESYNC_AUTO_EVENT ? SynchronizationEvent : NotificationEvent);
+    if (ret_len) *ret_len = sizeof(*out);
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS esync_create_mutex( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr, BOOLEAN initial )
+{
+    TRACE("name %s, initial %d.\n",
+        attr ? debugstr_us(attr->ObjectName) : "<no name>", initial);
+
+    return create_esync( ESYNC_MUTEX, handle, access, attr, initial ? 0 : 1, 0 );
+}
+
+NTSTATUS esync_open_mutex( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr )
+{
+    TRACE("name %s.\n", debugstr_us(attr->ObjectName));
+
+    return open_esync( ESYNC_MUTEX, handle, access, attr );
+}
+
+NTSTATUS esync_release_mutex( HANDLE *handle, LONG *prev )
+{
+    struct esync *obj;
+    struct mutex *mutex;
+    static const uint64_t value = 1;
+    NTSTATUS ret;
+
+    TRACE("%p, %p.\n", handle, prev);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+    mutex = obj->shm;
+
+    /* This is thread-safe, because the only thread that can change the tid to
+     * or from our tid is ours. */
+    if (mutex->tid != GetCurrentThreadId()) return STATUS_MUTANT_NOT_OWNED;
+
+    if (prev) *prev = mutex->count;
+
+    mutex->count--;
+
+    if (!mutex->count)
+    {
+        /* This is also thread-safe, as long as signaling the file is the last
+         * thing we do. Other threads don't care about the tid if it isn't
+         * theirs. */
+        mutex->tid = 0;
+
+        if (write( obj->fd, &value, sizeof(value) ) == -1)
+            return errno_to_status( errno );
+    }
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS esync_query_mutex( HANDLE handle, void *info, ULONG *ret_len )
+{
+    struct esync *obj;
+    struct mutex *mutex;
+    MUTANT_BASIC_INFORMATION *out = info;
+    NTSTATUS ret;
+
+    TRACE("handle %p, info %p, ret_len %p.\n", handle, info, ret_len);
+
+    if ((ret = get_object( handle, &obj ))) return ret;
+    mutex = obj->shm;
+
+    out->CurrentCount = 1 - mutex->count;
+    out->OwnedByCaller = (mutex->tid == GetCurrentThreadId());
+    out->AbandonedState = (mutex->tid == ~0);
+    if (ret_len) *ret_len = sizeof(*out);
+
+    return STATUS_SUCCESS;
+}
+
+#define TICKSPERSEC        10000000
+#define TICKSPERMSEC       10000
+
+static LONGLONG update_timeout( ULONGLONG end )
+{
+    LARGE_INTEGER now;
+    LONGLONG timeleft;
+
+    NtQuerySystemTime( &now );
+    timeleft = end - now.QuadPart;
+    if (timeleft < 0) timeleft = 0;
+    return timeleft;
+}
+
+static int do_poll( struct pollfd *fds, nfds_t nfds, ULONGLONG *end )
+{
+    int ret;
+
+    do
+    {
+        if (end)
+        {
+            LONGLONG timeleft = update_timeout( *end );
+
+#ifdef HAVE_PPOLL
+            /* We use ppoll() if available since the time granularity is better. */
+            struct timespec tmo_p;
+            tmo_p.tv_sec = timeleft / (ULONGLONG)TICKSPERSEC;
+            tmo_p.tv_nsec = (timeleft % TICKSPERSEC) * 100;
+            ret = ppoll( fds, nfds, &tmo_p, NULL );
+#else
+            ret = poll( fds, nfds, timeleft / TICKSPERMSEC );
+#endif
+        }
+        else
+            ret = poll( fds, nfds, -1 );
+
+    /* If we receive EINTR we were probably suspended (SIGUSR1), possibly for a
+     * system APC. The right thing to do is just try again. */
+    } while (ret < 0 && errno == EINTR);
+
+    return ret;
+}
+
+/* Return TRUE if abandoned. */
+static BOOL update_grabbed_object( struct esync *obj )
+{
+    BOOL ret = FALSE;
+
+    if (obj->type == ESYNC_MUTEX)
+    {
+        struct mutex *mutex = obj->shm;
+        /* We don't have to worry about a race between this and read(); the
+         * fact that we grabbed it means the count is now zero, so nobody else
+         * can (and the only thread that can release it is us). */
+        if (mutex->tid == ~0)
+            ret = TRUE;
+        mutex->tid = GetCurrentThreadId();
+        mutex->count++;
+    }
+    else if (obj->type == ESYNC_SEMAPHORE)
+    {
+        struct semaphore *semaphore = obj->shm;
+        /* We don't have to worry about a race between this and read(); the
+         * fact that we were able to grab it at all means the count is nonzero,
+         * and if someone else grabbed it then the count must have been >= 2,
+         * etc. */
+        InterlockedExchangeAdd( &semaphore->count, -1 );
+    }
+    else if (obj->type == ESYNC_AUTO_EVENT)
+    {
+        struct event *event = obj->shm;
+        /* We don't have to worry about a race between this and read(), since
+         * this is just a hint, and the real state is in the kernel object.
+         * This might already be 0, but that's okay! */
+        event->signaled = 0;
+    }
+
+    return ret;
+}
+
+/* A value of STATUS_NOT_IMPLEMENTED returned from this function means that we
+ * need to delegate to server_select(). */
+static NTSTATUS __esync_wait_objects( unsigned int count, const HANDLE *handles, BOOLEAN wait_any,
+                             BOOLEAN alertable, const LARGE_INTEGER *timeout )
+{
+    static const LARGE_INTEGER zero;
+
+    struct esync *objs[MAXIMUM_WAIT_OBJECTS];
+    struct pollfd fds[MAXIMUM_WAIT_OBJECTS + 1];
+    int has_esync = 0, has_server = 0;
+    BOOL msgwait = FALSE;
+    LONGLONG timeleft;
+    LARGE_INTEGER now;
+    DWORD pollcount;
+    ULONGLONG end;
+    int64_t value;
+    ssize_t size;
+    int i, j, ret;
+
+    /* Grab the APC fd if we don't already have it. */
+    if (alertable && ntdll_get_thread_data()->esync_apc_fd == -1)
+    {
+        obj_handle_t fd_handle;
+        sigset_t sigset;
+        int fd = -1;
+
+        server_enter_uninterrupted_section( &fd_cache_mutex, &sigset );
+        SERVER_START_REQ( get_esync_apc_fd )
+        {
+            if (!(ret = wine_server_call( req )))
+            {
+                fd = receive_fd( &fd_handle );
+                assert( fd_handle == GetCurrentThreadId() );
+            }
+        }
+        SERVER_END_REQ;
+        server_leave_uninterrupted_section( &fd_cache_mutex, &sigset );
+
+        ntdll_get_thread_data()->esync_apc_fd = fd;
+    }
+
+    NtQuerySystemTime( &now );
+    if (timeout)
+    {
+        if (timeout->QuadPart == TIMEOUT_INFINITE)
+            timeout = NULL;
+        else if (timeout->QuadPart >= 0)
+            end = timeout->QuadPart;
+        else
+            end = now.QuadPart - timeout->QuadPart;
+    }
+
+    for (i = 0; i < count; i++)
+    {
+        ret = get_object( handles[i], &objs[i] );
+        if (ret == STATUS_SUCCESS)
+            has_esync = 1;
+        else if (ret == STATUS_NOT_IMPLEMENTED)
+            has_server = 1;
+        else
+            return ret;
+    }
+
+    if (objs[count - 1] && objs[count - 1]->type == ESYNC_QUEUE)
+        msgwait = TRUE;
+
+    if (has_esync && has_server)
+        FIXME("Can't wait on esync and server objects at the same time!\n");
+    else if (has_server)
+        return STATUS_NOT_IMPLEMENTED;
+
+    if (TRACE_ON(esync))
+    {
+        TRACE("Waiting for %s of %d handles:", wait_any ? "any" : "all", count);
+        for (i = 0; i < count; i++)
+            TRACE(" %p", handles[i]);
+
+        if (msgwait)
+            TRACE(" or driver events");
+        if (alertable)
+            TRACE(", alertable");
+
+        if (!timeout)
+            TRACE(", timeout = INFINITE.\n");
+        else
+        {
+            timeleft = update_timeout( end );
+            TRACE(", timeout = %ld.%07ld sec.\n",
+                (long) timeleft / TICKSPERSEC, (long) timeleft % TICKSPERSEC);
+        }
+    }
+
+    if (wait_any || count == 1)
+    {
+        /* Try to check objects now, so we can obviate poll() at least. */
+        for (i = 0; i < count; i++)
+        {
+            struct esync *obj = objs[i];
+
+            if (obj)
+            {
+                switch (obj->type)
+                {
+                case ESYNC_MUTEX:
+                {
+                    struct mutex *mutex = obj->shm;
+
+                    if (mutex->tid == GetCurrentThreadId())
+                    {
+                        TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                        mutex->count++;
+                        return i;
+                    }
+                    else if (!mutex->count)
+                    {
+                        if ((size = read( obj->fd, &value, sizeof(value) )) == sizeof(value))
+                        {
+                            if (mutex->tid == ~0)
+                            {
+                                TRACE("Woken up by abandoned mutex %p [%d].\n", handles[i], i);
+                                i += STATUS_ABANDONED_WAIT_0;
+                            }
+                            else
+                                TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                            mutex->tid = GetCurrentThreadId();
+                            mutex->count++;
+                            return i;
+                        }
+                    }
+                    break;
+                }
+                case ESYNC_SEMAPHORE:
+                {
+                    struct semaphore *semaphore = obj->shm;
+
+                    if (semaphore->count)
+                    {
+                        if ((size = read( obj->fd, &value, sizeof(value) )) == sizeof(value))
+                        {
+                            TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                            InterlockedDecrement( &semaphore->count );
+                            return i;
+                        }
+                    }
+                    break;
+                }
+                case ESYNC_AUTO_EVENT:
+                {
+                    struct event *event = obj->shm;
+
+                    if (event->signaled)
+                    {
+                        if ((size = read( obj->fd, &value, sizeof(value) )) == sizeof(value))
+                        {
+                            TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                            event->signaled = 0;
+                            return i;
+                        }
+                    }
+                    break;
+                }
+                case ESYNC_MANUAL_EVENT:
+                {
+                    struct event *event = obj->shm;
+
+                    if (event->signaled)
+                    {
+                        TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                        return i;
+                    }
+                    break;
+                }
+                case ESYNC_AUTO_SERVER:
+                case ESYNC_MANUAL_SERVER:
+                case ESYNC_QUEUE:
+                    /* We can't wait on any of these. Fortunately I don't think
+                     * they'll ever be uncontended anyway (at least, they won't be
+                     * performance-critical). */
+                    break;
+                }
+            }
+
+            fds[i].fd = obj ? obj->fd : -1;
+            fds[i].events = POLLIN;
+        }
+        if (alertable)
+        {
+            fds[i].fd = ntdll_get_thread_data()->esync_apc_fd;
+            fds[i].events = POLLIN;
+            i++;
+        }
+        pollcount = i;
+
+        while (1)
+        {
+            ret = do_poll( fds, pollcount, timeout ? &end : NULL );
+            if (ret > 0)
+            {
+                /* We must check this first! The server may set an event that
+                 * we're waiting on, but we need to return STATUS_USER_APC. */
+                if (alertable)
+                {
+                    if (fds[pollcount - 1].revents & POLLIN)
+                        goto userapc;
+                }
+
+                /* Find out which object triggered the wait. */
+                for (i = 0; i < count; i++)
+                {
+                    struct esync *obj = objs[i];
+
+                    if (fds[i].revents & (POLLERR | POLLHUP | POLLNVAL))
+                    {
+                        ERR("Polling on fd %d returned %#x.\n", fds[i].fd, fds[i].revents);
+                        return STATUS_INVALID_HANDLE;
+                    }
+
+                    if (obj)
+                    {
+                        if (obj->type == ESYNC_MANUAL_EVENT
+                                || obj->type == ESYNC_MANUAL_SERVER
+                                || obj->type == ESYNC_QUEUE)
+                        {
+                            /* Don't grab the object, just check if it's signaled. */
+                            if (fds[i].revents & POLLIN)
+                            {
+                                TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                                return i;
+                            }
+                        }
+                        else
+                        {
+                            if ((size = read( fds[i].fd, &value, sizeof(value) )) == sizeof(value))
+                            {
+                                /* We found our object. */
+                                TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                                if (update_grabbed_object( obj ))
+                                    return STATUS_ABANDONED_WAIT_0 + i;
+                                return i;
+                            }
+                        }
+                    }
+                }
+
+                /* If we got here, someone else stole (or reset, etc.) whatever
+                 * we were waiting for. So keep waiting. */
+                NtQuerySystemTime( &now );
+            }
+            else
+                goto err;
+        }
+    }
+    else
+    {
+        /* Wait-all is a little trickier to implement correctly. Fortunately,
+         * it's not as common.
+         *
+         * The idea is basically just to wait in sequence on every object in the
+         * set. Then when we're done, try to grab them all in a tight loop. If
+         * that fails, release any resources we've grabbed (and yes, we can
+         * reliably do this—it's just mutexes and semaphores that we have to
+         * put back, and in both cases we just put back 1), and if any of that
+         * fails we start over.
+         *
+         * What makes this inherently bad is that we might temporarily grab a
+         * resource incorrectly. Hopefully it'll be quick (and hey, it won't
+         * block on wineserver) so nobody will notice. Besides, consider: if
+         * object A becomes signaled but someone grabs it before we can grab it
+         * and everything else, then they could just as well have grabbed it
+         * before it became signaled. Similarly if object A was signaled and we
+         * were blocking on object B, then B becomes available and someone grabs
+         * A before we can, then they might have grabbed A before B became
+         * signaled. In either case anyone who tries to wait on A or B will be
+         * waiting for an instant while we put things back. */
+
+        while (1)
+        {
+tryagain:
+            /* First step: try to poll on each object in sequence. */
+            fds[0].events = POLLIN;
+            pollcount = 1;
+            if (alertable)
+            {
+                /* We also need to wait on APCs. */
+                fds[1].fd = ntdll_get_thread_data()->esync_apc_fd;
+                fds[1].events = POLLIN;
+                pollcount++;
+            }
+            for (i = 0; i < count; i++)
+            {
+                struct esync *obj = objs[i];
+
+                fds[0].fd = obj ? obj->fd : -1;
+
+                if (obj && obj->type == ESYNC_MUTEX)
+                {
+                    /* It might be ours. */
+                    struct mutex *mutex = obj->shm;
+
+                    if (mutex->tid == GetCurrentThreadId())
+                        continue;
+                }
+
+                ret = do_poll( fds, pollcount, timeout ? &end : NULL );
+                if (ret <= 0)
+                    goto err;
+                else if (alertable && (fds[1].revents & POLLIN))
+                    goto userapc;
+
+                if (fds[0].revents & (POLLHUP | POLLERR | POLLNVAL))
+                {
+                    ERR("Polling on fd %d returned %#x.\n", fds[0].fd, fds[0].revents);
+                    return STATUS_INVALID_HANDLE;
+                }
+            }
+
+            /* If we got here and we haven't timed out, that means all of the
+             * handles were signaled. Check to make sure they still are. */
+            for (i = 0; i < count; i++)
+            {
+                fds[i].fd = objs[i] ? objs[i]->fd : -1;
+                fds[i].events = POLLIN;
+            }
+            /* There's no reason to check for APCs here. */
+            pollcount = i;
+
+            /* Poll everything to see if they're still signaled. */
+            ret = poll( fds, pollcount, 0 );
+            if (ret == pollcount)
+            {
+                BOOL abandoned = FALSE;
+
+                /* Quick, grab everything. */
+                for (i = 0; i < count; i++)
+                {
+                    struct esync *obj = objs[i];
+
+                    switch (obj->type)
+                    {
+                    case ESYNC_MUTEX:
+                    {
+                        struct mutex *mutex = obj->shm;
+                        if (mutex->tid == GetCurrentThreadId())
+                            break;
+                        /* otherwise fall through */
+                    }
+                    case ESYNC_SEMAPHORE:
+                    case ESYNC_AUTO_EVENT:
+                        if ((size = read( fds[i].fd, &value, sizeof(value) )) != sizeof(value))
+                        {
+                            /* We were too slow. Put everything back. */
+                            value = 1;
+                            for (j = i; j >= 0; j--)
+                            {
+                                if (write( obj->fd, &value, sizeof(value) ) == -1)
+                                    return errno_to_status( errno );
+                            }
+
+                            goto tryagain;  /* break out of two loops and a switch */
+                        }
+                        break;
+                    default:
+                        /* If a manual-reset event changed between there and
+                         * here, it's shouldn't be a problem. */
+                        break;
+                    }
+                }
+
+                /* If we got here, we successfully waited on every object. */
+                /* Make sure to let ourselves know that we grabbed the mutexes
+                 * and semaphores. */
+                for (i = 0; i < count; i++)
+                    abandoned |= update_grabbed_object( objs[i] );
+
+                if (abandoned)
+                {
+                    TRACE("Wait successful, but some object(s) were abandoned.\n");
+                    return STATUS_ABANDONED;
+                }
+                TRACE("Wait successful.\n");
+                return STATUS_SUCCESS;
+            }
+
+            /* If we got here, ppoll() returned less than all of our objects.
+             * So loop back to the beginning and try again. */
+        } /* while(1) */
+    } /* else (wait-all) */
+
+err:
+    /* We should only get here if poll() failed. */
+
+    if (ret == 0)
+    {
+        TRACE("Wait timed out.\n");
+        return STATUS_TIMEOUT;
+    }
+    else
+    {
+        ERR("ppoll failed: %s\n", strerror(errno));
+        return errno_to_status( errno );
+    }
+
+userapc:
+    TRACE("Woken up by user APC.\n");
+
+    /* We have to make a server call anyway to get the APC to execute, so just
+     * delegate down to server_select(). */
+    ret = server_wait( NULL, 0, SELECT_INTERRUPTIBLE | SELECT_ALERTABLE, &zero );
+
+    /* This can happen if we received a system APC, and the APC fd was woken up
+     * before we got SIGUSR1. poll() doesn't return EINTR in that case. The
+     * right thing to do seems to be to return STATUS_USER_APC anyway. */
+    if (ret == STATUS_TIMEOUT) ret = STATUS_USER_APC;
+    return ret;
+}
+
+/* We need to let the server know when we are doing a message wait, and when we
+ * are done with one, so that all of the code surrounding hung queues works.
+ * We also need this for WaitForInputIdle(). */
+static void server_set_msgwait( int in_msgwait )
+{
+    SERVER_START_REQ( esync_msgwait )
+    {
+        req->in_msgwait = in_msgwait;
+        wine_server_call( req );
+    }
+    SERVER_END_REQ;
+}
+
+/* This is a very thin wrapper around the proper implementation above. The
+ * purpose is to make sure the server knows when we are doing a message wait.
+ * This is separated into a wrapper function since there are at least a dozen
+ * exit paths from esync_wait_objects(). */
+NTSTATUS esync_wait_objects( DWORD count, const HANDLE *handles, BOOLEAN wait_any,
+                             BOOLEAN alertable, const LARGE_INTEGER *timeout )
+{
+    BOOL msgwait = FALSE;
+    struct esync *obj;
+    NTSTATUS ret;
+
+    if (count && !get_object( handles[count - 1], &obj ) && obj->type == ESYNC_QUEUE)
+    {
+        msgwait = TRUE;
+        server_set_msgwait( 1 );
+    }
+
+    ret = __esync_wait_objects( count, handles, wait_any, alertable, timeout );
+
+    if (msgwait)
+        server_set_msgwait( 0 );
+
+    return ret;
+}
+
+NTSTATUS esync_signal_and_wait( HANDLE signal, HANDLE wait, BOOLEAN alertable,
+    const LARGE_INTEGER *timeout )
+{
+    struct esync *obj;
+    NTSTATUS ret;
+
+    if ((ret = get_object( signal, &obj ))) return ret;
+
+    switch (obj->type)
+    {
+    case ESYNC_SEMAPHORE:
+        ret = esync_release_semaphore( signal, 1, NULL );
+        break;
+    case ESYNC_AUTO_EVENT:
+    case ESYNC_MANUAL_EVENT:
+        ret = esync_set_event( signal );
+        break;
+    case ESYNC_MUTEX:
+        ret = esync_release_mutex( signal, NULL );
+        break;
+    default:
+        return STATUS_OBJECT_TYPE_MISMATCH;
+    }
+    if (ret) return ret;
+
+    return esync_wait_objects( 1, &wait, TRUE, alertable, timeout );
+}
+
+void esync_init(void)
+{
+    struct stat st;
+
+    if (!do_esync())
+    {
+        /* make sure the server isn't running with WINEESYNC */
+        HANDLE handle;
+        NTSTATUS ret;
+
+        ret = create_esync( 0, &handle, 0, NULL, 0, 0 );
+        if (ret != STATUS_NOT_IMPLEMENTED)
+        {
+            ERR("Server is running with WINEESYNC but this process is not, please enable WINEESYNC or restart wineserver.\n");
+            exit(1);
+        }
+
+        return;
+    }
+
+    if (stat( config_dir, &st ) == -1)
+        ERR("Cannot stat %s\n", config_dir);
+
+    if (st.st_ino != (unsigned long)st.st_ino)
+        sprintf( shm_name, "/wine-%lx%08lx-esync", (unsigned long)((unsigned long long)st.st_ino >> 32), (unsigned long)st.st_ino );
+    else
+        sprintf( shm_name, "/wine-%lx-esync", (unsigned long)st.st_ino );
+
+    if ((shm_fd = shm_open( shm_name, O_RDWR, 0644 )) == -1)
+    {
+        /* probably the server isn't running with WINEESYNC, tell the user and bail */
+        if (errno == ENOENT)
+            ERR("Failed to open esync shared memory file; make sure no stale wineserver instances are running without WINEESYNC.\n");
+        else
+            ERR("Failed to initialize shared memory: %s\n", strerror( errno ));
+        exit(1);
+    }
+
+    pagesize = sysconf( _SC_PAGESIZE );
+
+    shm_addrs = calloc( 128, sizeof(shm_addrs[0]) );
+    shm_addrs_size = 128;
+}
diff -ruN --show-c-function dlls/ntdll/unix/esync.h dlls/ntdll/unix/esync.h
--- dlls/ntdll/unix/esync.h	1969-12-31 16:00:00.000000000 -0800
+++ dlls/ntdll/unix/esync.h	2025-10-24 16:11:42.421881987 -0700
@@ -0,0 +1,61 @@
+/*
+ * eventfd-based synchronization objects
+ *
+ * Copyright (C) 2018 Zebediah Figura
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
+ */
+
+extern int do_esync(void);
+extern void esync_init(void);
+extern NTSTATUS esync_close( HANDLE handle );
+
+extern NTSTATUS esync_create_semaphore(HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr, int initial, int max);
+extern NTSTATUS esync_open_semaphore( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr );
+extern NTSTATUS esync_query_semaphore( HANDLE handle, void *info, ULONG *ret_len );
+extern NTSTATUS esync_release_semaphore( HANDLE handle, unsigned int count, ULONG *prev );
+
+extern NTSTATUS esync_create_event( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr, EVENT_TYPE type, BOOLEAN initial );
+extern NTSTATUS esync_open_event( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr );
+extern NTSTATUS esync_pulse_event( HANDLE handle );
+extern NTSTATUS esync_query_event( HANDLE handle, void *info, ULONG *ret_len );
+extern NTSTATUS esync_reset_event( HANDLE handle );
+extern NTSTATUS esync_set_event( HANDLE handle );
+
+extern NTSTATUS esync_create_mutex( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr, BOOLEAN initial );
+extern NTSTATUS esync_open_mutex( HANDLE *handle, ACCESS_MASK access,
+    const OBJECT_ATTRIBUTES *attr );
+extern NTSTATUS esync_query_mutex( HANDLE handle, void *info, ULONG *ret_len );
+extern NTSTATUS esync_release_mutex( HANDLE *handle, LONG *prev );
+
+extern NTSTATUS esync_wait_objects( DWORD count, const HANDLE *handles, BOOLEAN wait_any,
+                                    BOOLEAN alertable, const LARGE_INTEGER *timeout );
+extern NTSTATUS esync_signal_and_wait( HANDLE signal, HANDLE wait, BOOLEAN alertable,
+    const LARGE_INTEGER *timeout );
+
+
+/* We have to synchronize on the fd cache mutex so that our calls to receive_fd
+ * don't race with theirs. It looks weird, I know.
+ *
+ * If we weren't trying to avoid touching the code I'd rename the mutex to
+ * "server_fd_mutex" or something similar. */
+extern pthread_mutex_t fd_cache_mutex;
+
+extern int receive_fd( obj_handle_t *handle );
diff -ruN --show-c-function dlls/ntdll/unix/loader.c dlls/ntdll/unix/loader.c
--- dlls/ntdll/unix/loader.c	2025-10-21 17:44:35.922771491 -0700
+++ dlls/ntdll/unix/loader.c	2025-10-24 16:11:42.392388034 -0700
@@ -90,6 +90,7 @@
 #include "winioctl.h"
 #include "winternl.h"
 #include "unix_private.h"
+#include "esync.h"
 #include "wine/list.h"
 #include "ntsyscalls.h"
 #include "wine/debug.h"
@@ -1907,6 +1908,7 @@ static void start_main_thread(void)
     signal_init_threading();
     dbg_init();
     startup_info_size = server_init_process();
+    esync_init();
     virtual_map_user_shared_data();
     init_cpu_info();
     init_files();
diff -ruN --show-c-function dlls/ntdll/unix/server.c dlls/ntdll/unix/server.c
--- dlls/ntdll/unix/server.c	2025-10-21 17:44:35.922771491 -0700
+++ dlls/ntdll/unix/server.c	2025-10-24 16:11:42.394072782 -0700
@@ -79,6 +79,7 @@
 #include "wine/server.h"
 #include "wine/debug.h"
 #include "unix_private.h"
+#include "esync.h"
 #include "ddk/wdm.h"
 
 WINE_DEFAULT_DEBUG_CHANNEL(server);
@@ -909,24 +910,15 @@ unsigned int server_queue_process_apc( H
         }
         else
         {
-            sigset_t sigset;
-
             NtWaitForSingleObject( handle, FALSE, NULL );
 
-            server_enter_uninterrupted_section( &fd_cache_mutex, &sigset );
-
-            /* remove the handle from the cache, get_apc_result will close it for us */
-            close_inproc_sync( handle );
-
             SERVER_START_REQ( get_apc_result )
             {
                 req->handle = wine_server_obj_handle( handle );
-                if (!(ret = server_call_unlocked( req ))) *result = reply->result;
+                if (!(ret = wine_server_call( req ))) *result = reply->result;
             }
             SERVER_END_REQ;
 
-            server_leave_uninterrupted_section( &fd_cache_mutex, &sigset );
-
             if (!ret && result->type == APC_NONE) continue;  /* APC didn't run, try again */
         }
         return ret;
@@ -985,7 +977,7 @@ void CDECL wine_server_send_fd( int fd )
  *
  * Receive a file descriptor passed from the server.
  */
-int wine_server_receive_fd( obj_handle_t *handle )
+int receive_fd( obj_handle_t *handle )
 {
     struct iovec vec;
     struct msghdr msghdr;
@@ -1180,7 +1172,7 @@ int server_get_unix_fd( HANDLE handle, u
                 if (type) *type = reply->type;
                 if (options) *options = reply->options;
                 access = reply->access;
-                if ((fd = wine_server_receive_fd( &fd_handle )) != -1)
+                if ((fd = receive_fd( &fd_handle )) != -1)
                 {
                     assert( wine_server_ptr_handle(fd_handle) == handle );
                     *needs_close = (!reply->cacheable ||
@@ -1594,7 +1586,6 @@ size_t server_init_process(void)
 {
     const char *arch = getenv( "WINEARCH" );
     const char *env_socket = getenv( "WINESERVERSOCKET" );
-    struct ntdll_thread_data *data = ntdll_get_thread_data();
     obj_handle_t version;
     unsigned int i;
     int ret, reply_pipe;
@@ -1634,7 +1625,7 @@ size_t server_init_process(void)
     pthread_sigmask( SIG_BLOCK, &server_block_set, NULL );
 
     /* receive the first thread request fd on the main socket */
-    data->request_fd = wine_server_receive_fd( &version );
+    ntdll_get_thread_data()->request_fd = receive_fd( &version );
 
 #ifdef SO_PASSCRED
     /* now that we hopefully received the server_pid, disable SO_PASSCRED */
@@ -1669,24 +1660,16 @@ size_t server_init_process(void)
         req->unix_pid    = getpid();
         req->unix_tid    = get_unix_tid();
         req->reply_fd    = reply_pipe;
-        req->wait_fd     = data->wait_fd[1];
+        req->wait_fd     = ntdll_get_thread_data()->wait_fd[1];
         req->debug_level = (TRACE_ON(server) != 0);
         wine_server_set_reply( req, supported_machines, sizeof(supported_machines) );
-        if (!(ret = wine_server_call( req )))
-        {
-            obj_handle_t handle;
-            pid               = reply->pid;
-            tid               = reply->tid;
-            peb->SessionId    = reply->session_id;
-            info_size         = reply->info_size;
-            server_start_time = reply->server_start;
-            supported_machines_count = wine_server_reply_size( reply ) / sizeof(*supported_machines);
-            if (reply->inproc_device)
-            {
-                inproc_device_fd = wine_server_receive_fd( &handle );
-                assert( handle == reply->inproc_device );
-            }
-        }
+        ret = wine_server_call( req );
+        pid               = reply->pid;
+        tid               = reply->tid;
+        peb->SessionId    = reply->session_id;
+        info_size         = reply->info_size;
+        server_start_time = reply->server_start;
+        supported_machines_count = wine_server_reply_size( reply ) / sizeof(*supported_machines);
     }
     SERVER_END_REQ;
     close( reply_pipe );
@@ -1855,17 +1838,12 @@ NTSTATUS WINAPI NtDuplicateObject( HANDL
         return result.dup_handle.status;
     }
 
-    /* hold fd_cache_mutex to prevent the fd from being added again between the
-     * call to remove_fd_from_cache and close_handle */
     server_enter_uninterrupted_section( &fd_cache_mutex, &sigset );
 
     /* always remove the cached fd; if the server request fails we'll just
      * retrieve it again */
     if (options & DUPLICATE_CLOSE_SOURCE)
-    {
         fd = remove_fd_from_cache( source );
-        close_inproc_sync( source );
-    }
 
     SERVER_START_REQ( dup_handle )
     {
@@ -1931,14 +1909,14 @@ NTSTATUS WINAPI NtClose( HANDLE handle )
     if (HandleToLong( handle ) >= ~5 && HandleToLong( handle ) <= ~0)
         return STATUS_SUCCESS;
 
-    /* hold fd_cache_mutex to prevent the fd from being added again between the
-     * call to remove_fd_from_cache and close_handle */
     server_enter_uninterrupted_section( &fd_cache_mutex, &sigset );
 
     /* always remove the cached fd; if the server request fails we'll just
      * retrieve it again */
     fd = remove_fd_from_cache( handle );
-    close_inproc_sync( handle );
+
+    if (do_esync())
+        esync_close( handle );
 
     SERVER_START_REQ( close_handle )
     {
diff -ruN --show-c-function dlls/ntdll/unix/sync.c dlls/ntdll/unix/sync.c
--- dlls/ntdll/unix/sync.c	2025-10-21 17:44:36.788790987 -0700
+++ dlls/ntdll/unix/sync.c	2025-10-24 16:11:42.419885458 -0700
@@ -30,11 +30,9 @@
 #include <assert.h>
 #include <errno.h>
 #include <fcntl.h>
-#include <inttypes.h>
 #include <limits.h>
 #include <signal.h>
 #include <sys/types.h>
-#include <sys/ioctl.h>
 #include <sys/mman.h>
 #ifdef HAVE_SYS_SYSCALL_H
 #include <sys/syscall.h>
@@ -50,7 +48,6 @@
 #endif
 #include <string.h>
 #include <stdarg.h>
-#include <stdint.h>
 #include <stdio.h>
 #include <stdlib.h>
 #include <time.h>
@@ -60,9 +57,6 @@
 #ifdef HAVE_KQUEUE
 # include <sys/event.h>
 #endif
-#ifdef HAVE_LINUX_NTSYNC_H
-# include <linux/ntsync.h>
-#endif
 
 #include "ntstatus.h"
 #define WIN32_NO_STATUS
@@ -72,20 +66,18 @@
 #include "wine/server.h"
 #include "wine/debug.h"
 #include "unix_private.h"
+#include "esync.h"
 
 WINE_DEFAULT_DEBUG_CHANNEL(sync);
 
 HANDLE keyed_event = 0;
-int inproc_device_fd = -1;
 
 static const char *debugstr_timeout( const LARGE_INTEGER *timeout )
 {
     if (!timeout) return "(infinite)";
-    return wine_dbg_sprintf( "%lld.%07ld", (long long)(timeout->QuadPart / TICKSPERSEC),
-                             (long)(timeout->QuadPart % TICKSPERSEC) );
+    return wine_dbgstr_longlong( timeout->QuadPart );
 }
 
-
 /* return a monotonic time counter, in Win32 ticks */
 static inline ULONGLONG monotonic_counter(void)
 {
@@ -309,644 +301,6 @@ static unsigned int validate_open_object
     return STATUS_SUCCESS;
 }
 
-#ifdef NTSYNC_IOC_EVENT_READ
-
-static NTSTATUS linux_release_semaphore_obj( int obj, ULONG count, ULONG *prev_count )
-{
-    if (ioctl( obj, NTSYNC_IOC_SEM_RELEASE, &count ) < 0)
-    {
-        if (errno == EOVERFLOW) return STATUS_SEMAPHORE_LIMIT_EXCEEDED;
-        return errno_to_status( errno );
-    }
-    if (prev_count) *prev_count = count;
-    return STATUS_SUCCESS;
-}
-
-static NTSTATUS linux_query_semaphore_obj( int obj, SEMAPHORE_BASIC_INFORMATION *info )
-{
-    struct ntsync_sem_args args = {0};
-    if (ioctl( obj, NTSYNC_IOC_SEM_READ, &args ) < 0) return errno_to_status( errno );
-    info->CurrentCount = args.count;
-    info->MaximumCount = args.max;
-    return STATUS_SUCCESS;
-}
-
-static NTSTATUS linux_set_event_obj( int obj, LONG *prev_state )
-{
-    __u32 prev;
-    if (ioctl( obj, NTSYNC_IOC_EVENT_SET, &prev ) < 0) return errno_to_status( errno );
-    if (prev_state) *prev_state = prev;
-    return STATUS_SUCCESS;
-}
-
-static NTSTATUS linux_reset_event_obj( int obj, LONG *prev_state )
-{
-    __u32 prev;
-    if (ioctl( obj, NTSYNC_IOC_EVENT_RESET, &prev ) < 0) return errno_to_status( errno );
-    if (prev_state) *prev_state = prev;
-    return STATUS_SUCCESS;
-}
-
-static NTSTATUS linux_pulse_event_obj( int obj, LONG *prev_state )
-{
-    __u32 prev;
-    if (ioctl( obj, NTSYNC_IOC_EVENT_PULSE, &prev ) < 0) return errno_to_status( errno );
-    if (prev_state) *prev_state = prev;
-    return STATUS_SUCCESS;
-}
-
-static NTSTATUS linux_query_event_obj( int obj, enum inproc_sync_type type, EVENT_BASIC_INFORMATION *info )
-{
-    struct ntsync_event_args args = {0};
-    if (ioctl( obj, NTSYNC_IOC_EVENT_READ, &args ) < 0) return errno_to_status( errno );
-    info->EventType = args.manual ? NotificationEvent : SynchronizationEvent;
-    info->EventState = args.signaled;
-    return STATUS_SUCCESS;
-}
-
-static NTSTATUS linux_release_mutex_obj( int obj, LONG *prev_count )
-{
-    struct ntsync_mutex_args args = {.owner = GetCurrentThreadId()};
-    if (ioctl( obj, NTSYNC_IOC_MUTEX_UNLOCK, &args ) < 0)
-    {
-        if (errno == EOVERFLOW) return STATUS_MUTANT_LIMIT_EXCEEDED;
-        if (errno == EPERM) return STATUS_MUTANT_NOT_OWNED;
-        return errno_to_status( errno );
-    }
-    if (prev_count) *prev_count = 1 - args.count;
-    return STATUS_SUCCESS;
-}
-
-static NTSTATUS linux_query_mutex_obj( int obj, MUTANT_BASIC_INFORMATION *info )
-{
-    struct ntsync_mutex_args args = {0};
-    if (ioctl( obj, NTSYNC_IOC_MUTEX_READ, &args ) < 0)
-    {
-        if (errno == EOWNERDEAD)
-        {
-            info->AbandonedState = TRUE;
-            info->OwnedByCaller = FALSE;
-            info->CurrentCount = 1;
-            return STATUS_SUCCESS;
-        }
-        return errno_to_status( errno );
-    }
-    info->AbandonedState = FALSE;
-    info->OwnedByCaller = (args.owner == GetCurrentThreadId());
-    info->CurrentCount = 1 - args.count;
-    return STATUS_SUCCESS;
-}
-
-static NTSTATUS linux_wait_objs( int device, const DWORD count, const int *objs,
-                                 BOOLEAN wait_any, int alert_fd, const LARGE_INTEGER *timeout )
-{
-    struct ntsync_wait_args args = {0};
-    unsigned long request;
-    struct timespec now;
-    int ret;
-
-    if (!timeout || timeout->QuadPart == TIMEOUT_INFINITE)
-    {
-        args.timeout = ~(__u64)0;
-    }
-    else if (timeout->QuadPart <= 0)
-    {
-        clock_gettime( CLOCK_MONOTONIC, &now );
-        args.timeout = ((ULONGLONG)now.tv_sec * NSECPERSEC) + now.tv_nsec + (-timeout->QuadPart * 100);
-    }
-    else
-    {
-        args.timeout = (timeout->QuadPart * 100) - (SECS_1601_TO_1970 * NSECPERSEC);
-        args.flags |= NTSYNC_WAIT_REALTIME;
-    }
-
-    args.objs = (uintptr_t)objs;
-    args.count = count;
-    args.owner = GetCurrentThreadId();
-    args.index = ~0u;
-    args.alert = alert_fd;
-
-    if (wait_any || count == 1) request = NTSYNC_IOC_WAIT_ANY;
-    else request = NTSYNC_IOC_WAIT_ALL;
-
-    do { ret = ioctl( device, request, &args ); }
-    while (ret < 0 && errno == EINTR);
-
-    if (!ret)
-    {
-        if (args.index == count)
-        {
-            static const LARGE_INTEGER timeout;
-
-            ret = server_wait( NULL, 0, SELECT_INTERRUPTIBLE | SELECT_ALERTABLE, &timeout );
-            assert( ret == STATUS_USER_APC );
-            return ret;
-        }
-
-        return wait_any ? args.index : 0;
-    }
-    if (errno == EOWNERDEAD) return STATUS_ABANDONED + (wait_any ? args.index : 0);
-    if (errno == ETIMEDOUT) return STATUS_TIMEOUT;
-    return errno_to_status( errno );
-}
-
-#else /* NTSYNC_IOC_EVENT_READ */
-
-static NTSTATUS linux_release_semaphore_obj( int obj, ULONG count, ULONG *prev_count )
-{
-    return STATUS_NOT_IMPLEMENTED;
-}
-
-static NTSTATUS linux_query_semaphore_obj( int obj, SEMAPHORE_BASIC_INFORMATION *info )
-{
-    return STATUS_NOT_IMPLEMENTED;
-}
-
-static NTSTATUS linux_set_event_obj( int obj, LONG *prev_state )
-{
-    return STATUS_NOT_IMPLEMENTED;
-}
-
-static NTSTATUS linux_reset_event_obj( int obj, LONG *prev_state )
-{
-    return STATUS_NOT_IMPLEMENTED;
-}
-
-static NTSTATUS linux_pulse_event_obj( int obj, LONG *prev_state )
-{
-    return STATUS_NOT_IMPLEMENTED;
-}
-
-static NTSTATUS linux_query_event_obj( int obj, enum inproc_sync_type type, EVENT_BASIC_INFORMATION *info )
-{
-    return STATUS_NOT_IMPLEMENTED;
-}
-
-static NTSTATUS linux_release_mutex_obj( int obj, LONG *prev_count )
-{
-    return STATUS_NOT_IMPLEMENTED;
-}
-
-static NTSTATUS linux_query_mutex_obj( int obj, MUTANT_BASIC_INFORMATION *info )
-{
-    return STATUS_NOT_IMPLEMENTED;
-}
-
-static NTSTATUS linux_wait_objs( int device, const DWORD count, const int *objs,
-                                 BOOLEAN wait_any, int alert_fd, const LARGE_INTEGER *timeout )
-{
-    return STATUS_NOT_IMPLEMENTED;
-}
-
-#endif /* NTSYNC_IOC_EVENT_READ */
-
-/* It's possible for synchronization primitives to remain alive even after being
- * closed, because a thread is still waiting on them. It's rare in practice, and
- * documented as being undefined behaviour by Microsoft, but it works, and some
- * applications rely on it. This means we need to refcount handles, and defer
- * deleting them on the server side until the refcount reaches zero. We do this
- * by having each client process hold a handle to the in-process synchronization
- * object, as well as a private refcount. When the client refcount reaches zero,
- * it closes the handle; when all handles are closed, the server deletes the
- * in-process synchronization object.
- *
- * We also need this for signal-and-wait. The signal and wait operations aren't
- * atomic, but we can't perform the signal and then return STATUS_INVALID_HANDLE
- * for the wait—we need to either do both operations or neither. That means we
- * need to grab references to both objects, and prevent them from being
- * destroyed before we're done with them.
- *
- * We want lookup of objects from the cache to be very fast; ideally, it should
- * be lock-free. We achieve this by using atomic modifications to "refcount",
- * and guaranteeing that all other fields are valid and correct *as long as*
- * refcount is nonzero, and we store the entire structure in memory which will
- * never be freed.
- *
- * This means that acquiring the object can't use a simple atomic increment; it
- * has to use a compare-and-swap loop to ensure that it doesn't try to increment
- * an object with a zero refcount. That's still leagues better than a real lock,
- * though, and release can be a single atomic decrement.
- *
- * It also means that threads modifying the cache need to take a lock, to
- * prevent other threads from writing to it concurrently.
- *
- * It's possible for an object currently in use (by a waiter) to be closed and
- * the same handle immediately reallocated to a different object. This should be
- * a very rare situation, and in that case we simply don't cache the handle.
- */
-struct inproc_sync
-{
-    LONG           refcount;  /* reference count of the sync object */
-    int            fd;        /* unix file descriptor */
-    unsigned int   access;    /* handle access rights */
-    unsigned short type;      /* enum inproc_sync_type as short to save space */
-    unsigned short closed;    /* fd has been closed but sync is still referenced */
-};
-
-#define INPROC_SYNC_CACHE_BLOCK_SIZE  (65536 / sizeof(struct inproc_sync))
-#define INPROC_SYNC_CACHE_ENTRIES     128
-
-static struct inproc_sync *inproc_sync_cache[INPROC_SYNC_CACHE_ENTRIES];
-static struct inproc_sync inproc_sync_cache_initial_block[INPROC_SYNC_CACHE_BLOCK_SIZE];
-
-static inline unsigned int inproc_sync_handle_to_index( HANDLE handle, unsigned int *entry )
-{
-    unsigned int idx = (wine_server_obj_handle(handle) >> 2) - 1;
-    *entry = idx / INPROC_SYNC_CACHE_BLOCK_SIZE;
-    return idx % INPROC_SYNC_CACHE_BLOCK_SIZE;
-}
-
-static struct inproc_sync *cache_inproc_sync( HANDLE handle, struct inproc_sync *sync )
-{
-    unsigned int entry, idx = inproc_sync_handle_to_index( handle, &entry );
-    struct inproc_sync *cache;
-    int refcount;
-
-    /* don't cache pseudo-handles; waiting on them is pointless anyway */
-    if ((ULONG)(ULONG_PTR)handle > 0xfffffffa) return sync;
-
-    if (entry >= INPROC_SYNC_CACHE_ENTRIES)
-    {
-        FIXME( "too many allocated handles, not caching %p\n", handle );
-        return sync;
-    }
-
-    if (!inproc_sync_cache[entry])  /* do we need to allocate a new block of entries? */
-    {
-        if (!entry) inproc_sync_cache[0] = inproc_sync_cache_initial_block;
-        else
-        {
-            static const size_t size = INPROC_SYNC_CACHE_BLOCK_SIZE * sizeof(struct inproc_sync);
-            void *ptr = anon_mmap_alloc( size, PROT_READ | PROT_WRITE );
-            if (ptr == MAP_FAILED) return sync;
-            if (InterlockedCompareExchangePointer( (void **)&inproc_sync_cache[entry], ptr, NULL ))
-                munmap( ptr, size ); /* someone beat us to it */
-        }
-    }
-
-    cache = &inproc_sync_cache[entry][idx];
-
-    if (InterlockedCompareExchange( &cache->refcount, 0, 0 ))
-    {
-        /* The handle is currently being used for another object (i.e. it was
-         * closed and then reused, but some thread is waiting on the old handle
-         * or otherwise simultaneously using the old object). We can't cache
-         * this object until the old one is completely destroyed. */
-        return sync;
-    }
-
-    cache->fd = sync->fd;
-    cache->access = sync->access;
-    cache->type = sync->type;
-    cache->closed = sync->closed;
-    /* Make sure we set the other members before the refcount; this store needs
-     * release semantics [paired with the load in get_cached_inproc_sync()].
-     * Set the refcount to 2 (one for the handle, one for the caller). */
-    refcount = InterlockedExchange( &cache->refcount, 2 );
-    assert( !refcount );
-
-    assert( sync->refcount == 1 );
-    memset( sync, 0, sizeof(*sync) );
-
-    return cache;
-}
-
-/* returns the previous value */
-static inline LONG interlocked_inc_if_nonzero( LONG *dest )
-{
-    LONG val, tmp;
-    for (val = *dest;; val = tmp)
-    {
-        if (!val || (tmp = InterlockedCompareExchange( dest, val + 1, val )) == val)
-            break;
-    }
-    return val;
-}
-
-static void release_inproc_sync( struct inproc_sync *sync )
-{
-    /* save the fd now; as soon as the refcount hits 0 we cannot
-     * access the cache anymore */
-    int fd = sync->fd;
-    LONG ref = InterlockedDecrement( &sync->refcount );
-
-    assert( ref >= 0 );
-    if (!ref) close( fd );
-}
-
-static struct inproc_sync *get_cached_inproc_sync( HANDLE handle )
-{
-    unsigned int entry, idx = inproc_sync_handle_to_index( handle, &entry );
-    struct inproc_sync *cache;
-
-    if (entry >= INPROC_SYNC_CACHE_ENTRIES || !inproc_sync_cache[entry]) return NULL;
-
-    cache = &inproc_sync_cache[entry][idx];
-
-    /* this load needs acquire semantics [paired with the store in
-     * cache_inproc_sync()] */
-    if (!interlocked_inc_if_nonzero( &cache->refcount )) return NULL;
-
-    if (cache->closed)
-    {
-        /* The object is still being used, but "handle" has been closed. The
-         * handle value might have been reused for another object in the
-         * meantime, in which case we have to report that valid object, so
-         * force the caller to check the server. */
-        release_inproc_sync( cache );
-        return NULL;
-    }
-
-    return cache;
-}
-
-/* fd_cache_mutex must be held to avoid races with other thread receiving fds */
-static NTSTATUS get_server_inproc_sync( HANDLE handle, struct inproc_sync *sync )
-{
-    NTSTATUS ret;
-
-    SERVER_START_REQ( get_inproc_sync_fd )
-    {
-        req->handle = wine_server_obj_handle( handle );
-        if (!(ret = wine_server_call( req )))
-        {
-            obj_handle_t fd_handle;
-            sync->refcount = 1;
-            sync->fd = wine_server_receive_fd( &fd_handle );
-            assert( wine_server_ptr_handle(fd_handle) == handle );
-            sync->access = reply->access;
-            sync->type = reply->type;
-            sync->closed = 0;
-        }
-    }
-    SERVER_END_REQ;
-
-    return ret;
-}
-
-/* returns a pointer to a cache entry; if the object could not be cached,
- * returns "cache" instead, which should be allocated on stack */
-static NTSTATUS get_inproc_sync( HANDLE handle, enum inproc_sync_type desired_type, ACCESS_MASK desired_access,
-                                 struct inproc_sync *stack, struct inproc_sync **out )
-{
-    struct inproc_sync *sync;
-    sigset_t sigset;
-    NTSTATUS ret;
-
-    /* try to find it in the cache already */
-    if ((sync = get_cached_inproc_sync( handle ))) ret = STATUS_SUCCESS;
-    else
-    {
-        /* We need to use fd_cache_mutex here to protect against races with
-         * other threads trying to receive fds for the fd cache,
-         * and we need to use an uninterrupted section to prevent reentrancy.
-         * We also need fd_cache_mutex to protect against the same race with
-         * NtClose, that is, to prevent the object from being cached again between
-         * close_inproc_sync() and close_handle. */
-        server_enter_uninterrupted_section( &fd_cache_mutex, &sigset );
-        if ((sync = get_cached_inproc_sync( handle ))) ret = STATUS_SUCCESS;
-        else ret = get_server_inproc_sync( handle, stack );
-        server_leave_uninterrupted_section( &fd_cache_mutex, &sigset );
-        if (ret) return ret;
-
-        if (!sync) sync = cache_inproc_sync( handle, stack );
-    }
-
-    if (desired_type != INPROC_SYNC_UNKNOWN && desired_type != sync->type)
-    {
-        release_inproc_sync( sync );
-        return STATUS_OBJECT_TYPE_MISMATCH;
-    }
-    if ((sync->access & desired_access) != desired_access)
-    {
-        release_inproc_sync( sync );
-        return STATUS_ACCESS_DENIED;
-    }
-
-    *out = sync;
-    return STATUS_SUCCESS;
-}
-
-extern NTSTATUS check_signal_access( struct inproc_sync *sync )
-{
-    switch (sync->type)
-    {
-    case INPROC_SYNC_INTERNAL:
-        return STATUS_OBJECT_TYPE_MISMATCH;
-    case INPROC_SYNC_EVENT:
-        if (!(sync->access & EVENT_MODIFY_STATE)) return STATUS_ACCESS_DENIED;
-        return STATUS_SUCCESS;
-    case INPROC_SYNC_MUTEX:
-        if (!(sync->access & SYNCHRONIZE)) return STATUS_ACCESS_DENIED;
-        return STATUS_SUCCESS;
-    case INPROC_SYNC_SEMAPHORE:
-        if (!(sync->access & SEMAPHORE_MODIFY_STATE)) return STATUS_ACCESS_DENIED;
-        return STATUS_SUCCESS;
-    }
-
-    assert( 0 );
-    return STATUS_OBJECT_TYPE_MISMATCH;
-}
-
-/* caller must hold fd_cache_mutex */
-void close_inproc_sync( HANDLE handle )
-{
-    struct inproc_sync *cache;
-
-    if (inproc_device_fd < 0) return;
-    if ((cache = get_cached_inproc_sync( handle )))
-    {
-        cache->closed = 1;
-        /* once for the reference we just grabbed, and once for the handle */
-        release_inproc_sync( cache );
-        release_inproc_sync( cache );
-    }
-}
-
-static NTSTATUS inproc_release_semaphore( HANDLE handle, ULONG count, ULONG *prev_count )
-{
-    struct inproc_sync stack, *sync;
-    NTSTATUS ret;
-
-    if (inproc_device_fd < 0) return STATUS_NOT_IMPLEMENTED;
-    if ((ret = get_inproc_sync( handle, INPROC_SYNC_SEMAPHORE, SEMAPHORE_MODIFY_STATE, &stack, &sync ))) return ret;
-    ret = linux_release_semaphore_obj( sync->fd, count, prev_count );
-    release_inproc_sync( sync );
-    return ret;
-}
-
-static NTSTATUS inproc_query_semaphore( HANDLE handle, SEMAPHORE_BASIC_INFORMATION *info )
-{
-    struct inproc_sync stack, *sync;
-    NTSTATUS ret;
-
-    if (inproc_device_fd < 0) return STATUS_NOT_IMPLEMENTED;
-    if ((ret = get_inproc_sync( handle, INPROC_SYNC_SEMAPHORE, SEMAPHORE_QUERY_STATE, &stack, &sync ))) return ret;
-    ret = linux_query_semaphore_obj( sync->fd, info );
-    release_inproc_sync( sync );
-    return ret;
-}
-
-static NTSTATUS inproc_set_event( HANDLE handle, LONG *prev_state )
-{
-    struct inproc_sync stack, *sync;
-    NTSTATUS ret;
-
-    if (inproc_device_fd < 0) return STATUS_NOT_IMPLEMENTED;
-    if ((ret = get_inproc_sync( handle, INPROC_SYNC_EVENT, EVENT_MODIFY_STATE, &stack, &sync ))) return ret;
-    ret = linux_set_event_obj( sync->fd, prev_state );
-    release_inproc_sync( sync );
-    return ret;
-}
-
-static NTSTATUS inproc_reset_event( HANDLE handle, LONG *prev_state )
-{
-    struct inproc_sync stack, *sync;
-    NTSTATUS ret;
-
-    if (inproc_device_fd < 0) return STATUS_NOT_IMPLEMENTED;
-    if ((ret = get_inproc_sync( handle, INPROC_SYNC_EVENT, EVENT_MODIFY_STATE, &stack, &sync ))) return ret;
-    ret = linux_reset_event_obj( sync->fd, prev_state );
-    release_inproc_sync( sync );
-    return ret;
-}
-
-static NTSTATUS inproc_pulse_event( HANDLE handle, LONG *prev_state )
-{
-    struct inproc_sync stack, *sync;
-    NTSTATUS ret;
-
-    if (inproc_device_fd < 0) return STATUS_NOT_IMPLEMENTED;
-    if ((ret = get_inproc_sync( handle, INPROC_SYNC_EVENT, EVENT_MODIFY_STATE, &stack, &sync ))) return ret;
-    ret = linux_pulse_event_obj( sync->fd, prev_state );
-    release_inproc_sync( sync );
-    return ret;
-}
-
-static NTSTATUS inproc_query_event( HANDLE handle, EVENT_BASIC_INFORMATION *info )
-{
-    struct inproc_sync stack, *sync;
-    NTSTATUS ret;
-
-    if (inproc_device_fd < 0) return STATUS_NOT_IMPLEMENTED;
-    if ((ret = get_inproc_sync( handle, INPROC_SYNC_EVENT, EVENT_QUERY_STATE, &stack, &sync ))) return ret;
-    ret = linux_query_event_obj( sync->fd, sync->type, info );
-    release_inproc_sync( sync );
-    return ret;
-}
-
-static NTSTATUS inproc_release_mutex( HANDLE handle, LONG *prev_count )
-{
-    struct inproc_sync stack, *sync;
-    NTSTATUS ret;
-
-    if (inproc_device_fd < 0) return STATUS_NOT_IMPLEMENTED;
-    if ((ret = get_inproc_sync( handle, INPROC_SYNC_MUTEX, 0, &stack, &sync ))) return ret;
-    ret = linux_release_mutex_obj( sync->fd, prev_count );
-    release_inproc_sync( sync );
-    return ret;
-}
-
-static NTSTATUS inproc_query_mutex( HANDLE handle, MUTANT_BASIC_INFORMATION *info )
-{
-    struct inproc_sync stack, *sync;
-    NTSTATUS ret;
-
-    if (inproc_device_fd < 0) return STATUS_NOT_IMPLEMENTED;
-    if ((ret = get_inproc_sync( handle, INPROC_SYNC_MUTEX, MUTANT_QUERY_STATE, &stack, &sync ))) return ret;
-    ret = linux_query_mutex_obj( sync->fd, info );
-    release_inproc_sync( sync );
-    return ret;
-}
-
-static int get_inproc_alert_fd(void)
-{
-    struct ntdll_thread_data *data = ntdll_get_thread_data();
-    obj_handle_t token;
-    sigset_t sigset;
-    int fd;
-
-    if ((fd = data->alert_fd) < 0)
-    {
-        server_enter_uninterrupted_section( &fd_cache_mutex, &sigset );
-
-        SERVER_START_REQ( get_inproc_alert_fd )
-        {
-            if (!server_call_unlocked( req ))
-            {
-                data->alert_fd = fd = wine_server_receive_fd( &token );
-                assert( token == reply->handle );
-            }
-        }
-        SERVER_END_REQ;
-
-        server_leave_uninterrupted_section( &fd_cache_mutex, &sigset );
-    }
-
-    return fd;
-}
-
-static NTSTATUS inproc_wait( DWORD count, const HANDLE *handles, BOOLEAN wait_any,
-                             BOOLEAN alertable, const LARGE_INTEGER *timeout )
-{
-    struct inproc_sync *syncs[64], stack[ARRAY_SIZE(syncs)];
-    int objs[ARRAY_SIZE(syncs)], alert_fd = 0;
-    NTSTATUS ret;
-
-    if (inproc_device_fd < 0) return STATUS_NOT_IMPLEMENTED;
-
-    assert( count <= ARRAY_SIZE(syncs) );
-    for (int i = 0; i < count; ++i)
-    {
-        if ((ret = get_inproc_sync( handles[i], INPROC_SYNC_UNKNOWN, SYNCHRONIZE, &stack[i], &syncs[i] )))
-        {
-            while (i--) release_inproc_sync( syncs[i] );
-            return ret;
-        }
-        objs[i] = syncs[i]->fd;
-    }
-
-    if (alertable) alert_fd = get_inproc_alert_fd();
-    ret = linux_wait_objs( inproc_device_fd, count, objs, wait_any, alert_fd, timeout );
-
-    while (count--) release_inproc_sync( syncs[count] );
-    return ret;
-}
-
-static NTSTATUS inproc_signal_and_wait( HANDLE signal, HANDLE wait,
-                                        BOOLEAN alertable, const LARGE_INTEGER *timeout )
-{
-    struct inproc_sync stack_signal, stack_wait, *signal_sync = &stack_signal, *wait_sync = &stack_wait;
-    int alert_fd = 0;
-    NTSTATUS ret;
-
-    if (inproc_device_fd < 0) return STATUS_NOT_IMPLEMENTED;
-
-    if ((ret = get_inproc_sync( signal, INPROC_SYNC_UNKNOWN, 0, &stack_signal, &signal_sync ))) return ret;
-    if ((ret = check_signal_access( signal_sync ))) goto done;
-
-    if ((ret = get_inproc_sync( wait, INPROC_SYNC_UNKNOWN, SYNCHRONIZE, &stack_wait, &wait_sync ))) goto done;
-
-    switch (signal_sync->type)
-    {
-    case INPROC_SYNC_EVENT:     ret = linux_set_event_obj( signal_sync->fd, NULL ); break;
-    case INPROC_SYNC_MUTEX:     ret = linux_release_mutex_obj( signal_sync->fd, NULL ); break;
-    case INPROC_SYNC_SEMAPHORE: ret = linux_release_semaphore_obj( signal_sync->fd, 1, NULL ); break;
-    default: assert( 0 ); break;
-    }
-
-    if (!ret)
-    {
-        if (alertable) alert_fd = get_inproc_alert_fd();
-        ret = linux_wait_objs( inproc_device_fd, 1, &wait_sync->fd, TRUE, alert_fd, timeout );
-    }
-
-    release_inproc_sync( wait_sync );
-done:
-    release_inproc_sync( signal_sync );
-    return ret;
-}
-
 
 /******************************************************************************
  *              NtCreateSemaphore (NTDLL.@)
@@ -958,13 +312,13 @@ NTSTATUS WINAPI NtCreateSemaphore( HANDL
     data_size_t len;
     struct object_attributes *objattr;
 
-    TRACE( "access %#x, name %s, initial %d, max %d\n", access,
-           attr ? debugstr_us(attr->ObjectName) : "(null)", initial, max );
-
     *handle = 0;
     if (max <= 0 || initial < 0 || initial > max) return STATUS_INVALID_PARAMETER;
     if ((ret = alloc_object_attributes( attr, &objattr, &len ))) return ret;
 
+    if (do_esync())
+        return esync_create_semaphore( handle, access, attr, initial, max );
+
     SERVER_START_REQ( create_semaphore )
     {
         req->access  = access;
@@ -988,9 +342,11 @@ NTSTATUS WINAPI NtOpenSemaphore( HANDLE
 {
     unsigned int ret;
 
-    TRACE( "access %#x, name %s\n", access, attr ? debugstr_us(attr->ObjectName) : "(null)" );
-
     *handle = 0;
+
+    if (do_esync())
+        return esync_open_semaphore( handle, access, attr );
+
     if ((ret = validate_open_object_attributes( attr ))) return ret;
 
     SERVER_START_REQ( open_semaphore )
@@ -1027,11 +383,8 @@ NTSTATUS WINAPI NtQuerySemaphore( HANDLE
 
     if (len != sizeof(SEMAPHORE_BASIC_INFORMATION)) return STATUS_INFO_LENGTH_MISMATCH;
 
-    if ((ret = inproc_query_semaphore( handle, out )) != STATUS_NOT_IMPLEMENTED)
-    {
-        if (!ret && ret_len) *ret_len = sizeof(SEMAPHORE_BASIC_INFORMATION);
-        return ret;
-    }
+    if (do_esync())
+        return esync_query_semaphore( handle, info, ret_len );
 
     SERVER_START_REQ( query_semaphore )
     {
@@ -1055,10 +408,8 @@ NTSTATUS WINAPI NtReleaseSemaphore( HAND
 {
     unsigned int ret;
 
-    TRACE( "handle %p, count %u, prev_count %p\n", handle, count, previous );
-
-    if ((ret = inproc_release_semaphore( handle, count, previous )) != STATUS_NOT_IMPLEMENTED)
-        return ret;
+    if (do_esync())
+        return esync_release_semaphore( handle, count, previous );
 
     SERVER_START_REQ( release_semaphore )
     {
@@ -1084,11 +435,12 @@ NTSTATUS WINAPI NtCreateEvent( HANDLE *h
     data_size_t len;
     struct object_attributes *objattr;
 
-    TRACE( "access %#x, name %s, type %u, state %u\n", access,
-           attr ? debugstr_us(attr->ObjectName) : "(null)", type, state );
-
     *handle = 0;
     if (type != NotificationEvent && type != SynchronizationEvent) return STATUS_INVALID_PARAMETER;
+
+    if (do_esync())
+        return esync_create_event( handle, access, attr, type, state );
+
     if ((ret = alloc_object_attributes( attr, &objattr, &len ))) return ret;
 
     SERVER_START_REQ( create_event )
@@ -1114,11 +466,12 @@ NTSTATUS WINAPI NtOpenEvent( HANDLE *han
 {
     unsigned int ret;
 
-    TRACE( "access %#x, name %s\n", access, attr ? debugstr_us(attr->ObjectName) : "(null)" );
-
     *handle = 0;
     if ((ret = validate_open_object_attributes( attr ))) return ret;
 
+    if (do_esync())
+        return esync_open_event( handle, access, attr );
+
     SERVER_START_REQ( open_event )
     {
         req->access     = access;
@@ -1139,12 +492,11 @@ NTSTATUS WINAPI NtOpenEvent( HANDLE *han
  */
 NTSTATUS WINAPI NtSetEvent( HANDLE handle, LONG *prev_state )
 {
+    /* This comment is a dummy to make sure this patch applies in the right place. */
     unsigned int ret;
 
-    TRACE( "handle %p, prev_state %p\n", handle, prev_state );
-
-    if ((ret = inproc_set_event( handle, prev_state )) != STATUS_NOT_IMPLEMENTED)
-        return ret;
+    if (do_esync())
+        return esync_set_event( handle );
 
     SERVER_START_REQ( event_op )
     {
@@ -1172,12 +524,12 @@ NTSTATUS WINAPI NtSetEventBoostPriority(
  */
 NTSTATUS WINAPI NtResetEvent( HANDLE handle, LONG *prev_state )
 {
+    /* This comment is a dummy to make sure this patch applies in the right place. */
     unsigned int ret;
 
-    TRACE( "handle %p, prev_state %p\n", handle, prev_state );
+    if (do_esync())
+        return esync_reset_event( handle );
 
-    if ((ret = inproc_reset_event( handle, prev_state )) != STATUS_NOT_IMPLEMENTED)
-        return ret;
 
     SERVER_START_REQ( event_op )
     {
@@ -1208,10 +560,8 @@ NTSTATUS WINAPI NtPulseEvent( HANDLE han
 {
     unsigned int ret;
 
-    TRACE( "handle %p, prev_state %p\n", handle, prev_state );
-
-    if ((ret = inproc_pulse_event( handle, prev_state )) != STATUS_NOT_IMPLEMENTED)
-        return ret;
+    if (do_esync())
+        return esync_pulse_event( handle );
 
     SERVER_START_REQ( event_op )
     {
@@ -1244,11 +594,8 @@ NTSTATUS WINAPI NtQueryEvent( HANDLE han
 
     if (len != sizeof(EVENT_BASIC_INFORMATION)) return STATUS_INFO_LENGTH_MISMATCH;
 
-    if ((ret = inproc_query_event( handle, out )) != STATUS_NOT_IMPLEMENTED)
-    {
-        if (!ret && ret_len) *ret_len = sizeof(EVENT_BASIC_INFORMATION);
-        return ret;
-    }
+    if (do_esync())
+        return esync_query_event( handle, info, ret_len );
 
     SERVER_START_REQ( query_event )
     {
@@ -1275,10 +622,11 @@ NTSTATUS WINAPI NtCreateMutant( HANDLE *
     data_size_t len;
     struct object_attributes *objattr;
 
-    TRACE( "access %#x, name %s, owned %u\n", access,
-           attr ? debugstr_us(attr->ObjectName) : "(null)", owned );
-
     *handle = 0;
+
+    if (do_esync())
+        return esync_create_mutex( handle, access, attr, owned );
+
     if ((ret = alloc_object_attributes( attr, &objattr, &len ))) return ret;
 
     SERVER_START_REQ( create_mutex )
@@ -1303,11 +651,12 @@ NTSTATUS WINAPI NtOpenMutant( HANDLE *ha
 {
     unsigned int ret;
 
-    TRACE( "access %#x, name %s\n", access, attr ? debugstr_us(attr->ObjectName) : "(null)" );
-
     *handle = 0;
     if ((ret = validate_open_object_attributes( attr ))) return ret;
 
+    if (do_esync())
+        return esync_open_mutex( handle, access, attr );
+
     SERVER_START_REQ( open_mutex )
     {
         req->access  = access;
@@ -1330,10 +679,8 @@ NTSTATUS WINAPI NtReleaseMutant( HANDLE
 {
     unsigned int ret;
 
-    TRACE( "handle %p, prev_count %p\n", handle, prev_count );
-
-    if ((ret = inproc_release_mutex( handle, prev_count )) != STATUS_NOT_IMPLEMENTED)
-        return ret;
+    if (do_esync())
+        return esync_release_mutex( handle, prev_count );
 
     SERVER_START_REQ( release_mutex )
     {
@@ -1365,11 +712,8 @@ NTSTATUS WINAPI NtQueryMutant( HANDLE ha
 
     if (len != sizeof(MUTANT_BASIC_INFORMATION)) return STATUS_INFO_LENGTH_MISMATCH;
 
-    if ((ret = inproc_query_mutex( handle, out )) != STATUS_NOT_IMPLEMENTED)
-    {
-        if (!ret && ret_len) *ret_len = sizeof(MUTANT_BASIC_INFORMATION);
-        return ret;
-    }
+    if (do_esync())
+        return esync_query_mutex( handle, info, ret_len );
 
     SERVER_START_REQ( query_mutex )
     {
@@ -2140,9 +1484,6 @@ NTSTATUS WINAPI NtCreateTimer( HANDLE *h
     data_size_t len;
     struct object_attributes *objattr;
 
-    TRACE( "access %#x, name %s, type %u\n", access,
-           attr ? debugstr_us(attr->ObjectName) : "(null)", type );
-
     *handle = 0;
     if (type != NotificationTimer && type != SynchronizationTimer) return STATUS_INVALID_PARAMETER;
     if ((ret = alloc_object_attributes( attr, &objattr, &len ))) return ret;
@@ -2170,8 +1511,6 @@ NTSTATUS WINAPI NtOpenTimer( HANDLE *han
 {
     unsigned int ret;
 
-    TRACE( "access %#x, name %s\n", access, attr ? debugstr_us(attr->ObjectName) : "(null)" );
-
     *handle = 0;
     if ((ret = validate_open_object_attributes( attr ))) return ret;
 
@@ -2225,8 +1564,6 @@ NTSTATUS WINAPI NtCancelTimer( HANDLE ha
 {
     unsigned int ret;
 
-    TRACE( "handle %p, state %p\n", handle, state );
-
     SERVER_START_REQ( cancel_timer )
     {
         req->handle = wine_server_obj_handle( handle );
@@ -2295,29 +1632,20 @@ NTSTATUS WINAPI NtWaitForMultipleObjects
 {
     union select_op select_op;
     UINT i, flags = SELECT_INTERRUPTIBLE;
-    unsigned int ret;
 
     if (!count || count > MAXIMUM_WAIT_OBJECTS) return STATUS_INVALID_PARAMETER_1;
 
-    if (TRACE_ON(sync))
-    {
-        TRACE( "wait_any %u, alertable %u, handles {%p", wait_any, alertable, handles[0] );
-        for (i = 1; i < count; i++) TRACE( ", %p", handles[i] );
-        TRACE( "}, timeout %s\n", debugstr_timeout(timeout) );
-    }
-
-    if ((ret = inproc_wait( count, handles, wait_any, alertable, timeout )) != STATUS_NOT_IMPLEMENTED)
+    if (do_esync())
     {
-        TRACE( "-> %#x\n", ret );
-        return ret;
+        NTSTATUS ret = esync_wait_objects( count, handles, wait_any, alertable, timeout );
+        if (ret != STATUS_NOT_IMPLEMENTED)
+            return ret;
     }
 
     if (alertable) flags |= SELECT_ALERTABLE;
     select_op.wait.op = wait_any ? SELECT_WAIT : SELECT_WAIT_ALL;
     for (i = 0; i < count; i++) select_op.wait.handles[i] = wine_server_obj_handle( handles[i] );
-    ret = server_wait( &select_op, offsetof( union select_op, wait.handles[count] ), flags, timeout );
-    TRACE( "-> %#x\n", ret );
-    return ret;
+    return server_wait( &select_op, offsetof( union select_op, wait.handles[count] ), flags, timeout );
 }
 
 
@@ -2338,15 +1666,12 @@ NTSTATUS WINAPI NtSignalAndWaitForSingle
 {
     union select_op select_op;
     UINT flags = SELECT_INTERRUPTIBLE;
-    NTSTATUS ret;
 
-    TRACE( "signal %p, wait %p, alertable %u, timeout %s\n", signal, wait, alertable, debugstr_timeout(timeout) );
+    if (do_esync())
+        return esync_signal_and_wait( signal, wait, alertable, timeout );
 
     if (!signal) return STATUS_INVALID_HANDLE;
 
-    if ((ret = inproc_signal_and_wait( signal, wait, alertable, timeout )) != STATUS_NOT_IMPLEMENTED)
-        return ret;
-
     if (alertable) flags |= SELECT_ALERTABLE;
     select_op.signal_and_wait.op = SELECT_SIGNAL_AND_WAIT;
     select_op.signal_and_wait.wait = wine_server_obj_handle( wait );
@@ -2589,9 +1914,6 @@ NTSTATUS WINAPI NtCreateKeyedEvent( HAND
     data_size_t len;
     struct object_attributes *objattr;
 
-    TRACE( "access %#x, name %s, flags %#x\n", access,
-           attr ? debugstr_us(attr->ObjectName) : "(null)", flags );
-
     *handle = 0;
     if ((ret = alloc_object_attributes( attr, &objattr, &len ))) return ret;
 
@@ -2616,8 +1938,6 @@ NTSTATUS WINAPI NtOpenKeyedEvent( HANDLE
 {
     unsigned int ret;
 
-    TRACE( "access %#x, name %s\n", access, attr ? debugstr_us(attr->ObjectName) : "(null)" );
-
     *handle = 0;
     if ((ret = validate_open_object_attributes( attr ))) return ret;
 
@@ -2644,8 +1964,6 @@ NTSTATUS WINAPI NtWaitForKeyedEvent( HAN
     union select_op select_op;
     UINT flags = SELECT_INTERRUPTIBLE;
 
-    TRACE( "handle %p, key %p, alertable %u, timeout %s\n", handle, key, alertable, debugstr_timeout(timeout) );
-
     if (!handle) handle = keyed_event;
     if ((ULONG_PTR)key & 1) return STATUS_INVALID_PARAMETER_1;
     if (alertable) flags |= SELECT_ALERTABLE;
@@ -2665,8 +1983,6 @@ NTSTATUS WINAPI NtReleaseKeyedEvent( HAN
     union select_op select_op;
     UINT flags = SELECT_INTERRUPTIBLE;
 
-    TRACE( "handle %p, key %p, alertable %u, timeout %s\n", handle, key, alertable, debugstr_timeout(timeout) );
-
     if (!handle) handle = keyed_event;
     if ((ULONG_PTR)key & 1) return STATUS_INVALID_PARAMETER_1;
     if (alertable) flags |= SELECT_ALERTABLE;
diff -ruN --show-c-function dlls/ntdll/unix/thread.c dlls/ntdll/unix/thread.c
--- dlls/ntdll/unix/thread.c	2025-10-21 17:44:35.924771537 -0700
+++ dlls/ntdll/unix/thread.c	2025-10-24 16:11:42.355429472 -0700
@@ -1104,7 +1104,6 @@ static void contexts_from_server( CONTEX
  */
 static DECLSPEC_NORETURN void pthread_exit_wrapper( int status )
 {
-    close( ntdll_get_thread_data()->alert_fd );
     close( ntdll_get_thread_data()->wait_fd[0] );
     close( ntdll_get_thread_data()->wait_fd[1] );
     close( ntdll_get_thread_data()->reply_fd );
@@ -1844,15 +1843,8 @@ NTSTATUS get_thread_context( HANDLE hand
 
     if (ret == STATUS_PENDING)
     {
-        sigset_t sigset;
-
         NtWaitForSingleObject( context_handle, FALSE, NULL );
 
-        server_enter_uninterrupted_section( &fd_cache_mutex, &sigset );
-
-        /* remove the handle from the cache, get_thread_context will close it for us */
-        close_inproc_sync( context_handle );
-
         SERVER_START_REQ( get_thread_context )
         {
             req->context = wine_server_obj_handle( context_handle );
@@ -1860,12 +1852,10 @@ NTSTATUS get_thread_context( HANDLE hand
             req->machine = machine;
             req->native_flags = flags & get_native_context_flags( native_machine, machine );
             wine_server_set_reply( req, server_contexts, sizeof(server_contexts) );
-            ret = server_call_unlocked( req );
+            ret = wine_server_call( req );
             count = wine_server_reply_size( reply ) / sizeof(server_contexts[0]);
         }
         SERVER_END_REQ;
-
-        server_leave_uninterrupted_section( &fd_cache_mutex, &sigset );
     }
     if (!ret && count)
     {
diff -ruN --show-c-function dlls/ntdll/unix/unix_private.h dlls/ntdll/unix/unix_private.h
--- dlls/ntdll/unix/unix_private.h	2025-10-21 17:44:35.924771537 -0700
+++ dlls/ntdll/unix/unix_private.h	2025-10-24 16:11:42.412689919 -0700
@@ -105,10 +105,10 @@ struct ntdll_thread_data
     SYSTEM_SERVICE_TABLE     *syscall_table; /* 214/0370 syscall table */
     struct syscall_frame     *syscall_frame; /* 218/0378 current syscall frame */
     int                       syscall_trace; /* 21c/0380 syscall trace flag */
+    int                       esync_apc_fd;  /* fd to wait on for user APCs */
     int                       request_fd;    /* fd for sending server requests */
     int                       reply_fd;      /* fd for receiving server replies */
     int                       wait_fd[2];    /* fd for sleeping server requests */
-    int                       alert_fd;      /* inproc sync fd for user apc alerts */
     BOOL                      allow_writes;  /* ThreadAllowWrites flags */
     pthread_t                 pthread_id;    /* pthread thread id */
     void                     *kernel_stack;  /* stack for thread startup and kernel syscalls */
@@ -198,10 +198,8 @@ extern unsigned int supported_machines_c
 extern USHORT supported_machines[8];
 extern BOOL process_exiting;
 extern HANDLE keyed_event;
-extern int inproc_device_fd;
 extern timeout_t server_start_time;
 extern sigset_t server_block_set;
-extern pthread_mutex_t fd_cache_mutex;
 extern struct _KUSER_SHARED_DATA *user_shared_data;
 
 extern void init_environment(void);
@@ -233,7 +231,6 @@ extern unsigned int server_queue_process
                                               union apc_result *result );
 extern int server_get_unix_fd( HANDLE handle, unsigned int wanted_access, int *unix_fd,
                                int *needs_close, enum server_fd_type *type, unsigned int *options );
-extern int wine_server_receive_fd( obj_handle_t *handle );
 extern void process_exit_wrapper( int status ) DECLSPEC_NORETURN;
 extern size_t server_init_process(void);
 extern void server_init_process_done(void);
@@ -389,8 +386,6 @@ extern NTSTATUS wow64_wine_spawnvp( void
 
 extern void dbg_init(void);
 
-extern void close_inproc_sync( HANDLE handle );
-
 extern NTSTATUS call_user_apc_dispatcher( CONTEXT *context_ptr, unsigned int flags, ULONG_PTR arg1, ULONG_PTR arg2,
                                           ULONG_PTR arg3, PNTAPCFUNC func, NTSTATUS status );
 extern NTSTATUS call_user_exception_dispatcher( EXCEPTION_RECORD *rec, CONTEXT *context );
@@ -399,7 +394,6 @@ extern void call_raise_user_exception_di
 #define IMAGE_DLLCHARACTERISTICS_PREFER_NATIVE 0x0010 /* Wine extension */
 
 #define TICKSPERSEC 10000000
-#define NSECPERSEC 1000000000
 #define SECS_1601_TO_1970  ((369 * 365 + 89) * (ULONGLONG)86400)
 
 static inline ULONGLONG ticks_from_time_t( time_t time )
diff -ruN --show-c-function dlls/ntdll/unix/virtual.c dlls/ntdll/unix/virtual.c
--- dlls/ntdll/unix/virtual.c	2025-10-21 17:44:35.924771537 -0700
+++ dlls/ntdll/unix/virtual.c	2025-10-24 16:11:42.412930636 -0700
@@ -4028,11 +4028,11 @@ static TEB *init_teb( void *ptr, BOOL is
     teb->StaticUnicodeString.Buffer = teb->StaticUnicodeBuffer;
     teb->StaticUnicodeString.MaximumLength = sizeof(teb->StaticUnicodeBuffer);
     thread_data = (struct ntdll_thread_data *)&teb->GdiTebBatch;
+    thread_data->esync_apc_fd = -1;
     thread_data->request_fd = -1;
     thread_data->reply_fd   = -1;
     thread_data->wait_fd[0] = -1;
     thread_data->wait_fd[1] = -1;
-    thread_data->alert_fd   = -1;
     list_add_head( &teb_list, &thread_data->entry );
     return teb;
 }
diff -ruN --show-c-function dlls/rpcrt4/rpc_server.c dlls/rpcrt4/rpc_server.c
--- dlls/rpcrt4/rpc_server.c	2025-10-21 17:44:35.967772505 -0700
+++ dlls/rpcrt4/rpc_server.c	2025-10-24 16:11:42.405955467 -0700
@@ -701,10 +701,6 @@ static DWORD CALLBACK RPCRT4_server_thre
   }
   LeaveCriticalSection(&cps->cs);
 
-  EnterCriticalSection(&listen_cs);
-  CloseHandle(cps->server_thread);
-  cps->server_thread = NULL;
-  LeaveCriticalSection(&listen_cs);
   TRACE("done\n");
   return 0;
 }
@@ -1570,7 +1566,10 @@ RPC_STATUS WINAPI RpcMgmtWaitServerListe
       LIST_FOR_EACH_ENTRY(protseq, &protseqs, RpcServerProtseq, entry)
       {
           if ((wait_thread = protseq->server_thread))
+          {
+              protseq->server_thread = NULL;
               break;
+          }
       }
       LeaveCriticalSection(&server_cs);
       if (!wait_thread)
@@ -1579,6 +1578,7 @@ RPC_STATUS WINAPI RpcMgmtWaitServerListe
       TRACE("waiting for thread %lu\n", GetThreadId(wait_thread));
       LeaveCriticalSection(&listen_cs);
       WaitForSingleObject(wait_thread, INFINITE);
+      CloseHandle(wait_thread);
       EnterCriticalSection(&listen_cs);
   }
   if (listen_done_event == event)
diff -ruN --show-c-function dlls/user32/tests/input.c dlls/user32/tests/input.c
--- dlls/user32/tests/input.c	2025-10-21 17:44:36.024773788 -0700
+++ dlls/user32/tests/input.c	2025-10-24 16:11:42.361480848 -0700
@@ -4316,8 +4316,8 @@ static void test_SendInput_mouse_message
 
     mouse_event( MOUSEEVENTF_LEFTDOWN, 0, 0, 0, 0 );
     wait_messages( 5, FALSE );
-    button_down_hwnd[1].message.hwnd = hwnd;
-    ok_seq( button_down_hwnd );
+    button_down_hwnd_todo[1].message.hwnd = hwnd;
+    ok_seq( button_down_hwnd_todo );
     mouse_event( MOUSEEVENTF_LEFTUP, 0, 0, 0, 0 );
     wait_messages( 5, FALSE );
     button_up_hwnd[1].message.hwnd = hwnd;
diff -ruN --show-c-function dlls/win32u/class.c dlls/win32u/class.c
--- dlls/win32u/class.c	2025-10-21 17:44:36.043292120 -0700
+++ dlls/win32u/class.c	2025-10-24 16:11:42.351525983 -0700
@@ -47,14 +47,19 @@ SYSTEM_BASIC_INFORMATION system_info;
 typedef struct tagCLASS
 {
     struct list  entry;         /* Entry in class list */
+    UINT         style;         /* Class style */
     BOOL         local;         /* Local class? */
     WNDPROC      winproc;       /* Window procedure */
+    INT          cbClsExtra;    /* Class extra bytes */
+    INT          cbWndExtra;    /* Window extra bytes */
     struct dce  *dce;           /* Opaque pointer to class DCE */
+    UINT_PTR     instance;      /* Module that created the task */
     HICON        hIcon;         /* Default icon */
     HICON        hIconSm;       /* Default small icon */
     HICON        hIconSmIntern; /* Internal small icon, derived from hIcon */
     HCURSOR      hCursor;       /* Default cursor */
     HBRUSH       hbrBackground; /* Default background */
+    ATOM         atom;          /* name of the class */
     struct client_menu_name menu_name; /* Default menu name */
     const shared_object_t *shared; /* class object in session shared memory */
 } CLASS;
@@ -384,25 +389,6 @@ static CLASS *get_class_ptr( HWND hwnd,
     return NULL;
 }
 
-static NTSTATUS get_shared_class( CLASS *class, struct object_lock *lock, const class_shm_t **class_shm )
-{
-    const shared_object_t *object;
-
-    TRACE( "class %p, lock %p, class_shm %p\n", class, lock, class_shm );
-
-    if (!(object = class->shared)) return STATUS_INVALID_HANDLE;
-
-    if (!lock->id || !shared_object_release_seqlock( object, lock->seq ))
-    {
-        shared_object_acquire_seqlock( object, &lock->seq );
-        *class_shm = &object->shm.class;
-        lock->id = object->id;
-        return STATUS_PENDING;
-    }
-
-    return STATUS_SUCCESS;
-}
-
 static NTSTATUS get_shared_window_class( HWND hwnd, struct object_lock *lock, const class_shm_t **class_shm )
 {
     const shared_object_t *object;
@@ -444,19 +430,6 @@ static BOOL class_name_matches( CLASS *c
     return name->Length == len && !wcsnicmp( class_name, name->Buffer, len / sizeof(WCHAR) );
 }
 
-static UINT_PTR get_class_instance( CLASS *class )
-{
-    struct object_lock lock = OBJECT_LOCK_INIT;
-    const class_shm_t *class_shm;
-    UINT_PTR instance = 0;
-    NTSTATUS status;
-
-    while ((status = get_shared_class( class, &lock, &class_shm )) == STATUS_PENDING)
-        instance = class_shm->instance;
-    if (status) return 0;
-    return instance;
-}
-
 static CLASS *find_class( HINSTANCE module, UNICODE_STRING *name )
 {
     ULONG_PTR instance = (UINT_PTR)module;
@@ -466,11 +439,10 @@ static CLASS *find_class( HINSTANCE modu
     user_lock();
     LIST_FOR_EACH_ENTRY( class, &class_list, CLASS, entry )
     {
-        UINT_PTR class_instance = get_class_instance( class );
         if (!class_name_matches( class, name )) continue;
-        is_win16 = !(class_instance >> 16);
-        if (!instance || !class->local || class_instance == instance ||
-            (!is_win16 && ((class_instance & ~0xffff) == (instance & ~0xffff))))
+        is_win16 = !(class->instance >> 16);
+        if (!instance || !class->local || class->instance == instance ||
+            (!is_win16 && ((class->instance & ~0xffff) == (instance & ~0xffff))))
         {
             TRACE( "%s %lx -> %p\n", debugstr_us(name), instance, class );
             return class;
@@ -543,17 +515,21 @@ ATOM WINAPI NtUserRegisterClassExWOW( co
     if (wc->cbWndExtra > 40)  /* Extra bytes are limited to 40 in Win32 */
         WARN("Win extra bytes %d is > 40\n", wc->cbWndExtra );
 
-    if (!(class = calloc( 1, sizeof(*class) ))) return 0;
+    if (!(class = calloc( 1, sizeof(CLASS) + wc->cbClsExtra ))) return 0;
 
+    class->style      = wc->style;
     class->local      = !is_builtin && !(wc->style & CS_GLOBALCLASS);
+    class->cbWndExtra = wc->cbWndExtra;
+    class->cbClsExtra = wc->cbClsExtra;
+    class->instance   = (UINT_PTR)instance;
 
     SERVER_START_REQ( create_class )
     {
         req->local      = class->local;
-        req->style      = wc->style;
-        req->instance   = wine_server_client_ptr( instance );
-        req->cls_extra  = wc->cbClsExtra;
-        req->win_extra  = wc->cbWndExtra;
+        req->style      = class->style;
+        req->instance   = class->instance;
+        req->extra      = class->cbClsExtra;
+        req->win_extra  = class->cbWndExtra;
         req->client_ptr = wine_server_client_ptr( class );
         req->atom       = wine_server_add_atom( req, name );
         req->name_offset = version->Length / sizeof(WCHAR);
@@ -602,6 +578,7 @@ ATOM WINAPI NtUserRegisterClassExWOW( co
     class->hIconSmIntern = sm_icon;
     class->hCursor       = wc->hCursor;
     class->hbrBackground = wc->hbrBackground;
+    class->atom          = atom;
     class->winproc       = alloc_winproc( wc->lpfnWndProc, ansi );
     if (client_menu_name) class->menu_name = *client_menu_name;
     class->shared        = shared;
@@ -649,38 +626,31 @@ BOOL WINAPI NtUserUnregisterClass( UNICO
 ATOM WINAPI NtUserGetClassInfoEx( HINSTANCE instance, UNICODE_STRING *name, WNDCLASSEXW *wc,
                                   struct client_menu_name *menu_name, BOOL ansi )
 {
-    struct object_lock lock = OBJECT_LOCK_INIT;
-    const class_shm_t *class_shm;
-    NTSTATUS status;
     CLASS *class;
-    ATOM atom = 0;
+    ATOM atom;
 
     /* create the desktop window to trigger builtin class registration */
     if (!is_desktop_class( name ) && !is_message_class( name )) get_desktop_window();
 
     if (!(class = find_class( instance, name ))) return 0;
 
-    while ((status = get_shared_class( class, &lock, &class_shm )) == STATUS_PENDING)
+    if (wc)
     {
-        if (wc)
-        {
-            wc->style         = class_shm->style;
-            wc->lpfnWndProc   = get_winproc( class->winproc, ansi );
-            wc->cbClsExtra    = class_shm->cls_extra;
-            wc->cbWndExtra    = class_shm->win_extra;
-            wc->hInstance     = (instance == user32_module) ? 0 : instance;
-            wc->hIcon         = class->hIcon;
-            wc->hIconSm       = class->hIconSm ? class->hIconSm : class->hIconSmIntern;
-            wc->hCursor       = class->hCursor;
-            wc->hbrBackground = class->hbrBackground;
-            wc->lpszMenuName  = ansi ? (const WCHAR *)class->menu_name.nameA : class->menu_name.nameW;
-            wc->lpszClassName = name->Buffer;
-        }
-        atom = class_shm->atom;
+        wc->style         = class->style;
+        wc->lpfnWndProc   = get_winproc( class->winproc, ansi );
+        wc->cbClsExtra    = class->cbClsExtra;
+        wc->cbWndExtra    = class->cbWndExtra;
+        wc->hInstance     = (instance == user32_module) ? 0 : instance;
+        wc->hIcon         = class->hIcon;
+        wc->hIconSm       = class->hIconSm ? class->hIconSm : class->hIconSmIntern;
+        wc->hCursor       = class->hCursor;
+        wc->hbrBackground = class->hbrBackground;
+        wc->lpszMenuName  = ansi ? (const WCHAR *)class->menu_name.nameA : class->menu_name.nameW;
+        wc->lpszClassName = name->Buffer;
     }
-    if (status) return 0;
 
     if (menu_name) *menu_name = class->menu_name;
+    atom = class->atom;
     release_class_ptr( class );
     return atom;
 }
@@ -797,7 +767,7 @@ INT WINAPI NtUserGetClassName( HWND hwnd
 }
 
 /* Set class info with the wine server. */
-static BOOL set_server_info( HWND hwnd, INT offset, LONG_PTR newval, UINT size, ULONG_PTR *oldval )
+static BOOL set_server_info( HWND hwnd, INT offset, LONG_PTR newval, UINT size )
 {
     BOOL ret;
 
@@ -808,7 +778,6 @@ static BOOL set_server_info( HWND hwnd,
         req->size = size;
         req->new_info = newval;
         ret = !wine_server_call_err( req );
-        *oldval = reply->old_info;
     }
     SERVER_END_REQ;
     return ret;
@@ -822,7 +791,16 @@ static ULONG_PTR set_class_long_size( HW
 
     if (!(class = get_class_ptr( hwnd, TRUE ))) return 0;
 
-    switch(offset)
+    if (offset >= 0)
+    {
+        if (set_server_info( hwnd, offset, newval, size ))
+        {
+            void *ptr = (char *)(class + 1) + offset;
+            memcpy( &retval, ptr, size );
+            memcpy( ptr, &newval, size );
+        }
+    }
+    else switch(offset)
     {
     case GCLP_MENUNAME:
         {
@@ -905,20 +883,25 @@ static ULONG_PTR set_class_long_size( HW
         class->hIconSmIntern = small_icon;
         break;
     case GCL_STYLE:
-        if (!set_server_info( hwnd, offset, newval, size, &retval )) break;
+        if (!set_server_info( hwnd, offset, newval, size )) break;
+        retval = class->style;
+        class->style = newval;
         break;
     case GCL_CBWNDEXTRA:
-        if (!set_server_info( hwnd, offset, newval, size, &retval )) break;
+        if (!set_server_info( hwnd, offset, newval, size )) break;
+        retval = class->cbWndExtra;
+        class->cbWndExtra = newval;
         break;
     case GCLP_HMODULE:
-        if (!set_server_info( hwnd, offset, newval, size, &retval )) break;
+        if (!set_server_info( hwnd, offset, newval, size )) break;
+        retval = class->instance;
+        class->instance = newval;
         break;
     case GCL_CBCLSEXTRA:  /* cannot change this one */
         RtlSetLastWin32Error( ERROR_INVALID_PARAMETER );
         break;
     default:
-        if (offset >= 0) set_server_info( hwnd, offset, newval, size, &retval );
-        else RtlSetLastWin32Error( ERROR_INVALID_INDEX );
+        RtlSetLastWin32Error( ERROR_INVALID_INDEX );
         break;
     }
     release_class_ptr( class );
@@ -949,62 +932,11 @@ WORD WINAPI NtUserSetClassWord( HWND hwn
     return set_class_long_size( hwnd, offset, newval, sizeof(WORD), TRUE );
 }
 
-static ULONG_PTR get_class_long_shm( HWND hwnd, INT offset, UINT size, BOOL ansi )
-{
-    struct object_lock lock = OBJECT_LOCK_INIT;
-    const class_shm_t *class_shm;
-    ULONG_PTR ret = 0;
-    BOOL valid = TRUE;
-    NTSTATUS status;
-
-    while ((status = get_shared_window_class( hwnd, &lock, &class_shm )) == STATUS_PENDING)
-    {
-        switch (offset)
-        {
-        case GCW_ATOM:           ret = class_shm->atom; break;
-        case GCL_STYLE:          ret = class_shm->style; break;
-        case GCL_CBCLSEXTRA:     ret = class_shm->cls_extra; break;
-        case GCL_CBWNDEXTRA:     ret = class_shm->win_extra; break;
-        case GCLP_HMODULE:       ret = class_shm->instance; break;
-        default:
-            valid = offset >= 0 && offset <= (INT)(class_shm->cls_extra - size);
-            if (valid) memcpy( &ret, (char *)class_shm->extra + offset, size );
-            break;
-        }
-    }
-    if (status)
-    {
-        RtlSetLastWin32Error( ERROR_INVALID_WINDOW_HANDLE );
-        return 0;
-    }
-    if (!valid)
-    {
-        WARN( "Invalid window %p offset %d size %u\n", hwnd, offset, size );
-        RtlSetLastWin32Error( ERROR_INVALID_INDEX );
-        return 0;
-    }
-
-    return ret;
-}
-
 static ULONG_PTR get_class_long_size( HWND hwnd, INT offset, UINT size, BOOL ansi )
 {
     CLASS *class;
     ULONG_PTR retvalue = 0;
 
-    switch (offset)
-    {
-    case GCLP_HICONSM:
-    case GCLP_WNDPROC:
-    case GCLP_HICON:
-    case GCLP_HCURSOR:
-    case GCLP_HBRBACKGROUND:
-    case GCLP_MENUNAME:
-        break;
-    default:
-        return get_class_long_shm( hwnd, offset, size, ansi );
-    }
-
     if (!(class = get_class_ptr( hwnd, FALSE ))) return 0;
 
     if (class == OBJ_OTHER_PROCESS)
@@ -1036,6 +968,25 @@ static ULONG_PTR get_class_long_size( HW
         return retvalue;
     }
 
+    if (offset >= 0)
+    {
+        if (offset <= class->cbClsExtra - size)
+        {
+            if (size == sizeof(DWORD))
+            {
+                DWORD retdword;
+                memcpy( &retdword, (char *)(class + 1) + offset, sizeof(DWORD) );
+                retvalue = retdword;
+            }
+            else
+                memcpy( &retvalue, (char *)(class + 1) + offset, sizeof(ULONG_PTR) );
+        }
+        else
+            RtlSetLastWin32Error( ERROR_INVALID_INDEX );
+        release_class_ptr( class );
+        return retvalue;
+    }
+
     switch(offset)
     {
     case GCLP_HBRBACKGROUND:
@@ -1050,12 +1001,27 @@ static ULONG_PTR get_class_long_size( HW
     case GCLP_HICONSM:
         retvalue = (ULONG_PTR)(class->hIconSm ? class->hIconSm : class->hIconSmIntern);
         break;
+    case GCL_STYLE:
+        retvalue = class->style;
+        break;
+    case GCL_CBWNDEXTRA:
+        retvalue = class->cbWndExtra;
+        break;
+    case GCL_CBCLSEXTRA:
+        retvalue = class->cbClsExtra;
+        break;
+    case GCLP_HMODULE:
+        retvalue = class->instance;
+        break;
     case GCLP_WNDPROC:
         retvalue = (ULONG_PTR)get_winproc( class->winproc, ansi );
         break;
     case GCLP_MENUNAME:
         retvalue = ansi ? (ULONG_PTR)class->menu_name.nameA : (ULONG_PTR)class->menu_name.nameW;
         break;
+    case GCW_ATOM:
+        retvalue = class->atom;
+        break;
     default:
         RtlSetLastWin32Error( ERROR_INVALID_INDEX );
         break;
diff -ruN --show-c-function dlls/win32u/dce.c dlls/win32u/dce.c
--- dlls/win32u/dce.c	2025-10-21 17:44:36.800791257 -0700
+++ dlls/win32u/dce.c	2025-10-24 16:11:42.365244713 -0700
@@ -1803,7 +1803,7 @@ BOOL WINAPI NtUserRedrawWindow( HWND hwn
     }
 
     /* process pending expose events before painting */
-    if (flags & RDW_UPDATENOW) process_driver_events( QS_PAINT );
+    if (flags & RDW_UPDATENOW) user_driver->pProcessEvents( QS_PAINT );
 
     if (rect && !hrgn)
     {
diff -ruN --show-c-function dlls/win32u/hook.c dlls/win32u/hook.c
--- dlls/win32u/hook.c	2025-10-21 17:44:36.044774238 -0700
+++ dlls/win32u/hook.c	2025-10-24 16:11:42.369127903 -0700
@@ -31,7 +31,9 @@
 
 WINE_DEFAULT_DEBUG_CHANNEL(hook);
 
-static const char * const hook_names[NB_HOOKS] =
+#define WH_WINEVENT (WH_MAXHOOK+1)
+
+static const char * const hook_names[WH_WINEVENT - WH_MINHOOK + 1] =
 {
     "WH_MSGFILTER",
     "WH_JOURNALRECORD",
diff -ruN --show-c-function dlls/win32u/input.c dlls/win32u/input.c
--- dlls/win32u/input.c	2025-10-21 17:44:36.044774238 -0700
+++ dlls/win32u/input.c	2025-10-24 16:11:42.365426668 -0700
@@ -787,6 +787,21 @@ BOOL WINAPI NtUserGetCursorInfo( CURSORI
     return TRUE;
 }
 
+static void check_for_events( UINT flags )
+{
+    struct peek_message_filter filter =
+    {
+        .internal = TRUE,
+        .flags = PM_REMOVE,
+    };
+    MSG msg;
+
+    if (!user_driver->pProcessEvents( flags ))
+        flush_window_surfaces( TRUE );
+
+    peek_message( &msg, &filter );
+}
+
 /**********************************************************************
  *           GetAsyncKeyState (win32u.@)
  */
diff -ruN --show-c-function dlls/win32u/message.c dlls/win32u/message.c
--- dlls/win32u/message.c	2025-10-21 17:44:36.801791279 -0700
+++ dlls/win32u/message.c	2025-10-24 16:11:42.371306619 -0700
@@ -27,8 +27,6 @@
 #include <assert.h>
 #include "ntstatus.h"
 #define WIN32_NO_STATUS
-#include "winternl.h"
-#include "ddk/wdm.h"
 #include "win32u_private.h"
 #include "ntuser_private.h"
 #include "winnls.h"
@@ -42,44 +40,6 @@ WINE_DEFAULT_DEBUG_CHANNEL(msg);
 WINE_DECLARE_DEBUG_CHANNEL(key);
 WINE_DECLARE_DEBUG_CHANNEL(relay);
 
-#define QS_DRIVER       0x80000000
-#define QS_HARDWARE     0x40000000
-#define QS_INTERNAL     (QS_DRIVER | QS_HARDWARE)
-
-static const struct _KUSER_SHARED_DATA *user_shared_data = (struct _KUSER_SHARED_DATA *)0x7ffe0000;
-
-static LONG atomic_load_long( const volatile LONG *ptr )
-{
-#if defined(__i386__) || defined(__x86_64__)
-    return *ptr;
-#else
-    return __atomic_load_n( ptr, __ATOMIC_SEQ_CST );
-#endif
-}
-
-static ULONG atomic_load_ulong( const volatile ULONG *ptr )
-{
-#if defined(__i386__) || defined(__x86_64__)
-    return *ptr;
-#else
-    return __atomic_load_n( ptr, __ATOMIC_SEQ_CST );
-#endif
-}
-
-static UINT64 get_tick_count(void)
-{
-    ULONG high, low;
-
-    do
-    {
-        high = atomic_load_long( &user_shared_data->TickCount.High1Time );
-        low = atomic_load_ulong( &user_shared_data->TickCount.LowPart );
-    }
-    while (high != atomic_load_long( &user_shared_data->TickCount.High2Time ));
-    /* note: we ignore TickCountMultiplier */
-    return (UINT64)high << 32 | low;
-}
-
 #define MAX_WINPROC_RECURSION  64
 
 #define WM_NCMOUSEFIRST WM_NCMOUSEMOVE
@@ -87,16 +47,6 @@ static UINT64 get_tick_count(void)
 
 #define MAX_PACK_COUNT 4
 
-struct peek_message_filter
-{
-    HWND hwnd;
-    UINT first;
-    UINT last;
-    UINT mask;
-    UINT flags;
-    BOOL internal;
-};
-
 /* info about the message currently being received by the current thread */
 struct received_message_info
 {
@@ -2809,7 +2759,7 @@ static BOOL process_hardware_message( MS
  * returns FALSE if we need to make a server request to update the queue masks or bits
  */
 static BOOL check_queue_bits( UINT wake_mask, UINT changed_mask, UINT signal_bits, UINT clear_bits,
-                              UINT *wake_bits, UINT *changed_bits, BOOL internal )
+                              UINT *wake_bits, UINT *changed_bits )
 {
     struct object_lock lock = OBJECT_LOCK_INIT;
     const queue_shm_t *queue_shm;
@@ -2818,9 +2768,8 @@ static BOOL check_queue_bits( UINT wake_
 
     while ((status = get_shared_queue( &lock, &queue_shm )) == STATUS_PENDING)
     {
-        if (internal) skip = !(queue_shm->internal_bits & QS_HARDWARE);
         /* if the masks need an update */
-        else if (queue_shm->wake_mask != wake_mask) skip = FALSE;
+        if (queue_shm->wake_mask != wake_mask) skip = FALSE;
         else if (queue_shm->changed_mask != changed_mask) skip = FALSE;
         /* or if some bits need to be cleared, or queue is signaled */
         else if (queue_shm->wake_bits & signal_bits) skip = FALSE;
@@ -2829,7 +2778,7 @@ static BOOL check_queue_bits( UINT wake_
         {
             *wake_bits = queue_shm->wake_bits;
             *changed_bits = queue_shm->changed_bits;
-            skip = get_tick_count() - (UINT64)queue_shm->access_time / 10000 < 3000; /* avoid hung queue */
+            skip = TRUE;
         }
     }
 
@@ -2844,7 +2793,7 @@ static BOOL check_queue_bits( UINT wake_
  * available; -1 on error.
  * All pending sent messages are processed before returning.
  */
-static int peek_message( MSG *msg, const struct peek_message_filter *filter )
+int peek_message( MSG *msg, const struct peek_message_filter *filter )
 {
     LRESULT result;
     HWND hwnd = filter->hwnd;
@@ -2884,8 +2833,9 @@ static int peek_message( MSG *msg, const
         thread_info->client_info.msg_source = prev_source;
         wake_mask = filter->mask & (QS_SENDMESSAGE | QS_SMRESULT);
 
-        if (check_queue_bits( wake_mask, filter->mask, wake_mask | signal_bits, filter->mask | clear_bits,
-                              &wake_bits, &changed_bits, filter->internal ))
+        if (NtGetTickCount() - thread_info->last_getmsg_time < 3000 && /* avoid hung queue */
+            check_queue_bits( wake_mask, filter->mask, wake_mask | signal_bits, filter->mask | clear_bits,
+                              &wake_bits, &changed_bits ))
             res = STATUS_PENDING;
         else SERVER_START_REQ( get_message )
         {
@@ -2898,6 +2848,7 @@ static int peek_message( MSG *msg, const
             req->wake_mask = wake_mask;
             req->changed_mask = filter->mask;
             wine_server_set_reply( req, buffer, buffer_size );
+            thread_info->last_getmsg_time = NtGetTickCount();
             if (!(res = wine_server_call( req )))
             {
                 size = wine_server_reply_size( reply );
@@ -3180,64 +3131,6 @@ static HANDLE get_server_queue_handle(vo
     return ret;
 }
 
-static BOOL is_queue_signaled(void)
-{
-    struct object_lock lock = OBJECT_LOCK_INIT;
-    const queue_shm_t *queue_shm;
-    BOOL signaled = FALSE;
-    UINT status;
-
-    while ((status = get_shared_queue( &lock, &queue_shm )) == STATUS_PENDING)
-        signaled = (queue_shm->wake_bits & queue_shm->wake_mask) ||
-                   (queue_shm->changed_bits & queue_shm->changed_mask);
-    if (status) return FALSE;
-
-    return signaled;
-}
-
-static BOOL check_internal_bits( UINT mask )
-{
-    struct object_lock lock = OBJECT_LOCK_INIT;
-    const queue_shm_t *queue_shm;
-    BOOL signaled = FALSE;
-    UINT status;
-
-    while ((status = get_shared_queue( &lock, &queue_shm )) == STATUS_PENDING)
-        signaled = queue_shm->internal_bits & mask;
-    if (status) return FALSE;
-
-    return signaled;
-}
-
-BOOL process_driver_events( UINT mask )
-{
-    if (check_internal_bits( QS_DRIVER ) && user_driver->pProcessEvents( mask ))
-    {
-        SERVER_START_REQ( set_queue_mask )
-        {
-            req->poll_events = 1;
-            wine_server_call( req );
-        }
-        SERVER_END_REQ;
-    }
-
-    /* process every pending internal hardware messages */
-    if (check_internal_bits( QS_HARDWARE ))
-    {
-        struct peek_message_filter filter = {.internal = TRUE};
-        MSG msg;
-        peek_message( &msg, &filter );
-    }
-
-    /* check for hardware messages requiring client dispatch */
-    return check_internal_bits( QS_HARDWARE );
-}
-
-void check_for_events( UINT flags )
-{
-    if (!process_driver_events( flags )) flush_window_surfaces( TRUE );
-}
-
 /* monotonic timer tick for throttling driver event checks */
 static inline LONGLONG get_driver_check_time(void)
 {
@@ -3252,7 +3145,7 @@ static inline void check_for_driver_even
     if (get_user_thread_info()->last_driver_time != get_driver_check_time())
     {
         flush_window_surfaces( FALSE );
-        process_driver_events( QS_ALLINPUT );
+        user_driver->pProcessEvents( QS_ALLINPUT );
         get_user_thread_info()->last_driver_time = get_driver_check_time();
     }
 }
@@ -3269,16 +3162,10 @@ static inline LARGE_INTEGER *get_nt_time
 static DWORD wait_message( DWORD count, const HANDLE *handles, DWORD timeout, DWORD mask, DWORD flags )
 {
     struct thunk_lock_params params = {.dispatch.callback = thunk_lock_callback};
-    LARGE_INTEGER time, now, *abs;
+    LARGE_INTEGER time;
+    DWORD ret;
     void *ret_ptr;
     ULONG ret_len;
-    DWORD ret;
-
-    if ((abs = get_nt_timeout( &time, timeout )))
-    {
-        NtQuerySystemTime( &now );
-        abs->QuadPart = now.QuadPart - abs->QuadPart;
-    }
 
     if (!KeUserDispatchCallback( &params.dispatch, sizeof(params), &ret_ptr, &ret_len ) &&
         ret_len == sizeof(params.locks))
@@ -3287,16 +3174,17 @@ static DWORD wait_message( DWORD count,
         params.restore = TRUE;
     }
 
-    if (process_driver_events( QS_ALLINPUT )) ret = count - 1;
+    if (user_driver->pProcessEvents( mask )) ret = count - 1;
     else
     {
-        do ret = NtWaitForMultipleObjects( count, handles, !(flags & MWMO_WAITALL), !!(flags & MWMO_ALERTABLE), abs );
-        while (ret == count - 1 && !process_driver_events( QS_ALLINPUT ) && !is_queue_signaled());
-    }
-    if (HIWORD(ret)) /* is it an error code? */
-    {
-        RtlSetLastWin32Error( RtlNtStatusToDosError(ret) );
-        ret = WAIT_FAILED;
+        ret = NtWaitForMultipleObjects( count, handles, !(flags & MWMO_WAITALL),
+                                        !!(flags & MWMO_ALERTABLE), get_nt_timeout( &time, timeout ));
+        if (ret == count - 1) user_driver->pProcessEvents( mask );
+        else if (HIWORD(ret)) /* is it an error code? */
+        {
+            RtlSetLastWin32Error( RtlNtStatusToDosError(ret) );
+            ret = WAIT_FAILED;
+        }
     }
 
     if (ret == WAIT_TIMEOUT && !count && !timeout) NtYieldExecution();
@@ -3318,10 +3206,7 @@ static BOOL check_queue_masks( UINT wake
     UINT status;
 
     while ((status = get_shared_queue( &lock, &queue_shm )) == STATUS_PENDING)
-    {
-        if (queue_shm->wake_mask != wake_mask || queue_shm->changed_mask != changed_mask) skip = FALSE;
-        else skip = get_tick_count() - (UINT64)queue_shm->access_time / 10000 < 3000; /* avoid hung queue */
-    }
+        skip = queue_shm->wake_mask == wake_mask && queue_shm->changed_mask == changed_mask;
 
     if (status) return FALSE;
     return skip;
@@ -3345,6 +3230,7 @@ static DWORD wait_objects( DWORD count,
         {
             req->wake_mask    = wake_mask;
             req->changed_mask = changed_mask;
+            req->skip_wait    = 0;
             wine_server_call( req );
         }
         SERVER_END_REQ;
@@ -3659,12 +3545,13 @@ static void wait_message_reply( UINT fla
         UINT wake_bits, changed_bits;
 
         if (check_queue_bits( wake_mask, wake_mask, wake_mask, wake_mask,
-                              &wake_bits, &changed_bits, FALSE ))
+                              &wake_bits, &changed_bits ))
             wake_bits = wake_bits & wake_mask;
         else SERVER_START_REQ( set_queue_mask )
         {
             req->wake_mask    = wake_mask;
             req->changed_mask = wake_mask;
+            req->skip_wait    = 1;
             wine_server_call( req );
             wake_bits = reply->wake_bits & wake_mask;
         }
diff -ruN --show-c-function dlls/win32u/ntuser_private.h dlls/win32u/ntuser_private.h
--- dlls/win32u/ntuser_private.h	2025-10-21 17:44:36.801791279 -0700
+++ dlls/win32u/ntuser_private.h	2025-10-24 16:11:42.369713054 -0700
@@ -112,6 +112,7 @@ struct user_thread_info
 {
     struct ntuser_thread_info     client_info;            /* Data shared with client */
     HANDLE                        server_queue;           /* Handle to server-side queue */
+    DWORD                         last_getmsg_time;       /* Get/PeekMessage last request time */
     LONGLONG                      last_driver_time;       /* Get/PeekMessage driver event time */
     WORD                          hook_call_depth;        /* Number of recursively called hook procs */
     WORD                          hook_unicode;           /* Is current hook unicode? */
@@ -212,8 +213,17 @@ extern void free_dce( struct dce *dce, H
 extern void invalidate_dce( WND *win, const RECT *old_rect );
 
 /* message.c */
-extern BOOL process_driver_events( UINT mask );
-extern void check_for_events( UINT flags );
+struct peek_message_filter
+{
+    HWND hwnd;
+    UINT first;
+    UINT last;
+    UINT mask;
+    UINT flags;
+    BOOL internal;
+};
+
+extern int peek_message( MSG *msg, const struct peek_message_filter *filter );
 
 /* systray.c */
 extern LRESULT system_tray_call( HWND hwnd, UINT msg, WPARAM wparam, LPARAM lparam, void *data );
diff -ruN --show-c-function dlls/wineandroid.drv/window.c dlls/wineandroid.drv/window.c
--- dlls/wineandroid.drv/window.c	2025-10-21 17:44:36.064774689 -0700
+++ dlls/wineandroid.drv/window.c	2025-10-24 16:11:42.362590865 -0700
@@ -391,19 +391,13 @@ static void pull_events(void)
 }
 
 
-static int check_fd_events( int fd, int events )
-{
-    struct pollfd pfd = {.fd = fd, .events = events};
-    if (poll( &pfd, 1, 0 ) <= 0) return 0;
-    return pfd.revents;
-}
-
 /***********************************************************************
  *           process_events
  */
 static int process_events( DWORD mask )
 {
     struct java_event *event, *next, *previous;
+    unsigned int count = 0;
 
     assert( GetCurrentThreadId() == desktop_tid );
 
@@ -511,11 +505,12 @@ static int process_events( DWORD mask )
             FIXME( "got event %u\n", event->data.type );
         }
         free( event );
+        count++;
         /* next may have been removed by a recursive call, so reset it to the beginning of the list */
         next = LIST_ENTRY( event_queue.next, struct java_event, entry );
     }
     current_event = previous;
-    return !check_fd_events( event_pipe[0], POLLIN );
+    return count;
 }
 
 
diff -ruN --show-c-function dlls/winemac.drv/event.c dlls/winemac.drv/event.c
--- dlls/winemac.drv/event.c	2025-10-21 17:44:36.077774981 -0700
+++ dlls/winemac.drv/event.c	2025-10-24 16:11:42.362703188 -0700
@@ -26,8 +26,6 @@
 
 #include "config.h"
 
-#include <poll.h>
-
 #include "ntstatus.h"
 #define WIN32_NO_STATUS
 #include "macdrv.h"
@@ -528,13 +526,25 @@ void macdrv_handle_event(const macdrv_ev
 }
 
 
-static int check_fd_events( int fd, int events )
+/***********************************************************************
+ *              process_events
+ */
+static int process_events(macdrv_event_queue queue, macdrv_event_mask mask)
 {
-    struct pollfd pfd = {.fd = fd, .events = events};
-    if (poll( &pfd, 1, 0 ) <= 0) return 0;
-    return pfd.revents;
+    macdrv_event *event;
+    int count = 0;
+
+    while (macdrv_copy_event_from_queue(queue, mask, &event))
+    {
+        count++;
+        macdrv_handle_event(event);
+        macdrv_release_event(event);
+    }
+    if (count) TRACE("processed %d events\n", count);
+    return count;
 }
 
+
 /***********************************************************************
  *              ProcessEvents   (MACDRV.@)
  */
@@ -542,8 +552,6 @@ BOOL macdrv_ProcessEvents(DWORD mask)
 {
     struct macdrv_thread_data *data = macdrv_thread_data();
     macdrv_event_mask event_mask = get_event_mask(mask);
-    macdrv_event *event;
-    int count = 0;
 
     TRACE("mask %x\n", mask);
 
@@ -555,13 +563,5 @@ BOOL macdrv_ProcessEvents(DWORD mask)
         data->current_event->type != WINDOW_DRAG_BEGIN)
         event_mask = 0;  /* don't process nested events */
 
-    while (macdrv_copy_event_from_queue(data->queue, event_mask, &event))
-    {
-        count++;
-        macdrv_handle_event(event);
-        macdrv_release_event(event);
-    }
-
-    if (count) TRACE("processed %d events\n", count);
-    return !check_fd_events(macdrv_get_event_queue_fd(data->queue), POLLIN);
+    return process_events(data->queue, event_mask);
 }
diff -ruN --show-c-function dlls/winex11.drv/event.c dlls/winex11.drv/event.c
--- dlls/winex11.drv/event.c	2025-10-21 17:44:36.089230439 -0700
+++ dlls/winex11.drv/event.c	2025-10-24 16:11:42.362808589 -0700
@@ -258,6 +258,7 @@ static void xembed_request_focus( Displa
     xev.xclient.data.l[4] = 0;
 
     XSendEvent(display, window, False, NoEventMask, &xev);
+    XFlush( display );
 }
 
 /***********************************************************************
@@ -463,28 +464,19 @@ static inline BOOL call_event_handler( D
     return ret;
 }
 
-static int check_fd_events( int fd, int events )
-{
-    struct pollfd pfd = {.fd = fd, .events = events};
-    if (poll( &pfd, 1, 0 ) <= 0) return 0;
-    return pfd.revents;
-}
 
 /***********************************************************************
- *           ProcessEvents   (X11DRV.@)
+ *           process_events
  */
-BOOL X11DRV_ProcessEvents( DWORD mask )
+static BOOL process_events( Display *display, Bool (*filter)(Display*, XEvent*,XPointer), ULONG_PTR arg )
 {
-    struct x11drv_thread_data *data = x11drv_thread_data();
     XEvent event, prev_event;
     int count = 0;
+    BOOL queued = FALSE;
     enum event_merge_action action = MERGE_DISCARD;
 
-    if (!data) return FALSE;
-    if (data->current_event) mask = 0;  /* don't process nested events */
-
     prev_event.type = 0;
-    while (XCheckIfEvent( data->display, &event, filter_event, (XPointer)(UINT_PTR)mask ))
+    while (XCheckIfEvent( display, &event, filter, (char *)arg ))
     {
         count++;
         if (XFilterEvent( &event, None ))
@@ -525,32 +517,42 @@ BOOL X11DRV_ProcessEvents( DWORD mask )
         switch( action )
         {
         case MERGE_HANDLE:  /* handle prev, keep new */
-            call_event_handler( data->display, &prev_event );
+            queued |= call_event_handler( display, &prev_event );
             /* fall through */
         case MERGE_DISCARD:  /* discard prev, keep new */
             free_event_data( &prev_event );
             prev_event = event;
             break;
         case MERGE_KEEP:  /* handle new, keep prev for future merging */
-            call_event_handler( data->display, &event );
+            queued |= call_event_handler( display, &event );
             /* fall through */
         case MERGE_IGNORE: /* ignore new, keep prev for future merging */
             free_event_data( &event );
             break;
         }
     }
-    if (prev_event.type) call_event_handler( data->display, &prev_event );
+    if (prev_event.type) queued |= call_event_handler( display, &prev_event );
     free_event_data( &prev_event );
     XFlush( gdi_display );
-    if (count) TRACE( "processed %d events\n", count );
-
-    if (check_fd_events( ConnectionNumber( data->display ), POLLIN )) return FALSE;
-    XFlush( data->display ); /* all events have been processed, flush any pending request */
-    return TRUE;
+    if (count) TRACE( "processed %d events, returning %d\n", count, queued );
+    return queued;
 }
 
 
 /***********************************************************************
+ *           ProcessEvents   (X11DRV.@)
+ */
+BOOL X11DRV_ProcessEvents( DWORD mask )
+{
+    struct x11drv_thread_data *data = x11drv_thread_data();
+
+    if (!data) return FALSE;
+    if (data->current_event) mask = 0;  /* don't process nested events */
+
+    return process_events( data->display, filter_event, mask );
+}
+
+/***********************************************************************
  *           EVENT_x11_time_to_win32_time
  *
  * Make our timer and the X timer line up as best we can
diff -ruN --show-c-function dlls/winex11.drv/window.c dlls/winex11.drv/window.c
--- dlls/winex11.drv/window.c	2025-10-21 17:44:36.089775251 -0700
+++ dlls/winex11.drv/window.c	2025-10-24 16:11:42.351290897 -0700
@@ -1292,6 +1292,8 @@ static void window_set_net_wm_state( str
                         SubstructureRedirectMask | SubstructureNotifyMask, &xev );
         }
     }
+
+    XFlush( data->display );
 }
 
 static void window_set_config( struct x11drv_win_data *data, RECT rect, BOOL above )
@@ -1539,6 +1541,8 @@ static void window_set_wm_state( struct
 
     /* override redirect windows won't receive WM_STATE property changes */
     if (!data->managed) data->wm_state_serial = 0;
+
+    XFlush( data->display );
 }
 
 static void window_set_managed( struct x11drv_win_data *data, BOOL new_managed )
@@ -1926,6 +1930,7 @@ void set_net_active_window( HWND hwnd, H
     TRACE( "requesting _NET_ACTIVE_WINDOW %p/%lx serial %lu\n", hwnd, window, data->net_active_window_serial );
     XSendEvent( data->display, DefaultRootWindow( data->display ), False,
                 SubstructureRedirectMask | SubstructureNotifyMask, &xev );
+    XFlush( data->display );
 }
 
 BOOL window_is_reparenting( HWND hwnd )
diff -ruN --show-c-function include/config.h.in include/config.h.in
--- include/config.h.in	2025-10-21 17:44:46.934069872 -0700
+++ include/config.h.in	2025-10-24 16:11:50.703485250 -0700
@@ -201,9 +201,6 @@
 /* Define to 1 if you have the <linux/major.h> header file. */
 #undef HAVE_LINUX_MAJOR_H
 
-/* Define to 1 if you have the <linux/ntsync.h> header file. */
-#undef HAVE_LINUX_NTSYNC_H
-
 /* Define to 1 if you have the <linux/param.h> header file. */
 #undef HAVE_LINUX_PARAM_H
 
@@ -339,6 +336,9 @@
 /* Define to 1 if you have the 'posix_fallocate' function. */
 #undef HAVE_POSIX_FALLOCATE
 
+/* Define to 1 if you have the 'ppoll' function. */
+#undef HAVE_PPOLL
+
 /* Define to 1 if you have the 'prctl' function. */
 #undef HAVE_PRCTL
 
@@ -399,6 +399,9 @@
 /* Define to 1 if 'interface_id' is a member of 'sg_io_hdr_t'. */
 #undef HAVE_SG_IO_HDR_T_INTERFACE_ID
 
+/* Define to 1 if you have the `shm_open' function. */
+#undef HAVE_SHM_OPEN
+
 /* Define to 1 if 'si_fd' is a member of 'siginfo_t'. */
 #undef HAVE_SIGINFO_T_SI_FD
 
@@ -528,6 +531,9 @@
 /* Define to 1 if you have the <sys/epoll.h> header file. */
 #undef HAVE_SYS_EPOLL_H
 
+/* Define to 1 if you have the <sys/eventfd.h> header file. */
+#undef HAVE_SYS_EVENTFD_H
+
 /* Define to 1 if you have the <sys/event.h> header file. */
 #undef HAVE_SYS_EVENT_H
 
diff -ruN --show-c-function include/wine/server_protocol.h include/wine/server_protocol.h
--- include/wine/server_protocol.h	2025-10-21 17:44:36.806791392 -0700
+++ include/wine/server_protocol.h	2025-10-24 16:11:48.562587954 -0700
@@ -974,8 +974,6 @@ struct obj_locator
 };
 
 #define MAX_ATOM_LEN     255
-#define WH_WINEVENT      (WH_MAXHOOK + 1)
-#define NB_HOOKS         (WH_WINEVENT - WH_MINHOOK + 1)
 
 struct shared_cursor
 {
@@ -996,13 +994,11 @@ typedef volatile struct
 
 typedef volatile struct
 {
-    timeout_t            access_time;
+    int                  hooks_count[WH_MAX - WH_MIN + 2];
     unsigned int         wake_mask;
     unsigned int         wake_bits;
     unsigned int         changed_mask;
     unsigned int         changed_bits;
-    unsigned int         internal_bits;
-    int                  hooks_count[NB_HOOKS];
 } queue_shm_t;
 
 typedef volatile struct
@@ -1024,16 +1020,9 @@ typedef volatile struct
 
 typedef volatile struct
 {
-    atom_t               atom;
-    unsigned int         style;
-    unsigned int         cls_extra;
-    unsigned int         win_extra;
-    mod_handle_t         instance;
     data_size_t          name_offset;
     data_size_t          name_len;
     WCHAR                name[MAX_ATOM_LEN];
-    unsigned short       __pad;
-    char                 extra[];
 } class_shm_t;
 
 typedef volatile struct
@@ -1181,10 +1170,8 @@ struct init_first_thread_reply
     thread_id_t  tid;
     timeout_t    server_start;
     unsigned int session_id;
-    obj_handle_t inproc_device;
     data_size_t  info_size;
     /* VARARG(machines,ushorts); */
-    char __pad_36[4];
 };
 
 
@@ -3018,7 +3005,7 @@ struct set_queue_mask_request
     struct request_header __header;
     unsigned int wake_mask;
     unsigned int changed_mask;
-    int          poll_events;
+    int          skip_wait;
 };
 struct set_queue_mask_reply
 {
@@ -4494,11 +4481,12 @@ struct create_class_request
     atom_t         atom;
     unsigned int   style;
     mod_handle_t   instance;
+    int            extra;
+    int            win_extra;
     client_ptr_t   client_ptr;
-    short int      cls_extra;
-    short int      win_extra;
     data_size_t    name_offset;
     /* VARARG(name,unicode_str); */
+    char __pad_52[4];
 };
 struct create_class_reply
 {
@@ -5955,56 +5943,91 @@ struct get_next_thread_reply
     char __pad_12[4];
 };
 
+enum esync_type
+{
+    ESYNC_SEMAPHORE = 1,
+    ESYNC_AUTO_EVENT,
+    ESYNC_MANUAL_EVENT,
+    ESYNC_MUTEX,
+    ESYNC_AUTO_SERVER,
+    ESYNC_MANUAL_SERVER,
+    ESYNC_QUEUE,
+};
 
 
-struct set_keyboard_repeat_request
+struct create_esync_request
 {
     struct request_header __header;
-    int enable;
-    int delay;
-    int period;
+    unsigned int access;
+    int          initval;
+    int          type;
+    int          max;
+    /* VARARG(objattr,object_attributes); */
+    char __pad_28[4];
 };
-struct set_keyboard_repeat_reply
+struct create_esync_reply
 {
     struct reply_header __header;
-    int enable;
-    char __pad_12[4];
+    obj_handle_t handle;
+    int          type;
+    unsigned int shm_idx;
+    char __pad_20[4];
 };
 
-
-enum inproc_sync_type
+struct open_esync_request
+{
+    struct request_header __header;
+    unsigned int access;
+    unsigned int attributes;
+    obj_handle_t rootdir;
+    int          type;
+    /* VARARG(name,unicode_str); */
+    char __pad_28[4];
+};
+struct open_esync_reply
 {
-    INPROC_SYNC_UNKNOWN   = 0,
-    INPROC_SYNC_INTERNAL  = 1,
-    INPROC_SYNC_EVENT     = 2,
-    INPROC_SYNC_MUTEX     = 3,
-    INPROC_SYNC_SEMAPHORE = 4,
+    struct reply_header __header;
+    obj_handle_t handle;
+    int          type;
+    unsigned int shm_idx;
+    char __pad_20[4];
 };
 
 
-struct get_inproc_sync_fd_request
+struct get_esync_fd_request
 {
     struct request_header __header;
     obj_handle_t handle;
 };
-struct get_inproc_sync_fd_reply
+struct get_esync_fd_reply
 {
     struct reply_header __header;
-    int           type;
-    unsigned int access;
+    int          type;
+    unsigned int shm_idx;
 };
 
+struct esync_msgwait_request
+{
+    struct request_header __header;
+    int          in_msgwait;
+};
+struct esync_msgwait_reply
+{
+    struct reply_header __header;
+};
 
 
-struct get_inproc_alert_fd_request
+struct set_keyboard_repeat_request
 {
     struct request_header __header;
-    char __pad_12[4];
+    int enable;
+    int delay;
+    int period;
 };
-struct get_inproc_alert_fd_reply
+struct set_keyboard_repeat_reply
 {
     struct reply_header __header;
-    obj_handle_t handle;
+    int enable;
     char __pad_12[4];
 };
 
@@ -6114,6 +6137,17 @@ struct d3dkmt_object_open_name_reply
 };
 
 
+struct get_esync_apc_fd_request
+{
+    struct request_header __header;
+    char __pad_12[4];
+};
+struct get_esync_apc_fd_reply
+{
+    struct reply_header __header;
+};
+
+
 enum request
 {
     REQ_new_process,
@@ -6411,15 +6445,18 @@ enum request
     REQ_resume_process,
     REQ_get_next_process,
     REQ_get_next_thread,
+    REQ_create_esync,
+    REQ_open_esync,
+    REQ_get_esync_fd,
+    REQ_esync_msgwait,
     REQ_set_keyboard_repeat,
-    REQ_get_inproc_sync_fd,
-    REQ_get_inproc_alert_fd,
     REQ_d3dkmt_object_create,
     REQ_d3dkmt_object_update,
     REQ_d3dkmt_object_query,
     REQ_d3dkmt_object_open,
     REQ_d3dkmt_share_objects,
     REQ_d3dkmt_object_open_name,
+    REQ_get_esync_apc_fd,
     REQ_NB_REQUESTS
 };
 
@@ -6722,15 +6759,18 @@ union generic_request
     struct resume_process_request resume_process_request;
     struct get_next_process_request get_next_process_request;
     struct get_next_thread_request get_next_thread_request;
+    struct create_esync_request create_esync_request;
+    struct open_esync_request open_esync_request;
+    struct get_esync_fd_request get_esync_fd_request;
+    struct esync_msgwait_request esync_msgwait_request;
     struct set_keyboard_repeat_request set_keyboard_repeat_request;
-    struct get_inproc_sync_fd_request get_inproc_sync_fd_request;
-    struct get_inproc_alert_fd_request get_inproc_alert_fd_request;
     struct d3dkmt_object_create_request d3dkmt_object_create_request;
     struct d3dkmt_object_update_request d3dkmt_object_update_request;
     struct d3dkmt_object_query_request d3dkmt_object_query_request;
     struct d3dkmt_object_open_request d3dkmt_object_open_request;
     struct d3dkmt_share_objects_request d3dkmt_share_objects_request;
     struct d3dkmt_object_open_name_request d3dkmt_object_open_name_request;
+    struct get_esync_apc_fd_request get_esync_apc_fd_request;
 };
 union generic_reply
 {
@@ -7031,17 +7071,20 @@ union generic_reply
     struct resume_process_reply resume_process_reply;
     struct get_next_process_reply get_next_process_reply;
     struct get_next_thread_reply get_next_thread_reply;
+    struct create_esync_reply create_esync_reply;
+    struct open_esync_reply open_esync_reply;
+    struct get_esync_fd_reply get_esync_fd_reply;
+    struct esync_msgwait_reply esync_msgwait_reply;
     struct set_keyboard_repeat_reply set_keyboard_repeat_reply;
-    struct get_inproc_sync_fd_reply get_inproc_sync_fd_reply;
-    struct get_inproc_alert_fd_reply get_inproc_alert_fd_reply;
     struct d3dkmt_object_create_reply d3dkmt_object_create_reply;
     struct d3dkmt_object_update_reply d3dkmt_object_update_reply;
     struct d3dkmt_object_query_reply d3dkmt_object_query_reply;
     struct d3dkmt_object_open_reply d3dkmt_object_open_reply;
     struct d3dkmt_share_objects_reply d3dkmt_share_objects_reply;
     struct d3dkmt_object_open_name_reply d3dkmt_object_open_name_reply;
+    struct get_esync_apc_fd_reply get_esync_apc_fd_reply;
 };
 
-#define SERVER_PROTOCOL_VERSION 923
+#define SERVER_PROTOCOL_VERSION 924
 
 #endif /* __WINE_WINE_SERVER_PROTOCOL_H */
diff -ruN --show-c-function README.esync README.esync
--- README.esync	1969-12-31 16:00:00.000000000 -0800
+++ README.esync	2025-10-24 16:11:42.420116727 -0700
@@ -0,0 +1,196 @@
+This is eventfd-based synchronization, or 'esync' for short. Turn it on with
+WINEESYNC=1; debug it with +esync.
+
+== BUGS AND LIMITATIONS ==
+
+Please let me know if you find any bugs. If you can, also attach a log with
++seh,+pid,+esync,+server,+timestamp.
+
+If you get something like "eventfd: Too many open files" and then things start
+crashing, you've probably run out of file descriptors. esync creates one
+eventfd descriptor for each synchronization object, and some games may use a
+large number of these.  Linux by default limits a process to 4096 file
+descriptors, which probably was reasonable back in the nineties but isn't
+really anymore. (Fortunately Debian and derivatives [Ubuntu, Mint] already
+have a reasonable limit.) To raise the limit you'll want to edit
+/etc/security/limits.conf and add a line like
+
+* hard nofile 1048576
+
+then restart your session.
+
+On distributions using systemd, the settings in `/etc/security/limits.conf`
+will be overridden by systemd's own settings. If you run `ulimit -Hn` and it
+returns a lower number than the one you've previously set, then you can set
+
+DefaultLimitNOFILE=1048576
+
+in both `/etc/systemd/system.conf` and `/etc/systemd/user.conf`. You can then
+execute `sudo systemctl daemon-reexec` and restart your session. Check again
+with `ulimit -Hn` that the limit is correct.
+
+Also note that if the wineserver has esync active, all clients also must, and
+vice versa. Otherwise things will probably crash quite badly.
+
+== EXPLANATION ==
+
+The aim is to execute all synchronization operations in "user-space", that is,
+without going through wineserver. We do this using Linux's eventfd
+facility. The main impetus to using eventfd is so that we can poll multiple
+objects at once; in particular we can't do this with futexes, or pthread
+semaphores, or the like. The only way I know of to wait on any of multiple
+objects is to use select/poll/epoll to wait on multiple fds, and eventfd gives
+us those fds in a quite usable way.
+
+Whenever a semaphore, event, or mutex is created, we have the server, instead
+of creating a traditional server-side event/semaphore/mutex, instead create an
+'esync' primitive. These live in esync.c and are very slim objects; in fact,
+they don't even know what type of primitive they are. The server is involved
+at all because we still need a way of creating named objects, passing handles
+to another process, etc.
+
+The server creates an eventfd file descriptor with the requested parameters
+and passes it back to ntdll. ntdll creates an object of the appropriate type,
+then caches it in a table. This table is copied almost wholesale from the fd
+cache code in server.c.
+
+Specific operations follow quite straightforwardly from eventfd:
+
+* To release an object, or set an event, we simply write() to it.
+* An object is signalled if read() succeeds on it. Notably, we create all
+  eventfd descriptors with O_NONBLOCK, so that we can atomically check if an
+  object is signalled and grab it if it is. This also lets us reset events.
+* For objects whose state should not be reset upon waiting—e.g. manual-reset
+  events—we simply check for the POLLIN flag instead of reading.
+* Semaphores are handled by the EFD_SEMAPHORE flag. This matches up quite well
+  (although with some difficulties; see below).
+* Mutexes store their owner thread locally. This isn't reliable information if
+  a different process's thread owns the mutex, but this doesn't matter—a
+  thread should only care whether it owns the mutex, so it knows whether to
+  try waiting on it or simply to increase the recursion count.
+
+The interesting part about esync is that (almost) all waits happen in ntdll,
+including those on server-bound objects. The idea here is that on the server
+side, for any waitable object, we create an eventfd file descriptor (not an
+esync primitive), and then pass it to ntdll if the program tries to wait on
+it. These are cached too, so only the first wait will require a round trip to
+the server. Then the server signals the file descriptor as appropriate, and
+thereby wakes up the client. So far this is implemented for processes,
+threads, message queues (difficult; see below), and device managers (necessary
+for drivers to work). All of these are necessarily server-bound, so we
+wouldn't really gain anything by signalling on the client side instead. Of
+course, except possibly for message queues, it's not likely that any program
+(cutting-edge D3D game or not) is going to be causing a great wineserver load
+by waiting on any of these objects; the motivation was rather to provide a way
+to wait on ntdll-bound and server-bound objects at the same time.
+
+Some cases are still passed to the server, and there's probably no reason not
+to keep them that way. Those that I noticed while testing include: async
+objects, which are internal to the file APIs and never exposed to userspace,
+startup_info objects, which are internal to the loader and signalled when a
+process starts, and keyed events, which are exposed through an ntdll API
+(although not through kernel32) but can't be mixed with other objects (you
+have to use NtWaitForKeyedEvent()). Other cases include: named pipes, debug
+events, sockets, and timers. It's unlikely we'll want to optimize debug events
+or sockets (or any of the other, rather rare, objects), but it is possible
+we'll want to optimize named pipes or timers.
+
+There were two sort of complications when working out the above. The first one
+was events. The trouble is that (1) the server actually creates some events by
+itself and (2) the server sometimes manipulates events passed by the
+client. Resolving the first case was easy enough, and merely entailed creating
+eventfd descriptors for the events the same way as for processes and threads
+(note that we don't really lose anything this way; the events include
+"LowMemoryCondition" and the event that signals system processes to shut
+down). For the second case I basically had to hook the server-side event
+functions to redirect to esync versions if the event was actually an esync
+primitive.
+
+The second complication was message queues. The difficulty here is that X11
+signals events by writing into a pipe (at least I think it's a pipe?), and so
+as a result wineserver has to poll on that descriptor. In theory we could just
+let wineserver do so and then signal us as appropriate, except that wineserver
+only polls on the pipe when the thread is waiting for events (otherwise we'd
+get e.g. keyboard input while the thread is doing something else, and spin
+forever trying to wake up a thread that doesn't care). The obvious solution is
+just to poll on that fd ourselves, and that's what I did—it's just that
+getting the fd from wineserver was kind of ugly, and the code for waiting was
+also kind of ugly basically because we have to wait on both X11's fd and the
+"normal" process/thread-style wineserver fd that we use to signal sent
+messages. The upshot about the whole thing was that races are basically
+impossible, since a thread can only wait on its own queue.
+
+System APCs already work, since the server will forcibly suspend a thread if
+it's not already waiting, and so we just need to check for EINTR from
+poll(). User APCs and alertable waits are implemented in a similar style to
+message queues (well, sort of): whenever someone executes an alertable wait,
+we add an additional eventfd to the list, which the server signals when an APC
+arrives. If that eventfd gets signaled, we hand it off to the server to take
+care of, and return STATUS_USER_APC.
+
+Originally I kept the volatile state of semaphores and mutexes inside a
+variable local to the handle, with the knowledge that this would break if
+someone tried to open the handle elsewhere or duplicate it. It did, and so now
+this state is stored inside shared memory. This is of the POSIX variety, is
+allocated by the server (but never mapped there) and lives under the path
+"/wine-esync".
+
+There are a couple things that this infrastructure can't handle, although
+surprisingly there aren't that many. In particular:
+* Implementing wait-all, i.e. WaitForMultipleObjects(..., TRUE, ...), is not
+  exactly possible the way we'd like it to be possible. In theory that
+  function should wait until it knows all objects are available, then grab
+  them all at once atomically. The server (like the kernel) can do this
+  because the server is single-threaded and can't race with itself. We can't
+  do this in ntdll, though. The approach I've taken I've laid out in great
+  detail in the relevant patch, but for a quick summary we poll on each object
+  until it's signaled (but don't grab it), check them all again, and if
+  they're all signaled we try to grab them all at once in a tight loop, and if
+  we fail on any of them we reset the count on whatever we shouldn't have
+  consumed. Such a blip would necessarily be very quick.
+* The whole patchset only works on Linux, where eventfd is available. However,
+  it should be possible to make it work on a Mac, since eventfd is just a
+  quicker, easier way to use pipes (i.e. instead of writing 1 to the fd you'd
+  write 1 byte; instead of reading a 64-bit value from the fd you'd read as
+  many bytes as you can carry, which is admittedly less than 2**64 but
+  can probably be something reasonable.) It's also possible, although I
+  haven't yet looked, to use some different kind of synchronization
+  primitives, but pipes would be easiest to tack onto this framework.
+* PulseEvent() can't work the way it's supposed to work. Fortunately it's rare
+  and deprecated. It's also explicitly mentioned on MSDN that a thread can
+  miss the notification for a kernel APC, so in a sense we're not necessarily
+  doing anything wrong.
+
+There are some things that are perfectly implementable but that I just haven't
+done yet:
+* Other synchronizable server primitives. It's unlikely we'll need any of
+  these, except perhaps named pipes (which would honestly be rather difficult)
+  and (maybe) timers.
+* Access masks. We'd need to store these inside ntdll, and validate them when
+  someone tries to execute esync operations.
+
+This patchset was inspired by Daniel Santos' "hybrid synchronization"
+patchset. My idea was to create a framework whereby even contended waits could
+be executed in userspace, eliminating a lot of the complexity that his
+synchronization primitives used. I do however owe some significant gratitude
+toward him for setting me on the right path.
+
+I've tried to maximize code separation, both to make any potential rebases
+easier and to ensure that esync is only active when configured. All code in
+existing source files is guarded with "if (do_esync())", and generally that
+condition is followed by "return esync_version_of_this_method(...);", where
+the latter lives in esync.c and is declared in esync.h. I've also tried to
+make the patchset very clear and readable—to write it as if I were going to
+submit it upstream. (Some intermediate patches do break things, which Wine is
+generally against, but I think it's for the better in this case.) I have cut
+some corners, though; there is some error checking missing, or implicit
+assumptions that the program is behaving correctly.
+
+I've tried to be careful about races. There are a lot of comments whose
+purpose are basically to assure me that races are impossible. In most cases we
+don't have to worry about races since all of the low-level synchronization is
+done by the kernel.
+
+Anyway, yeah, this is esync. Use it if you like.
+
+--Zebediah Figura
diff -ruN --show-c-function server/async.c server/async.c
--- server/async.c	2025-10-21 17:44:36.355168673 -0700
+++ server/async.c	2025-10-24 16:11:42.396536709 -0700
@@ -78,10 +78,10 @@ static const struct object_ops async_ops
     add_queue,                 /* add_queue */
     remove_queue,              /* remove_queue */
     async_signaled,            /* signaled */
+    NULL,                      /* get_esync_fd */
     async_satisfied,           /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
-    default_get_sync,          /* get_sync */
     default_map_access,        /* map_access */
     default_get_sd,            /* get_sd */
     default_set_sd,            /* set_sd */
@@ -700,10 +700,10 @@ static const struct object_ops iosb_ops
     no_add_queue,             /* add_queue */
     NULL,                     /* remove_queue */
     NULL,                     /* signaled */
+    NULL,                     /* get_esync_fd */
     NULL,                     /* satisfied */
     no_signal,                /* signal */
     no_get_fd,                /* get_fd */
-    default_get_sync,         /* get_sync */
     default_map_access,       /* map_access */
     default_get_sd,           /* get_sd */
     default_set_sd,           /* set_sd */
diff -ruN --show-c-function server/atom.c server/atom.c
--- server/atom.c	2025-10-21 17:44:36.355168673 -0700
+++ server/atom.c	2025-10-24 16:11:42.396685341 -0700
@@ -77,10 +77,10 @@ static const struct object_ops atom_tabl
     no_add_queue,                 /* add_queue */
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
+    NULL,                         /* get_esync_fd */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-    default_get_sync,             /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
diff -ruN --show-c-function server/change.c server/change.c
--- server/change.c	2025-10-21 17:44:36.355168673 -0700
+++ server/change.c	2025-10-24 16:11:42.420245511 -0700
@@ -109,13 +109,13 @@ static const struct object_ops dir_ops =
     sizeof(struct dir),       /* size */
     &file_type,               /* type */
     dir_dump,                 /* dump */
-    NULL,                     /* add_queue */
-    NULL,                     /* remove_queue */
-    NULL,                     /* signaled */
-    NULL,                     /* satisfied */
+    add_queue,                /* add_queue */
+    remove_queue,             /* remove_queue */
+    default_fd_signaled,      /* signaled */
+    default_fd_get_esync_fd,  /* get_esync_fd */
+    no_satisfied,             /* satisfied */
     no_signal,                /* signal */
     dir_get_fd,               /* get_fd */
-    default_fd_get_sync,      /* get_sync */
     default_map_access,       /* map_access */
     dir_get_sd,               /* get_sd */
     dir_set_sd,               /* set_sd */
diff -ruN --show-c-function server/class.c server/class.c
--- server/class.c	2025-10-21 17:44:36.355168673 -0700
+++ server/class.c	2025-10-24 16:11:42.352070176 -0700
@@ -46,36 +46,36 @@ struct window_class
     struct process     *process;         /* process owning the class */
     int                 count;           /* reference count */
     int                 local;           /* local class? */
-    atom_t              atom;            /* class atom for versioned class */
+    atom_t              atom;            /* class atom */
+    atom_t              base_atom;       /* base class atom for versioned class */
+    mod_handle_t        instance;        /* module instance */
+    unsigned int        style;           /* class style */
+    int                 win_extra;       /* number of window extra bytes */
     client_ptr_t        client_ptr;      /* pointer to class in client address space */
     class_shm_t        *shared;          /* class in session shared memory */
+    int                 nb_extra_bytes;  /* number of extra bytes */
+    char                extra_bytes[1];  /* extra bytes storage */
 };
 
-C_ASSERT( sizeof(class_shm_t) == offsetof(class_shm_t, extra[0]) );
-
-static struct window_class *create_class( struct process *process, int local, struct unicode_str *name, unsigned int name_offset,
-                                          atom_t atom, mod_handle_t instance, unsigned int style, int cls_extra, int win_extra )
+static struct window_class *create_class( struct process *process, int extra_bytes, int local,
+                                          struct unicode_str *name, unsigned int name_offset )
 {
     struct window_class *class;
 
-    if (!(class = mem_alloc( sizeof(*class) ))) return NULL;
+    if (!(class = mem_alloc( sizeof(*class) + extra_bytes - 1 ))) return NULL;
 
     class->process = (struct process *)grab_object( process );
     class->count = 0;
     class->local = local;
+    class->nb_extra_bytes = extra_bytes;
+    memset( class->extra_bytes, 0, extra_bytes );
 
-    if (!(class->shared = alloc_shared_object( offsetof(class_shm_t, extra[cls_extra]) ))) goto failed;
+    if (!(class->shared = alloc_shared_object())) goto failed;
     SHARED_WRITE_BEGIN( class->shared, class_shm_t )
     {
         memcpy( (void *)shared->name, name->str, name->len );
-        shared->name_offset  = name_offset;
-        shared->name_len     = name->len;
-        shared->atom         = atom;
-        shared->instance     = instance;
-        shared->style        = style;
-        shared->win_extra    = win_extra;
-        shared->cls_extra    = cls_extra;
-        memset( (void *)shared->extra, 0, cls_extra );
+        shared->name_offset = name_offset;
+        shared->name_len = name->len;
     }
     SHARED_WRITE_END;
 
@@ -96,7 +96,7 @@ static void destroy_class( struct window
     struct atom_table *table = get_user_atom_table();
 
     release_atom( table, class->atom );
-    release_atom( table, class->shared->atom );
+    release_atom( table, class->base_atom );
     list_remove( &class->entry );
     release_object( class->process );
     if (class->shared) free_shared_object( class->shared );
@@ -121,11 +121,10 @@ static struct window_class *find_class(
 
     LIST_FOR_EACH_ENTRY( class, &process->classes, struct window_class, entry )
     {
-        const class_shm_t *shared = class->shared;
         if (class->atom != atom) continue;
-        is_win16 = !(shared->instance >> 16);
-        if (!instance || !class->local || shared->instance == instance ||
-            (!is_win16 && ((shared->instance & ~0xffff) == (instance & ~0xffff)))) return class;
+        is_win16 = !(class->instance >> 16);
+        if (!instance || !class->local || class->instance == instance ||
+            (!is_win16 && ((class->instance & ~0xffff) == (instance & ~0xffff)))) return class;
     }
     return NULL;
 }
@@ -137,7 +136,7 @@ struct window_class *grab_class( struct
     if (class)
     {
         class->count++;
-        *extra_bytes = class->shared->win_extra;
+        *extra_bytes = class->win_extra;
         *locator = get_shared_object_locator( class->shared );
     }
     else set_error( STATUS_INVALID_HANDLE );
@@ -152,7 +151,7 @@ void release_class( struct window_class
 
 int is_desktop_class( struct window_class *class )
 {
-    return (class->shared->atom == DESKTOP_ATOM && !class->local);
+    return (class->atom == DESKTOP_ATOM && !class->local);
 }
 
 int is_message_class( struct window_class *class )
@@ -161,17 +160,17 @@ int is_message_class( struct window_clas
     static const struct unicode_str name = { messageW, sizeof(messageW) };
     struct atom_table *table = get_user_atom_table();
 
-    return (!class->local && class->shared->atom == find_atom( table, &name ));
+    return (!class->local && class->atom == find_atom( table, &name ));
 }
 
 int get_class_style( struct window_class *class )
 {
-    return class->shared->style;
+    return class->style;
 }
 
 atom_t get_class_atom( struct window_class *class )
 {
-    return class->shared->atom;
+    return class->base_atom;
 }
 
 client_ptr_t get_class_client_ptr( struct window_class *class )
@@ -230,7 +229,7 @@ DECL_HANDLER(create_class)
         release_atom( table, base_atom );
         return;
     }
-    if (req->cls_extra < 0 || req->cls_extra > 4096 || req->win_extra < 0 || req->win_extra > 4096)
+    if (req->extra < 0 || req->extra > 4096 || req->win_extra < 0 || req->win_extra > 4096)
     {
         /* don't allow stupid values here */
         set_error( STATUS_INVALID_PARAMETER );
@@ -239,14 +238,17 @@ DECL_HANDLER(create_class)
         return;
     }
 
-    if (!(class = create_class( current->process, req->local, &name, offset, base_atom,
-                                req->instance, req->style, req->cls_extra, req->win_extra )))
+    if (!(class = create_class( current->process, req->extra, req->local, &name, offset )))
     {
         release_atom( table, atom );
         release_atom( table, base_atom );
         return;
     }
     class->atom       = atom;
+    class->base_atom  = base_atom;
+    class->instance   = req->instance;
+    class->style      = req->style;
+    class->win_extra  = req->win_extra;
     class->client_ptr = req->client_ptr;
     reply->locator   = get_shared_object_locator( class->shared );
     reply->atom      = base_atom;
@@ -287,43 +289,39 @@ DECL_HANDLER(set_class_info)
         return;
     }
 
-    SHARED_WRITE_BEGIN( class->shared, class_shm_t )
+    switch (req->offset)
     {
-        switch (req->offset)
+    case GCL_STYLE:
+        reply->old_info = class->style;
+        class->style = req->new_info;
+        break;
+    case GCL_CBWNDEXTRA:
+        if (req->new_info > 4096)
+        {
+            set_error( STATUS_INVALID_PARAMETER );
+            return;
+        }
+        reply->old_info = class->win_extra;
+        class->win_extra = req->new_info;
+        break;
+    case GCL_CBCLSEXTRA:
+        set_win32_error( ERROR_INVALID_INDEX );
+        break;
+    case GCLP_HMODULE:
+        reply->old_info = class->instance;
+        class->instance = req->new_info;
+        break;
+    default:
+        if (req->size > sizeof(req->new_info) || req->offset < 0 ||
+            req->offset > class->nb_extra_bytes - (int)req->size)
         {
-        case GCL_STYLE:
-            reply->old_info = shared->style;
-            shared->style = req->new_info;
-            break;
-        case GCL_CBWNDEXTRA:
-            if (req->new_info > 4096)
-            {
-                set_error( STATUS_INVALID_PARAMETER );
-                return;
-            }
-            reply->old_info = shared->win_extra;
-            shared->win_extra = req->new_info;
-            break;
-        case GCL_CBCLSEXTRA:
             set_win32_error( ERROR_INVALID_INDEX );
-            break;
-        case GCLP_HMODULE:
-            reply->old_info = shared->instance;
-            shared->instance = req->new_info;
-            break;
-        default:
-            if (req->size > sizeof(req->new_info) || req->offset < 0 ||
-                req->offset > class->shared->cls_extra - (int)req->size)
-            {
-                set_win32_error( ERROR_INVALID_INDEX );
-                return;
-            }
-            memcpy( &reply->old_info, (char *)shared->extra + req->offset, req->size );
-            memcpy( (char *)shared->extra + req->offset, &req->new_info, req->size );
-            break;
+            return;
         }
+        memcpy( &reply->old_info, class->extra_bytes + req->offset, req->size );
+        memcpy( class->extra_bytes + req->offset, &req->new_info, req->size );
+        break;
     }
-    SHARED_WRITE_END;
 }
 
 
@@ -345,8 +343,19 @@ DECL_HANDLER(get_class_info)
         /* not supported */
         set_win32_error( ERROR_INVALID_HANDLE );
         break;
+    case GCL_STYLE:          reply->info = class->style; break;
+    case GCL_CBWNDEXTRA:     reply->info = class->win_extra; break;
+    case GCL_CBCLSEXTRA:     reply->info = class->nb_extra_bytes; break;
+    case GCLP_HMODULE:       reply->info = class->instance; break;
+    case GCW_ATOM:           reply->info = class->atom; break;
     default:
-        set_win32_error( ERROR_INVALID_INDEX );
+        if (req->size > sizeof(reply->info) || req->offset < 0 ||
+            req->offset > class->nb_extra_bytes - (int)req->size)
+        {
+            set_win32_error( ERROR_INVALID_INDEX );
+            return;
+        }
+        memcpy( &reply->info, class->extra_bytes + req->offset, req->size );
         break;
     }
 }
diff -ruN --show-c-function server/clipboard.c server/clipboard.c
--- server/clipboard.c	2025-10-21 17:44:36.355168673 -0700
+++ server/clipboard.c	2025-10-24 16:11:42.396957237 -0700
@@ -76,10 +76,10 @@ static const struct object_ops clipboard
     no_add_queue,                 /* add_queue */
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
+    NULL,                         /* get_esync_fd */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-    default_get_sync,             /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
diff -ruN --show-c-function server/completion.c server/completion.c
--- server/completion.c	2025-10-21 17:44:36.355168673 -0700
+++ server/completion.c	2025-10-24 16:11:42.397076473 -0700
@@ -72,11 +72,11 @@ struct completion_wait
 
 struct completion
 {
-    struct object       obj;
-    struct object      *sync;
-    struct list         queue;
-    struct list         wait_queue;
-    unsigned int        depth;
+    struct object  obj;
+    struct list    queue;
+    struct list    wait_queue;
+    unsigned int   depth;
+    int            closed;
 };
 
 static void completion_wait_dump( struct object*, int );
@@ -92,10 +92,10 @@ static const struct object_ops completio
     add_queue,                      /* add_queue */
     remove_queue,                   /* remove_queue */
     completion_wait_signaled,       /* signaled */
+    NULL,                           /* get_esync_fd */
     completion_wait_satisfied,      /* satisfied */
     no_signal,                      /* signal */
     no_get_fd,                      /* get_fd */
-    default_get_sync,               /* get_sync */
     default_map_access,             /* map_access */
     default_get_sd,                 /* get_sd */
     default_set_sd,                 /* set_sd */
@@ -155,7 +155,7 @@ static void completion_wait_satisfied( s
 }
 
 static void completion_dump( struct object*, int );
-static struct object *completion_get_sync( struct object * );
+static int completion_signaled( struct object *obj, struct wait_queue_entry *entry );
 static int completion_close_handle( struct object *obj, struct process *process, obj_handle_t handle );
 static void completion_destroy( struct object * );
 
@@ -164,13 +164,13 @@ static const struct object_ops completio
     sizeof(struct completion), /* size */
     &completion_type,          /* type */
     completion_dump,           /* dump */
-    NULL,                      /* add_queue */
-    NULL,                      /* remove_queue */
-    NULL,                      /* signaled */
-    NULL,                      /* satisfied */
+    add_queue,                 /* add_queue */
+    remove_queue,              /* remove_queue */
+    completion_signaled,       /* signaled */
+    NULL,                      /* get_esync_fd */
+    no_satisfied,              /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
-    completion_get_sync,       /* get_sync */
     default_map_access,        /* map_access */
     default_get_sd,            /* get_sd */
     default_set_sd,            /* set_sd */
@@ -193,8 +193,6 @@ static void completion_destroy( struct o
     {
         free( tmp );
     }
-
-    if (completion->sync) release_object( completion->sync );
 }
 
 static void completion_dump( struct object *obj, int verbose )
@@ -205,11 +203,11 @@ static void completion_dump( struct obje
     fprintf( stderr, "Completion depth=%u\n", completion->depth );
 }
 
-static struct object *completion_get_sync( struct object *obj )
+static int completion_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct completion *completion = (struct completion *)obj;
-    assert( obj->ops == &completion_ops );
-    return grab_object( completion->sync );
+
+    return !list_empty( &completion->queue ) || completion->closed;
 }
 
 static int completion_close_handle( struct object *obj, struct process *process, obj_handle_t handle )
@@ -230,7 +228,8 @@ static int completion_close_handle( stru
             cleanup_thread_completion( wait->thread );
         }
     }
-    signal_sync( completion->sync );
+    completion->closed = 1;
+    wake_up( obj, 0 );
     return 1;
 }
 
@@ -274,16 +273,10 @@ static struct completion *create_complet
     {
         if (get_error() != STATUS_OBJECT_NAME_EXISTS)
         {
-            completion->sync = NULL;
             list_init( &completion->queue );
             list_init( &completion->wait_queue );
             completion->depth = 0;
-
-            if (!(completion->sync = create_internal_sync( 1, 0 )))
-            {
-                release_object( completion );
-                return NULL;
-            }
+            completion->closed = 0;
         }
     }
 
@@ -316,7 +309,7 @@ void add_completion( struct completion *
         wake_up( &wait->obj, 1 );
         if (list_empty( &completion->queue )) return;
     }
-    if (!list_empty( &completion->queue )) signal_sync( completion->sync );
+    if (!list_empty( &completion->queue )) wake_up( &completion->obj, 0 );
 }
 
 /* create a completion */
@@ -417,7 +410,6 @@ DECL_HANDLER(remove_completion)
         reply->information = msg->information;
         free( msg );
         reply->wait_handle = 0;
-        if (list_empty( &completion->queue )) reset_sync( completion->sync );
     }
 
     release_object( completion );
diff -ruN --show-c-function server/console.c server/console.c
--- server/console.c	2025-10-21 17:44:36.355168673 -0700
+++ server/console.c	2025-10-24 16:11:42.421451841 -0700
@@ -41,6 +41,7 @@
 #include "wincon.h"
 #include "winternl.h"
 #include "wine/condrv.h"
+#include "esync.h"
 
 struct screen_buffer;
 
@@ -53,7 +54,7 @@ struct history_line
 struct console
 {
     struct object                obj;           /* object header */
-    struct object               *sync;          /* sync object for wait/signal */
+    int                          signaled;      /* is console signaled */
     struct thread               *renderer;      /* console renderer thread */
     struct screen_buffer        *active;        /* active screen buffer */
     struct console_server       *server;        /* console server object */
@@ -68,25 +69,26 @@ struct console
 
 static void console_dump( struct object *obj, int verbose );
 static void console_destroy( struct object *obj );
+static int console_signaled( struct object *obj, struct wait_queue_entry *entry );
 static struct fd *console_get_fd( struct object *obj );
-static struct object *console_get_sync( struct object *obj );
 static struct object *console_lookup_name( struct object *obj, struct unicode_str *name,
                                            unsigned int attr, struct object *root );
 static struct object *console_open_file( struct object *obj, unsigned int access,
                                          unsigned int sharing, unsigned int options );
+static int console_add_queue( struct object *obj, struct wait_queue_entry *entry );
 
 static const struct object_ops console_ops =
 {
     sizeof(struct console),           /* size */
     &file_type,                       /* type */
     console_dump,                     /* dump */
-    NULL,                             /* add_queue */
-    NULL,                             /* remove_queue */
-    NULL,                             /* signaled */
-    NULL,                             /* satisfied */
+    console_add_queue,                /* add_queue */
+    remove_queue,                     /* remove_queue */
+    console_signaled,                 /* signaled */
+    NULL,                             /* get_esync_fd */
+    no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     console_get_fd,                   /* get_fd */
-    console_get_sync,                 /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -133,22 +135,23 @@ struct console_host_ioctl
 
 struct console_server
 {
-    struct object         obj;            /* object header */
-    struct object        *sync;           /* sync object for wait/signal */
-    struct fd            *fd;             /* pseudo-fd for ioctls */
-    struct console       *console;        /* attached console */
-    struct list           queue;          /* ioctl queue */
-    struct list           read_queue;     /* blocking read queue */
+    struct object         obj;         /* object header */
+    struct fd            *fd;          /* pseudo-fd for ioctls */
+    struct console       *console;     /* attached console */
+    struct list           queue;       /* ioctl queue */
+    struct list           read_queue;  /* blocking read queue */
     unsigned int          busy : 1;       /* flag if server processing an ioctl */
     unsigned int          once_input : 1; /* flag if input thread has already been requested */
-    int                   term_fd;        /* UNIX terminal fd */
-    struct termios        termios;        /* original termios */
+    int                   term_fd;     /* UNIX terminal fd */
+    struct termios        termios;     /* original termios */
+    int                   esync_fd;
 };
 
 static void console_server_dump( struct object *obj, int verbose );
 static void console_server_destroy( struct object *obj );
+static int console_server_signaled( struct object *obj, struct wait_queue_entry *entry );
+static int console_server_get_esync_fd( struct object *obj, enum esync_type *type );
 static struct fd *console_server_get_fd( struct object *obj );
-static struct object *console_server_get_sync( struct object *obj );
 static struct object *console_server_lookup_name( struct object *obj, struct unicode_str *name,
                                                 unsigned int attr, struct object *root );
 static struct object *console_server_open_file( struct object *obj, unsigned int access,
@@ -159,13 +162,13 @@ static const struct object_ops console_s
     sizeof(struct console_server),    /* size */
     &file_type,                       /* type */
     console_server_dump,              /* dump */
-    NULL,                             /* add_queue */
-    NULL,                             /* remove_queue */
-    NULL,                             /* signaled */
-    NULL,                             /* satisfied */
+    add_queue,                        /* add_queue */
+    remove_queue,                     /* remove_queue */
+    console_server_signaled,          /* signaled */
+    console_server_get_esync_fd,      /* get_esync_fd */
+    no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     console_server_get_fd,            /* get_fd */
-    console_server_get_sync,          /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -210,7 +213,6 @@ struct font_info
 struct screen_buffer
 {
     struct object         obj;           /* object header */
-    struct object        *sync;          /* sync object for wait/signal */
     struct list           entry;         /* entry in list of all screen buffers */
     struct console       *input;         /* associated console input */
     unsigned int          id;            /* buffer id */
@@ -220,8 +222,8 @@ struct screen_buffer
 
 static void screen_buffer_dump( struct object *obj, int verbose );
 static void screen_buffer_destroy( struct object *obj );
+static int screen_buffer_signaled( struct object *obj, struct wait_queue_entry *entry );
 static struct fd *screen_buffer_get_fd( struct object *obj );
-static struct object *screen_buffer_get_sync( struct object *obj );
 static struct object *screen_buffer_open_file( struct object *obj, unsigned int access,
                                                unsigned int sharing, unsigned int options );
 
@@ -230,13 +232,13 @@ static const struct object_ops screen_bu
     sizeof(struct screen_buffer),     /* size */
     &file_type,                       /* type */
     screen_buffer_dump,               /* dump */
-    NULL,                             /* add_queue */
-    NULL,                             /* remove_queue */
-    NULL,                             /* signaled */
-    NULL,                             /* satisfied */
+    add_queue,                        /* add_queue */
+    remove_queue,                     /* remove_queue */
+    screen_buffer_signaled,           /* signaled */
+    NULL,                             /* get_esync_fd */
+    no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     screen_buffer_get_fd,             /* get_fd */
-    screen_buffer_get_sync,           /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -283,10 +285,10 @@ static const struct object_ops console_d
     no_add_queue,                     /* add_queue */
     NULL,                             /* remove_queue */
     NULL,                             /* signaled */
+    NULL,                             /* get_esync_fd */
     no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     no_get_fd,                        /* get_fd */
-    default_get_sync,                 /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -303,17 +305,16 @@ static const struct object_ops console_d
 struct console_input
 {
     struct object         obj;         /* object header */
-    struct object        *sync;        /* sync object for wait/signal */
     struct fd            *fd;          /* pseudo-fd */
     struct list           entry;       /* entry in console->inputs */
     struct console       *console;     /* associated console at creation time */
 };
 
 static void console_input_dump( struct object *obj, int verbose );
+static int console_input_signaled( struct object *obj, struct wait_queue_entry *entry );
 static struct object *console_input_open_file( struct object *obj, unsigned int access,
                                                unsigned int sharing, unsigned int options );
 static struct fd *console_input_get_fd( struct object *obj );
-static struct object *console_input_get_sync( struct object *obj );
 static void console_input_destroy( struct object *obj );
 
 static const struct object_ops console_input_ops =
@@ -321,13 +322,13 @@ static const struct object_ops console_i
     sizeof(struct console_input),     /* size */
     &device_type,                     /* type */
     console_input_dump,               /* dump */
-    NULL,                             /* add_queue */
-    NULL,                             /* remove_queue */
-    NULL,                             /* signaled */
-    NULL,                             /* satisfied */
+    add_queue,                        /* add_queue */
+    remove_queue,                     /* remove_queue */
+    console_input_signaled,           /* signaled */
+    NULL,                             /* get_esync_fd */
+    no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     console_input_get_fd,             /* get_fd */
-    console_input_get_sync,           /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -364,15 +365,14 @@ static const struct fd_ops console_input
 struct console_output
 {
     struct object         obj;         /* object header */
-    struct object        *sync;        /* sync object for wait/signal */
     struct fd            *fd;          /* pseudo-fd */
     struct list           entry;       /* entry in console->outputs */
     struct console       *console;     /* associated console at creation time */
 };
 
 static void console_output_dump( struct object *obj, int verbose );
+static int console_output_signaled( struct object *obj, struct wait_queue_entry *entry );
 static struct fd *console_output_get_fd( struct object *obj );
-static struct object *console_output_get_sync( struct object *obj );
 static struct object *console_output_open_file( struct object *obj, unsigned int access,
                                                 unsigned int sharing, unsigned int options );
 static void console_output_destroy( struct object *obj );
@@ -382,13 +382,13 @@ static const struct object_ops console_o
     sizeof(struct console_output),    /* size */
     &device_type,                     /* type */
     console_output_dump,              /* dump */
-    NULL,                             /* add_queue */
-    NULL,                             /* remove_queue */
-    NULL,                             /* signaled */
-    NULL,                             /* satisfied */
+    add_queue,                        /* add_queue */
+    remove_queue,                     /* remove_queue */
+    console_output_signaled,          /* signaled */
+    NULL,                             /* get_esync_fd */
+    no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     console_output_get_fd,            /* get_fd */
-    console_output_get_sync,          /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -444,10 +444,10 @@ static const struct object_ops console_c
     no_add_queue,                     /* add_queue */
     NULL,                             /* remove_queue */
     NULL,                             /* signaled */
+    NULL,                             /* get_esync_fd */
     no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     console_connection_get_fd,        /* get_fd */
-    default_get_sync,                 /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -482,18 +482,10 @@ static const struct fd_ops console_conne
 static int queue_host_ioctl( struct console_server *server, unsigned int code, unsigned int output,
                              struct async *async, struct async_queue *queue );
 
-static struct fd *console_get_fd( struct object *obj )
-{
-    struct console *console = (struct console *)obj;
-    assert( obj->ops == &console_ops );
-    return (struct fd *)grab_object( console->fd );
-}
-
-static struct object *console_get_sync( struct object *obj )
+static int console_add_queue( struct object *obj, struct wait_queue_entry *entry )
 {
-    struct console *console = (struct console *)obj;
+    struct console *console = (struct console*)obj;
     assert( obj->ops == &console_ops );
-
     /* before waiting, ensure conhost's input thread has been started */
     if (console->server && !console->server->once_input)
     {
@@ -501,8 +493,20 @@ static struct object *console_get_sync(
         if (console->server->term_fd == -1)
             queue_host_ioctl( console->server, IOCTL_CONDRV_PEEK, 0, NULL, NULL );
     }
+    return add_queue( &console->obj, entry );
+}
+
+static int console_signaled( struct object *obj, struct wait_queue_entry *entry )
+{
+    struct console *console = (struct console*)obj;
+    return console->signaled;
+}
 
-    return grab_object( console->sync );
+static struct fd *console_get_fd( struct object *obj )
+{
+    struct console *console = (struct console *)obj;
+    assert( obj->ops == &console_ops );
+    return (struct fd *)grab_object( console->fd );
 }
 
 static enum server_fd_type console_get_fd_type( struct fd *fd )
@@ -541,9 +545,11 @@ static struct object *create_console(voi
 {
     struct console *console;
 
-    if (!(console = alloc_object( &console_ops ))) return NULL;
-    console->sync          = NULL;
+    if (!(console = alloc_object( &console_ops )))
+        return NULL;
+
     console->renderer      = NULL;
+    console->signaled      = 0;
     console->active        = NULL;
     console->server        = NULL;
     console->fd            = NULL;
@@ -554,14 +560,14 @@ static struct object *create_console(voi
     init_async_queue( &console->ioctl_q );
     init_async_queue( &console->read_q );
 
-    if (!(console->sync = create_internal_sync( 1, 0 ))) goto error;
-    if (!(console->fd = alloc_pseudo_fd( &console_fd_ops, &console->obj, FILE_SYNCHRONOUS_IO_NONALERT ))) goto error;
+    console->fd = alloc_pseudo_fd( &console_fd_ops, &console->obj, FILE_SYNCHRONOUS_IO_NONALERT );
+    if (!console->fd)
+    {
+        release_object( console );
+        return NULL;
+    }
     allow_fd_caching( console->fd );
     return &console->obj;
-
-error:
-    release_object( console );
-    return NULL;
 }
 
 static void console_host_ioctl_terminate( struct console_host_ioctl *call, unsigned int status )
@@ -589,7 +595,7 @@ static int queue_host_ioctl( struct cons
         queue_async( queue, async );
     }
     list_add_tail( &server->queue, &ioctl->entry );
-    signal_sync( server->sync );
+    wake_up( &server->obj, 0 );
     if (async) set_error( STATUS_PENDING );
     return 1;
 }
@@ -602,6 +608,8 @@ static void disconnect_console_server( s
         list_remove( &call->entry );
         console_host_ioctl_terminate( call, STATUS_CANCELLED );
     }
+    if (do_esync())
+        esync_clear( server->esync_fd );
     while (!list_empty( &server->read_queue ))
     {
         struct console_host_ioctl *call = LIST_ENTRY( list_head( &server->read_queue ), struct console_host_ioctl, entry );
@@ -621,7 +629,7 @@ static void disconnect_console_server( s
         assert( server->console->server == server );
         server->console->server = NULL;
         server->console = NULL;
-        signal_sync( server->sync );
+        wake_up( &server->obj, 0 );
     }
 }
 
@@ -645,8 +653,9 @@ static struct object *create_screen_buff
         return NULL;
     }
 
-    if (!(screen_buffer = alloc_object( &screen_buffer_ops ))) return NULL;
-    screen_buffer->sync  = grab_object( console->sync );
+    if (!(screen_buffer = alloc_object( &screen_buffer_ops )))
+        return NULL;
+
     screen_buffer->id    = ++console->last_id;
     screen_buffer->input = console;
     init_async_queue( &screen_buffer->ioctl_q );
@@ -777,12 +786,6 @@ static void console_destroy( struct obje
     LIST_FOR_EACH_ENTRY( output, &console->outputs, struct console_output, entry )
         output->console = NULL;
 
-    if (console->sync)
-    {
-        reset_sync( console->sync );
-        release_object( console->sync );
-    }
-
     free_async_queue( &console->ioctl_q );
     free_async_queue( &console->read_q );
     if (console->fd)
@@ -862,10 +865,17 @@ static void screen_buffer_destroy( struc
                               screen_buffer->id, NULL, NULL );
     }
     free_async_queue( &screen_buffer->ioctl_q );
-    if (screen_buffer->sync) release_object( screen_buffer->sync );
     if (screen_buffer->fd) release_object( screen_buffer->fd );
 }
 
+static int screen_buffer_signaled( struct object *obj, struct wait_queue_entry *entry )
+{
+    struct screen_buffer *screen_buffer = (struct screen_buffer *)obj;
+    assert( obj->ops == &screen_buffer_ops );
+    if (!screen_buffer->input) return 0;
+    return screen_buffer->input->signaled;
+}
+
 static struct object *screen_buffer_open_file( struct object *obj, unsigned int access,
                                                unsigned int sharing, unsigned int options )
 {
@@ -882,13 +892,6 @@ static struct fd *screen_buffer_get_fd(
     return NULL;
 }
 
-static struct object *screen_buffer_get_sync( struct object *obj )
-{
-    struct screen_buffer *screen_buffer = (struct screen_buffer *)obj;
-    assert( obj->ops == &screen_buffer_ops );
-    return grab_object( screen_buffer->sync );
-}
-
 static void console_server_dump( struct object *obj, int verbose )
 {
     assert( obj->ops == &console_server_ops );
@@ -900,8 +903,8 @@ static void console_server_destroy( stru
     struct console_server *server = (struct console_server *)obj;
     assert( obj->ops == &console_server_ops );
     disconnect_console_server( server );
-    if (server->sync) release_object( server->sync );
     if (server->fd) release_object( server->fd );
+    if (do_esync()) close( server->esync_fd );
 }
 
 static struct object *console_server_lookup_name( struct object *obj, struct unicode_str *name,
@@ -936,25 +939,31 @@ static struct object *console_server_loo
         release_object( screen_buffer );
         server->console->server = server;
 
-        if (list_empty( &server->queue )) reset_sync( server->sync );
         return &server->console->obj;
     }
 
     return NULL;
 }
 
-static struct fd *console_server_get_fd( struct object* obj )
+static int console_server_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct console_server *server = (struct console_server*)obj;
     assert( obj->ops == &console_server_ops );
-    return (struct fd *)grab_object( server->fd );
+    return !server->console || !list_empty( &server->queue );
 }
 
-static struct object *console_server_get_sync( struct object *obj )
+static int console_server_get_esync_fd( struct object *obj, enum esync_type *type )
 {
-    struct console_server *server = (struct console_server *)obj;
+    struct console_server *server = (struct console_server*)obj;
+    *type = ESYNC_MANUAL_SERVER;
+    return server->esync_fd;
+}
+
+static struct fd *console_server_get_fd( struct object* obj )
+{
+    struct console_server *server = (struct console_server*)obj;
     assert( obj->ops == &console_server_ops );
-    return grab_object( server->sync );
+    return (struct fd *)grab_object( server->fd );
 }
 
 static struct object *console_server_open_file( struct object *obj, unsigned int access,
@@ -968,23 +977,25 @@ static struct object *create_console_ser
     struct console_server *server;
 
     if (!(server = alloc_object( &console_server_ops ))) return NULL;
-    server->sync       = NULL;
-    server->fd         = NULL;
     server->console    = NULL;
     server->busy       = 0;
     server->once_input = 0;
     server->term_fd    = -1;
     list_init( &server->queue );
     list_init( &server->read_queue );
-
-    if (!(server->sync = create_internal_sync( 1, 1 ))) goto error;
-    if (!(server->fd = alloc_pseudo_fd( &console_server_fd_ops, &server->obj, FILE_SYNCHRONOUS_IO_NONALERT ))) goto error;
+    server->fd = alloc_pseudo_fd( &console_server_fd_ops, &server->obj, FILE_SYNCHRONOUS_IO_NONALERT );
+    if (!server->fd)
+    {
+        release_object( server );
+        return NULL;
+    }
     allow_fd_caching(server->fd);
-    return &server->obj;
+    server->esync_fd = -1;
 
-error:
-    release_object( server );
-    return NULL;
+    if (do_esync())
+        server->esync_fd = esync_create_fd( 0, 0 );
+
+    return &server->obj;
 }
 
 static int is_blocking_read_ioctl( unsigned int code )
@@ -1350,7 +1361,6 @@ static struct object *console_device_loo
 
         name->len = 0;
         if (!(console_input = alloc_object( &console_input_ops ))) return NULL;
-        console_input->sync = grab_object( current->process->console->sync );
         console_input->fd = alloc_pseudo_fd( &console_input_fd_ops, &console_input->obj,
                                              FILE_SYNCHRONOUS_IO_NONALERT );
         if (!console_input->fd)
@@ -1375,7 +1385,6 @@ static struct object *console_device_loo
 
         name->len = 0;
         if (!(console_output = alloc_object( &console_output_ops ))) return NULL;
-        console_output->sync = grab_object( current->process->console->sync );
         console_output->fd = alloc_pseudo_fd( &console_output_fd_ops, &console_output->obj,
                                              FILE_SYNCHRONOUS_IO_NONALERT );
         if (!console_output->fd)
@@ -1438,18 +1447,19 @@ static void console_input_dump( struct o
     fputs( "console Input device\n", stderr );
 }
 
-static struct fd *console_input_get_fd( struct object *obj )
+static int console_input_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct console_input *console_input = (struct console_input *)obj;
     assert( obj->ops == &console_input_ops );
-    return (struct fd *)grab_object( console_input->fd );
+    if (!console_input->console) return 0;
+    return console_input->console->signaled;
 }
 
-static struct object *console_input_get_sync( struct object *obj )
+static struct fd *console_input_get_fd( struct object *obj )
 {
     struct console_input *console_input = (struct console_input *)obj;
     assert( obj->ops == &console_input_ops );
-    return grab_object( console_input->sync );
+    return (struct fd *)grab_object( console_input->fd );
 }
 
 static struct object *console_input_open_file( struct object *obj, unsigned int access,
@@ -1465,7 +1475,6 @@ static void console_input_destroy( struc
     assert( obj->ops == &console_input_ops );
     if (console_input->fd) release_object( console_input->fd );
     if (console_input->console) list_remove( &console_input->entry );
-    if (console_input->sync) release_object( console_input->sync );
 }
 
 static void console_input_ioctl( struct fd *fd, ioctl_code_t code, struct async *async )
@@ -1509,18 +1518,19 @@ static void console_output_dump( struct
     fputs( "console Output device\n", stderr );
 }
 
-static struct fd *console_output_get_fd( struct object *obj )
+static int console_output_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct console_output *console_output = (struct console_output *)obj;
     assert( obj->ops == &console_output_ops );
-    return (struct fd *)grab_object( console_output->fd );
+    if (!console_output->console) return 0;
+    return console_output->console->signaled;
 }
 
-static struct object *console_output_get_sync( struct object *obj )
+static struct fd *console_output_get_fd( struct object *obj )
 {
     struct console_output *console_output = (struct console_output *)obj;
     assert( obj->ops == &console_output_ops );
-    return grab_object( console_output->sync );
+    return (struct fd *)grab_object( console_output->fd );
 }
 
 static struct object *console_output_open_file( struct object *obj, unsigned int access,
@@ -1536,7 +1546,6 @@ static void console_output_destroy( stru
     assert( obj->ops == &console_output_ops );
     if (console_output->fd) release_object( console_output->fd );
     if (console_output->console) list_remove( &console_output->entry );
-    if (console_output->sync) release_object( console_output->sync );
 }
 
 static void console_output_ioctl( struct fd *fd, ioctl_code_t code, struct async *async )
@@ -1573,7 +1582,10 @@ struct object *create_console_device( st
 DECL_HANDLER(get_next_console_request)
 {
     struct console_host_ioctl *ioctl = NULL, *next;
+    struct screen_buffer *screen_buffer;
     struct console_server *server;
+    struct console_output *output;
+    struct console_input *input;
     struct iosb *iosb = NULL;
 
     server = (struct console_server *)get_handle_obj( current->process, req->handle, 0, &console_server_ops );
@@ -1588,8 +1600,18 @@ DECL_HANDLER(get_next_console_request)
 
     if (!server->console->renderer) server->console->renderer = current;
 
-    if (!req->signal) reset_sync( server->console->sync );
-    else signal_sync( server->console->sync );
+    if (!req->signal) server->console->signaled = 0;
+    else if (!server->console->signaled)
+    {
+        server->console->signaled = 1;
+        wake_up( &server->console->obj, 0 );
+        LIST_FOR_EACH_ENTRY( screen_buffer, &server->console->screen_buffers, struct screen_buffer, entry )
+            wake_up( &screen_buffer->obj, 0 );
+        LIST_FOR_EACH_ENTRY( input, &server->console->inputs, struct console_input, entry )
+            wake_up( &input->obj, 0 );
+        LIST_FOR_EACH_ENTRY( output, &server->console->outputs, struct console_output, entry )
+            wake_up( &output->obj, 0 );
+    }
 
     if (req->read)
     {
@@ -1610,6 +1632,8 @@ DECL_HANDLER(get_next_console_request)
         /* set result of previous ioctl */
         ioctl = LIST_ENTRY( list_head( &server->queue ), struct console_host_ioctl, entry );
         list_remove( &ioctl->entry );
+        if (do_esync() && list_empty( &server->queue ))
+            esync_clear( server->esync_fd );
     }
 
     if (ioctl)
@@ -1633,7 +1657,11 @@ DECL_HANDLER(get_next_console_request)
         free( ioctl );
         if (iosb) release_object( iosb );
 
-        if (req->read) goto done;
+        if (req->read)
+        {
+            release_object( server );
+            return;
+        }
         server->busy = 0;
     }
 
@@ -1691,8 +1719,8 @@ DECL_HANDLER(get_next_console_request)
     {
         set_error( STATUS_PENDING );
     }
+    if (do_esync() && list_empty( &server->queue ))
+        esync_clear( server->esync_fd );
 
-done:
-    if (list_empty( &server->queue )) reset_sync( server->sync );
     release_object( server );
 }
diff -ruN --show-c-function server/d3dkmt.c server/d3dkmt.c
--- server/d3dkmt.c	2025-10-21 17:44:36.355168673 -0700
+++ server/d3dkmt.c	2025-10-24 16:11:42.368974723 -0700
@@ -57,10 +57,10 @@ static const struct object_ops d3dkmt_ob
     no_add_queue,                   /* add_queue */
     NULL,                           /* remove_queue */
     NULL,                           /* signaled */
+    NULL,                           /* get_esync_fd */
     NULL,                           /* satisfied */
     no_signal,                      /* signal */
     d3dkmt_object_get_fd,           /* get_fd */
-    default_get_sync,               /* get_sync */
     default_map_access,             /* map_access */
     default_get_sd,                 /* get_sd */
     default_set_sd,                 /* set_sd */
@@ -131,9 +131,9 @@ static const struct object_ops dxgk_shar
     NULL,                               /* remove_queue */
     NULL,                               /* signaled */
     NULL,                               /* satisfied */
+    NULL,                               /* get_esync_fd */
     no_signal,                          /* signal */
     no_get_fd,                          /* get_fd */
-    default_get_sync,                   /* get_sync */
     default_map_access,                 /* map_access */
     default_get_sd,                     /* get_sd */
     default_set_sd,                     /* set_sd */
@@ -197,10 +197,10 @@ static const struct object_ops dxgk_shar
     no_add_queue,                           /* add_queue */
     NULL,                                   /* remove_queue */
     NULL,                                   /* signaled */
+    NULL,                                   /* get_esync_fd */
     NULL,                                   /* satisfied */
     no_signal,                              /* signal */
     no_get_fd,                              /* get_fd */
-    default_get_sync,                       /* get_sync */
     default_map_access,                     /* map_access */
     default_get_sd,                         /* get_sd */
     default_set_sd,                         /* set_sd */
diff -ruN --show-c-function server/debugger.c server/debugger.c
--- server/debugger.c	2025-10-21 17:44:36.355168673 -0700
+++ server/debugger.c	2025-10-24 16:11:42.397405909 -0700
@@ -43,7 +43,6 @@ enum debug_event_state { EVENT_QUEUED, E
 struct debug_event
 {
     struct object          obj;       /* object header */
-    struct event_sync     *sync;      /* sync object for wait/signal */
     struct list            entry;     /* entry in event queue */
     struct thread         *sender;    /* thread which sent this event */
     struct file           *file;      /* file object for events that need one */
@@ -70,14 +69,13 @@ struct type_descr debug_obj_type =
 struct debug_obj
 {
     struct object        obj;         /* object header */
-    struct object       *sync;       /* sync object for wait/signal */
     struct list          event_queue; /* pending events queue */
     unsigned int         flags;       /* debug flags */
 };
 
 
 static void debug_event_dump( struct object *obj, int verbose );
-static struct object *debug_event_get_sync( struct object *obj );
+static int debug_event_signaled( struct object *obj, struct wait_queue_entry *entry );
 static void debug_event_destroy( struct object *obj );
 
 static const struct object_ops debug_event_ops =
@@ -85,13 +83,13 @@ static const struct object_ops debug_eve
     sizeof(struct debug_event),    /* size */
     &no_type,                      /* type */
     debug_event_dump,              /* dump */
-    NULL,                          /* add_queue */
-    NULL,                          /* remove_queue */
-    NULL,                          /* signaled */
-    NULL,                          /* satisfied */
+    add_queue,                     /* add_queue */
+    remove_queue,                  /* remove_queue */
+    debug_event_signaled,          /* signaled */
+    NULL,                          /* get_esync_fd */
+    no_satisfied,                  /* satisfied */
     no_signal,                     /* signal */
     no_get_fd,                     /* get_fd */
-    debug_event_get_sync,          /* get_sync */
     default_map_access,            /* map_access */
     default_get_sd,                /* get_sd */
     default_set_sd,                /* set_sd */
@@ -106,7 +104,7 @@ static const struct object_ops debug_eve
 };
 
 static void debug_obj_dump( struct object *obj, int verbose );
-static struct object *debug_obj_get_sync( struct object *obj );
+static int debug_obj_signaled( struct object *obj, struct wait_queue_entry *entry );
 static void debug_obj_destroy( struct object *obj );
 
 static const struct object_ops debug_obj_ops =
@@ -114,13 +112,13 @@ static const struct object_ops debug_obj
     sizeof(struct debug_obj),      /* size */
     &debug_obj_type,               /* type */
     debug_obj_dump,                /* dump */
-    NULL,                          /* add_queue */
-    NULL,                          /* remove_queue */
-    NULL,                          /* signaled */
-    NULL,                          /* satisfied */
+    add_queue,                     /* add_queue */
+    remove_queue,                  /* remove_queue */
+    debug_obj_signaled,            /* signaled */
+    NULL,                          /* get_esync_fd */
+    no_satisfied,                  /* satisfied */
     no_signal,                     /* signal */
     no_get_fd,                     /* get_fd */
-    debug_obj_get_sync,            /* get_sync */
     default_map_access,            /* map_access */
     default_get_sd,                /* get_sd */
     default_set_sd,                /* set_sd */
@@ -256,7 +254,7 @@ static void link_event( struct debug_obj
     {
         /* grab reference since debugger could be killed while trying to wake up */
         grab_object( debug_obj );
-        signal_sync( debug_obj->sync );
+        wake_up( &debug_obj->obj, 0 );
         release_object( debug_obj );
     }
 }
@@ -265,11 +263,10 @@ static void link_event( struct debug_obj
 static void resume_event( struct debug_obj *debug_obj, struct debug_event *event )
 {
     event->state = EVENT_QUEUED;
-    reset_sync( (struct object *)event->sync );
     if (!event->sender->process->debug_event)
     {
         grab_object( debug_obj );
-        signal_sync( debug_obj->sync );
+        wake_up( &debug_obj->obj, 0 );
         release_object( debug_obj );
     }
 }
@@ -278,7 +275,6 @@ static void resume_event( struct debug_o
 static void delay_event( struct debug_obj *debug_obj, struct debug_event *event )
 {
     event->state = EVENT_DELAYED;
-    reset_sync( (struct object *)event->sync );
     if (event->sender->process->debug_event == event) event->sender->process->debug_event = NULL;
 }
 
@@ -305,11 +301,11 @@ static void debug_event_dump( struct obj
              debug_event->sender, debug_event->data.code, debug_event->state );
 }
 
-static struct object *debug_event_get_sync( struct object *obj )
+static int debug_event_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct debug_event *debug_event = (struct debug_event *)obj;
     assert( obj->ops == &debug_event_ops );
-    return grab_object( debug_event->sync );
+    return debug_event->state == EVENT_CONTINUED;
 }
 
 static void debug_event_destroy( struct object *obj )
@@ -317,7 +313,6 @@ static void debug_event_destroy( struct
     struct debug_event *event = (struct debug_event *)obj;
     assert( obj->ops == &debug_event_ops );
 
-    if (event->sync) release_object( event->sync );
     if (event->file) release_object( event->file );
     release_object( event->sender );
 }
@@ -330,11 +325,11 @@ static void debug_obj_dump( struct objec
              debug_obj->event_queue.next, debug_obj->event_queue.prev );
 }
 
-static struct object *debug_obj_get_sync( struct object *obj )
+static int debug_obj_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct debug_obj *debug_obj = (struct debug_obj *)obj;
     assert( obj->ops == &debug_obj_ops );
-    return grab_object( debug_obj->sync );
+    return find_event_to_send( debug_obj ) != NULL;
 }
 
 static void debug_obj_destroy( struct object *obj )
@@ -349,8 +344,6 @@ static void debug_obj_destroy( struct ob
     /* free all pending events */
     while ((ptr = list_head( &debug_obj->event_queue )))
         unlink_event( debug_obj, LIST_ENTRY( ptr, struct debug_event, entry ));
-
-    if (debug_obj->sync) release_object( debug_obj->sync );
 }
 
 struct debug_obj *get_debug_obj( struct process *process, obj_handle_t handle, unsigned int access )
@@ -368,15 +361,8 @@ static struct debug_obj *create_debug_ob
     {
         if (get_error() != STATUS_OBJECT_NAME_EXISTS)
         {
-            debug_obj->sync  = NULL;
             debug_obj->flags = flags;
             list_init( &debug_obj->event_queue );
-
-            if (!(debug_obj->sync = create_internal_sync( 1, 0 )))
-            {
-                release_object( debug_obj );
-                return NULL;
-            }
         }
     }
     return debug_obj;
@@ -422,7 +408,7 @@ static int continue_debug_event( struct
                 assert( event->sender->process->debug_event == event );
                 event->status = status;
                 event->state  = EVENT_CONTINUED;
-                signal_sync( (struct object *)event->sync );
+                wake_up( &event->obj, 0 );
                 unlink_event( debug_obj, event );
                 resume_process( process );
                 return 1;
@@ -443,21 +429,12 @@ static struct debug_event *alloc_debug_e
 
     /* build the event */
     if (!(event = alloc_object( &debug_event_ops ))) return NULL;
-    event->sync      = NULL;
     event->state     = EVENT_QUEUED;
     event->sender    = (struct thread *)grab_object( thread );
     event->file      = NULL;
     memset( &event->data, 0, sizeof(event->data) );
     fill_debug_event[code - DbgCreateThreadStateChange]( event, arg );
     event->data.code = code;
-
-    /* create a server-side sync here, as send_debug_event still uses server_select to pass contexts around */
-    if (!(event->sync = create_server_internal_sync( 1, 0 )))
-    {
-        release_object( event );
-        return NULL;
-    }
-
     return event;
 }
 
@@ -543,7 +520,7 @@ void debugger_detach( struct process *pr
         assert( event->state != EVENT_CONTINUED );
         event->status = DBG_CONTINUE;
         event->state  = EVENT_CONTINUED;
-        signal_sync( (struct object *)event->sync );
+        wake_up( &event->obj, 0 );
         unlink_event( debug_obj, event );
         /* from queued debug event */
         resume_process( process );
@@ -589,13 +566,11 @@ DECL_HANDLER(wait_debug_event)
     if ((event = find_event_to_send( debug_obj )))
     {
         event->state = EVENT_SENT;
-        reset_sync( (struct object *)event->sync );
         event->sender->process->debug_event = event;
         reply->pid = get_process_id( event->sender->process );
         reply->tid = get_thread_id( event->sender );
         alloc_event_handles( event, current->process );
         set_reply_data( &event->data, min( get_reply_max_size(), sizeof(event->data) ));
-        if (!find_event_to_send( debug_obj )) reset_sync( debug_obj->sync );
     }
     else
     {
diff -ruN --show-c-function server/device.c server/device.c
--- server/device.c	2025-10-21 17:44:36.355168673 -0700
+++ server/device.c	2025-10-24 16:11:42.407671434 -0700
@@ -38,6 +38,7 @@
 #include "handle.h"
 #include "request.h"
 #include "process.h"
+#include "esync.h"
 
 /* IRP object */
 
@@ -66,10 +67,10 @@ static const struct object_ops irp_call_
     no_add_queue,                     /* add_queue */
     NULL,                             /* remove_queue */
     NULL,                             /* signaled */
+    NULL,                             /* get_esync_fd */
     NULL,                             /* satisfied */
     no_signal,                        /* signal */
     no_get_fd,                        /* get_fd */
-    default_get_sync,                 /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -89,15 +90,16 @@ static const struct object_ops irp_call_
 struct device_manager
 {
     struct object          obj;            /* object header */
-    struct object         *sync;           /* sync object for wait/signal */
     struct list            devices;        /* list of devices */
     struct list            requests;       /* list of pending irps across all devices */
     struct irp_call       *current_call;   /* call currently executed on client side */
     struct wine_rb_tree    kernel_objects; /* map of objects that have client side pointer associated */
+    int                    esync_fd;       /* esync file descriptor */
 };
 
 static void device_manager_dump( struct object *obj, int verbose );
-static struct object *device_manager_get_sync( struct object *obj );
+static int device_manager_signaled( struct object *obj, struct wait_queue_entry *entry );
+static int device_manager_get_esync_fd( struct object *obj, enum esync_type *type );
 static void device_manager_destroy( struct object *obj );
 
 static const struct object_ops device_manager_ops =
@@ -105,13 +107,13 @@ static const struct object_ops device_ma
     sizeof(struct device_manager),    /* size */
     &no_type,                         /* type */
     device_manager_dump,              /* dump */
-    NULL,                             /* add_queue */
-    NULL,                             /* remove_queue */
-    NULL,                             /* signaled */
-    NULL,                             /* satisfied */
+    add_queue,                        /* add_queue */
+    remove_queue,                     /* remove_queue */
+    device_manager_signaled,          /* signaled */
+    device_manager_get_esync_fd,      /* get_esync_fd */
+    no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     no_get_fd,                        /* get_fd */
-    device_manager_get_sync,          /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -166,10 +168,10 @@ static const struct object_ops device_op
     no_add_queue,                     /* add_queue */
     NULL,                             /* remove_queue */
     NULL,                             /* signaled */
+    NULL,                             /* get_esync_fd */
     no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     no_get_fd,                        /* get_fd */
-    default_get_sync,                 /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -216,13 +218,13 @@ static const struct object_ops device_fi
     sizeof(struct device_file),       /* size */
     &file_type,                       /* type */
     device_file_dump,                 /* dump */
-    NULL,                             /* add_queue */
-    NULL,                             /* remove_queue */
-    NULL,                             /* signaled */
-    NULL,                             /* satisfied */
+    add_queue,                        /* add_queue */
+    remove_queue,                     /* remove_queue */
+    default_fd_signaled,              /* signaled */
+    NULL,                             /* get_esync_fd */
+    no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     device_file_get_fd,               /* get_fd */
-    default_fd_get_sync,              /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -423,7 +425,7 @@ static void add_irp_to_queue( struct dev
     irp->thread = thread ? (struct thread *)grab_object( thread ) : NULL;
     if (irp->file) list_add_tail( &irp->file->requests, &irp->dev_entry );
     list_add_tail( &manager->requests, &irp->mgr_entry );
-    if (list_head( &manager->requests ) == &irp->mgr_entry) signal_sync( manager->sync );
+    if (list_head( &manager->requests ) == &irp->mgr_entry) wake_up( &manager->obj, 0 );  /* first one */
 }
 
 static struct object *device_open_file( struct object *obj, unsigned int access,
@@ -753,7 +755,6 @@ struct object *create_unix_device( struc
 /* terminate requests when the underlying device is deleted */
 static void delete_file( struct device_file *file )
 {
-    struct device_manager *manager = file->device->manager;
     struct irp_call *irp, *next;
 
     /* the pending requests may be the only thing holding a reference to the file */
@@ -762,11 +763,13 @@ static void delete_file( struct device_f
     /* terminate all pending requests */
     LIST_FOR_EACH_ENTRY_SAFE( irp, next, &file->requests, struct irp_call, dev_entry )
     {
+        if (do_esync() && file->device->manager && list_empty( &file->device->manager->requests ))
+            esync_clear( file->device->manager->esync_fd );
+
         list_remove( &irp->mgr_entry );
         set_irp_result( irp, STATUS_FILE_DELETED, NULL, 0, 0 );
     }
 
-    if (list_empty( &manager->requests )) reset_sync( manager->sync );
     release_object( file );
 }
 
@@ -791,11 +794,18 @@ static void device_manager_dump( struct
     fprintf( stderr, "Device manager\n" );
 }
 
-static struct object *device_manager_get_sync( struct object *obj )
+static int device_manager_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct device_manager *manager = (struct device_manager *)obj;
-    assert( obj->ops == &device_manager_ops );
-    return grab_object( manager->sync );
+
+    return !list_empty( &manager->requests );
+}
+
+static int device_manager_get_esync_fd( struct object *obj, enum esync_type *type )
+{
+    struct device_manager *manager = (struct device_manager *)obj;
+    *type = ESYNC_MANUAL_SERVER;
+    return manager->esync_fd;
 }
 
 static void device_manager_destroy( struct object *obj )
@@ -833,7 +843,8 @@ static void device_manager_destroy( stru
         release_object( irp );
     }
 
-    if (manager->sync) release_object( manager->sync );
+    if (do_esync())
+        close( manager->esync_fd );
 }
 
 static struct device_manager *create_device_manager(void)
@@ -842,17 +853,13 @@ static struct device_manager *create_dev
 
     if ((manager = alloc_object( &device_manager_ops )))
     {
-        manager->sync         = NULL;
         manager->current_call = NULL;
         list_init( &manager->devices );
         list_init( &manager->requests );
         wine_rb_init( &manager->kernel_objects, compare_kernel_object );
 
-        if (!(manager->sync = create_internal_sync( 1, 0 )))
-        {
-            release_object( manager );
-            return NULL;
-        }
+        if (do_esync())
+            manager->esync_fd = esync_create_fd( 0, 0 );
     }
     return manager;
 }
@@ -1039,11 +1046,12 @@ DECL_HANDLER(get_next_device_request)
                 }
                 list_remove( &irp->mgr_entry );
                 list_init( &irp->mgr_entry );
-                if (list_empty( &manager->requests )) reset_sync( manager->sync );
-
                 /* we already own the object if it's only on manager queue */
                 if (irp->file) grab_object( irp );
                 manager->current_call = irp;
+
+                if (do_esync() && list_empty( &manager->requests ))
+                    esync_clear( manager->esync_fd );
             }
             else close_handle( current->process, reply->next );
         }
diff -ruN --show-c-function server/directory.c server/directory.c
--- server/directory.c	2025-10-21 17:44:36.355168673 -0700
+++ server/directory.c	2025-10-24 16:11:42.397715316 -0700
@@ -69,10 +69,10 @@ static const struct object_ops object_ty
     no_add_queue,                 /* add_queue */
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
+    NULL,                         /* get_esync_fd */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-    default_get_sync,             /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
@@ -120,10 +120,10 @@ static const struct object_ops directory
     no_add_queue,                 /* add_queue */
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
+    NULL,                         /* get_esync_fd */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-    default_get_sync,             /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
diff -ruN --show-c-function server/esync.c server/esync.c
--- server/esync.c	1969-12-31 16:00:00.000000000 -0800
+++ server/esync.c	2025-10-24 16:11:42.420928197 -0700
@@ -0,0 +1,588 @@
+/*
+ * eventfd-based synchronization objects
+ *
+ * Copyright (C) 2018 Zebediah Figura
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
+ */
+
+#include "config.h"
+
+
+#include <fcntl.h>
+#include <stdio.h>
+#include <stdarg.h>
+#ifdef HAVE_SYS_EVENTFD_H
+# include <sys/eventfd.h>
+#endif
+#include <sys/mman.h>
+#ifdef HAVE_SYS_STAT_H
+# include <sys/stat.h>
+#endif
+#include <unistd.h>
+
+#include "ntstatus.h"
+#define WIN32_NO_STATUS
+#include "windef.h"
+#include "winternl.h"
+
+#include "handle.h"
+#include "request.h"
+#include "file.h"
+#include "esync.h"
+
+int do_esync(void)
+{
+#ifdef HAVE_SYS_EVENTFD_H
+    static int do_esync_cached = -1;
+
+    if (do_esync_cached == -1)
+        do_esync_cached = getenv("WINEESYNC") && atoi(getenv("WINEESYNC"));
+
+    return do_esync_cached;
+#else
+    return 0;
+#endif
+}
+
+static char shm_name[29];
+static int shm_fd;
+static off_t shm_size;
+static void **shm_addrs;
+static int shm_addrs_size;  /* length of the allocated shm_addrs array */
+static long pagesize;
+
+static void shm_cleanup(void)
+{
+    close( shm_fd );
+    if (shm_unlink( shm_name ) == -1)
+        perror( "shm_unlink" );
+}
+
+void esync_init(void)
+{
+    struct stat st;
+
+    if (fstat( config_dir_fd, &st ) == -1)
+        fatal_error( "cannot stat config dir\n" );
+
+    if (st.st_ino != (unsigned long)st.st_ino)
+        sprintf( shm_name, "/wine-%lx%08lx-esync", (unsigned long)((unsigned long long)st.st_ino >> 32), (unsigned long)st.st_ino );
+    else
+        sprintf( shm_name, "/wine-%lx-esync", (unsigned long)st.st_ino );
+
+    shm_unlink( shm_name );
+
+    shm_fd = shm_open( shm_name, O_RDWR | O_CREAT | O_EXCL, 0644 );
+    if (shm_fd == -1)
+        perror( "shm_open" );
+
+    pagesize = sysconf( _SC_PAGESIZE );
+
+    shm_addrs = calloc( 128, sizeof(shm_addrs[0]) );
+    shm_addrs_size = 128;
+
+    shm_size = pagesize;
+    if (ftruncate( shm_fd, shm_size ) == -1)
+        perror( "ftruncate" );
+
+    fprintf( stderr, "esync: up and running.\n" );
+
+    atexit( shm_cleanup );
+}
+
+static struct list mutex_list = LIST_INIT(mutex_list);
+
+struct esync
+{
+    struct object   obj;            /* object header */
+    int             fd;             /* eventfd file descriptor */
+    enum esync_type type;
+    unsigned int    shm_idx;        /* index into the shared memory section */
+    struct list     mutex_entry;    /* entry in the mutex list (if applicable) */
+};
+
+static void esync_dump( struct object *obj, int verbose );
+static int esync_get_esync_fd( struct object *obj, enum esync_type *type );
+static unsigned int esync_map_access( struct object *obj, unsigned int access );
+static void esync_destroy( struct object *obj );
+
+const struct object_ops esync_ops =
+{
+    sizeof(struct esync),      /* size */
+    &no_type,                  /* type */
+    esync_dump,                /* dump */
+    no_add_queue,              /* add_queue */
+    NULL,                      /* remove_queue */
+    NULL,                      /* signaled */
+    esync_get_esync_fd,        /* get_esync_fd */
+    NULL,                      /* satisfied */
+    no_signal,                 /* signal */
+    no_get_fd,                 /* get_fd */
+    esync_map_access,          /* map_access */
+    default_get_sd,            /* get_sd */
+    default_set_sd,            /* set_sd */
+    default_get_full_name,     /* get_full_name */
+    no_lookup_name,            /* lookup_name */
+    directory_link_name,       /* link_name */
+    default_unlink_name,       /* unlink_name */
+    no_open_file,              /* open_file */
+    no_kernel_obj_list,        /* get_kernel_obj_list */
+    no_close_handle,           /* close_handle */
+    esync_destroy              /* destroy */
+};
+
+static void esync_dump( struct object *obj, int verbose )
+{
+    struct esync *esync = (struct esync *)obj;
+    assert( obj->ops == &esync_ops );
+    fprintf( stderr, "esync fd=%d\n", esync->fd );
+}
+
+static int esync_get_esync_fd( struct object *obj, enum esync_type *type )
+{
+    struct esync *esync = (struct esync *)obj;
+    *type = esync->type;
+    return esync->fd;
+}
+
+static unsigned int esync_map_access( struct object *obj, unsigned int access )
+{
+    /* Sync objects have the same flags. */
+    if (access & GENERIC_READ)    access |= STANDARD_RIGHTS_READ | EVENT_QUERY_STATE;
+    if (access & GENERIC_WRITE)   access |= STANDARD_RIGHTS_WRITE | EVENT_MODIFY_STATE;
+    if (access & GENERIC_EXECUTE) access |= STANDARD_RIGHTS_EXECUTE | SYNCHRONIZE;
+    if (access & GENERIC_ALL)     access |= STANDARD_RIGHTS_ALL | EVENT_QUERY_STATE | EVENT_MODIFY_STATE;
+    return access & ~(GENERIC_READ | GENERIC_WRITE | GENERIC_EXECUTE | GENERIC_ALL);
+}
+
+static void esync_destroy( struct object *obj )
+{
+    struct esync *esync = (struct esync *)obj;
+    if (esync->type == ESYNC_MUTEX)
+        list_remove( &esync->mutex_entry );
+    close( esync->fd );
+}
+
+static int type_matches( enum esync_type type1, enum esync_type type2 )
+{
+    return (type1 == type2) ||
+           ((type1 == ESYNC_AUTO_EVENT || type1 == ESYNC_MANUAL_EVENT) &&
+            (type2 == ESYNC_AUTO_EVENT || type2 == ESYNC_MANUAL_EVENT));
+}
+
+static void *get_shm( unsigned int idx )
+{
+    int entry  = (idx * 8) / pagesize;
+    int offset = (idx * 8) % pagesize;
+
+    if (entry >= shm_addrs_size)
+    {
+        int new_size = max(shm_addrs_size * 2, entry + 1);
+
+        if (!(shm_addrs = realloc( shm_addrs, new_size * sizeof(shm_addrs[0]) )))
+            fprintf( stderr, "esync: couldn't expand shm_addrs array to size %d\n", entry + 1 );
+
+        memset( shm_addrs + shm_addrs_size, 0, (new_size - shm_addrs_size) * sizeof(shm_addrs[0]) );
+
+        shm_addrs_size = new_size;
+    }
+
+    if (!shm_addrs[entry])
+    {
+        void *addr = mmap( NULL, pagesize, PROT_READ | PROT_WRITE, MAP_SHARED, shm_fd, entry * pagesize );
+        if (addr == (void *)-1)
+        {
+            fprintf( stderr, "esync: failed to map page %d (offset %#lx): ", entry, entry * pagesize );
+            perror( "mmap" );
+        }
+
+        if (debug_level)
+            fprintf( stderr, "esync: Mapping page %d at %p.\n", entry, addr );
+
+        if (__sync_val_compare_and_swap( &shm_addrs[entry], 0, addr ))
+            munmap( addr, pagesize ); /* someone beat us to it */
+    }
+
+    return (void *)((unsigned long)shm_addrs[entry] + offset);
+}
+
+struct semaphore
+{
+    int max;
+    int count;
+};
+C_ASSERT(sizeof(struct semaphore) == 8);
+
+struct mutex
+{
+    DWORD tid;
+    int count;    /* recursion count */
+};
+C_ASSERT(sizeof(struct mutex) == 8);
+
+struct event
+{
+    int signaled;
+    int locked;
+};
+C_ASSERT(sizeof(struct event) == 8);
+
+struct esync *create_esync( struct object *root, const struct unicode_str *name,
+                            unsigned int attr, int initval, int max, enum esync_type type,
+                            const struct security_descriptor *sd )
+{
+#ifdef HAVE_SYS_EVENTFD_H
+    struct esync *esync;
+
+    if ((esync = create_named_object( root, &esync_ops, name, attr, sd )))
+    {
+        if (get_error() != STATUS_OBJECT_NAME_EXISTS)
+        {
+            int flags = EFD_CLOEXEC | EFD_NONBLOCK;
+
+            if (type == ESYNC_SEMAPHORE)
+                flags |= EFD_SEMAPHORE;
+
+            /* initialize it if it didn't already exist */
+            esync->fd = eventfd( initval, flags );
+            if (esync->fd == -1)
+            {
+                perror( "eventfd" );
+                file_set_error();
+                release_object( esync );
+                return NULL;
+            }
+            esync->type = type;
+
+            /* Use the fd as index, since that'll be unique across all
+             * processes, but should hopefully end up also allowing reuse. */
+            esync->shm_idx = esync->fd + 1; /* we keep index 0 reserved */
+            while (esync->shm_idx * 8 >= shm_size)
+            {
+                /* Better expand the shm section. */
+                shm_size += pagesize;
+                if (ftruncate( shm_fd, shm_size ) == -1)
+                {
+                    fprintf( stderr, "esync: couldn't expand %s to size %ld: ",
+                             shm_name, (long)shm_size );
+                    perror( "ftruncate" );
+                }
+            }
+
+            /* Initialize the shared memory portion. We want to do this on the
+             * server side to avoid a potential though unlikely race whereby
+             * the same object is opened and used between the time it's created
+             * and the time its shared memory portion is initialized. */
+            switch (type)
+            {
+            case ESYNC_SEMAPHORE:
+            {
+                struct semaphore *semaphore = get_shm( esync->shm_idx );
+                semaphore->max = max;
+                semaphore->count = initval;
+                break;
+            }
+            case ESYNC_AUTO_EVENT:
+            case ESYNC_MANUAL_EVENT:
+            {
+                struct event *event = get_shm( esync->shm_idx );
+                event->signaled = initval ? 1 : 0;
+                event->locked = 0;
+                break;
+            }
+            case ESYNC_MUTEX:
+            {
+                struct mutex *mutex = get_shm( esync->shm_idx );
+                mutex->tid = initval ? 0 : current->id;
+                mutex->count = initval ? 0 : 1;
+                list_add_tail( &mutex_list, &esync->mutex_entry );
+                break;
+            }
+            default:
+                assert( 0 );
+            }
+        }
+        else
+        {
+            /* validate the type */
+            if (!type_matches( type, esync->type ))
+            {
+                release_object( &esync->obj );
+                set_error( STATUS_OBJECT_TYPE_MISMATCH );
+                return NULL;
+            }
+        }
+    }
+    return esync;
+#else
+    /* FIXME: Provide a fallback implementation using pipe(). */
+    set_error( STATUS_NOT_IMPLEMENTED );
+    return NULL;
+#endif
+}
+
+/* Create a file descriptor for an existing handle.
+ * Caller must close the handle when it's done; it's not linked to an esync
+ * server object in any way. */
+int esync_create_fd( int initval, int flags )
+{
+#ifdef HAVE_SYS_EVENTFD_H
+    int fd;
+
+    fd = eventfd( initval, flags | EFD_CLOEXEC | EFD_NONBLOCK );
+    if (fd == -1)
+        perror( "eventfd" );
+
+    return fd;
+#else
+    return -1;
+#endif
+}
+
+/* Wake up a specific fd. */
+void esync_wake_fd( int fd )
+{
+    static const uint64_t value = 1;
+
+    if (write( fd, &value, sizeof(value) ) == -1)
+        perror( "esync: write" );
+}
+
+/* Wake up a server-side esync object. */
+void esync_wake_up( struct object *obj )
+{
+    enum esync_type dummy;
+    int fd;
+
+    if (obj->ops->get_esync_fd)
+    {
+        fd = obj->ops->get_esync_fd( obj, &dummy );
+        esync_wake_fd( fd );
+    }
+}
+
+void esync_clear( int fd )
+{
+    uint64_t value;
+
+    /* we don't care about the return value */
+    read( fd, &value, sizeof(value) );
+}
+
+static inline void small_pause(void)
+{
+#ifdef __i386__
+    __asm__ __volatile__( "rep;nop" : : : "memory" );
+#else
+    __asm__ __volatile__( "" : : : "memory" );
+#endif
+}
+
+/* Server-side event support. */
+void esync_set_event( struct esync *esync )
+{
+    static const uint64_t value = 1;
+    struct event *event = get_shm( esync->shm_idx );
+
+    assert( esync->obj.ops == &esync_ops );
+    assert( event != NULL );
+
+    if (debug_level)
+        fprintf( stderr, "esync_set_event() fd=%d\n", esync->fd );
+
+    if (esync->type == ESYNC_MANUAL_EVENT)
+    {
+        /* Acquire the spinlock. */
+        while (__sync_val_compare_and_swap( &event->locked, 0, 1 ))
+            small_pause();
+    }
+
+    if (!__atomic_exchange_n( &event->signaled, 1, __ATOMIC_SEQ_CST ))
+    {
+        if (write( esync->fd, &value, sizeof(value) ) == -1)
+            perror( "esync: write" );
+    }
+
+    if (esync->type == ESYNC_MANUAL_EVENT)
+    {
+        /* Release the spinlock. */
+        event->locked = 0;
+    }
+}
+
+void esync_reset_event( struct esync *esync )
+{
+    static uint64_t value = 1;
+    struct event *event = get_shm( esync->shm_idx );
+
+    assert( esync->obj.ops == &esync_ops );
+    assert( event != NULL );
+
+    if (debug_level)
+        fprintf( stderr, "esync_reset_event() fd=%d\n", esync->fd );
+
+    if (esync->type == ESYNC_MANUAL_EVENT)
+    {
+        /* Acquire the spinlock. */
+        while (__sync_val_compare_and_swap( &event->locked, 0, 1 ))
+            small_pause();
+    }
+
+    /* Only bother signaling the fd if we weren't already signaled. */
+    if (__atomic_exchange_n( &event->signaled, 0, __ATOMIC_SEQ_CST ))
+    {
+        /* we don't care about the return value */
+        read( esync->fd, &value, sizeof(value) );
+    }
+
+    if (esync->type == ESYNC_MANUAL_EVENT)
+    {
+        /* Release the spinlock. */
+        event->locked = 0;
+    }
+}
+
+void esync_abandon_mutexes( struct thread *thread )
+{
+    struct esync *esync;
+
+    LIST_FOR_EACH_ENTRY( esync, &mutex_list, struct esync, mutex_entry )
+    {
+        struct mutex *mutex = get_shm( esync->shm_idx );
+
+        if (mutex->tid == thread->id)
+        {
+            if (debug_level)
+                fprintf( stderr, "esync_abandon_mutexes() fd=%d\n", esync->fd );
+            mutex->tid = ~0;
+            mutex->count = 0;
+            esync_wake_fd( esync->fd );
+        }
+    }
+}
+
+DECL_HANDLER(create_esync)
+{
+    struct esync *esync;
+    struct unicode_str name;
+    struct object *root;
+    const struct security_descriptor *sd;
+    const struct object_attributes *objattr = get_req_object_attributes( &sd, &name, &root );
+
+    if (!do_esync())
+    {
+        set_error( STATUS_NOT_IMPLEMENTED );
+        return;
+    }
+
+    if (!req->type)
+    {
+        set_error( STATUS_INVALID_PARAMETER );
+        return;
+    }
+
+    if (!objattr) return;
+
+    if ((esync = create_esync( root, &name, objattr->attributes, req->initval, req->max, req->type, sd )))
+    {
+        if (get_error() == STATUS_OBJECT_NAME_EXISTS)
+            reply->handle = alloc_handle( current->process, esync, req->access, objattr->attributes );
+        else
+            reply->handle = alloc_handle_no_access_check( current->process, esync,
+                                                          req->access, objattr->attributes );
+
+        reply->type = esync->type;
+        reply->shm_idx = esync->shm_idx;
+        send_client_fd( current->process, esync->fd, reply->handle );
+        release_object( esync );
+    }
+
+    if (root) release_object( root );
+}
+
+DECL_HANDLER(open_esync)
+{
+    struct unicode_str name = get_req_unicode_str();
+
+    reply->handle = open_object( current->process, req->rootdir, req->access,
+                                 &esync_ops, &name, req->attributes );
+
+    /* send over the fd */
+    if (reply->handle)
+    {
+        struct esync *esync;
+
+        if (!(esync = (struct esync *)get_handle_obj( current->process, reply->handle,
+                                                      0, &esync_ops )))
+            return;
+
+        if (!type_matches( req->type, esync->type ))
+        {
+            set_error( STATUS_OBJECT_TYPE_MISMATCH );
+            release_object( esync );
+            return;
+        }
+
+        reply->type = esync->type;
+        reply->shm_idx = esync->shm_idx;
+
+        send_client_fd( current->process, esync->fd, reply->handle );
+        release_object( esync );
+    }
+}
+
+/* Retrieve a file descriptor for an esync object which will be signaled by the
+ * server. The client should only read from (i.e. wait on) this object. */
+DECL_HANDLER(get_esync_fd)
+{
+    struct object *obj;
+    enum esync_type type;
+    int fd;
+
+    if (!(obj = get_handle_obj( current->process, req->handle, SYNCHRONIZE, NULL )))
+        return;
+
+    if (obj->ops->get_esync_fd)
+    {
+        fd = obj->ops->get_esync_fd( obj, &type );
+        reply->type = type;
+        if (obj->ops == &esync_ops)
+        {
+            struct esync *esync = (struct esync *)obj;
+            reply->shm_idx = esync->shm_idx;
+        }
+        else
+            reply->shm_idx = 0;
+        send_client_fd( current->process, fd, req->handle );
+    }
+    else
+    {
+        if (debug_level)
+        {
+            fprintf( stderr, "%04x: esync: can't wait on object: ", current->id );
+            obj->ops->dump( obj, 0 );
+        }
+        set_error( STATUS_NOT_IMPLEMENTED );
+    }
+
+    release_object( obj );
+}
+
+/* Return the fd used for waiting on user APCs. */
+DECL_HANDLER(get_esync_apc_fd)
+{
+    send_client_fd( current->process, current->esync_apc_fd, current->id );
+}
diff -ruN --show-c-function server/esync.h server/esync.h
--- server/esync.h	1969-12-31 16:00:00.000000000 -0800
+++ server/esync.h	2025-10-24 16:11:42.421062973 -0700
@@ -0,0 +1,35 @@
+/*
+ * eventfd-based synchronization objects
+ *
+ * Copyright (C) 2018 Zebediah Figura
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
+ */
+
+#include <unistd.h>
+
+extern int do_esync(void);
+void esync_init(void);
+int esync_create_fd( int initval, int flags );
+void esync_wake_fd( int fd );
+void esync_wake_up( struct object *obj );
+void esync_clear( int fd );
+
+struct esync;
+
+extern const struct object_ops esync_ops;
+void esync_set_event( struct esync *esync );
+void esync_reset_event( struct esync *esync );
+void esync_abandon_mutexes( struct thread *thread );
diff -ruN --show-c-function server/event.c server/event.c
--- server/event.c	2025-10-21 17:44:36.355168673 -0700
+++ server/event.c	2025-10-24 16:11:42.405278612 -0700
@@ -35,6 +35,7 @@
 #include "thread.h"
 #include "request.h"
 #include "security.h"
+#include "esync.h"
 
 static const WCHAR event_name[] = {'E','v','e','n','t'};
 
@@ -50,116 +51,20 @@ struct type_descr event_type =
     },
 };
 
-struct event_sync
-{
-    struct object  obj;             /* object header */
-    unsigned int   manual : 1;      /* is it a manual reset event? */
-    unsigned int   signaled : 1;    /* event has been signaled */
-};
-
-static void event_sync_dump( struct object *obj, int verbose );
-static int event_sync_signaled( struct object *obj, struct wait_queue_entry *entry );
-static void event_sync_satisfied( struct object *obj, struct wait_queue_entry *entry );
-static int event_sync_signal( struct object *obj, unsigned int access, int signal );
-
-static const struct object_ops event_sync_ops =
-{
-    sizeof(struct event_sync), /* size */
-    &no_type,                  /* type */
-    event_sync_dump,           /* dump */
-    add_queue,                 /* add_queue */
-    remove_queue,              /* remove_queue */
-    event_sync_signaled,       /* signaled */
-    event_sync_satisfied,      /* satisfied */
-    event_sync_signal,         /* signal */
-    no_get_fd,                 /* get_fd */
-    default_get_sync,          /* get_sync */
-    default_map_access,        /* map_access */
-    default_get_sd,            /* get_sd */
-    default_set_sd,            /* set_sd */
-    default_get_full_name,     /* get_full_name */
-    no_lookup_name,            /* lookup_name */
-    directory_link_name,       /* link_name */
-    default_unlink_name,       /* unlink_name */
-    no_open_file,              /* open_file */
-    no_kernel_obj_list,        /* get_kernel_obj_list */
-    no_close_handle,           /* close_handle */
-    no_destroy                 /* destroy */
-};
-
-static struct object *create_event_sync( int manual, int signaled )
-{
-    struct event_sync *event;
-
-    if (get_inproc_device_fd() >= 0) return (struct object *)create_inproc_event_sync( manual, signaled );
-
-    if (!(event = alloc_object( &event_sync_ops ))) return NULL;
-    event->manual   = manual;
-    event->signaled = signaled;
-
-    return &event->obj;
-}
-
-struct event_sync *create_server_internal_sync( int manual, int signaled )
-{
-    struct event_sync *event;
-
-    if (!(event = alloc_object( &event_sync_ops ))) return NULL;
-    event->manual   = manual;
-    event->signaled = signaled;
-
-    return event;
-}
-
-struct object *create_internal_sync( int manual, int signaled )
-{
-    if (get_inproc_device_fd() >= 0) return (struct object *)create_inproc_internal_sync( manual, signaled );
-    return (struct object *)create_server_internal_sync( manual, signaled );
-}
-
-static void event_sync_dump( struct object *obj, int verbose )
-{
-    struct event_sync *event = (struct event_sync *)obj;
-    assert( obj->ops == &event_sync_ops );
-    fprintf( stderr, "Event manual=%d signaled=%d\n",
-             event->manual, event->signaled );
-}
-
-static int event_sync_signaled( struct object *obj, struct wait_queue_entry *entry )
-{
-    struct event_sync *event = (struct event_sync *)obj;
-    assert( obj->ops == &event_sync_ops );
-    return event->signaled;
-}
-
-static void event_sync_satisfied( struct object *obj, struct wait_queue_entry *entry )
-{
-    struct event_sync *event = (struct event_sync *)obj;
-    assert( obj->ops == &event_sync_ops );
-    /* Reset if it's an auto-reset event */
-    if (!event->manual) event->signaled = 0;
-}
-
-static int event_sync_signal( struct object *obj, unsigned int access, int signal )
-{
-    struct event_sync *event = (struct event_sync *)obj;
-    assert( obj->ops == &event_sync_ops );
-
-    /* wake up all waiters if manual reset, a single one otherwise */
-    if ((event->signaled = !!signal)) wake_up( &event->obj, !event->manual );
-    return 1;
-}
-
 struct event
 {
-    struct object      obj;             /* object header */
-    struct object     *sync;            /* event sync object */
-    struct list        kernel_object;   /* list of kernel object pointers */
+    struct object  obj;             /* object header */
+    struct list    kernel_object;   /* list of kernel object pointers */
+    int            manual_reset;    /* is it a manual reset event? */
+    int            signaled;        /* event has been signaled */
+    int            esync_fd;        /* esync file descriptor */
 };
 
 static void event_dump( struct object *obj, int verbose );
-static struct object *event_get_sync( struct object *obj );
-static int event_signal( struct object *obj, unsigned int access, int signal );
+static int event_signaled( struct object *obj, struct wait_queue_entry *entry );
+static void event_satisfied( struct object *obj, struct wait_queue_entry *entry );
+static int event_get_esync_fd( struct object *obj, enum esync_type *type );
+static int event_signal( struct object *obj, unsigned int access);
 static struct list *event_get_kernel_obj_list( struct object *obj );
 static void event_destroy( struct object *obj );
 
@@ -168,13 +73,13 @@ static const struct object_ops event_ops
     sizeof(struct event),      /* size */
     &event_type,               /* type */
     event_dump,                /* dump */
-    NULL,                      /* add_queue */
-    NULL,                      /* remove_queue */
-    NULL,                      /* signaled */
-    NULL,                      /* satisfied */
+    add_queue,                 /* add_queue */
+    remove_queue,              /* remove_queue */
+    event_signaled,            /* signaled */
+    event_get_esync_fd,        /* get_esync_fd */
+    event_satisfied,           /* satisfied */
     event_signal,              /* signal */
     no_get_fd,                 /* get_fd */
-    event_get_sync,            /* get_sync */
     default_map_access,        /* map_access */
     default_get_sd,            /* get_sd */
     default_set_sd,            /* set_sd */
@@ -185,7 +90,7 @@ static const struct object_ops event_ops
     no_open_file,              /* open_file */
     event_get_kernel_obj_list, /* get_kernel_obj_list */
     no_close_handle,           /* close_handle */
-    event_destroy,             /* destroy */
+    event_destroy              /* destroy */
 };
 
 
@@ -219,10 +124,10 @@ static const struct object_ops keyed_eve
     add_queue,                   /* add_queue */
     remove_queue,                /* remove_queue */
     keyed_event_signaled,        /* signaled */
+    NULL,                        /* get_esync_fd */
     no_satisfied,                /* satisfied */
     no_signal,                   /* signal */
     no_get_fd,                   /* get_fd */
-    default_get_sync,            /* get_sync */
     default_map_access,          /* map_access */
     default_get_sd,              /* get_sd */
     default_set_sd,              /* set_sd */
@@ -248,14 +153,12 @@ struct event *create_event( struct objec
         if (get_error() != STATUS_OBJECT_NAME_EXISTS)
         {
             /* initialize it if it didn't already exist */
-            event->sync = NULL;
             list_init( &event->kernel_object );
+            event->manual_reset = manual_reset;
+            event->signaled     = initial_state;
 
-            if (!(event->sync = create_event_sync( manual_reset, initial_state )))
-            {
-                release_object( event );
-                return NULL;
-            }
+            if (do_esync())
+                event->esync_fd = esync_create_fd( initial_state, 0 );
         }
     }
     return event;
@@ -263,48 +166,89 @@ struct event *create_event( struct objec
 
 struct event *get_event_obj( struct process *process, obj_handle_t handle, unsigned int access )
 {
+    struct object *obj;
+    if (do_esync() && (obj = get_handle_obj( process, handle, access, &esync_ops)))
+        return (struct event *)obj; /* even though it's not an event */
+
     return (struct event *)get_handle_obj( process, handle, access, &event_ops );
 }
 
+static void pulse_event( struct event *event )
+{
+    event->signaled = 1;
+    /* wake up all waiters if manual reset, a single one otherwise */
+    wake_up( &event->obj, !event->manual_reset );
+    event->signaled = 0;
+}
+
 void set_event( struct event *event )
 {
-    signal_sync( event->sync );
+    if (do_esync() && event->obj.ops == &esync_ops)
+    {
+        esync_set_event( (struct esync *)event );
+        return;
+    }
+
+    event->signaled = 1;
+    /* wake up all waiters if manual reset, a single one otherwise */
+    wake_up( &event->obj, !event->manual_reset );
 }
 
 void reset_event( struct event *event )
 {
-    reset_sync( event->sync );
+    if (do_esync() && event->obj.ops == &esync_ops)
+    {
+        esync_reset_event( (struct esync *)event );
+        return;
+    }
+    event->signaled = 0;
+
+    if (do_esync())
+        esync_clear( event->esync_fd );
 }
 
 static void event_dump( struct object *obj, int verbose )
 {
     struct event *event = (struct event *)obj;
     assert( obj->ops == &event_ops );
-    event->sync->ops->dump( event->sync, verbose );
+    fprintf( stderr, "Event manual=%d signaled=%d\n",
+             event->manual_reset, event->signaled );
 }
 
-static struct object *event_get_sync( struct object *obj )
+static int event_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct event *event = (struct event *)obj;
     assert( obj->ops == &event_ops );
-    return grab_object( event->sync );
+    return event->signaled;
 }
 
-static int event_signal( struct object *obj, unsigned int access, int signal )
+static int event_get_esync_fd( struct object *obj, enum esync_type *type )
+{
+    struct event *event = (struct event *)obj;
+    *type = event->manual_reset ? ESYNC_MANUAL_SERVER : ESYNC_AUTO_SERVER;
+    return event->esync_fd;
+}
+
+static void event_satisfied( struct object *obj, struct wait_queue_entry *entry )
 {
     struct event *event = (struct event *)obj;
     assert( obj->ops == &event_ops );
+    /* Reset if it's an auto-reset event */
+    if (!event->manual_reset) event->signaled = 0;
+}
 
-    assert( event->sync->ops == &event_sync_ops ); /* never called with inproc syncs */
-    assert( signal == -1 ); /* always called from signal_object */
+static int event_signal( struct object *obj, unsigned int access )
+{
+    struct event *event = (struct event *)obj;
+    assert( obj->ops == &event_ops );
 
     if (!(access & EVENT_MODIFY_STATE))
     {
         set_error( STATUS_ACCESS_DENIED );
         return 0;
     }
-
-    return event_sync_signal( event->sync, 0, 1 );
+    set_event( event );
+    return 1;
 }
 
 static struct list *event_get_kernel_obj_list( struct object *obj )
@@ -316,9 +260,9 @@ static struct list *event_get_kernel_obj
 static void event_destroy( struct object *obj )
 {
     struct event *event = (struct event *)obj;
-    assert( obj->ops == &event_ops );
 
-    if (event->sync) release_object( event->sync );
+    if (do_esync())
+        close( event->esync_fd );
 }
 
 struct keyed_event *create_keyed_event( struct object *root, const struct unicode_str *name,
@@ -411,19 +355,14 @@ DECL_HANDLER(open_event)
 /* do an event operation */
 DECL_HANDLER(event_op)
 {
-    struct event_sync *sync;
     struct event *event;
 
     if (!(event = get_event_obj( current->process, req->handle, EVENT_MODIFY_STATE ))) return;
-    assert( event->sync->ops == &event_sync_ops ); /* never called with inproc syncs */
-    sync = (struct event_sync *)event->sync;
-
-    reply->state = sync->signaled;
+    reply->state = event->signaled;
     switch(req->op)
     {
     case PULSE_EVENT:
-        set_event( event );
-        reset_event( event );
+        pulse_event( event );
         break;
     case SET_EVENT:
         set_event( event );
@@ -441,15 +380,12 @@ DECL_HANDLER(event_op)
 /* return details about the event */
 DECL_HANDLER(query_event)
 {
-    struct event_sync *sync;
     struct event *event;
 
     if (!(event = get_event_obj( current->process, req->handle, EVENT_QUERY_STATE ))) return;
-    assert( event->sync->ops == &event_sync_ops ); /* never called with inproc syncs */
-    sync = (struct event_sync *)event->sync;
 
-    reply->manual_reset = sync->manual;
-    reply->state = sync->signaled;
+    reply->manual_reset = event->manual_reset;
+    reply->state = event->signaled;
 
     release_object( event );
 }
diff -ruN --show-c-function server/fd.c server/fd.c
--- server/fd.c	2025-10-21 17:44:36.355168673 -0700
+++ server/fd.c	2025-10-24 16:11:42.420440892 -0700
@@ -94,6 +94,7 @@
 #include "handle.h"
 #include "process.h"
 #include "request.h"
+#include "esync.h"
 
 #include "winternl.h"
 #include "winioctl.h"
@@ -129,7 +130,6 @@ struct fd
 {
     struct object        obj;         /* object header */
     const struct fd_ops *fd_ops;      /* file descriptor operations */
-    struct object       *sync;        /* sync object for wait/signal */
     struct inode        *inode;       /* inode that this fd belongs to */
     struct list          inode_entry; /* entry in inode fd list */
     struct closed_fd    *closed;      /* structure to store the unix fd at destroy time */
@@ -146,6 +146,7 @@ struct fd
     int                  unix_fd;     /* unix file descriptor */
     unsigned int         no_fd_status;/* status to return when unix_fd is -1 */
     unsigned int         cacheable :1;/* can the fd be cached on the client side? */
+    unsigned int         signaled :1; /* is the fd signaled? */
     unsigned int         fs_locks :1; /* can we use filesystem locks for this fd? */
     int                  poll_index;  /* index of fd in poll array */
     struct async_queue   read_q;      /* async readers of this fd */
@@ -154,10 +155,10 @@ struct fd
     struct completion   *completion;  /* completion object attached to this fd */
     apc_param_t          comp_key;    /* completion key to set in completion events */
     unsigned int         comp_flags;  /* completion flags */
+    int                  esync_fd;    /* esync file descriptor */
 };
 
 static void fd_dump( struct object *obj, int verbose );
-static struct object *fd_get_sync( struct object *obj );
 static void fd_destroy( struct object *obj );
 
 static const struct object_ops fd_ops =
@@ -165,13 +166,13 @@ static const struct object_ops fd_ops =
     sizeof(struct fd),        /* size */
     &no_type,                 /* type */
     fd_dump,                  /* dump */
-    NULL,                     /* add_queue */
+    no_add_queue,             /* add_queue */
     NULL,                     /* remove_queue */
     NULL,                     /* signaled */
+    NULL,                     /* get_esync_fd */
     NULL,                     /* satisfied */
     no_signal,                /* signal */
     no_get_fd,                /* get_fd */
-    fd_get_sync,              /* get_sync */
     default_map_access,       /* map_access */
     default_get_sd,           /* get_sd */
     default_set_sd,           /* set_sd */
@@ -210,10 +211,10 @@ static const struct object_ops device_op
     no_add_queue,             /* add_queue */
     NULL,                     /* remove_queue */
     NULL,                     /* signaled */
+    NULL,                     /* get_esync_fd */
     NULL,                     /* satisfied */
     no_signal,                /* signal */
     no_get_fd,                /* get_fd */
-    default_get_sync,         /* get_sync */
     default_map_access,       /* map_access */
     default_get_sd,           /* get_sd */
     default_set_sd,           /* set_sd */
@@ -251,10 +252,10 @@ static const struct object_ops inode_ops
     no_add_queue,             /* add_queue */
     NULL,                     /* remove_queue */
     NULL,                     /* signaled */
+    NULL,                     /* get_esync_fd */
     NULL,                     /* satisfied */
     no_signal,                /* signal */
     no_get_fd,                /* get_fd */
-    default_get_sync,         /* get_sync */
     default_map_access,       /* map_access */
     default_get_sd,           /* get_sd */
     default_set_sd,           /* set_sd */
@@ -273,7 +274,6 @@ static const struct object_ops inode_ops
 struct file_lock
 {
     struct object       obj;         /* object header */
-    struct object      *sync;        /* sync object for wait/signal */
     struct fd          *fd;          /* fd owning this lock */
     struct list         fd_entry;    /* entry in list of locks on a given fd */
     struct list         inode_entry; /* entry in inode list of locks */
@@ -285,21 +285,20 @@ struct file_lock
 };
 
 static void file_lock_dump( struct object *obj, int verbose );
-static struct object *file_lock_get_sync( struct object *obj );
-static void file_lock_destroy( struct object *obj );
+static int file_lock_signaled( struct object *obj, struct wait_queue_entry *entry );
 
 static const struct object_ops file_lock_ops =
 {
     sizeof(struct file_lock),   /* size */
     &no_type,                   /* type */
     file_lock_dump,             /* dump */
-    NULL,                       /* add_queue */
-    NULL,                       /* remove_queue */
-    NULL,                       /* signaled */
-    NULL,                       /* satisfied */
+    add_queue,                  /* add_queue */
+    remove_queue,               /* remove_queue */
+    file_lock_signaled,         /* signaled */
+    NULL,                       /* get_esync_fd */
+    no_satisfied,               /* satisfied */
     no_signal,                  /* signal */
     no_get_fd,                  /* get_fd */
-    file_lock_get_sync,         /* get_sync */
     default_map_access,         /* map_access */
     default_get_sd,             /* get_sd */
     default_set_sd,             /* set_sd */
@@ -310,7 +309,7 @@ static const struct object_ops file_lock
     no_open_file,               /* open_file */
     no_kernel_obj_list,         /* get_kernel_obj_list */
     no_close_handle,            /* close_handle */
-    file_lock_destroy,          /* destroy */
+    no_destroy                  /* destroy */
 };
 
 
@@ -1243,18 +1242,11 @@ static void file_lock_dump( struct objec
     fprintf( stderr, "\n" );
 }
 
-static struct object *file_lock_get_sync( struct object *obj )
-{
-    struct file_lock *lock = (struct file_lock *)obj;
-    assert( obj->ops == &file_lock_ops );
-    return grab_object( lock->sync );
-}
-
-static void file_lock_destroy( struct object *obj )
+static int file_lock_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct file_lock *lock = (struct file_lock *)obj;
-    assert( obj->ops == &file_lock_ops );
-    if (lock->sync) release_object( lock->sync );
+    /* lock is signaled if it has lost its owner */
+    return !lock->process;
 }
 
 /* set (or remove) a Unix lock if possible for the given range */
@@ -1434,24 +1426,22 @@ static struct file_lock *add_lock( struc
     struct file_lock *lock;
 
     if (!(lock = alloc_object( &file_lock_ops ))) return NULL;
-    lock->sync    = NULL;
     lock->shared  = shared;
     lock->start   = start;
     lock->end     = end;
     lock->fd      = fd;
     lock->process = current->process;
 
-    if (!(lock->sync = create_internal_sync( 1, 0 ))) goto error;
     /* now try to set a Unix lock */
-    if (!set_unix_lock( lock->fd, lock->start, lock->end, lock->shared ? F_RDLCK : F_WRLCK )) goto error;
+    if (!set_unix_lock( lock->fd, lock->start, lock->end, lock->shared ? F_RDLCK : F_WRLCK ))
+    {
+        release_object( lock );
+        return NULL;
+    }
     list_add_tail( &fd->locks, &lock->fd_entry );
     list_add_tail( &fd->inode->locks, &lock->inode_entry );
     list_add_tail( &lock->process->locks, &lock->proc_entry );
     return lock;
-
-error:
-    release_object( lock );
-    return NULL;
 }
 
 /* remove an existing lock */
@@ -1465,7 +1455,7 @@ static void remove_lock( struct file_loc
     if (remove_unix) remove_unix_locks( lock->fd, lock->start, lock->end );
     if (list_empty( &inode->locks )) inode_close_pending( inode, 1 );
     lock->process = NULL;
-    signal_sync( lock->sync );
+    wake_up( &lock->obj, 0 );
     release_object( lock );
 }
 
@@ -1572,12 +1562,6 @@ static void fd_dump( struct object *obj,
     fprintf( stderr, "\n" );
 }
 
-static struct object *fd_get_sync( struct object *obj )
-{
-    struct fd *fd = (struct fd *)obj;
-    return grab_object( fd->sync );
-}
-
 static void fd_destroy( struct object *obj )
 {
     struct fd *fd = (struct fd *)obj;
@@ -1602,7 +1586,9 @@ static void fd_destroy( struct object *o
         if (fd->unix_fd != -1) close( fd->unix_fd );
         free( fd->unix_name );
     }
-    if (fd->sync) release_object( fd->sync );
+
+    if (do_esync())
+        close( fd->esync_fd );
 }
 
 /* check if the desired access is possible without violating */
@@ -1700,7 +1686,6 @@ static struct fd *alloc_fd_object(void)
     if (!fd) return NULL;
 
     fd->fd_ops     = NULL;
-    fd->sync       = NULL;
     fd->user       = NULL;
     fd->inode      = NULL;
     fd->closed     = NULL;
@@ -1714,24 +1699,27 @@ static struct fd *alloc_fd_object(void)
     fd->nt_name    = NULL;
     fd->nt_namelen = 0;
     fd->cacheable  = 0;
+    fd->signaled   = 1;
     fd->fs_locks   = 1;
     fd->poll_index = -1;
     fd->completion = NULL;
     fd->comp_flags = 0;
+    fd->esync_fd   = -1;
     init_async_queue( &fd->read_q );
     init_async_queue( &fd->write_q );
     init_async_queue( &fd->wait_q );
     list_init( &fd->inode_entry );
     list_init( &fd->locks );
 
-    if (!(fd->sync = create_internal_sync( 1, 1 ))) goto error;
-    if ((fd->poll_index = add_poll_user( fd )) == -1) goto error;
+    if (do_esync())
+        fd->esync_fd = esync_create_fd( 1, 0 );
 
+    if ((fd->poll_index = add_poll_user( fd )) == -1)
+    {
+        release_object( fd );
+        return NULL;
+    }
     return fd;
-
-error:
-    release_object( fd );
-    return NULL;
 }
 
 /* allocate a pseudo fd object, for objects that need to behave like files but don't have a unix fd */
@@ -1742,7 +1730,6 @@ struct fd *alloc_pseudo_fd( const struct
     if (!fd) return NULL;
 
     fd->fd_ops     = fd_user_ops;
-    fd->sync       = NULL;
     fd->user       = user;
     fd->inode      = NULL;
     fd->closed     = NULL;
@@ -1756,22 +1743,21 @@ struct fd *alloc_pseudo_fd( const struct
     fd->nt_namelen = 0;
     fd->unix_fd    = -1;
     fd->cacheable  = 0;
+    fd->signaled   = 1;
     fd->fs_locks   = 0;
     fd->poll_index = -1;
     fd->completion = NULL;
     fd->comp_flags = 0;
     fd->no_fd_status = STATUS_BAD_DEVICE_TYPE;
+    fd->esync_fd   = -1;
     init_async_queue( &fd->read_q );
     init_async_queue( &fd->write_q );
     init_async_queue( &fd->wait_q );
     list_init( &fd->inode_entry );
     list_init( &fd->locks );
 
-    if (!(fd->sync = create_internal_sync( 1, 1 )))
-    {
-        release_object( fd );
-        return NULL;
-    }
+    if (do_esync())
+        fd->esync_fd = esync_create_fd( 0, 0 );
     return fd;
 }
 
@@ -2175,8 +2161,11 @@ int is_fd_removable( struct fd *fd )
 void set_fd_signaled( struct fd *fd, int signaled )
 {
     if (fd->comp_flags & FILE_SKIP_SET_EVENT_ON_HANDLE) return;
-    if (signaled) signal_sync( fd->sync );
-    else reset_sync( fd->sync );
+    fd->signaled = signaled;
+    if (signaled) wake_up( fd->user, 0 );
+
+    if (do_esync() && !signaled)
+        esync_clear( fd->esync_fd );
 }
 
 /* check if events are pending and if yes return which one(s) */
@@ -2193,13 +2182,13 @@ int check_fd_events( struct fd *fd, int
     return pfd.revents;
 }
 
-/* default get_sync() routine for objects that poll() on an fd */
-struct object *default_fd_get_sync( struct object *obj )
+/* default signaled() routine for objects that poll() on an fd */
+int default_fd_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct fd *fd = get_obj_fd( obj );
-    struct object *sync = get_obj_sync( &fd->obj );
+    int ret = fd->signaled;
     release_object( fd );
-    return sync;
+    return ret;
 }
 
 /* default get_full_name() routine for objects with an fd */
@@ -2218,6 +2207,15 @@ WCHAR *default_fd_get_full_name( struct
     return ret;
 }
 
+int default_fd_get_esync_fd( struct object *obj, enum esync_type *type )
+{
+    struct fd *fd = get_obj_fd( obj );
+    int ret = fd->esync_fd;
+    *type = ESYNC_MANUAL_SERVER;
+    release_object( fd );
+    return ret;
+}
+
 int default_fd_get_poll_events( struct fd *fd )
 {
     int events = 0;
diff -ruN --show-c-function server/file.c server/file.c
--- server/file.c	2025-10-21 17:44:36.355168673 -0700
+++ server/file.c	2025-10-24 16:11:42.398376992 -0700
@@ -91,13 +91,13 @@ static const struct object_ops file_ops
     sizeof(struct file),          /* size */
     &file_type,                   /* type */
     file_dump,                    /* dump */
-    NULL,                         /* add_queue */
-    NULL,                         /* remove_queue */
-    NULL,                         /* signaled */
-    NULL,                         /* satisfied */
+    add_queue,                    /* add_queue */
+    remove_queue,                 /* remove_queue */
+    default_fd_signaled,          /* signaled */
+    NULL,                         /* get_esync_fd */
+    no_satisfied,                 /* satisfied */
     no_signal,                    /* signal */
     file_get_fd,                  /* get_fd */
-    default_fd_get_sync,          /* get_sync */
     default_map_access,           /* map_access */
     file_get_sd,                  /* get_sd */
     file_set_sd,                  /* set_sd */
diff -ruN --show-c-function server/file.h server/file.h
--- server/file.h	2025-10-21 17:44:36.355781240 -0700
+++ server/file.h	2025-10-24 16:11:42.418432229 -0700
@@ -108,7 +108,8 @@ extern void set_fd_signaled( struct fd *
 extern char *dup_fd_name( struct fd *root, const char *name ) __WINE_DEALLOC(free) __WINE_MALLOC;
 extern void get_nt_name( struct fd *fd, struct unicode_str *name );
 
-extern struct object *default_fd_get_sync( struct object *obj );
+extern int default_fd_signaled( struct object *obj, struct wait_queue_entry *entry );
+extern int default_fd_get_esync_fd( struct object *obj, enum esync_type *type );
 extern WCHAR *default_fd_get_full_name( struct object *obj, data_size_t max, data_size_t *ret_len );
 extern int default_fd_get_poll_events( struct fd *fd );
 extern void default_poll_event( struct fd *fd, int event );
@@ -195,7 +196,7 @@ extern struct mapping *create_session_ma
 extern void set_session_mapping( struct mapping *mapping );
 
 extern session_shm_t *shared_session;
-extern volatile void *alloc_shared_object( mem_size_t shm_size );
+extern volatile void *alloc_shared_object(void);
 extern void free_shared_object( volatile void *object_shm );
 extern void invalidate_shared_object( volatile void *object_shm );
 extern struct obj_locator get_shared_object_locator( volatile void *object_shm );
diff -ruN --show-c-function server/handle.c server/handle.c
--- server/handle.c	2025-10-21 17:44:36.355781240 -0700
+++ server/handle.c	2025-10-24 16:11:42.398510495 -0700
@@ -126,10 +126,10 @@ static const struct object_ops handle_ta
     no_add_queue,                    /* add_queue */
     NULL,                            /* remove_queue */
     NULL,                            /* signaled */
+    NULL,                            /* get_esync_fd */
     NULL,                            /* satisfied */
     no_signal,                       /* signal */
     no_get_fd,                       /* get_fd */
-    default_get_sync,                /* get_sync */
     default_map_access,              /* map_access */
     default_get_sd,                  /* get_sd */
     default_set_sd,                  /* set_sd */
diff -ruN --show-c-function server/hook.c server/hook.c
--- server/hook.c	2025-10-21 17:44:36.355781240 -0700
+++ server/hook.c	2025-10-24 16:11:42.398677672 -0700
@@ -58,6 +58,10 @@ struct hook
     data_size_t         module_size;
 };
 
+#define WH_WINEVENT (WH_MAXHOOK+1)
+
+#define NB_HOOKS (WH_WINEVENT-WH_MINHOOK+1)
+
 struct hook_table
 {
     struct object obj;              /* object header */
@@ -76,10 +80,10 @@ static const struct object_ops hook_tabl
     no_add_queue,                 /* add_queue */
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
+    NULL,                         /* get_esync_fd */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-    default_get_sync,             /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
diff -ruN --show-c-function server/inproc_sync.c server/inproc_sync.c
--- server/inproc_sync.c	2025-10-21 17:44:36.355781240 -0700
+++ server/inproc_sync.c	1969-12-31 16:00:00.000000000 -0800
@@ -1,307 +0,0 @@
-/*
- * In-process synchronization primitives
- *
- * Copyright (C) 2021-2022 Elizabeth Figura for CodeWeavers
- *
- * This library is free software; you can redistribute it and/or
- * modify it under the terms of the GNU Lesser General Public
- * License as published by the Free Software Foundation; either
- * version 2.1 of the License, or (at your option) any later version.
- *
- * This library is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * Lesser General Public License for more details.
- *
- * You should have received a copy of the GNU Lesser General Public
- * License along with this library; if not, write to the Free Software
- * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
- */
-
-#include "config.h"
-
-#include <assert.h>
-#include <stdint.h>
-#include <stdio.h>
-
-#include "ntstatus.h"
-#define WIN32_NO_STATUS
-#include "winternl.h"
-
-#include "file.h"
-#include "handle.h"
-#include "request.h"
-#include "thread.h"
-#include "user.h"
-
-#ifdef HAVE_LINUX_NTSYNC_H
-# include <linux/ntsync.h>
-#endif
-
-#ifdef NTSYNC_IOC_EVENT_READ
-
-#include <fcntl.h>
-#include <sys/ioctl.h>
-#include <sys/stat.h>
-#include <unistd.h>
-
-int get_inproc_device_fd(void)
-{
-    static int fd = -2;
-    if (fd == -2) fd = open( "/dev/ntsync", O_CLOEXEC | O_RDONLY );
-    return fd;
-}
-
-struct inproc_sync
-{
-    struct object          obj;  /* object header */
-    enum inproc_sync_type  type;
-    int                    fd;
-    struct list            entry;
-};
-
-static struct list inproc_mutexes = LIST_INIT( inproc_mutexes );
-
-static void inproc_sync_dump( struct object *obj, int verbose );
-static int inproc_sync_signal( struct object *obj, unsigned int access, int signal );
-static void inproc_sync_destroy( struct object *obj );
-
-static const struct object_ops inproc_sync_ops =
-{
-    sizeof(struct inproc_sync), /* size */
-    &no_type,                   /* type */
-    inproc_sync_dump,           /* dump */
-    no_add_queue,               /* add_queue */
-    NULL,                       /* remove_queue */
-    NULL,                       /* signaled */
-    NULL,                       /* satisfied */
-    inproc_sync_signal,         /* signal */
-    no_get_fd,                  /* get_fd */
-    default_get_sync,           /* get_sync */
-    default_map_access,         /* map_access */
-    default_get_sd,             /* get_sd */
-    default_set_sd,             /* set_sd */
-    default_get_full_name,      /* get_full_name */
-    no_lookup_name,             /* lookup_name */
-    directory_link_name,        /* link_name */
-    default_unlink_name,        /* unlink_name */
-    no_open_file,               /* open_file */
-    no_kernel_obj_list,         /* get_kernel_obj_list */
-    no_close_handle,            /* close_handle */
-    inproc_sync_destroy,        /* destroy */
-};
-
-int get_inproc_sync_fd( struct inproc_sync *sync )
-{
-    if (!sync) return -1;
-    return sync->fd;
-}
-
-struct inproc_sync *create_inproc_internal_sync( int manual, int signaled )
-{
-    struct ntsync_event_args args = {.signaled = signaled, .manual = manual};
-    struct inproc_sync *event;
-
-    if (!(event = alloc_object( &inproc_sync_ops ))) return NULL;
-    event->type = INPROC_SYNC_INTERNAL;
-    event->fd   = ioctl( get_inproc_device_fd(), NTSYNC_IOC_CREATE_EVENT, &args );
-    list_init( &event->entry );
-
-    if (event->fd == -1)
-    {
-        set_error( STATUS_TOO_MANY_OPENED_FILES );
-        release_object( event );
-        return NULL;
-    }
-    return event;
-}
-
-struct inproc_sync *create_inproc_event_sync( int manual, int signaled )
-{
-    struct ntsync_event_args args = {.signaled = signaled, .manual = manual};
-    struct inproc_sync *event;
-
-    if (!(event = alloc_object( &inproc_sync_ops ))) return NULL;
-    event->type = INPROC_SYNC_EVENT;
-    event->fd   = ioctl( get_inproc_device_fd(), NTSYNC_IOC_CREATE_EVENT, &args );
-    list_init( &event->entry );
-
-    if (event->fd == -1)
-    {
-        set_error( STATUS_TOO_MANY_OPENED_FILES );
-        release_object( event );
-        return NULL;
-    }
-    return event;
-}
-
-struct inproc_sync *create_inproc_mutex_sync( thread_id_t owner, unsigned int count )
-{
-    struct ntsync_mutex_args args = {.owner = owner, .count = count};
-    struct inproc_sync *mutex;
-
-    if (!(mutex = alloc_object( &inproc_sync_ops ))) return NULL;
-    mutex->type = INPROC_SYNC_MUTEX;
-    mutex->fd   = ioctl( get_inproc_device_fd(), NTSYNC_IOC_CREATE_MUTEX, &args );
-    list_add_tail( &inproc_mutexes, &mutex->entry );
-
-    if (mutex->fd == -1)
-    {
-        set_error( STATUS_TOO_MANY_OPENED_FILES );
-        release_object( mutex );
-        return NULL;
-    }
-    return mutex;
-}
-
-struct inproc_sync *create_inproc_semaphore_sync( unsigned int initial, unsigned int max )
-{
-    struct ntsync_sem_args args = {.count = initial, .max = max};
-    struct inproc_sync *sem;
-
-    if (!(sem = alloc_object( &inproc_sync_ops ))) return NULL;
-    sem->type = INPROC_SYNC_SEMAPHORE;
-    sem->fd   = ioctl( get_inproc_device_fd(), NTSYNC_IOC_CREATE_SEM, &args );
-    list_init( &sem->entry );
-
-    if (sem->fd == -1)
-    {
-        set_error( STATUS_TOO_MANY_OPENED_FILES );
-        release_object( sem );
-        return NULL;
-    }
-    return sem;
-}
-
-static void inproc_sync_dump( struct object *obj, int verbose )
-{
-    struct inproc_sync *sync = (struct inproc_sync *)obj;
-    assert( obj->ops == &inproc_sync_ops );
-    fprintf( stderr, "Inproc sync type=%d, fd=%d\n", sync->type, sync->fd );
-}
-
-void signal_inproc_sync( struct inproc_sync *sync )
-{
-    __u32 count;
-    if (debug_level) fprintf( stderr, "set_inproc_event %d\n", sync->fd );
-    ioctl( sync->fd, NTSYNC_IOC_EVENT_SET, &count );
-}
-
-void reset_inproc_sync( struct inproc_sync *sync )
-{
-    __u32 count;
-    if (debug_level) fprintf( stderr, "reset_inproc_event %d\n", sync->fd );
-    ioctl( sync->fd, NTSYNC_IOC_EVENT_RESET, &count );
-}
-
-static int inproc_sync_signal( struct object *obj, unsigned int access, int signal )
-{
-    struct inproc_sync *sync = (struct inproc_sync *)obj;
-    assert( obj->ops == &inproc_sync_ops );
-
-    assert( sync->type == INPROC_SYNC_INTERNAL || sync->type == INPROC_SYNC_EVENT ); /* never called for mutex / semaphore */
-    assert( signal == 0 || signal == 1 ); /* never called from signal_object */
-
-    if (signal) signal_inproc_sync( sync );
-    else reset_inproc_sync( sync );
-    return 1;
-}
-
-static void inproc_sync_destroy( struct object *obj )
-{
-    struct inproc_sync *sync = (struct inproc_sync *)obj;
-    assert( obj->ops == &inproc_sync_ops );
-    list_remove( &sync->entry );
-    close( sync->fd );
-}
-
-void abandon_inproc_mutexes( thread_id_t tid )
-{
-    struct inproc_sync *mutex;
-
-    LIST_FOR_EACH_ENTRY( mutex, &inproc_mutexes, struct inproc_sync, entry )
-        ioctl( mutex->fd, NTSYNC_IOC_MUTEX_KILL, &tid );
-}
-
-static int get_obj_inproc_sync( struct object *obj, int *type )
-{
-    struct object *sync;
-    int fd = -1;
-
-    if (!(sync = get_obj_sync( obj ))) return -1;
-    if (sync->ops == &inproc_sync_ops)
-    {
-        struct inproc_sync *inproc = (struct inproc_sync *)sync;
-        *type = inproc->type;
-        fd = inproc->fd;
-    }
-
-    release_object( sync );
-    return fd;
-}
-
-#else /* NTSYNC_IOC_EVENT_READ */
-
-int get_inproc_device_fd(void)
-{
-    return -1;
-}
-
-int get_inproc_sync_fd( struct inproc_sync *sync )
-{
-    return -1;
-}
-
-struct inproc_sync *create_inproc_internal_sync( int manual, int signaled )
-{
-    return NULL;
-}
-
-struct inproc_sync *create_inproc_event_sync( int manual, int signaled )
-{
-    return NULL;
-}
-
-struct inproc_sync *create_inproc_mutex_sync( thread_id_t owner, unsigned int count )
-{
-    return NULL;
-}
-
-struct inproc_sync *create_inproc_semaphore_sync( unsigned int initial, unsigned int max )
-{
-    return NULL;
-}
-
-void signal_inproc_sync( struct inproc_sync *sync )
-{
-}
-
-void reset_inproc_sync( struct inproc_sync *sync )
-{
-}
-
-void abandon_inproc_mutexes( thread_id_t tid )
-{
-}
-
-static int get_obj_inproc_sync( struct object *obj, int *type )
-{
-    return -1;
-}
-
-#endif /* NTSYNC_IOC_EVENT_READ */
-
-DECL_HANDLER(get_inproc_sync_fd)
-{
-    struct object *obj;
-    int fd;
-
-    if (!(obj = get_handle_obj( current->process, req->handle, 0, NULL ))) return;
-
-    reply->access = get_handle_access( current->process, req->handle );
-
-    if ((fd = get_obj_inproc_sync( obj, &reply->type )) < 0) set_error( STATUS_NOT_IMPLEMENTED );
-    else send_client_fd( current->process, fd, req->handle );
-
-    release_object( obj );
-}
diff -ruN --show-c-function server/mailslot.c server/mailslot.c
--- server/mailslot.c	2025-10-21 17:44:36.355781240 -0700
+++ server/mailslot.c	2025-10-24 16:11:42.398809493 -0700
@@ -79,13 +79,13 @@ static const struct object_ops mailslot_
     sizeof(struct mailslot),   /* size */
     &file_type,                /* type */
     mailslot_dump,             /* dump */
-    NULL,                      /* add_queue */
-    NULL,                      /* remove_queue */
-    NULL,                      /* signaled */
-    NULL,                      /* satisfied */
+    add_queue,                 /* add_queue */
+    remove_queue,              /* remove_queue */
+    default_fd_signaled,       /* signaled */
+    NULL,                      /* get_esync_fd */
+    no_satisfied,              /* satisfied */
     no_signal,                 /* signal */
     mailslot_get_fd,           /* get_fd */
-    default_fd_get_sync,       /* get_sync */
     mailslot_map_access,       /* map_access */
     default_get_sd,            /* get_sd */
     default_set_sd,            /* set_sd */
@@ -144,10 +144,10 @@ static const struct object_ops mail_writ
     no_add_queue,               /* add_queue */
     NULL,                       /* remove_queue */
     NULL,                       /* signaled */
+    NULL,                       /* get_esync_fd */
     NULL,                       /* satisfied */
     no_signal,                  /* signal */
     mail_writer_get_fd,         /* get_fd */
-    default_get_sync,           /* get_sync */
     mail_writer_map_access,     /* map_access */
     default_get_sd,             /* get_sd */
     default_set_sd,             /* set_sd */
@@ -210,10 +210,10 @@ static const struct object_ops mailslot_
     no_add_queue,                   /* add_queue */
     NULL,                           /* remove_queue */
     NULL,                           /* signaled */
+    NULL,                           /* get_esync_fd */
     no_satisfied,                   /* satisfied */
     no_signal,                      /* signal */
     no_get_fd,                      /* get_fd */
-    default_get_sync,               /* get_sync */
     default_map_access,             /* map_access */
     default_get_sd,                 /* get_sd */
     default_set_sd,                 /* set_sd */
@@ -238,13 +238,13 @@ static const struct object_ops mailslot_
     sizeof(struct mailslot_device_file),    /* size */
     &file_type,                             /* type */
     mailslot_device_file_dump,              /* dump */
-    NULL,                                   /* add_queue */
-    NULL,                                   /* remove_queue */
-    NULL,                                   /* signaled */
-    NULL,                                   /* satisfied */
+    add_queue,                              /* add_queue */
+    remove_queue,                           /* remove_queue */
+    default_fd_signaled,                    /* signaled */
+    NULL,                                   /* get_esync_fd */
+    no_satisfied,                           /* satisfied */
     no_signal,                              /* signal */
     mailslot_device_file_get_fd,            /* get_fd */
-    default_fd_get_sync,                    /* get_sync */
     default_map_access,                     /* map_access */
     default_get_sd,                         /* get_sd */
     default_set_sd,                         /* set_sd */
diff -ruN --show-c-function server/main.c server/main.c
--- server/main.c	2025-10-21 17:44:36.355781240 -0700
+++ server/main.c	2025-10-24 16:11:42.391670753 -0700
@@ -40,6 +40,7 @@
 #include "thread.h"
 #include "request.h"
 #include "unicode.h"
+#include "esync.h"
 
 /* command-line options */
 int debug_level = 0;
@@ -259,6 +260,9 @@ int main( int argc, char *argv[] )
     sock_init();
     open_master_socket();
 
+    if (do_esync())
+        esync_init();
+
     if (debug_level) fprintf( stderr, "wineserver: starting (pid=%ld)\n", (long) getpid() );
     set_current_time();
     init_signals();
diff -ruN --show-c-function server/Makefile.in server/Makefile.in
--- server/Makefile.in	2025-10-21 17:44:36.354932334 -0700
+++ server/Makefile.in	2025-10-24 16:11:42.391441507 -0700
@@ -12,12 +12,12 @@ SOURCES = \
 	debugger.c \
 	device.c \
 	directory.c \
+	esync.c \
 	event.c \
 	fd.c \
 	file.c \
 	handle.c \
 	hook.c \
-	inproc_sync.c \
 	mach.c \
 	mailslot.c \
 	main.c \
diff -ruN --show-c-function server/mapping.c server/mapping.c
--- server/mapping.c	2025-10-21 17:44:36.808791437 -0700
+++ server/mapping.c	2025-10-24 16:11:42.398989514 -0700
@@ -67,10 +67,10 @@ static const struct object_ops ranges_op
     no_add_queue,              /* add_queue */
     NULL,                      /* remove_queue */
     NULL,                      /* signaled */
+    NULL,                      /* get_esync_fd */
     NULL,                      /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
-    default_get_sync,          /* get_sync */
     default_map_access,        /* map_access */
     default_get_sd,            /* get_sd */
     default_set_sd,            /* set_sd */
@@ -104,10 +104,10 @@ static const struct object_ops shared_ma
     no_add_queue,              /* add_queue */
     NULL,                      /* remove_queue */
     NULL,                      /* signaled */
+    NULL,                      /* get_esync_fd */
     NULL,                      /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
-    default_get_sync,          /* get_sync */
     default_map_access,        /* map_access */
     default_get_sd,            /* get_sd */
     default_set_sd,            /* set_sd */
@@ -180,10 +180,10 @@ static const struct object_ops mapping_o
     no_add_queue,                /* add_queue */
     NULL,                        /* remove_queue */
     NULL,                        /* signaled */
+    NULL,                        /* get_esync_fd */
     NULL,                        /* satisfied */
     no_signal,                   /* signal */
     mapping_get_fd,              /* get_fd */
-    default_get_sync,            /* get_sync */
     default_map_access,          /* map_access */
     default_get_sd,              /* get_sd */
     default_set_sd,              /* set_sd */
@@ -244,7 +244,6 @@ struct session_object
 {
     struct list entry;      /* entry in the session free object list */
     mem_size_t offset;      /* offset of obj in the session shared mapping */
-    mem_size_t size;        /* size of obj in the session shared mapping */
     shared_object_t obj;    /* object actually shared with the client */
 };
 
@@ -1414,41 +1413,31 @@ static struct session_block *find_free_s
     return grow_session_mapping( size );
 }
 
-static struct session_object *find_free_session_object( mem_size_t size )
+volatile void *alloc_shared_object(void)
 {
     struct session_object *object;
+    struct list *ptr;
 
-    LIST_FOR_EACH_ENTRY( object, &session.free_objects, struct session_object, entry )
+    if ((ptr = list_head( &session.free_objects )))
     {
-        if (size == sizeof(*object) && object->size == size) return object;
-        if (size > sizeof(*object) && size <= object->size) return object;
-    }
-
-    return NULL;
-}
-
-volatile void *alloc_shared_object( mem_size_t shm_size )
-{
-    struct session_object *object;
-    mem_size_t size = sizeof(*object) - sizeof(object_shm_t) + max(shm_size, sizeof(object_shm_t));
-
-    if ((object = find_free_session_object( size )))
+        object = CONTAINING_RECORD( ptr, struct session_object, entry );
         list_remove( &object->entry );
+    }
     else
     {
+        mem_size_t size = sizeof(*object);
         struct session_block *block;
 
         if (!(block = find_free_session_block( size ))) return NULL;
         object = (struct session_object *)(block->data + block->used_size);
         object->offset = block->offset + (char *)&object->obj - block->data;
-        object->size = size;
         block->used_size += size;
     }
 
     SHARED_WRITE_BEGIN( &object->obj.shm, object_shm_t )
     {
         /* mark the object data as uninitialized */
-        mark_block_uninitialized( (void *)shared, shm_size );
+        mark_block_uninitialized( (void *)shared, sizeof(*shared) );
         CONTAINING_RECORD( shared, shared_object_t, shm )->id = ++session.last_object_id;
     }
     SHARED_WRITE_END;
@@ -1459,11 +1448,10 @@ volatile void *alloc_shared_object( mem_
 void free_shared_object( volatile void *object_shm )
 {
     struct session_object *object = CONTAINING_RECORD( object_shm, struct session_object, obj.shm );
-    mem_size_t shm_size = object->size - sizeof(*object) + sizeof(object_shm_t);
 
     SHARED_WRITE_BEGIN( &object->obj.shm, object_shm_t )
     {
-        mark_block_noaccess( (void *)shared, shm_size );
+        mark_block_noaccess( (void *)shared, sizeof(*shared) );
         CONTAINING_RECORD( shared, shared_object_t, shm )->id = 0;
     }
     SHARED_WRITE_END;
diff -ruN --show-c-function server/mutex.c server/mutex.c
--- server/mutex.c	2025-10-21 17:44:36.355781240 -0700
+++ server/mutex.c	2025-10-24 16:11:42.399168965 -0700
@@ -50,32 +50,33 @@ struct type_descr mutex_type =
     },
 };
 
-struct mutex_sync
+struct mutex
 {
-    struct object       obj;                /* object header */
-    struct thread      *owner;              /* mutex owner */
-    unsigned int        count;              /* recursion count */
-    int                 abandoned;          /* has it been abandoned? */
-    struct list         entry;              /* entry in owner thread mutex list */
+    struct object  obj;             /* object header */
+    struct thread *owner;           /* mutex owner */
+    unsigned int   count;           /* recursion count */
+    int            abandoned;       /* has it been abandoned? */
+    struct list    entry;           /* entry in owner thread mutex list */
 };
 
-static void mutex_sync_dump( struct object *obj, int verbose );
-static int mutex_sync_signaled( struct object *obj, struct wait_queue_entry *entry );
-static void mutex_sync_satisfied( struct object *obj, struct wait_queue_entry *entry );
-static void mutex_sync_destroy( struct object *obj );
-
-static const struct object_ops mutex_sync_ops =
-{
-    sizeof(struct mutex_sync), /* size */
-    &no_type,                  /* type */
-    mutex_sync_dump,           /* dump */
+static void mutex_dump( struct object *obj, int verbose );
+static int mutex_signaled( struct object *obj, struct wait_queue_entry *entry );
+static void mutex_satisfied( struct object *obj, struct wait_queue_entry *entry );
+static void mutex_destroy( struct object *obj );
+static int mutex_signal( struct object *obj, unsigned int access );
+
+static const struct object_ops mutex_ops =
+{
+    sizeof(struct mutex),      /* size */
+    &mutex_type,               /* type */
+    mutex_dump,                /* dump */
     add_queue,                 /* add_queue */
     remove_queue,              /* remove_queue */
-    mutex_sync_signaled,       /* signaled */
-    mutex_sync_satisfied,      /* satisfied */
-    no_signal,                 /* signal */
+    mutex_signaled,            /* signaled */
+    NULL,                      /* get_esync_fd */
+    mutex_satisfied,           /* satisfied */
+    mutex_signal,              /* signal */
     no_get_fd,                 /* get_fd */
-    default_get_sync,          /* get_sync */
     default_map_access,        /* map_access */
     default_get_sd,            /* get_sd */
     default_set_sd,            /* set_sd */
@@ -86,11 +87,12 @@ static const struct object_ops mutex_syn
     no_open_file,              /* open_file */
     no_kernel_obj_list,        /* get_kernel_obj_list */
     no_close_handle,           /* close_handle */
-    mutex_sync_destroy,        /* destroy */
+    mutex_destroy              /* destroy */
 };
 
+
 /* grab a mutex for a given thread */
-static void do_grab( struct mutex_sync *mutex, struct thread *thread )
+static void do_grab( struct mutex *mutex, struct thread *thread )
 {
     assert( !mutex->count || (mutex->owner == thread) );
 
@@ -104,106 +106,15 @@ static void do_grab( struct mutex_sync *
 }
 
 /* release a mutex once the recursion count is 0 */
-static int do_release( struct mutex_sync *mutex, struct thread *thread, int count )
-{
-    if (!mutex->count || (mutex->owner != thread))
-    {
-        set_error( STATUS_MUTANT_NOT_OWNED );
-        return 0;
-    }
-    if (!(mutex->count -= count))
-    {
-        /* remove the mutex from the thread list of owned mutexes */
-        list_remove( &mutex->entry );
-        mutex->owner = NULL;
-        wake_up( &mutex->obj, 0 );
-        release_object( mutex );
-    }
-    return 1;
-}
-
-static void mutex_sync_dump( struct object *obj, int verbose )
-{
-    struct mutex_sync *mutex = (struct mutex_sync *)obj;
-    assert( obj->ops == &mutex_sync_ops );
-    fprintf( stderr, "Mutex count=%u owner=%p\n", mutex->count, mutex->owner );
-}
-
-static void mutex_sync_destroy( struct object *obj )
+static void do_release( struct mutex *mutex )
 {
-    struct mutex_sync *mutex = (struct mutex_sync *)obj;
-    assert( obj->ops == &mutex_sync_ops );
     assert( !mutex->count );
-}
-
-static int mutex_sync_signaled( struct object *obj, struct wait_queue_entry *entry )
-{
-    struct mutex_sync *mutex = (struct mutex_sync *)obj;
-    assert( obj->ops == &mutex_sync_ops );
-    return (!mutex->count || (mutex->owner == get_wait_queue_thread( entry )));
-}
-
-static void mutex_sync_satisfied( struct object *obj, struct wait_queue_entry *entry )
-{
-    struct mutex_sync *mutex = (struct mutex_sync *)obj;
-    assert( obj->ops == &mutex_sync_ops );
-
-    do_grab( mutex, get_wait_queue_thread( entry ));
-    if (mutex->abandoned) make_wait_abandoned( entry );
-    mutex->abandoned = 0;
-}
-
-static struct object *create_mutex_sync( int owned )
-{
-    struct mutex_sync *mutex;
-
-    if (get_inproc_device_fd() >= 0) return (struct object *)create_inproc_mutex_sync( owned ? current->id : 0, owned ? 1 : 0 );
-
-    if (!(mutex = alloc_object( &mutex_sync_ops ))) return NULL;
-    mutex->count = 0;
+    /* remove the mutex from the thread list of owned mutexes */
+    list_remove( &mutex->entry );
     mutex->owner = NULL;
-    mutex->abandoned = 0;
-    if (owned) do_grab( mutex, current );
-
-    return &mutex->obj;
+    wake_up( &mutex->obj, 0 );
 }
 
-struct mutex
-{
-    struct object       obj;             /* object header */
-    struct object      *sync;            /* mutex sync object */
-};
-
-static void mutex_dump( struct object *obj, int verbose );
-static struct object *mutex_get_sync( struct object *obj );
-static int mutex_signal( struct object *obj, unsigned int access, int signal );
-static void mutex_destroy( struct object *obj );
-
-static const struct object_ops mutex_ops =
-{
-    sizeof(struct mutex),      /* size */
-    &mutex_type,               /* type */
-    mutex_dump,                /* dump */
-    NULL,                      /* add_queue */
-    NULL,                      /* remove_queue */
-    NULL,                      /* signaled */
-    NULL,                      /* satisfied */
-    mutex_signal,              /* signal */
-    no_get_fd,                 /* get_fd */
-    mutex_get_sync,            /* get_sync */
-    default_map_access,        /* map_access */
-    default_get_sd,            /* get_sd */
-    default_set_sd,            /* set_sd */
-    default_get_full_name,     /* get_full_name */
-    no_lookup_name,            /* lookup_name */
-    directory_link_name,       /* link_name */
-    default_unlink_name,       /* unlink_name */
-    no_open_file,              /* open_file */
-    no_kernel_obj_list,        /* get_kernel_obj_list */
-    no_close_handle,           /* close_handle */
-    mutex_destroy,             /* destroy */
-};
-
 static struct mutex *create_mutex( struct object *root, const struct unicode_str *name,
                                    unsigned int attr, int owned, const struct security_descriptor *sd )
 {
@@ -214,13 +125,10 @@ static struct mutex *create_mutex( struc
         if (get_error() != STATUS_OBJECT_NAME_EXISTS)
         {
             /* initialize it if it didn't already exist */
-            mutex->sync = NULL;
-
-            if (!(mutex->sync = create_mutex_sync( owned )))
-            {
-                release_object( mutex );
-                return NULL;
-            }
+            mutex->count = 0;
+            mutex->owner = NULL;
+            mutex->abandoned = 0;
+            if (owned) do_grab( mutex, current );
         }
     }
     return mutex;
@@ -232,50 +140,65 @@ void abandon_mutexes( struct thread *thr
 
     while ((ptr = list_head( &thread->mutex_list )) != NULL)
     {
-        struct mutex_sync *mutex = LIST_ENTRY( ptr, struct mutex_sync, entry );
+        struct mutex *mutex = LIST_ENTRY( ptr, struct mutex, entry );
         assert( mutex->owner == thread );
+        mutex->count = 0;
         mutex->abandoned = 1;
-        do_release( mutex, thread, mutex->count );
+        do_release( mutex );
     }
-
-    abandon_inproc_mutexes( thread->id );
 }
 
 static void mutex_dump( struct object *obj, int verbose )
 {
     struct mutex *mutex = (struct mutex *)obj;
     assert( obj->ops == &mutex_ops );
-    mutex->sync->ops->dump( mutex->sync, verbose );
+    fprintf( stderr, "Mutex count=%u owner=%p\n", mutex->count, mutex->owner );
 }
 
-static struct object *mutex_get_sync( struct object *obj )
+static int mutex_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct mutex *mutex = (struct mutex *)obj;
     assert( obj->ops == &mutex_ops );
-    return grab_object( mutex->sync );
+    return (!mutex->count || (mutex->owner == get_wait_queue_thread( entry )));
 }
 
-static int mutex_signal( struct object *obj, unsigned int access, int signal )
+static void mutex_satisfied( struct object *obj, struct wait_queue_entry *entry )
 {
     struct mutex *mutex = (struct mutex *)obj;
     assert( obj->ops == &mutex_ops );
 
-    assert( mutex->sync->ops == &mutex_sync_ops ); /* never called with inproc syncs */
-    assert( signal == -1 ); /* always called from signal_object */
+    do_grab( mutex, get_wait_queue_thread( entry ));
+    if (mutex->abandoned) make_wait_abandoned( entry );
+    mutex->abandoned = 0;
+}
+
+static int mutex_signal( struct object *obj, unsigned int access )
+{
+    struct mutex *mutex = (struct mutex *)obj;
+    assert( obj->ops == &mutex_ops );
 
     if (!(access & SYNCHRONIZE))
     {
         set_error( STATUS_ACCESS_DENIED );
         return 0;
     }
-    return do_release( (struct mutex_sync *)mutex->sync, current, 1 );
+    if (!mutex->count || (mutex->owner != current))
+    {
+        set_error( STATUS_MUTANT_NOT_OWNED );
+        return 0;
+    }
+    if (!--mutex->count) do_release( mutex );
+    return 1;
 }
 
 static void mutex_destroy( struct object *obj )
 {
     struct mutex *mutex = (struct mutex *)obj;
     assert( obj->ops == &mutex_ops );
-    if (mutex->sync) release_object( mutex->sync );
+
+    if (!mutex->count) return;
+    mutex->count = 0;
+    do_release( mutex );
 }
 
 /* create a mutex */
@@ -319,11 +242,12 @@ DECL_HANDLER(release_mutex)
     if ((mutex = (struct mutex *)get_handle_obj( current->process, req->handle,
                                                  0, &mutex_ops )))
     {
-        struct mutex_sync *sync = (struct mutex_sync *)mutex->sync;
-        assert( mutex->sync->ops == &mutex_sync_ops ); /* never called with inproc syncs */
-
-        reply->prev_count = sync->count;
-        do_release( sync, current, 1 );
+        if (!mutex->count || (mutex->owner != current)) set_error( STATUS_MUTANT_NOT_OWNED );
+        else
+        {
+            reply->prev_count = mutex->count;
+            if (!--mutex->count) do_release( mutex );
+        }
         release_object( mutex );
     }
 }
@@ -336,12 +260,9 @@ DECL_HANDLER(query_mutex)
     if ((mutex = (struct mutex *)get_handle_obj( current->process, req->handle,
                                                  MUTANT_QUERY_STATE, &mutex_ops )))
     {
-        struct mutex_sync *sync = (struct mutex_sync *)mutex->sync;
-        assert( mutex->sync->ops == &mutex_sync_ops ); /* never called with inproc syncs */
-
-        reply->count = sync->count;
-        reply->owned = (sync->owner == current);
-        reply->abandoned = sync->abandoned;
+        reply->count = mutex->count;
+        reply->owned = (mutex->owner == current);
+        reply->abandoned = mutex->abandoned;
 
         release_object( mutex );
     }
diff -ruN --show-c-function server/named_pipe.c server/named_pipe.c
--- server/named_pipe.c	2025-10-21 17:44:36.355781240 -0700
+++ server/named_pipe.c	2025-10-24 16:11:42.418576102 -0700
@@ -119,10 +119,10 @@ static const struct object_ops named_pip
     no_add_queue,                 /* add_queue */
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
+    NULL,                         /* get_esync_fd */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-    default_get_sync,             /* get_sync */
     named_pipe_map_access,        /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
@@ -165,13 +165,13 @@ static const struct object_ops pipe_serv
     sizeof(struct pipe_server),   /* size */
     &file_type,                   /* type */
     pipe_server_dump,             /* dump */
-    NULL,                         /* add_queue */
-    NULL,                         /* remove_queue */
-    NULL,                         /* signaled */
-    NULL,                         /* satisfied */
+    add_queue,                    /* add_queue */
+    remove_queue,                 /* remove_queue */
+    default_fd_signaled,          /* signaled */
+    default_fd_get_esync_fd,      /* get_esync_fd */
+    no_satisfied,                 /* satisfied */
     no_signal,                    /* signal */
     pipe_end_get_fd,              /* get_fd */
-    default_fd_get_sync,          /* get_sync */
     default_map_access,           /* map_access */
     pipe_end_get_sd,              /* get_sd */
     pipe_end_set_sd,              /* set_sd */
@@ -210,13 +210,13 @@ static const struct object_ops pipe_clie
     sizeof(struct pipe_end),      /* size */
     &file_type,                   /* type */
     pipe_client_dump,             /* dump */
-    NULL,                         /* add_queue */
-    NULL,                         /* remove_queue */
-    NULL,                         /* signaled */
-    NULL,                         /* satisfied */
+    add_queue,                    /* add_queue */
+    remove_queue,                 /* remove_queue */
+    default_fd_signaled,          /* signaled */
+    default_fd_get_esync_fd,      /* get_esync_fd */
+    no_satisfied,                 /* satisfied */
     no_signal,                    /* signal */
     pipe_end_get_fd,              /* get_fd */
-    default_fd_get_sync,          /* get_sync */
     default_map_access,           /* map_access */
     pipe_end_get_sd,              /* get_sd */
     pipe_end_set_sd,              /* set_sd */
@@ -262,10 +262,10 @@ static const struct object_ops named_pip
     no_add_queue,                     /* add_queue */
     NULL,                             /* remove_queue */
     NULL,                             /* signaled */
+    NULL,                             /* get_esync_fd */
     no_satisfied,                     /* satisfied */
     no_signal,                        /* signal */
     no_get_fd,                        /* get_fd */
-    default_get_sync,                 /* get_sync */
     default_map_access,               /* map_access */
     default_get_sd,                   /* get_sd */
     default_set_sd,                   /* set_sd */
@@ -291,13 +291,13 @@ static const struct object_ops named_pip
     sizeof(struct named_pipe_device_file),   /* size */
     &file_type,                              /* type */
     named_pipe_device_file_dump,             /* dump */
-    NULL,                                    /* add_queue */
-    NULL,                                    /* remove_queue */
-    NULL,                                    /* signaled */
-    NULL,                                    /* satisfied */
+    add_queue,                               /* add_queue */
+    remove_queue,                            /* remove_queue */
+    default_fd_signaled,                     /* signaled */
+    NULL,                                    /* get_esync_fd */
+    no_satisfied,                            /* satisfied */
     no_signal,                               /* signal */
     named_pipe_device_file_get_fd,           /* get_fd */
-    default_fd_get_sync,                     /* get_sync */
     default_map_access,                      /* map_access */
     default_get_sd,                          /* get_sd */
     default_set_sd,                          /* set_sd */
@@ -342,13 +342,13 @@ static const struct object_ops named_pip
     sizeof(struct named_pipe_device_file),   /* size */
     &file_type,                              /* type */
     named_pipe_dir_dump,                     /* dump */
-    NULL,                                    /* add_queue */
-    NULL,                                    /* remove_queue */
-    NULL,                                    /* signaled */
-    NULL,                                    /* satisfied */
+    add_queue,                               /* add_queue */
+    remove_queue,                            /* remove_queue */
+    default_fd_signaled,                     /* signaled */
+    NULL,                                    /* get_esync_fd */
+    no_satisfied,                            /* satisfied */
     no_signal,                               /* signal */
     named_pipe_dir_get_fd,                   /* get_fd */
-    default_fd_get_sync,                     /* get_sync */
     default_map_access,                      /* map_access */
     default_get_sd,                          /* get_sd */
     default_set_sd,                          /* set_sd */
diff -ruN --show-c-function server/object.c server/object.c
--- server/object.c	2025-10-21 17:44:36.355781240 -0700
+++ server/object.c	2025-10-24 16:11:42.399509892 -0700
@@ -109,10 +109,10 @@ static const struct object_ops apc_reser
     no_add_queue,               /* add_queue */
     NULL,                       /* remove_queue */
     NULL,                       /* signaled */
+    NULL,                       /* get_esync_fd */
     no_satisfied,               /* satisfied */
     no_signal,                  /* signal */
     no_get_fd,                  /* get_fd */
-    default_get_sync,           /* get_sync */
     default_map_access,         /* map_access */
     default_get_sd,             /* get_sd */
     default_set_sd,             /* set_sd */
@@ -134,10 +134,10 @@ static const struct object_ops completio
     no_add_queue,              /* add_queue */
     NULL,                      /* remove_queue */
     NULL,                      /* signaled */
+    NULL,                      /* get_esync_fd */
     no_satisfied,              /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
-    default_get_sync,          /* get_sync */
     default_map_access,        /* map_access */
     default_get_sd,            /* get_sd */
     default_set_sd,            /* set_sd */
@@ -630,7 +630,7 @@ void no_satisfied( struct object *obj, s
 {
 }
 
-int no_signal( struct object *obj, unsigned int access, int signal )
+int no_signal( struct object *obj, unsigned int access )
 {
     set_error( STATUS_OBJECT_TYPE_MISMATCH );
     return 0;
@@ -642,11 +642,6 @@ struct fd *no_get_fd( struct object *obj
     return NULL;
 }
 
-struct object *default_get_sync( struct object *obj )
-{
-    return grab_object( obj );
-}
-
 unsigned int default_map_access( struct object *obj, unsigned int access )
 {
     return map_access( access, &obj->ops->type->mapping );
diff -ruN --show-c-function server/object.h server/object.h
--- server/object.h	2025-10-21 17:44:36.355781240 -0700
+++ server/object.h	2025-10-24 16:11:42.399647063 -0700
@@ -78,14 +78,14 @@ struct object_ops
     void (*remove_queue)(struct object *,struct wait_queue_entry *);
     /* is object signaled? */
     int  (*signaled)(struct object *,struct wait_queue_entry *);
+    /* return the esync fd for this object */
+    int (*get_esync_fd)(struct object *, enum esync_type *type);
     /* wait satisfied */
     void (*satisfied)(struct object *,struct wait_queue_entry *);
-    /* signal/reset an object */
-    int  (*signal)(struct object *,unsigned int,int);
+    /* signal an object */
+    int  (*signal)(struct object *, unsigned int);
     /* return an fd object that can be used to read/write from the object */
     struct fd *(*get_fd)(struct object *);
-    /* return a sync that can be used to wait/signal the object */
-    struct object *(*get_sync)(struct object *);
     /* map access rights to the specific rights for this object */
     unsigned int (*map_access)(struct object *, unsigned int);
     /* returns the security descriptor of the object */
@@ -170,10 +170,8 @@ extern struct object *find_object( const
 extern struct object *find_object_index( const struct namespace *namespace, unsigned int index );
 extern int no_add_queue( struct object *obj, struct wait_queue_entry *entry );
 extern void no_satisfied( struct object *obj, struct wait_queue_entry *entry );
-extern int no_signal( struct object *obj, unsigned int access, int signal );
+extern int no_signal( struct object *obj, unsigned int access );
 extern struct fd *no_get_fd( struct object *obj );
-extern struct object *default_get_sync( struct object *obj );
-static inline struct object *get_obj_sync( struct object *obj ) { return obj->ops->get_sync( obj ); }
 extern unsigned int default_map_access( struct object *obj, unsigned int access );
 extern struct security_descriptor *default_get_sd( struct object *obj );
 extern int default_set_sd( struct object *obj, const struct security_descriptor *sd, unsigned int set_info );
@@ -219,14 +217,8 @@ static inline void *mem_append( void *pt
 /* event functions */
 
 struct event;
-struct event_sync;
 struct keyed_event;
 
-extern struct event_sync *create_server_internal_sync( int manual, int signaled );
-extern struct object *create_internal_sync( int manual, int signaled );
-extern void signal_sync( struct object *sync );
-extern void reset_sync( struct object *sync );
-
 extern struct event *create_event( struct object *root, const struct unicode_str *name,
                                    unsigned int attr, int manual_reset, int initial_state,
                                    const struct security_descriptor *sd );
@@ -241,19 +233,6 @@ extern void reset_event( struct event *e
 
 extern void abandon_mutexes( struct thread *thread );
 
-/* in-process synchronization functions */
-
-struct inproc_sync;
-extern int get_inproc_device_fd(void);
-extern int get_inproc_sync_fd( struct inproc_sync *sync );
-extern struct inproc_sync *create_inproc_internal_sync( int manual, int signaled );
-extern struct inproc_sync *create_inproc_event_sync( int manual, int signaled );
-extern struct inproc_sync *create_inproc_semaphore_sync( unsigned int initial, unsigned int max );
-extern struct inproc_sync *create_inproc_mutex_sync( thread_id_t owner, unsigned int count );
-extern void abandon_inproc_mutexes( thread_id_t owner );
-extern void signal_inproc_sync( struct inproc_sync *sync );
-extern void reset_inproc_sync( struct inproc_sync *sync );
-
 /* serial functions */
 
 int get_serial_async_timeout(struct object *obj, int type, int count);
diff -ruN --show-c-function server/process.c server/process.c
--- server/process.c	2025-10-21 17:44:36.355781240 -0700
+++ server/process.c	2025-10-24 16:11:42.403542236 -0700
@@ -64,6 +64,7 @@
 #include "request.h"
 #include "user.h"
 #include "security.h"
+#include "esync.h"
 
 /* process object */
 
@@ -90,12 +91,13 @@ struct type_descr process_type =
 };
 
 static void process_dump( struct object *obj, int verbose );
-static struct object *process_get_sync( struct object *obj );
+static int process_signaled( struct object *obj, struct wait_queue_entry *entry );
 static unsigned int process_map_access( struct object *obj, unsigned int access );
 static struct security_descriptor *process_get_sd( struct object *obj );
 static void process_poll_event( struct fd *fd, int event );
 static struct list *process_get_kernel_obj_list( struct object *obj );
 static void process_destroy( struct object *obj );
+static int process_get_esync_fd( struct object *obj, enum esync_type *type );
 static void terminate_process( struct process *process, struct thread *skip, int exit_code );
 
 static const struct object_ops process_ops =
@@ -103,13 +105,13 @@ static const struct object_ops process_o
     sizeof(struct process),      /* size */
     &process_type,               /* type */
     process_dump,                /* dump */
-    NULL,                        /* add_queue */
-    NULL,                        /* remove_queue */
-    NULL,                        /* signaled */
-    NULL,                        /* satisfied */
+    add_queue,                   /* add_queue */
+    remove_queue,                /* remove_queue */
+    process_signaled,            /* signaled */
+    process_get_esync_fd,        /* get_esync_fd */
+    no_satisfied,                /* satisfied */
     no_signal,                   /* signal */
     no_get_fd,                   /* get_fd */
-    process_get_sync,            /* get_sync */
     process_map_access,          /* map_access */
     process_get_sd,              /* get_sd */
     default_set_sd,              /* set_sd */
@@ -139,16 +141,15 @@ static const struct fd_ops process_fd_op
 
 struct startup_info
 {
-    struct object               obj;            /* object header */
-    struct object              *sync;           /* sync object for wait/signal */
-    struct process             *process;        /* created process */
-    data_size_t                 info_size;      /* size of startup info */
-    data_size_t                 data_size;      /* size of whole startup data */
-    struct startup_info_data   *data;           /* data for startup info */
+    struct object       obj;          /* object header */
+    struct process     *process;      /* created process */
+    data_size_t         info_size;    /* size of startup info */
+    data_size_t         data_size;    /* size of whole startup data */
+    struct startup_info_data *data;   /* data for startup info */
 };
 
 static void startup_info_dump( struct object *obj, int verbose );
-static struct object *startup_info_get_sync( struct object *obj );
+static int startup_info_signaled( struct object *obj, struct wait_queue_entry *entry );
 static void startup_info_destroy( struct object *obj );
 
 static const struct object_ops startup_info_ops =
@@ -156,13 +157,13 @@ static const struct object_ops startup_i
     sizeof(struct startup_info),   /* size */
     &no_type,                      /* type */
     startup_info_dump,             /* dump */
-    NULL,                          /* add_queue */
-    NULL,                          /* remove_queue */
-    NULL,                          /* signaled */
-    NULL,                          /* satisfied */
+    add_queue,                     /* add_queue */
+    remove_queue,                  /* remove_queue */
+    startup_info_signaled,         /* signaled */
+    NULL,                          /* get_esync_fd */
+    no_satisfied,                  /* satisfied */
     no_signal,                     /* signal */
     no_get_fd,                     /* get_fd */
-    startup_info_get_sync,         /* get_sync */
     default_map_access,            /* map_access */
     default_get_sd,                /* get_sd */
     default_set_sd,                /* set_sd */
@@ -193,24 +194,24 @@ struct type_descr job_type =
 };
 
 static void job_dump( struct object *obj, int verbose );
-static struct object *job_get_sync( struct object *obj );
+static int job_signaled( struct object *obj, struct wait_queue_entry *entry );
 static int job_close_handle( struct object *obj, struct process *process, obj_handle_t handle );
 static void job_destroy( struct object *obj );
 
 struct job
 {
-    struct object        obj;               /* object header */
-    struct object       *sync;              /* sync object for wait/signal */
-    struct list          process_list;      /* list of processes */
-    int                  num_processes;     /* count of running processes */
-    int                  total_processes;   /* count of processes which have been assigned */
-    unsigned int         limit_flags;       /* limit flags */
-    int                  terminating;       /* job is terminating */
-    struct completion   *completion_port;   /* associated completion port */
-    apc_param_t          completion_key;    /* key to send with completion messages */
-    struct job          *parent;
-    struct list          parent_job_entry;  /* list entry for parent job */
-    struct list          child_job_list;    /* list of child jobs */
+    struct object obj;             /* object header */
+    struct list process_list;      /* list of processes */
+    int num_processes;             /* count of running processes */
+    int total_processes;           /* count of processes which have been assigned */
+    unsigned int limit_flags;      /* limit flags */
+    int terminating;               /* job is terminating */
+    int signaled;                  /* job is signaled */
+    struct completion *completion_port; /* associated completion port */
+    apc_param_t completion_key;    /* key to send with completion messages */
+    struct job *parent;
+    struct list parent_job_entry;  /* list entry for parent job */
+    struct list child_job_list;    /* list of child jobs */
 };
 
 static const struct object_ops job_ops =
@@ -218,13 +219,13 @@ static const struct object_ops job_ops =
     sizeof(struct job),            /* size */
     &job_type,                     /* type */
     job_dump,                      /* dump */
-    NULL,                          /* add_queue */
-    NULL,                          /* remove_queue */
-    NULL,                          /* signaled */
-    NULL,                          /* satisfied */
+    add_queue,                     /* add_queue */
+    remove_queue,                  /* remove_queue */
+    job_signaled,                  /* signaled */
+    NULL,                          /* get_esync_fd */
+    no_satisfied,                  /* satisfied */
     no_signal,                     /* signal */
     no_get_fd,                     /* get_fd */
-    job_get_sync,                  /* get_sync */
     default_map_access,            /* map_access */
     default_get_sd,                /* get_sd */
     default_set_sd,                /* set_sd */
@@ -248,22 +249,16 @@ static struct job *create_job_object( st
         if (get_error() != STATUS_OBJECT_NAME_EXISTS)
         {
             /* initialize it if it didn't already exist */
-            job->sync = NULL;
             list_init( &job->process_list );
             list_init( &job->child_job_list );
             job->num_processes = 0;
             job->total_processes = 0;
             job->limit_flags = 0;
             job->terminating = 0;
+            job->signaled = 0;
             job->completion_port = NULL;
             job->completion_key = 0;
             job->parent = NULL;
-
-            if (!(job->sync = create_internal_sync( 1, 0 )))
-            {
-                release_object( job );
-                return NULL;
-            }
         }
     }
     return job;
@@ -418,7 +413,8 @@ static void terminate_job( struct job *j
         if (process->running_threads) terminate_process( process, NULL, exit_code );
     }
     job->terminating = 0;
-    signal_sync( job->sync );
+    job->signaled = 1;
+    wake_up( &job->obj, 0 );
 }
 
 static int job_close_handle( struct object *obj, struct process *process, obj_handle_t handle )
@@ -449,8 +445,6 @@ static void job_destroy( struct object *
         list_remove( &job->parent_job_entry );
         release_object( job->parent );
     }
-
-    if (job->sync) release_object( job->sync );
 }
 
 static void job_dump( struct object *obj, int verbose )
@@ -461,11 +455,10 @@ static void job_dump( struct object *obj
              list_count(&job->process_list), list_count(&job->child_job_list), job->parent );
 }
 
-static struct object *job_get_sync( struct object *obj )
+static int job_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct job *job = (struct job *)obj;
-    assert( obj->ops == &job_ops );
-    return grab_object( job->sync );
+    return job->signaled;
 }
 
 struct ptid_entry
@@ -564,7 +557,7 @@ static void set_process_startup_state( s
     if (process->startup_state == STARTUP_IN_PROGRESS) process->startup_state = state;
     if (process->startup_info)
     {
-        signal_sync( process->startup_info->sync );
+        wake_up( &process->startup_info->obj, 0 );
         release_object( process->startup_info );
         process->startup_info = NULL;
     }
@@ -663,7 +656,6 @@ struct process *create_process( int fd,
         close( fd );
         goto error;
     }
-    process->sync            = NULL;
     process->parent_id       = 0;
     process->debug_obj       = NULL;
     process->debug_event     = NULL;
@@ -701,6 +693,7 @@ struct process *create_process( int fd,
     process->rawinput_kbd    = NULL;
     memset( &process->image_info, 0, sizeof(process->image_info) );
     list_init( &process->rawinput_entry );
+    process->esync_fd        = -1;
     list_init( &process->kernel_object );
     list_init( &process->thread_list );
     list_init( &process->locks );
@@ -722,7 +715,6 @@ struct process *create_process( int fd,
         goto error;
     }
     if (!(process->msg_fd = create_anonymous_fd( &process_fd_ops, fd, &process->obj, 0 ))) goto error;
-    if (!(process->sync = create_internal_sync( 1, 0 ))) goto error;
 
     /* create the handle table */
     if (!parent)
@@ -752,6 +744,9 @@ struct process *create_process( int fd,
     if (!process->handles || !process->token) goto error;
     process->session_id = token_get_session_id( process->token );
 
+    if (do_esync())
+        process->esync_fd = esync_create_fd( 0, 0 );
+
     set_fd_events( process->msg_fd, POLLIN );  /* start listening to events */
     return process;
 
@@ -796,11 +791,11 @@ static void process_destroy( struct obje
     if (process->idle_event) release_object( process->idle_event );
     if (process->id) free_ptid( process->id );
     if (process->token) release_object( process->token );
-    if (process->sync) release_object( process->sync );
     list_remove( &process->rawinput_entry );
     free( process->rawinput_devices );
     free( process->dir_cache );
     free( process->image );
+    if (do_esync()) close( process->esync_fd );
 }
 
 /* dump a process on stdout for debugging purposes */
@@ -812,11 +807,17 @@ static void process_dump( struct object
     fprintf( stderr, "Process id=%04x handles=%p\n", process->id, process->handles );
 }
 
-static struct object *process_get_sync( struct object *obj )
+static int process_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct process *process = (struct process *)obj;
-    assert( obj->ops == &process_ops );
-    return grab_object( process->sync );
+    return !process->running_threads;
+}
+
+static int process_get_esync_fd( struct object *obj, enum esync_type *type )
+{
+    struct process *process = (struct process *)obj;
+    *type = ESYNC_MANUAL_SERVER;
+    return process->esync_fd;
 }
 
 static unsigned int process_map_access( struct object *obj, unsigned int access )
@@ -889,7 +890,6 @@ static void startup_info_destroy( struct
     assert( obj->ops == &startup_info_ops );
     free( info->data );
     if (info->process) release_object( info->process );
-    if (info->sync) release_object( info->sync );
 }
 
 static void startup_info_dump( struct object *obj, int verbose )
@@ -904,11 +904,10 @@ static void startup_info_dump( struct ob
     fputc( '\n', stderr );
 }
 
-static struct object *startup_info_get_sync( struct object *obj )
+static int startup_info_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct startup_info *info = (struct startup_info *)obj;
-    assert( obj->ops == &startup_info_ops );
-    return grab_object( info->sync );
+    return info->process && info->process->startup_state != STARTUP_IN_PROGRESS;
 }
 
 /* get a process from an id (and increment the refcount) */
@@ -1000,7 +999,7 @@ static void process_killed( struct proce
     finish_process_tracing( process );
     release_job_process( process );
     start_sigkill_timer( process );
-    signal_sync( process->sync );
+    wake_up( &process->obj, 0 );
 }
 
 /* add a thread to a process running threads list */
@@ -1218,16 +1217,9 @@ DECL_HANDLER(new_process)
         release_object( parent );
         return;
     }
-    info->sync     = NULL;
     info->process  = NULL;
     info->data     = NULL;
 
-    if (!(info->sync = create_internal_sync( 1, 0 )))
-    {
-        close( socket_fd );
-        goto done;
-    }
-
     info_ptr = get_req_data_after_objattr( objattr, &info->data_size );
 
     if ((req->handles_size & 3) || req->handles_size > info->data_size)
diff -ruN --show-c-function server/process.h server/process.h
--- server/process.h	2025-10-21 17:44:36.355781240 -0700
+++ server/process.h	2025-10-24 16:11:42.403818811 -0700
@@ -36,7 +36,6 @@ enum startup_state { STARTUP_IN_PROGRESS
 struct process
 {
     struct object        obj;             /* object header */
-    struct object       *sync;            /* sync object for wait/signal */
     struct list          entry;           /* entry in system-wide process list */
     process_id_t         parent_id;       /* parent process id (at the time of creation) */
     struct list          thread_list;     /* thread list */
@@ -88,6 +87,7 @@ struct process
     struct list          rawinput_entry;  /* entry in the rawinput process list */
     struct list          kernel_object;   /* list of kernel object pointers */
     struct pe_image_info image_info;      /* main exe image info */
+    int                  esync_fd;        /* esync file descriptor (signaled on exit) */
 };
 
 /* process functions */
diff -ruN --show-c-function server/protocol.def server/protocol.def
--- server/protocol.def	2025-10-21 17:44:36.808791437 -0700
+++ server/protocol.def	2025-10-24 16:11:42.413739171 -0700
@@ -990,8 +990,6 @@ struct obj_locator
 };
 
 #define MAX_ATOM_LEN     255
-#define WH_WINEVENT      (WH_MAXHOOK + 1)
-#define NB_HOOKS         (WH_WINEVENT - WH_MINHOOK + 1)
 
 struct shared_cursor
 {
@@ -1012,13 +1010,11 @@ typedef volatile struct
 
 typedef volatile struct
 {
-    timeout_t            access_time;      /* last time the queue was accessed */
+    int                  hooks_count[WH_MAX - WH_MIN + 2]; /* active hooks count */
     unsigned int         wake_mask;        /* wakeup mask */
     unsigned int         wake_bits;        /* wakeup bits */
     unsigned int         changed_mask;     /* changed wakeup mask */
     unsigned int         changed_bits;     /* changed wakeup bits */
-    unsigned int         internal_bits;    /* internal queue bits */
-    int                  hooks_count[NB_HOOKS];  /* active hooks count */
 } queue_shm_t;
 
 typedef volatile struct
@@ -1040,16 +1036,9 @@ typedef volatile struct
 
 typedef volatile struct
 {
-    atom_t               atom;               /* class atom */
-    unsigned int         style;              /* class style */
-    unsigned int         cls_extra;          /* number of class extra bytes */
-    unsigned int         win_extra;          /* number of window extra bytes */
-    mod_handle_t         instance;           /* module instance */
     data_size_t          name_offset;        /* offset in WCHAR of the unversioned class name, constant */
     data_size_t          name_len;           /* len in bytes of the class name, constant */
     WCHAR                name[MAX_ATOM_LEN]; /* class name, constant */
-    unsigned short       __pad;
-    char                 extra[];            /* extra bytes storage */
 } class_shm_t;
 
 typedef volatile struct
@@ -1159,7 +1148,6 @@ typedef volatile struct
     thread_id_t  tid;          /* thread id of the new thread */
     timeout_t    server_start; /* server start time */
     unsigned int session_id;   /* process session id */
-    obj_handle_t inproc_device;/* inproc device fd in flight with this handle */
     data_size_t  info_size;    /* total size of startup info */
     VARARG(machines,ushorts);  /* array of supported machines */
 @END
@@ -2311,7 +2299,7 @@ struct process_info
 @REQ(set_queue_mask)
     unsigned int wake_mask;    /* wakeup bits mask */
     unsigned int changed_mask; /* changed bits mask */
-    int          poll_events;  /* whether to poll queue fd */
+    int          skip_wait;    /* will we skip waiting if signaled? */
 @REPLY
     unsigned int wake_bits;    /* current wake bits */
     unsigned int changed_bits; /* current changed bits */
@@ -3257,9 +3245,9 @@ enum caret_state
     atom_t         atom;           /* class atom */
     unsigned int   style;          /* class style */
     mod_handle_t   instance;       /* module instance */
+    int            extra;          /* number of extra class bytes */
+    int            win_extra;      /* number of window extra bytes */
     client_ptr_t   client_ptr;     /* pointer to class in client address space */
-    short int      cls_extra;      /* number of extra class bytes */
-    short int      win_extra;      /* number of window extra bytes */
     data_size_t    name_offset;    /* base class name offset for specified atom */
     VARARG(name,unicode_str);      /* class name */
 @REPLY
@@ -4117,7 +4105,7 @@ struct handle_info
     obj_handle_t handle;       /* process handle */
 @END
 
-/* Iterate processes using global process list */
+/* Itererate processes using global process list */
 @REQ(get_next_process)
     obj_handle_t last;         /* process handle to start with */
     unsigned int access;       /* desired access for returned handle */
@@ -4138,39 +4126,61 @@ struct handle_info
     obj_handle_t handle;       /* next thread handle */
 @END
 
+enum esync_type
+{
+    ESYNC_SEMAPHORE = 1,
+    ESYNC_AUTO_EVENT,
+    ESYNC_MANUAL_EVENT,
+    ESYNC_MUTEX,
+    ESYNC_AUTO_SERVER,
+    ESYNC_MANUAL_SERVER,
+    ESYNC_QUEUE,
+};
 
-/* Setup keyboard auto-repeat */
-@REQ(set_keyboard_repeat)
-    int enable;                /* whether to enable auto-repeat */
-    int delay;                 /* auto-repeat delay in ms */
-    int period;                /* auto-repeat period in ms */
+/* Create a new eventfd-based synchronization object */
+@REQ(create_esync)
+    unsigned int access;        /* wanted access rights */
+    int          initval;       /* initial value */
+    int          type;          /* type of esync object */
+    int          max;           /* maximum count on a semaphore */
+    VARARG(objattr,object_attributes); /* object attributes */
 @REPLY
-    int enable;                /* previous state of auto-repeat enable */
+    obj_handle_t handle;        /* handle to the object */
+    int          type;          /* actual type (may be different for events) */
+    unsigned int shm_idx;
 @END
 
+@REQ(open_esync)
+    unsigned int access;        /* wanted access rights */
+    unsigned int attributes;    /* object attributes */
+    obj_handle_t rootdir;       /* root directory */
+    int          type;          /* type of esync object (above) */
+    VARARG(name,unicode_str);   /* object name */
+@REPLY
+    obj_handle_t handle;        /* handle to the event */
+    int          type;          /* type of esync object (above) */
+    unsigned int shm_idx;       /* this object's index into the shm section */
+@END
 
-enum inproc_sync_type
-{
-    INPROC_SYNC_UNKNOWN   = 0,
-    INPROC_SYNC_INTERNAL  = 1,
-    INPROC_SYNC_EVENT     = 2,
-    INPROC_SYNC_MUTEX     = 3,
-    INPROC_SYNC_SEMAPHORE = 4,
-};
-
-/* Get the in-process synchronization fd associated with the waitable handle */
-@REQ(get_inproc_sync_fd)
+/* Retrieve the esync fd for an object. */
+@REQ(get_esync_fd)
     obj_handle_t handle;        /* handle to the object */
 @REPLY
-    int           type;         /* inproc sync type */
-    unsigned int access;        /* handle access rights */
+    int          type;
+    unsigned int shm_idx;
 @END
 
+@REQ(esync_msgwait)
+    int          in_msgwait;    /* are we in a message wait? */
+@END
 
-/* Get the in-process synchronization fd for the current thread user APC alerts */
-@REQ(get_inproc_alert_fd)
+/* Setup keyboard auto-repeat */
+@REQ(set_keyboard_repeat)
+    int enable;                /* whether to enable auto-repeat */
+    int delay;                 /* auto-repeat delay in ms */
+    int period;                /* auto-repeat period in ms */
 @REPLY
-    obj_handle_t handle;        /* alert fd is in flight with this handle */
+    int enable;                /* previous state of auto-repeat enable */
 @END
 
 
@@ -4238,3 +4248,7 @@ enum inproc_sync_type
 @REPLY
     obj_handle_t        handle;         /* shared object handle */
 @END
+
+/* Retrieve the fd to wait on for user APCs. */
+@REQ(get_esync_apc_fd)
+@END
diff -ruN --show-c-function server/queue.c server/queue.c
--- server/queue.c	2025-10-21 17:44:36.809791459 -0700
+++ server/queue.c	2025-10-24 16:11:42.407287946 -0700
@@ -45,10 +45,7 @@
 #include "process.h"
 #include "request.h"
 #include "user.h"
-
-#define QS_DRIVER       0x80000000
-#define QS_HARDWARE     0x40000000
-#define QS_INTERNAL     (QS_DRIVER | QS_HARDWARE)
+#include "esync.h"
 
 #define WM_NCMOUSEFIRST WM_NCMOUSEMOVE
 #define WM_NCMOUSELAST  (WM_NCMOUSEFIRST+(WM_MOUSELAST-WM_MOUSEFIRST))
@@ -120,7 +117,6 @@ struct msg_queue
 {
     struct object          obj;             /* object header */
     struct fd             *fd;              /* optional file descriptor to poll */
-    struct object         *sync;            /* sync object for wait/signal */
     int                    paint_count;     /* pending paint messages count */
     int                    hotkey_count;    /* pending hotkey messages count */
     int                    quit_message;    /* is there a pending quit message? */
@@ -136,8 +132,11 @@ struct msg_queue
     struct timeout_user   *timeout;         /* timeout for next timer to expire */
     struct thread_input   *input;           /* thread input descriptor */
     struct hook_table     *hooks;           /* hook table */
+    timeout_t              last_get_msg;    /* time of last get message call */
     int                    keystate_lock;   /* owns an input keystate lock */
     queue_shm_t           *shared;          /* queue in session shared memory */
+    int                    esync_fd;        /* esync file descriptor (signalled on message) */
+    int                    esync_in_msgwait; /* our thread is currently waiting on us */
 };
 
 struct hotkey
@@ -151,7 +150,11 @@ struct hotkey
 };
 
 static void msg_queue_dump( struct object *obj, int verbose );
-static struct object *msg_queue_get_sync( struct object *obj );
+static int msg_queue_add_queue( struct object *obj, struct wait_queue_entry *entry );
+static void msg_queue_remove_queue( struct object *obj, struct wait_queue_entry *entry );
+static int msg_queue_signaled( struct object *obj, struct wait_queue_entry *entry );
+static int msg_queue_get_esync_fd( struct object *obj, enum esync_type *type );
+static void msg_queue_satisfied( struct object *obj, struct wait_queue_entry *entry );
 static void msg_queue_destroy( struct object *obj );
 static void msg_queue_poll_event( struct fd *fd, int event );
 static void thread_input_dump( struct object *obj, int verbose );
@@ -163,13 +166,13 @@ static const struct object_ops msg_queue
     sizeof(struct msg_queue),  /* size */
     &no_type,                  /* type */
     msg_queue_dump,            /* dump */
-    NULL,                      /* add_queue */
-    NULL,                      /* remove_queue */
-    NULL,                      /* signaled */
-    NULL,                      /* satisfied */
+    msg_queue_add_queue,       /* add_queue */
+    msg_queue_remove_queue,    /* remove_queue */
+    msg_queue_signaled,        /* signaled */
+    msg_queue_get_esync_fd,    /* get_esync_fd */
+    msg_queue_satisfied,       /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
-    msg_queue_get_sync,        /* get_sync */
     default_map_access,        /* map_access */
     default_get_sd,            /* get_sd */
     default_set_sd,            /* set_sd */
@@ -204,10 +207,10 @@ static const struct object_ops thread_in
     no_add_queue,                 /* add_queue */
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
+    NULL,                         /* get_esync_fd */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-    default_get_sync,             /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
@@ -263,7 +266,7 @@ static struct thread_input *create_threa
         memcpy( input->desktop_keystate, (const void *)input->desktop->shared->keystate,
                 sizeof(input->desktop_keystate) );
 
-        if (!(input->shared = alloc_shared_object( sizeof(*input->shared) )))
+        if (!(input->shared = alloc_shared_object()))
         {
             release_object( input );
             return NULL;
@@ -306,7 +309,6 @@ static struct msg_queue *create_msg_queu
     if ((queue = alloc_object( &msg_queue_ops )))
     {
         queue->fd              = NULL;
-        queue->sync            = NULL;
         queue->paint_count     = 0;
         queue->hotkey_count    = 0;
         queue->quit_message    = 0;
@@ -316,15 +318,17 @@ static struct msg_queue *create_msg_queu
         queue->timeout         = NULL;
         queue->input           = (struct thread_input *)grab_object( input );
         queue->hooks           = NULL;
+        queue->last_get_msg    = current_time;
         queue->keystate_lock   = 0;
+        queue->esync_fd        = -1;
+        queue->esync_in_msgwait = 0;
         list_init( &queue->send_result );
         list_init( &queue->callback_result );
         list_init( &queue->pending_timers );
         list_init( &queue->expired_timers );
         for (i = 0; i < NB_MSG_KINDS; i++) list_init( &queue->msg_list[i] );
 
-        if (!(queue->sync = create_internal_sync( 1, 0 ))) goto error;
-        if (!(queue->shared = alloc_shared_object( sizeof(*queue->shared) )))
+        if (!(queue->shared = alloc_shared_object()))
         {
             release_object( queue );
             return NULL;
@@ -333,15 +337,16 @@ static struct msg_queue *create_msg_queu
         SHARED_WRITE_BEGIN( queue->shared, queue_shm_t )
         {
             memset( (void *)shared->hooks_count, 0, sizeof(shared->hooks_count) );
-            shared->access_time = monotonic_time;
             shared->wake_mask = 0;
             shared->wake_bits = 0;
             shared->changed_mask = 0;
             shared->changed_bits = 0;
-            shared->internal_bits = 0;
         }
         SHARED_WRITE_END;
 
+        if (do_esync())
+            queue->esync_fd = esync_create_fd( 0, 0 );
+
         thread->queue = queue;
 
         if ((desktop = get_thread_desktop( thread, 0 )))
@@ -352,10 +357,6 @@ static struct msg_queue *create_msg_queu
     }
     if (new_input) release_object( new_input );
     return queue;
-
-error:
-    release_object( queue );
-    return NULL;
 }
 
 /* free the message queue of a thread at thread exit */
@@ -716,22 +717,18 @@ void add_queue_hook_count( struct thread
 }
 
 /* check the queue status */
-static inline int get_queue_status( struct msg_queue *queue )
+static inline int is_signaled( struct msg_queue *queue )
 {
     queue_shm_t *queue_shm = queue->shared;
     return (queue_shm->wake_bits & queue_shm->wake_mask) ||
-           (queue_shm->changed_bits & queue_shm->changed_mask) ||
-            queue_shm->internal_bits;
+           (queue_shm->changed_bits & queue_shm->changed_mask);
 }
 
 /* set some queue bits */
 static inline void set_queue_bits( struct msg_queue *queue, unsigned int bits )
 {
     queue_shm_t *queue_shm = queue->shared;
-    unsigned int internal = bits & QS_INTERNAL;
-    bits &= ~QS_INTERNAL;
 
-    /* lock the key state on key press, including from hardware messages */
     if (bits & (QS_KEY | QS_MOUSEBUTTON))
     {
         if (!queue->keystate_lock) lock_input_keystate( queue->input );
@@ -742,36 +739,32 @@ static inline void set_queue_bits( struc
     {
         shared->wake_bits |= bits;
         shared->changed_bits |= bits;
-        shared->internal_bits |= internal;
     }
     SHARED_WRITE_END;
 
-    if (get_queue_status( queue )) signal_sync( queue->sync );
+    if (is_signaled( queue )) wake_up( &queue->obj, 0 );
 }
 
 /* clear some queue bits */
 static inline void clear_queue_bits( struct msg_queue *queue, unsigned int bits )
 {
     queue_shm_t *queue_shm = queue->shared;
-    unsigned int internal = bits & QS_INTERNAL;
-    bits &= ~QS_INTERNAL;
 
     SHARED_WRITE_BEGIN( queue_shm, queue_shm_t )
     {
         shared->wake_bits &= ~bits;
         shared->changed_bits &= ~bits;
-        shared->internal_bits &= ~internal;
-        bits = shared->wake_bits;
     }
     SHARED_WRITE_END;
 
-    /* release the keystate lock when last key message has been processed */
-    if (!internal && !(bits & (QS_KEY | QS_MOUSEBUTTON)))
+    if (!(queue_shm->wake_bits & (QS_KEY | QS_MOUSEBUTTON)))
     {
         if (queue->keystate_lock) unlock_input_keystate( queue->input );
         queue->keystate_lock = 0;
     }
-    if (!get_queue_status( queue )) reset_sync( queue->sync );
+
+    if (do_esync() && !is_signaled( queue ))
+        esync_clear( queue->esync_fd );
 }
 
 /* check if message is matched by the filter */
@@ -802,7 +795,8 @@ static inline int get_hardware_msg_bit(
     if (message == WM_INPUT_DEVICE_CHANGE || message == WM_INPUT) return QS_RAWINPUT;
     if (message == WM_MOUSEMOVE || message == WM_NCMOUSEMOVE) return QS_MOUSEMOVE;
     if (message >= WM_KEYFIRST && message <= WM_KEYLAST) return QS_KEY;
-    if (message >= WM_WINE_FIRST_DRIVER_MSG && message <= WM_WINE_LAST_DRIVER_MSG) return QS_HARDWARE;
+    if (message == WM_WINE_CLIPCURSOR) return QS_RAWINPUT;
+    if (message == WM_WINE_SETCURSOR) return QS_RAWINPUT;
     return QS_MOUSEBUTTON;
 }
 
@@ -1280,15 +1274,47 @@ static void cleanup_results( struct msg_
 /* check if the thread owning the queue is hung (not checking for messages) */
 static int is_queue_hung( struct msg_queue *queue )
 {
-    /* queue is hung if it's signaled and thread didn't access it for more than 5 seconds */
-    return get_queue_status( queue ) && monotonic_time - queue->shared->access_time > 5 * TICKS_PER_SEC;
+    struct wait_queue_entry *entry;
+
+    if (current_time - queue->last_get_msg <= 5 * TICKS_PER_SEC)
+        return 0;  /* less than 5 seconds since last get message -> not hung */
+
+    LIST_FOR_EACH_ENTRY( entry, &queue->obj.wait_queue, struct wait_queue_entry, entry )
+    {
+        if (get_wait_queue_thread(entry)->queue == queue)
+            return 0;  /* thread is waiting on queue -> not hung */
+    }
+
+    if (do_esync() && queue->esync_in_msgwait)
+        return 0;   /* thread is waiting on queue in absentia -> not hung */
+
+    return 1;
 }
 
-static struct object *msg_queue_get_sync( struct object *obj )
+static int msg_queue_add_queue( struct object *obj, struct wait_queue_entry *entry )
 {
     struct msg_queue *queue = (struct msg_queue *)obj;
-    assert( obj->ops == &msg_queue_ops );
-    return grab_object( queue->sync );
+
+    /* a thread can only wait on its own queue */
+    if (get_wait_queue_thread(entry)->queue != queue)
+    {
+        set_error( STATUS_ACCESS_DENIED );
+        return 0;
+    }
+
+    if (queue->fd && list_empty( &obj->wait_queue ))  /* first on the queue */
+        set_fd_events( queue->fd, POLLIN );
+    add_queue( obj, entry );
+    return 1;
+}
+
+static void msg_queue_remove_queue(struct object *obj, struct wait_queue_entry *entry )
+{
+    struct msg_queue *queue = (struct msg_queue *)obj;
+
+    remove_queue( obj, entry );
+    if (queue->fd && list_empty( &obj->wait_queue ))  /* last on the queue is gone */
+        set_fd_events( queue->fd, 0 );
 }
 
 static void msg_queue_dump( struct object *obj, int verbose )
@@ -1299,6 +1325,43 @@ static void msg_queue_dump( struct objec
              queue_shm->wake_bits, queue_shm->wake_mask );
 }
 
+static int msg_queue_signaled( struct object *obj, struct wait_queue_entry *entry )
+{
+    struct msg_queue *queue = (struct msg_queue *)obj;
+    int ret = 0;
+
+    if (queue->fd)
+    {
+        if ((ret = check_fd_events( queue->fd, POLLIN )))
+            /* stop waiting on select() if we are signaled */
+            set_fd_events( queue->fd, 0 );
+        else if (!list_empty( &obj->wait_queue ))
+            /* restart waiting on poll() if we are no longer signaled */
+            set_fd_events( queue->fd, POLLIN );
+    }
+    return ret || is_signaled( queue );
+}
+
+static int msg_queue_get_esync_fd( struct object *obj, enum esync_type *type )
+{
+    struct msg_queue *queue = (struct msg_queue *)obj;
+    *type = ESYNC_QUEUE;
+    return queue->esync_fd;
+}
+
+static void msg_queue_satisfied( struct object *obj, struct wait_queue_entry *entry )
+{
+    struct msg_queue *queue = (struct msg_queue *)obj;
+    queue_shm_t *queue_shm = queue->shared;
+
+    SHARED_WRITE_BEGIN( queue_shm, queue_shm_t )
+    {
+        shared->wake_mask = 0;
+        shared->changed_mask = 0;
+    }
+    SHARED_WRITE_END;
+}
+
 static void msg_queue_destroy( struct object *obj )
 {
     struct msg_queue *queue = (struct msg_queue *)obj;
@@ -1342,7 +1405,7 @@ static void msg_queue_destroy( struct ob
     if (queue->hooks) release_object( queue->hooks );
     if (queue->fd) release_object( queue->fd );
     if (queue->shared) free_shared_object( queue->shared );
-    if (queue->sync) release_object( queue->sync );
+    if (do_esync()) close( queue->esync_fd );
 }
 
 static void msg_queue_poll_event( struct fd *fd, int event )
@@ -1352,7 +1415,7 @@ static void msg_queue_poll_event( struct
 
     if (event & (POLLERR | POLLHUP)) set_fd_events( fd, -1 );
     else set_fd_events( queue->fd, 0 );
-    set_queue_bits( queue, QS_DRIVER );
+    wake_up( &queue->obj, 0 );
 }
 
 static void thread_input_dump( struct object *obj, int verbose )
@@ -1768,7 +1831,6 @@ static void release_hardware_message( st
         }
     }
     if (clr_bit) clear_queue_bits( queue, clr_bit );
-    if (list_empty( &input->msg_list )) clear_queue_bits( queue, QS_HARDWARE );
 
     update_thread_input_key_state( input, msg->msg, msg->wparam );
     list_remove( &msg->entry );
@@ -1827,7 +1889,6 @@ static user_handle_t find_hardware_messa
     {
     case QS_POINTER:
     case QS_RAWINPUT:
-    case QS_HARDWARE:
         if (!(win = msg->win) && input) win = input_shm->focus;
         break;
     case QS_KEY:
@@ -1898,13 +1959,13 @@ static void queue_hardware_message( stru
     struct thread_input *input;
     struct hardware_msg_data *msg_data = msg->data;
     unsigned int msg_code;
-    int flags, msg_bit;
+    int flags;
 
     update_desktop_key_state( desktop, msg->msg, msg->wparam );
     last_input_time = get_tick_count();
     if (msg->msg != WM_MOUSEMOVE) always_queue = 1;
 
-    switch ((msg_bit = get_hardware_msg_bit( msg->msg )))
+    switch (get_hardware_msg_bit( msg->msg ))
     {
     case QS_KEY:
         if (queue_hotkey_message( desktop, msg )) return;
@@ -1954,7 +2015,7 @@ static void queue_hardware_message( stru
     {
         msg->unique_id = 0;  /* will be set once we return it to the app */
         list_add_tail( &input->msg_list, &msg->entry );
-        set_queue_bits( thread->queue, QS_HARDWARE | msg_bit );
+        set_queue_bits( thread->queue, get_hardware_msg_bit( msg->msg ) );
     }
     release_object( thread );
 }
@@ -2692,6 +2753,12 @@ static int check_hw_message_filter( user
     }
 }
 
+/* is this message an internal driver notification message */
+static inline BOOL is_internal_hardware_message( unsigned int message )
+{
+    return (message >= WM_WINE_FIRST_DRIVER_MSG && message <= WM_WINE_LAST_DRIVER_MSG);
+}
+
 /* find a hardware message for the given queue */
 static int get_hardware_message( struct thread *thread, unsigned int hw_id, user_handle_t filter_win,
                                  unsigned int first, unsigned int last, unsigned int flags,
@@ -2729,7 +2796,6 @@ static int get_hardware_message( struct
     while (ptr)
     {
         struct message *msg = LIST_ENTRY( ptr, struct message, entry );
-        int msg_bit = get_hardware_msg_bit( msg->msg );
         struct hardware_msg_data *data = msg->data;
 
         ptr = list_next( &input->msg_list, ptr );
@@ -2753,7 +2819,7 @@ static int get_hardware_message( struct
             if (win_thread->queue->input == input)
             {
                 /* wake the other thread */
-                set_queue_bits( win_thread->queue, QS_HARDWARE | msg_bit );
+                set_queue_bits( win_thread->queue, get_hardware_msg_bit( msg->msg ) );
                 got_one = 1;
             }
             else
@@ -2772,7 +2838,7 @@ static int get_hardware_message( struct
          * match the filter we skip it */
         if (got_one || !check_hw_message_filter( win, msg_code, filter_win, first, last ))
         {
-            clear_bits &= ~msg_bit;
+            clear_bits &= ~get_hardware_msg_bit( msg->msg );
             continue;
         }
 
@@ -2796,14 +2862,13 @@ static int get_hardware_message( struct
 
         data->hw_id = msg->unique_id;
         set_reply_data( msg->data, msg->data_size );
-
-        if (msg_bit == QS_HARDWARE) flags |= PM_REMOVE; /* always remove internal hardware messages right away */
-        else if (!(msg_bit & (QS_RAWINPUT | QS_POINTER))) flags &= ~PM_REMOVE; /* wait for accept_hardware_message request */
-        if (flags & PM_REMOVE) release_hardware_message( current->queue, data->hw_id );
+        if ((get_hardware_msg_bit( msg->msg ) & (QS_RAWINPUT | QS_POINTER) && (flags & PM_REMOVE)) ||
+            is_internal_hardware_message( msg->msg ))
+            release_hardware_message( current->queue, data->hw_id );
         return 1;
     }
     /* nothing found, clear the hardware queue bits */
-    clear_queue_bits( thread->queue, QS_HARDWARE | clear_bits );
+    clear_queue_bits( thread->queue, clear_bits );
     return 0;
 }
 
@@ -3083,10 +3148,7 @@ DECL_HANDLER(set_queue_fd)
     if ((unix_fd = get_file_unix_fd( file )) != -1)
     {
         if ((unix_fd = dup( unix_fd )) != -1)
-        {
             queue->fd = create_anonymous_fd( &msg_queue_fd_ops, unix_fd, &queue->obj, 0 );
-            set_fd_events( queue->fd, POLLIN );
-        }
         else
             file_set_error();
     }
@@ -3098,31 +3160,39 @@ DECL_HANDLER(set_queue_fd)
 DECL_HANDLER(set_queue_mask)
 {
     struct msg_queue *queue = get_current_queue();
-    queue_shm_t *queue_shm;
 
-    if (!queue) return;
-    queue_shm = queue->shared;
-
-    if (req->poll_events)
+    if (queue)
     {
-        if (!queue->fd) return;
-        clear_queue_bits( queue, QS_DRIVER );
-        set_fd_events( queue->fd, POLLIN );
-        return;
-    }
+        queue_shm_t *queue_shm = queue->shared;
 
-    SHARED_WRITE_BEGIN( queue_shm, queue_shm_t )
-    {
-        shared->access_time  = monotonic_time;
-        shared->wake_mask    = req->wake_mask;
-        shared->changed_mask = req->changed_mask;
-        reply->wake_bits     = shared->wake_bits;
-        reply->changed_bits  = shared->changed_bits;
-    }
-    SHARED_WRITE_END;
+        SHARED_WRITE_BEGIN( queue_shm, queue_shm_t )
+        {
+            shared->wake_mask = req->wake_mask;
+            shared->changed_mask = req->changed_mask;
+        }
+        SHARED_WRITE_END;
+
+        reply->wake_bits    = queue_shm->wake_bits;
+        reply->changed_bits = queue_shm->changed_bits;
+
+        if (is_signaled( queue ))
+        {
+            /* if skip wait is set, do what would have been done in the subsequent wait */
+            if (req->skip_wait)
+            {
+                SHARED_WRITE_BEGIN( queue_shm, queue_shm_t )
+                {
+                    shared->wake_mask = 0;
+                    shared->changed_mask = 0;
+                }
+                SHARED_WRITE_END;
+            }
+            else wake_up( &queue->obj, 0 );
+        }
 
-    if (!get_queue_status( queue )) reset_sync( queue->sync );
-    else signal_sync( queue->sync );
+        if (do_esync() && !is_signaled( queue ))
+            esync_clear( queue->esync_fd );
+    }
 }
 
 
@@ -3130,20 +3200,23 @@ DECL_HANDLER(set_queue_mask)
 DECL_HANDLER(get_queue_status)
 {
     struct msg_queue *queue = current->queue;
-    queue_shm_t *queue_shm;
+    if (queue)
+    {
+        queue_shm_t *queue_shm = queue->shared;
 
-    if (!queue) return;
-    queue_shm = queue->shared;
+        reply->wake_bits    = queue_shm->wake_bits;
+        reply->changed_bits = queue_shm->changed_bits;
 
-    SHARED_WRITE_BEGIN( queue_shm, queue_shm_t )
-    {
-        reply->wake_bits      = shared->wake_bits;
-        reply->changed_bits   = shared->changed_bits;
-        shared->changed_bits &= ~req->clear_bits;
-    }
-    SHARED_WRITE_END;
+        SHARED_WRITE_BEGIN( queue_shm, queue_shm_t )
+        {
+            shared->changed_bits &= ~req->clear_bits;
+        }
+        SHARED_WRITE_END;
 
-    if (!get_queue_status( queue )) reset_sync( queue->sync );
+        if (do_esync() && !is_signaled( queue ))
+            esync_clear( queue->esync_fd );
+    }
+    else reply->wake_bits = reply->changed_bits = 0;
 }
 
 
@@ -3313,11 +3386,7 @@ DECL_HANDLER(get_message)
         return;
     }
 
-    SHARED_WRITE_BEGIN( queue_shm, queue_shm_t )
-    {
-        shared->access_time = monotonic_time;
-    }
-    SHARED_WRITE_END;
+    queue->last_get_msg = current_time;
 
     /* first check for sent messages */
     if ((ptr = list_head( &queue->msg_list[SEND_MESSAGE] )))
@@ -3343,8 +3412,6 @@ DECL_HANDLER(get_message)
     }
     SHARED_WRITE_END;
 
-    if (!get_queue_status( queue )) reset_sync( queue->sync );
-
     /* then check for posted messages */
     if ((filter & QS_POSTMESSAGE) &&
         get_posted_message( queue, get_win, req->get_first, req->get_last, req->flags, reply ))
@@ -3404,9 +3471,11 @@ DECL_HANDLER(get_message)
     }
     SHARED_WRITE_END;
 
-    if (!get_queue_status( queue )) reset_sync( queue->sync );
-    else signal_sync( queue->sync );
     set_error( STATUS_PENDING );  /* FIXME */
+
+    if (do_esync() && !is_signaled( queue ))
+        esync_clear( queue->esync_fd );
+
 }
 
 
@@ -4065,7 +4134,7 @@ DECL_HANDLER(get_rawinput_buffer)
 {
     const size_t align = is_machine_64bit( current->process->machine ) ? 7 : 3;
     data_size_t buffer_size = get_reply_max_size() & ~align;
-    struct msg_queue *queue = current->queue;
+    struct thread_input *input = current->queue->input;
     struct message *msg, *next_msg;
     int count = 0;
     char *buffer;
@@ -4078,7 +4147,7 @@ DECL_HANDLER(get_rawinput_buffer)
 
     if (!req->read_data)
     {
-        LIST_FOR_EACH_ENTRY( msg, &queue->input->msg_list, struct message, entry )
+        LIST_FOR_EACH_ENTRY( msg, &input->msg_list, struct message, entry )
         {
             if (msg->msg == WM_INPUT)
             {
@@ -4096,7 +4165,7 @@ DECL_HANDLER(get_rawinput_buffer)
 
         reply->next_size = get_reply_max_size();
 
-        LIST_FOR_EACH_ENTRY_SAFE( msg, next_msg, &queue->input->msg_list, struct message, entry )
+        LIST_FOR_EACH_ENTRY_SAFE( msg, next_msg, &input->msg_list, struct message, entry )
         {
             if (msg->msg == WM_INPUT)
             {
@@ -4126,7 +4195,6 @@ DECL_HANDLER(get_rawinput_buffer)
 
         if (!next_size)
         {
-            clear_queue_bits( queue, QS_RAWINPUT | (list_empty( &queue->input->msg_list ) ? QS_HARDWARE : 0) );
             if (count) next_size = sizeof(RAWINPUT);
             else reply->next_size = 0;
         }
@@ -4184,6 +4252,23 @@ DECL_HANDLER(update_rawinput_devices)
     }
 }
 
+DECL_HANDLER(esync_msgwait)
+{
+    struct msg_queue *queue = get_current_queue();
+    const queue_shm_t *queue_shm;
+
+    if (!queue) return;
+    queue_shm = queue->shared;
+    queue->esync_in_msgwait = req->in_msgwait;
+
+    if (current->process->idle_event && !(queue_shm->wake_mask & QS_SMRESULT))
+        set_event( current->process->idle_event );
+
+    /* and start/stop waiting on the driver */
+    if (queue->fd)
+        set_fd_events( queue->fd, req->in_msgwait ? POLLIN : 0 );
+}
+
 DECL_HANDLER(set_keyboard_repeat)
 {
     struct desktop *desktop;
@@ -4202,3 +4287,4 @@ DECL_HANDLER(set_keyboard_repeat)
 
     release_object( desktop );
 }
+
diff -ruN --show-c-function server/registry.c server/registry.c
--- server/registry.c	2025-10-21 17:44:36.356781262 -0700
+++ server/registry.c	2025-10-24 16:11:42.400525490 -0700
@@ -180,10 +180,10 @@ static const struct object_ops key_ops =
     no_add_queue,            /* add_queue */
     NULL,                    /* remove_queue */
     NULL,                    /* signaled */
+    NULL,                    /* get_esync_fd */
     NULL,                    /* satisfied */
     no_signal,               /* signal */
     no_get_fd,               /* get_fd */
-    default_get_sync,        /* get_sync */
     key_map_access,          /* map_access */
     key_get_sd,              /* get_sd */
     default_set_sd,          /* set_sd */
diff -ruN --show-c-function server/request.c server/request.c
--- server/request.c	2025-10-21 17:44:36.356781262 -0700
+++ server/request.c	2025-10-24 16:11:42.400758222 -0700
@@ -89,10 +89,10 @@ static const struct object_ops master_so
     no_add_queue,                  /* add_queue */
     NULL,                          /* remove_queue */
     NULL,                          /* signaled */
+    NULL,                          /* get_esync_fd */
     NULL,                          /* satisfied */
     no_signal,                     /* signal */
     no_get_fd,                     /* get_fd */
-    default_get_sync,              /* get_sync */
     default_map_access,            /* map_access */
     default_get_sd,                /* get_sd */
     default_set_sd,                /* set_sd */
diff -ruN --show-c-function server/request_handlers.h server/request_handlers.h
--- server/request_handlers.h	2025-10-21 17:44:36.809791459 -0700
+++ server/request_handlers.h	2025-10-24 16:11:48.569394573 -0700
@@ -302,15 +302,18 @@ DECL_HANDLER(suspend_process);
 DECL_HANDLER(resume_process);
 DECL_HANDLER(get_next_process);
 DECL_HANDLER(get_next_thread);
+DECL_HANDLER(create_esync);
+DECL_HANDLER(open_esync);
+DECL_HANDLER(get_esync_fd);
+DECL_HANDLER(esync_msgwait);
 DECL_HANDLER(set_keyboard_repeat);
-DECL_HANDLER(get_inproc_sync_fd);
-DECL_HANDLER(get_inproc_alert_fd);
 DECL_HANDLER(d3dkmt_object_create);
 DECL_HANDLER(d3dkmt_object_update);
 DECL_HANDLER(d3dkmt_object_query);
 DECL_HANDLER(d3dkmt_object_open);
 DECL_HANDLER(d3dkmt_share_objects);
 DECL_HANDLER(d3dkmt_object_open_name);
+DECL_HANDLER(get_esync_apc_fd);
 
 typedef void (*req_handler)( const void *req, void *reply );
 static const req_handler req_handlers[REQ_NB_REQUESTS] =
@@ -610,15 +613,18 @@ static const req_handler req_handlers[RE
     (req_handler)req_resume_process,
     (req_handler)req_get_next_process,
     (req_handler)req_get_next_thread,
+    (req_handler)req_create_esync,
+    (req_handler)req_open_esync,
+    (req_handler)req_get_esync_fd,
+    (req_handler)req_esync_msgwait,
     (req_handler)req_set_keyboard_repeat,
-    (req_handler)req_get_inproc_sync_fd,
-    (req_handler)req_get_inproc_alert_fd,
     (req_handler)req_d3dkmt_object_create,
     (req_handler)req_d3dkmt_object_update,
     (req_handler)req_d3dkmt_object_query,
     (req_handler)req_d3dkmt_object_open,
     (req_handler)req_d3dkmt_share_objects,
     (req_handler)req_d3dkmt_object_open_name,
+    (req_handler)req_get_esync_apc_fd,
 };
 
 C_ASSERT( sizeof(abstime_t) == 8 );
@@ -721,9 +727,8 @@ C_ASSERT( offsetof(struct init_first_thr
 C_ASSERT( offsetof(struct init_first_thread_reply, tid) == 12 );
 C_ASSERT( offsetof(struct init_first_thread_reply, server_start) == 16 );
 C_ASSERT( offsetof(struct init_first_thread_reply, session_id) == 24 );
-C_ASSERT( offsetof(struct init_first_thread_reply, inproc_device) == 28 );
-C_ASSERT( offsetof(struct init_first_thread_reply, info_size) == 32 );
-C_ASSERT( sizeof(struct init_first_thread_reply) == 40 );
+C_ASSERT( offsetof(struct init_first_thread_reply, info_size) == 28 );
+C_ASSERT( sizeof(struct init_first_thread_reply) == 32 );
 C_ASSERT( offsetof(struct init_thread_request, unix_tid) == 12 );
 C_ASSERT( offsetof(struct init_thread_request, reply_fd) == 16 );
 C_ASSERT( offsetof(struct init_thread_request, wait_fd) == 20 );
@@ -1316,7 +1321,7 @@ C_ASSERT( offsetof(struct set_queue_fd_r
 C_ASSERT( sizeof(struct set_queue_fd_request) == 16 );
 C_ASSERT( offsetof(struct set_queue_mask_request, wake_mask) == 12 );
 C_ASSERT( offsetof(struct set_queue_mask_request, changed_mask) == 16 );
-C_ASSERT( offsetof(struct set_queue_mask_request, poll_events) == 20 );
+C_ASSERT( offsetof(struct set_queue_mask_request, skip_wait) == 20 );
 C_ASSERT( sizeof(struct set_queue_mask_request) == 24 );
 C_ASSERT( offsetof(struct set_queue_mask_reply, wake_bits) == 8 );
 C_ASSERT( offsetof(struct set_queue_mask_reply, changed_bits) == 12 );
@@ -1827,11 +1832,11 @@ C_ASSERT( offsetof(struct create_class_r
 C_ASSERT( offsetof(struct create_class_request, atom) == 16 );
 C_ASSERT( offsetof(struct create_class_request, style) == 20 );
 C_ASSERT( offsetof(struct create_class_request, instance) == 24 );
-C_ASSERT( offsetof(struct create_class_request, client_ptr) == 32 );
-C_ASSERT( offsetof(struct create_class_request, cls_extra) == 40 );
-C_ASSERT( offsetof(struct create_class_request, win_extra) == 42 );
-C_ASSERT( offsetof(struct create_class_request, name_offset) == 44 );
-C_ASSERT( sizeof(struct create_class_request) == 48 );
+C_ASSERT( offsetof(struct create_class_request, extra) == 32 );
+C_ASSERT( offsetof(struct create_class_request, win_extra) == 36 );
+C_ASSERT( offsetof(struct create_class_request, client_ptr) == 40 );
+C_ASSERT( offsetof(struct create_class_request, name_offset) == 48 );
+C_ASSERT( sizeof(struct create_class_request) == 56 );
 C_ASSERT( offsetof(struct create_class_reply, locator) == 8 );
 C_ASSERT( offsetof(struct create_class_reply, atom) == 24 );
 C_ASSERT( sizeof(struct create_class_reply) == 32 );
@@ -2295,20 +2300,37 @@ C_ASSERT( offsetof(struct get_next_threa
 C_ASSERT( sizeof(struct get_next_thread_request) == 32 );
 C_ASSERT( offsetof(struct get_next_thread_reply, handle) == 8 );
 C_ASSERT( sizeof(struct get_next_thread_reply) == 16 );
+C_ASSERT( offsetof(struct create_esync_request, access) == 12 );
+C_ASSERT( offsetof(struct create_esync_request, initval) == 16 );
+C_ASSERT( offsetof(struct create_esync_request, type) == 20 );
+C_ASSERT( offsetof(struct create_esync_request, max) == 24 );
+C_ASSERT( sizeof(struct create_esync_request) == 32 );
+C_ASSERT( offsetof(struct create_esync_reply, handle) == 8 );
+C_ASSERT( offsetof(struct create_esync_reply, type) == 12 );
+C_ASSERT( offsetof(struct create_esync_reply, shm_idx) == 16 );
+C_ASSERT( sizeof(struct create_esync_reply) == 24 );
+C_ASSERT( offsetof(struct open_esync_request, access) == 12 );
+C_ASSERT( offsetof(struct open_esync_request, attributes) == 16 );
+C_ASSERT( offsetof(struct open_esync_request, rootdir) == 20 );
+C_ASSERT( offsetof(struct open_esync_request, type) == 24 );
+C_ASSERT( sizeof(struct open_esync_request) == 32 );
+C_ASSERT( offsetof(struct open_esync_reply, handle) == 8 );
+C_ASSERT( offsetof(struct open_esync_reply, type) == 12 );
+C_ASSERT( offsetof(struct open_esync_reply, shm_idx) == 16 );
+C_ASSERT( sizeof(struct open_esync_reply) == 24 );
+C_ASSERT( offsetof(struct get_esync_fd_request, handle) == 12 );
+C_ASSERT( sizeof(struct get_esync_fd_request) == 16 );
+C_ASSERT( offsetof(struct get_esync_fd_reply, type) == 8 );
+C_ASSERT( offsetof(struct get_esync_fd_reply, shm_idx) == 12 );
+C_ASSERT( sizeof(struct get_esync_fd_reply) == 16 );
+C_ASSERT( offsetof(struct esync_msgwait_request, in_msgwait) == 12 );
+C_ASSERT( sizeof(struct esync_msgwait_request) == 16 );
 C_ASSERT( offsetof(struct set_keyboard_repeat_request, enable) == 12 );
 C_ASSERT( offsetof(struct set_keyboard_repeat_request, delay) == 16 );
 C_ASSERT( offsetof(struct set_keyboard_repeat_request, period) == 20 );
 C_ASSERT( sizeof(struct set_keyboard_repeat_request) == 24 );
 C_ASSERT( offsetof(struct set_keyboard_repeat_reply, enable) == 8 );
 C_ASSERT( sizeof(struct set_keyboard_repeat_reply) == 16 );
-C_ASSERT( offsetof(struct get_inproc_sync_fd_request, handle) == 12 );
-C_ASSERT( sizeof(struct get_inproc_sync_fd_request) == 16 );
-C_ASSERT( offsetof(struct get_inproc_sync_fd_reply, type) == 8 );
-C_ASSERT( offsetof(struct get_inproc_sync_fd_reply, access) == 12 );
-C_ASSERT( sizeof(struct get_inproc_sync_fd_reply) == 16 );
-C_ASSERT( sizeof(struct get_inproc_alert_fd_request) == 16 );
-C_ASSERT( offsetof(struct get_inproc_alert_fd_reply, handle) == 8 );
-C_ASSERT( sizeof(struct get_inproc_alert_fd_reply) == 16 );
 C_ASSERT( offsetof(struct d3dkmt_object_create_request, type) == 12 );
 C_ASSERT( offsetof(struct d3dkmt_object_create_request, fd) == 16 );
 C_ASSERT( sizeof(struct d3dkmt_object_create_request) == 24 );
@@ -2346,3 +2368,4 @@ C_ASSERT( offsetof(struct d3dkmt_object_
 C_ASSERT( sizeof(struct d3dkmt_object_open_name_request) == 32 );
 C_ASSERT( offsetof(struct d3dkmt_object_open_name_reply, handle) == 8 );
 C_ASSERT( sizeof(struct d3dkmt_object_open_name_reply) == 16 );
+C_ASSERT( sizeof(struct get_esync_apc_fd_request) == 16 );
diff -ruN --show-c-function server/request_trace.h server/request_trace.h
--- server/request_trace.h	2025-10-21 17:44:36.809791459 -0700
+++ server/request_trace.h	2025-10-24 16:11:48.566322191 -0700
@@ -147,7 +147,6 @@ static void dump_init_first_thread_reply
     fprintf( stderr, ", tid=%04x", req->tid );
     dump_timeout( ", server_start=", &req->server_start );
     fprintf( stderr, ", session_id=%08x", req->session_id );
-    fprintf( stderr, ", inproc_device=%04x", req->inproc_device );
     fprintf( stderr, ", info_size=%u", req->info_size );
     dump_varargs_ushorts( ", machines=", cur_size );
 }
@@ -1384,7 +1383,7 @@ static void dump_set_queue_mask_request(
 {
     fprintf( stderr, " wake_mask=%08x", req->wake_mask );
     fprintf( stderr, ", changed_mask=%08x", req->changed_mask );
-    fprintf( stderr, ", poll_events=%d", req->poll_events );
+    fprintf( stderr, ", skip_wait=%d", req->skip_wait );
 }
 
 static void dump_set_queue_mask_reply( const struct set_queue_mask_reply *req )
@@ -2378,9 +2377,9 @@ static void dump_create_class_request( c
     fprintf( stderr, ", atom=%04x", req->atom );
     fprintf( stderr, ", style=%08x", req->style );
     dump_uint64( ", instance=", &req->instance );
-    dump_uint64( ", client_ptr=", &req->client_ptr );
-    fprintf( stderr, ", cls_extra=%d", req->cls_extra );
+    fprintf( stderr, ", extra=%d", req->extra );
     fprintf( stderr, ", win_extra=%d", req->win_extra );
+    dump_uint64( ", client_ptr=", &req->client_ptr );
     fprintf( stderr, ", name_offset=%u", req->name_offset );
     dump_varargs_unicode_str( ", name=", cur_size );
 }
@@ -3361,36 +3360,64 @@ static void dump_get_next_thread_reply(
     fprintf( stderr, " handle=%04x", req->handle );
 }
 
-static void dump_set_keyboard_repeat_request( const struct set_keyboard_repeat_request *req )
+static void dump_create_esync_request( const struct create_esync_request *req )
 {
-    fprintf( stderr, " enable=%d", req->enable );
-    fprintf( stderr, ", delay=%d", req->delay );
-    fprintf( stderr, ", period=%d", req->period );
+    fprintf( stderr, " access=%08x", req->access );
+    fprintf( stderr, ", initval=%d", req->initval );
+    fprintf( stderr, ", type=%d", req->type );
+    fprintf( stderr, ", max=%d", req->max );
+    dump_varargs_object_attributes( ", objattr=", cur_size );
 }
 
-static void dump_set_keyboard_repeat_reply( const struct set_keyboard_repeat_reply *req )
+static void dump_create_esync_reply( const struct create_esync_reply *req )
 {
-    fprintf( stderr, " enable=%d", req->enable );
+    fprintf( stderr, " handle=%04x", req->handle );
+    fprintf( stderr, ", type=%d", req->type );
+    fprintf( stderr, ", shm_idx=%08x", req->shm_idx );
+}
+
+static void dump_open_esync_request( const struct open_esync_request *req )
+{
+    fprintf( stderr, " access=%08x", req->access );
+    fprintf( stderr, ", attributes=%08x", req->attributes );
+    fprintf( stderr, ", rootdir=%04x", req->rootdir );
+    fprintf( stderr, ", type=%d", req->type );
+    dump_varargs_unicode_str( ", name=", cur_size );
 }
 
-static void dump_get_inproc_sync_fd_request( const struct get_inproc_sync_fd_request *req )
+static void dump_open_esync_reply( const struct open_esync_reply *req )
+{
+    fprintf( stderr, " handle=%04x", req->handle );
+    fprintf( stderr, ", type=%d", req->type );
+    fprintf( stderr, ", shm_idx=%08x", req->shm_idx );
+}
+
+static void dump_get_esync_fd_request( const struct get_esync_fd_request *req )
 {
     fprintf( stderr, " handle=%04x", req->handle );
 }
 
-static void dump_get_inproc_sync_fd_reply( const struct get_inproc_sync_fd_reply *req )
+static void dump_get_esync_fd_reply( const struct get_esync_fd_reply *req )
 {
     fprintf( stderr, " type=%d", req->type );
-    fprintf( stderr, ", access=%08x", req->access );
+    fprintf( stderr, ", shm_idx=%08x", req->shm_idx );
 }
 
-static void dump_get_inproc_alert_fd_request( const struct get_inproc_alert_fd_request *req )
+static void dump_esync_msgwait_request( const struct esync_msgwait_request *req )
 {
+    fprintf( stderr, " in_msgwait=%d", req->in_msgwait );
 }
 
-static void dump_get_inproc_alert_fd_reply( const struct get_inproc_alert_fd_reply *req )
+static void dump_set_keyboard_repeat_request( const struct set_keyboard_repeat_request *req )
 {
-    fprintf( stderr, " handle=%04x", req->handle );
+    fprintf( stderr, " enable=%d", req->enable );
+    fprintf( stderr, ", delay=%d", req->delay );
+    fprintf( stderr, ", period=%d", req->period );
+}
+
+static void dump_set_keyboard_repeat_reply( const struct set_keyboard_repeat_reply *req )
+{
+    fprintf( stderr, " enable=%d", req->enable );
 }
 
 static void dump_d3dkmt_object_create_request( const struct d3dkmt_object_create_request *req )
@@ -3468,6 +3495,10 @@ static void dump_d3dkmt_object_open_name
     fprintf( stderr, " handle=%04x", req->handle );
 }
 
+static void dump_get_esync_apc_fd_request( const struct get_esync_apc_fd_request *req )
+{
+}
+
 typedef void (*dump_func)( const void *req );
 
 static const dump_func req_dumpers[REQ_NB_REQUESTS] =
@@ -3767,15 +3798,18 @@ static const dump_func req_dumpers[REQ_N
     (dump_func)dump_resume_process_request,
     (dump_func)dump_get_next_process_request,
     (dump_func)dump_get_next_thread_request,
+    (dump_func)dump_create_esync_request,
+    (dump_func)dump_open_esync_request,
+    (dump_func)dump_get_esync_fd_request,
+    (dump_func)dump_esync_msgwait_request,
     (dump_func)dump_set_keyboard_repeat_request,
-    (dump_func)dump_get_inproc_sync_fd_request,
-    (dump_func)dump_get_inproc_alert_fd_request,
     (dump_func)dump_d3dkmt_object_create_request,
     (dump_func)dump_d3dkmt_object_update_request,
     (dump_func)dump_d3dkmt_object_query_request,
     (dump_func)dump_d3dkmt_object_open_request,
     (dump_func)dump_d3dkmt_share_objects_request,
     (dump_func)dump_d3dkmt_object_open_name_request,
+    (dump_func)dump_get_esync_apc_fd_request,
 };
 
 static const dump_func reply_dumpers[REQ_NB_REQUESTS] =
@@ -4075,15 +4109,18 @@ static const dump_func reply_dumpers[REQ
     NULL,
     (dump_func)dump_get_next_process_reply,
     (dump_func)dump_get_next_thread_reply,
+    (dump_func)dump_create_esync_reply,
+    (dump_func)dump_open_esync_reply,
+    (dump_func)dump_get_esync_fd_reply,
+    NULL,
     (dump_func)dump_set_keyboard_repeat_reply,
-    (dump_func)dump_get_inproc_sync_fd_reply,
-    (dump_func)dump_get_inproc_alert_fd_reply,
     (dump_func)dump_d3dkmt_object_create_reply,
     NULL,
     (dump_func)dump_d3dkmt_object_query_reply,
     (dump_func)dump_d3dkmt_object_open_reply,
     (dump_func)dump_d3dkmt_share_objects_reply,
     (dump_func)dump_d3dkmt_object_open_name_reply,
+    NULL,
 };
 
 static const char * const req_names[REQ_NB_REQUESTS] =
@@ -4383,15 +4420,18 @@ static const char * const req_names[REQ_
     "resume_process",
     "get_next_process",
     "get_next_thread",
+    "create_esync",
+    "open_esync",
+    "get_esync_fd",
+    "esync_msgwait",
     "set_keyboard_repeat",
-    "get_inproc_sync_fd",
-    "get_inproc_alert_fd",
     "d3dkmt_object_create",
     "d3dkmt_object_update",
     "d3dkmt_object_query",
     "d3dkmt_object_open",
     "d3dkmt_share_objects",
     "d3dkmt_object_open_name",
+    "get_esync_apc_fd",
 };
 
 static const struct
diff -ruN --show-c-function server/semaphore.c server/semaphore.c
--- server/semaphore.c	2025-10-21 17:44:36.357781284 -0700
+++ server/semaphore.c	2025-10-24 16:11:42.400890332 -0700
@@ -50,121 +50,30 @@ struct type_descr semaphore_type =
     },
 };
 
-struct semaphore_sync
-{
-    struct object       obj;                /* object header */
-    unsigned int        count;              /* current count */
-    unsigned int        max;                /* maximum possible count */
-};
-
-static void semaphore_sync_dump( struct object *obj, int verbose );
-static int semaphore_sync_signaled( struct object *obj, struct wait_queue_entry *entry );
-static void semaphore_sync_satisfied( struct object *obj, struct wait_queue_entry *entry );
-
-static const struct object_ops semaphore_sync_ops =
-{
-    sizeof(struct semaphore_sync), /* size */
-    &no_type,                      /* type */
-    semaphore_sync_dump,           /* dump */
-    add_queue,                     /* add_queue */
-    remove_queue,                  /* remove_queue */
-    semaphore_sync_signaled,       /* signaled */
-    semaphore_sync_satisfied,      /* satisfied */
-    no_signal,                     /* signal */
-    no_get_fd,                     /* get_fd */
-    default_get_sync,              /* get_sync */
-    default_map_access,            /* map_access */
-    default_get_sd,                /* get_sd */
-    default_set_sd,                /* set_sd */
-    default_get_full_name,         /* get_full_name */
-    no_lookup_name,                /* lookup_name */
-    directory_link_name,           /* link_name */
-    default_unlink_name,           /* unlink_name */
-    no_open_file,                  /* open_file */
-    no_kernel_obj_list,            /* get_kernel_obj_list */
-    no_close_handle,               /* close_handle */
-    no_destroy                     /* destroy */
-};
-
-static int release_semaphore( struct semaphore_sync *sem, unsigned int count,
-                              unsigned int *prev )
-{
-    if (prev) *prev = sem->count;
-    if (sem->count + count < sem->count || sem->count + count > sem->max)
-    {
-        set_error( STATUS_SEMAPHORE_LIMIT_EXCEEDED );
-        return 0;
-    }
-    else if (sem->count)
-    {
-        /* there cannot be any thread to wake up if the count is != 0 */
-        sem->count += count;
-    }
-    else
-    {
-        sem->count = count;
-        wake_up( &sem->obj, count );
-    }
-    return 1;
-}
-
-static void semaphore_sync_dump( struct object *obj, int verbose )
-{
-    struct semaphore_sync *sem = (struct semaphore_sync *)obj;
-    assert( obj->ops == &semaphore_sync_ops );
-    fprintf( stderr, "Semaphore count=%d max=%d\n", sem->count, sem->max );
-}
-
-static int semaphore_sync_signaled( struct object *obj, struct wait_queue_entry *entry )
-{
-    struct semaphore_sync *sem = (struct semaphore_sync *)obj;
-    assert( obj->ops == &semaphore_sync_ops );
-    return (sem->count > 0);
-}
-
-static void semaphore_sync_satisfied( struct object *obj, struct wait_queue_entry *entry )
-{
-    struct semaphore_sync *sem = (struct semaphore_sync *)obj;
-    assert( obj->ops == &semaphore_sync_ops );
-    assert( sem->count );
-    sem->count--;
-}
-
-static struct object *create_semaphore_sync( unsigned int initial, unsigned int max )
-{
-    struct semaphore_sync *sem;
-
-    if (get_inproc_device_fd() >= 0) return (struct object *)create_inproc_semaphore_sync( initial, max );
-
-    if (!(sem = alloc_object( &semaphore_sync_ops ))) return NULL;
-    sem->count = initial;
-    sem->max   = max;
-    return &sem->obj;
-}
-
 struct semaphore
 {
-    struct object          obj;    /* object header */
-    struct object         *sync;   /* semaphore sync object */
+    struct object  obj;    /* object header */
+    unsigned int   count;  /* current count */
+    unsigned int   max;    /* maximum possible count */
 };
 
 static void semaphore_dump( struct object *obj, int verbose );
-static struct object *semaphore_get_sync( struct object *obj );
-static int semaphore_signal( struct object *obj, unsigned int access, int signal );
-static void semaphore_destroy( struct object *obj );
+static int semaphore_signaled( struct object *obj, struct wait_queue_entry *entry );
+static void semaphore_satisfied( struct object *obj, struct wait_queue_entry *entry );
+static int semaphore_signal( struct object *obj, unsigned int access );
 
 static const struct object_ops semaphore_ops =
 {
     sizeof(struct semaphore),      /* size */
     &semaphore_type,               /* type */
     semaphore_dump,                /* dump */
-    NULL,                          /* add_queue */
-    NULL,                          /* remove_queue */
-    NULL,                          /* signaled */
-    NULL,                          /* satisfied */
+    add_queue,                     /* add_queue */
+    remove_queue,                  /* remove_queue */
+    semaphore_signaled,            /* signaled */
+    NULL,                          /* get_esync_fd */
+    semaphore_satisfied,           /* satisfied */
     semaphore_signal,              /* signal */
     no_get_fd,                     /* get_fd */
-    semaphore_get_sync,            /* get_sync */
     default_map_access,            /* map_access */
     default_get_sd,                /* get_sd */
     default_set_sd,                /* set_sd */
@@ -175,9 +84,10 @@ static const struct object_ops semaphore
     no_open_file,                  /* open_file */
     no_kernel_obj_list,            /* get_kernel_obj_list */
     no_close_handle,               /* close_handle */
-    semaphore_destroy,             /* destroy */
+    no_destroy                     /* destroy */
 };
 
+
 static struct semaphore *create_semaphore( struct object *root, const struct unicode_str *name,
                                            unsigned int attr, unsigned int initial, unsigned int max,
                                            const struct security_descriptor *sd )
@@ -194,53 +104,68 @@ static struct semaphore *create_semaphor
         if (get_error() != STATUS_OBJECT_NAME_EXISTS)
         {
             /* initialize it if it didn't already exist */
-            sem->sync = NULL;
-
-            if (!(sem->sync = create_semaphore_sync( initial, max )))
-            {
-                release_object( sem );
-                return NULL;
-            }
+            sem->count = initial;
+            sem->max   = max;
         }
     }
     return sem;
 }
 
+static int release_semaphore( struct semaphore *sem, unsigned int count,
+                              unsigned int *prev )
+{
+    if (prev) *prev = sem->count;
+    if (sem->count + count < sem->count || sem->count + count > sem->max)
+    {
+        set_error( STATUS_SEMAPHORE_LIMIT_EXCEEDED );
+        return 0;
+    }
+    else if (sem->count)
+    {
+        /* there cannot be any thread to wake up if the count is != 0 */
+        sem->count += count;
+    }
+    else
+    {
+        sem->count = count;
+        wake_up( &sem->obj, count );
+    }
+    return 1;
+}
+
 static void semaphore_dump( struct object *obj, int verbose )
 {
     struct semaphore *sem = (struct semaphore *)obj;
     assert( obj->ops == &semaphore_ops );
-    sem->sync->ops->dump( sem->sync, verbose );
+    fprintf( stderr, "Semaphore count=%d max=%d\n", sem->count, sem->max );
 }
 
-static struct object *semaphore_get_sync( struct object *obj )
+static int semaphore_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct semaphore *sem = (struct semaphore *)obj;
     assert( obj->ops == &semaphore_ops );
-    return grab_object( sem->sync );
+    return (sem->count > 0);
 }
 
-static int semaphore_signal( struct object *obj, unsigned int access, int signal )
+static void semaphore_satisfied( struct object *obj, struct wait_queue_entry *entry )
 {
     struct semaphore *sem = (struct semaphore *)obj;
     assert( obj->ops == &semaphore_ops );
+    assert( sem->count );
+    sem->count--;
+}
 
-    assert( sem->sync->ops == &semaphore_sync_ops ); /* never called with inproc syncs */
-    assert( signal == -1 ); /* always called from signal_object */
+static int semaphore_signal( struct object *obj, unsigned int access )
+{
+    struct semaphore *sem = (struct semaphore *)obj;
+    assert( obj->ops == &semaphore_ops );
 
     if (!(access & SEMAPHORE_MODIFY_STATE))
     {
         set_error( STATUS_ACCESS_DENIED );
         return 0;
     }
-    return release_semaphore( (struct semaphore_sync *)sem->sync, 1, NULL );
-}
-
-static void semaphore_destroy( struct object *obj )
-{
-    struct semaphore *sem = (struct semaphore *)obj;
-    assert( obj->ops == &semaphore_ops );
-    if (sem->sync) release_object( sem->sync );
+    return release_semaphore( sem, 1, NULL );
 }
 
 /* create a semaphore */
@@ -284,10 +209,7 @@ DECL_HANDLER(release_semaphore)
     if ((sem = (struct semaphore *)get_handle_obj( current->process, req->handle,
                                                    SEMAPHORE_MODIFY_STATE, &semaphore_ops )))
     {
-        struct semaphore_sync *sync = (struct semaphore_sync *)sem->sync;
-        assert( sem->sync->ops == &semaphore_sync_ops ); /* never called with inproc syncs */
-
-        release_semaphore( sync, req->count, &reply->prev_count );
+        release_semaphore( sem, req->count, &reply->prev_count );
         release_object( sem );
     }
 }
@@ -300,11 +222,8 @@ DECL_HANDLER(query_semaphore)
     if ((sem = (struct semaphore *)get_handle_obj( current->process, req->handle,
                                                    SEMAPHORE_QUERY_STATE, &semaphore_ops )))
     {
-        struct semaphore_sync *sync = (struct semaphore_sync *)sem->sync;
-        assert( sem->sync->ops == &semaphore_sync_ops ); /* never called with inproc syncs */
-
-        reply->current = sync->count;
-        reply->max = sync->max;
+        reply->current = sem->count;
+        reply->max = sem->max;
         release_object( sem );
     }
 }
diff -ruN --show-c-function server/serial.c server/serial.c
--- server/serial.c	2025-10-21 17:44:36.357781284 -0700
+++ server/serial.c	2025-10-24 16:11:42.400988158 -0700
@@ -88,13 +88,13 @@ static const struct object_ops serial_op
     sizeof(struct serial),        /* size */
     &file_type,                   /* type */
     serial_dump,                  /* dump */
-    NULL,                         /* add_queue */
-    NULL,                         /* remove_queue */
-    NULL,                         /* signaled */
-    NULL,                         /* satisfied */
+    add_queue,                    /* add_queue */
+    remove_queue,                 /* remove_queue */
+    default_fd_signaled,          /* signaled */
+    NULL,                         /* get_esync_fd */
+    no_satisfied,                 /* satisfied */
     no_signal,                    /* signal */
     serial_get_fd,                /* get_fd */
-    default_fd_get_sync,          /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
diff -ruN --show-c-function server/signal.c server/signal.c
--- server/signal.c	2025-10-21 17:44:36.357781284 -0700
+++ server/signal.c	2025-10-24 16:11:42.401090593 -0700
@@ -62,10 +62,10 @@ static const struct object_ops handler_o
     no_add_queue,             /* add_queue */
     NULL,                     /* remove_queue */
     NULL,                     /* signaled */
+    NULL,                     /* get_esync_fd */
     NULL,                     /* satisfied */
     no_signal,                /* signal */
     no_get_fd,                /* get_fd */
-    default_get_sync,         /* get_sync */
     default_map_access,       /* map_access */
     default_get_sd,           /* get_sd */
     default_set_sd,           /* set_sd */
diff -ruN --show-c-function server/sock.c server/sock.c
--- server/sock.c	2025-10-21 17:44:36.357781284 -0700
+++ server/sock.c	2025-10-24 16:11:42.401278359 -0700
@@ -483,13 +483,13 @@ static const struct object_ops sock_ops
     sizeof(struct sock),          /* size */
     &file_type,                   /* type */
     sock_dump,                    /* dump */
-    NULL,                         /* add_queue */
-    NULL,                         /* remove_queue */
-    NULL,                         /* signaled */
-    NULL,                         /* satisfied */
+    add_queue,                    /* add_queue */
+    remove_queue,                 /* remove_queue */
+    default_fd_signaled,          /* signaled */
+    NULL,                         /* get_esync_fd */
+    no_satisfied,                 /* satisfied */
     no_signal,                    /* signal */
     sock_get_fd,                  /* get_fd */
-    default_fd_get_sync,          /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
@@ -3706,10 +3706,10 @@ static const struct object_ops ifchange_
     no_add_queue,            /* add_queue */
     NULL,                    /* remove_queue */
     NULL,                    /* signaled */
+    NULL,                    /* get_esync_fd */
     no_satisfied,            /* satisfied */
     no_signal,               /* signal */
     ifchange_get_fd,         /* get_fd */
-    default_get_sync,        /* get_sync */
     default_map_access,      /* map_access */
     default_get_sd,          /* get_sd */
     default_set_sd,          /* set_sd */
@@ -3928,10 +3928,10 @@ static const struct object_ops socket_de
     no_add_queue,               /* add_queue */
     NULL,                       /* remove_queue */
     NULL,                       /* signaled */
+    NULL,                       /* get_esync_fd */
     no_satisfied,               /* satisfied */
     no_signal,                  /* signal */
     no_get_fd,                  /* get_fd */
-    default_get_sync,           /* get_sync */
     default_map_access,         /* map_access */
     default_get_sd,             /* get_sd */
     default_set_sd,             /* set_sd */
diff -ruN --show-c-function server/symlink.c server/symlink.c
--- server/symlink.c	2025-10-21 17:44:36.357781284 -0700
+++ server/symlink.c	2025-10-24 16:11:42.401602685 -0700
@@ -71,10 +71,10 @@ static const struct object_ops symlink_o
     no_add_queue,                 /* add_queue */
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
+    NULL,                         /* get_esync_fd */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-    default_get_sync,             /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
diff -ruN --show-c-function server/thread.c server/thread.c
--- server/thread.c	2025-10-21 17:44:36.809791459 -0700
+++ server/thread.c	2025-10-24 16:11:42.421200444 -0700
@@ -60,6 +60,7 @@
 #include "request.h"
 #include "user.h"
 #include "security.h"
+#include "esync.h"
 
 
 /* thread queues */
@@ -85,7 +86,6 @@ struct thread_wait
 struct thread_apc
 {
     struct object       obj;      /* object header */
-    struct object      *sync;     /* sync object for wait/signal */
     struct list         entry;    /* queue linked list */
     struct thread      *caller;   /* thread that queued this apc */
     struct object      *owner;    /* object that queued this apc */
@@ -96,7 +96,7 @@ struct thread_apc
 };
 
 static void dump_thread_apc( struct object *obj, int verbose );
-static struct object *thread_apc_get_sync( struct object *obj );
+static int thread_apc_signaled( struct object *obj, struct wait_queue_entry *entry );
 static void thread_apc_destroy( struct object *obj );
 static void clear_apc_queue( struct list *queue );
 
@@ -105,13 +105,13 @@ static const struct object_ops thread_ap
     sizeof(struct thread_apc),  /* size */
     &no_type,                   /* type */
     dump_thread_apc,            /* dump */
-    NULL,                       /* add_queue */
-    NULL,                       /* remove_queue */
-    NULL,                       /* signaled */
-    NULL,                       /* satisfied */
+    add_queue,                  /* add_queue */
+    remove_queue,               /* remove_queue */
+    thread_apc_signaled,        /* signaled */
+    NULL,                       /* get_esync_fd */
+    no_satisfied,               /* satisfied */
     no_signal,                  /* signal */
     no_get_fd,                  /* get_fd */
-    thread_apc_get_sync,        /* get_sync */
     default_map_access,         /* map_access */
     default_get_sd,             /* get_sd */
     default_set_sd,             /* set_sd */
@@ -130,10 +130,9 @@ static const struct object_ops thread_ap
 
 struct context
 {
-    struct object           obj;        /* object header */
-    struct object          *sync;       /* sync object for wait/signal */
-    unsigned int            status;     /* status of the context */
-    struct context_data     regs[2];    /* context data */
+    struct object   obj;        /* object header */
+    unsigned int    status;     /* status of the context */
+    struct context_data regs[2];/* context data */
 };
 #define CTX_NATIVE  0  /* context for native machine */
 #define CTX_WOW     1  /* context if thread is inside WoW */
@@ -142,21 +141,20 @@ struct context
 static const unsigned int system_flags = SERVER_CTX_DEBUG_REGISTERS;
 
 static void dump_context( struct object *obj, int verbose );
-static struct object *context_get_sync( struct object *obj );
-static void context_destroy( struct object *obj );
+static int context_signaled( struct object *obj, struct wait_queue_entry *entry );
 
 static const struct object_ops context_ops =
 {
     sizeof(struct context),     /* size */
     &no_type,                   /* type */
     dump_context,               /* dump */
-    NULL,                       /* add_queue */
-    NULL,                       /* remove_queue */
-    NULL,                       /* signaled */
-    NULL,                       /* satisfied */
+    add_queue,                  /* add_queue */
+    remove_queue,               /* remove_queue */
+    context_signaled,           /* signaled */
+    NULL,                       /* get_esync_fd */
+    no_satisfied,               /* satisfied */
     no_signal,                  /* signal */
     no_get_fd,                  /* get_fd */
-    context_get_sync,           /* get_sync */
     default_map_access,         /* map_access */
     default_get_sd,             /* get_sd */
     default_set_sd,             /* set_sd */
@@ -167,7 +165,7 @@ static const struct object_ops context_o
     no_open_file,               /* open_file */
     no_kernel_obj_list,         /* get_kernel_obj_list */
     no_close_handle,            /* close_handle */
-    context_destroy,            /* destroy */
+    no_destroy                  /* destroy */
 };
 
 
@@ -189,7 +187,8 @@ struct type_descr thread_type =
 };
 
 static void dump_thread( struct object *obj, int verbose );
-static struct object *thread_get_sync( struct object *obj );
+static int thread_signaled( struct object *obj, struct wait_queue_entry *entry );
+static int thread_get_esync_fd( struct object *obj, enum esync_type *type );
 static unsigned int thread_map_access( struct object *obj, unsigned int access );
 static void thread_poll_event( struct fd *fd, int event );
 static struct list *thread_get_kernel_obj_list( struct object *obj );
@@ -200,13 +199,13 @@ static const struct object_ops thread_op
     sizeof(struct thread),      /* size */
     &thread_type,               /* type */
     dump_thread,                /* dump */
-    NULL,                       /* add_queue */
-    NULL,                       /* remove_queue */
-    NULL,                       /* signaled */
-    NULL,                       /* satisfied */
+    add_queue,                  /* add_queue */
+    remove_queue,               /* remove_queue */
+    thread_signaled,            /* signaled */
+    thread_get_esync_fd,        /* get_esync_fd */
+    no_satisfied,               /* satisfied */
     no_signal,                  /* signal */
     no_get_fd,                  /* get_fd */
-    thread_get_sync,            /* get_sync */
     thread_map_access,          /* map_access */
     default_get_sd,             /* get_sd */
     default_set_sd,             /* set_sd */
@@ -398,13 +397,13 @@ static inline void init_thread_structure
 {
     int i;
 
-    thread->sync            = NULL;
-    thread->alert_sync      = NULL;
     thread->unix_pid        = -1;  /* not known yet */
     thread->unix_tid        = -1;  /* not known yet */
     thread->context         = NULL;
     thread->teb             = 0;
     thread->entry_point     = 0;
+    thread->esync_fd        = -1;
+    thread->esync_apc_fd    = -1;
     thread->system_regs     = 0;
     thread->queue           = NULL;
     thread->wait            = NULL;
@@ -466,35 +465,20 @@ static void dump_context( struct object
 }
 
 
-static struct object *context_get_sync( struct object *obj )
+static int context_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct context *context = (struct context *)obj;
-    assert( obj->ops == &context_ops );
-    return grab_object( context->sync );
+    return context->status != STATUS_PENDING;
 }
 
-static void context_destroy( struct object *obj )
-{
-    struct context *context = (struct context *)obj;
-    assert( obj->ops == &context_ops );
-    if (context->sync) release_object( context->sync );
-}
 
 static struct context *create_thread_context( struct thread *thread )
 {
     struct context *context;
     if (!(context = alloc_object( &context_ops ))) return NULL;
-    context->sync   = NULL;
     context->status = STATUS_PENDING;
     memset( &context->regs, 0, sizeof(context->regs) );
     context->regs[CTX_NATIVE].machine = native_machine;
-
-    if (!(context->sync = create_internal_sync( 1, 0 )))
-    {
-        release_object( context );
-        return NULL;
-    }
-
     return context;
 }
 
@@ -561,9 +545,11 @@ struct thread *create_thread( int fd, st
         release_object( thread );
         return NULL;
     }
-    if (!(thread->request_fd = create_anonymous_fd( &thread_fd_ops, fd, &thread->obj, 0 ))) goto error;
-    if (!(thread->sync = create_internal_sync( 1, 0 ))) goto error;
-    if (get_inproc_device_fd() >= 0 && !(thread->alert_sync = create_inproc_internal_sync( 1, 0 ))) goto error;
+    if (!(thread->request_fd = create_anonymous_fd( &thread_fd_ops, fd, &thread->obj, 0 )))
+    {
+        release_object( thread );
+        return NULL;
+    }
 
     if (process->desktop)
     {
@@ -575,13 +561,15 @@ struct thread *create_thread( int fd, st
         }
     }
 
+    if (do_esync())
+    {
+        thread->esync_fd = esync_create_fd( 0, 0 );
+        thread->esync_apc_fd = esync_create_fd( 0, 0 );
+    }
+
     set_fd_events( thread->request_fd, POLLIN );  /* start listening to events */
     add_process_thread( thread->process, thread );
     return thread;
-
-error:
-    release_object( thread );
-    return NULL;
 }
 
 /* handle a client event */
@@ -613,7 +601,7 @@ static void cleanup_thread( struct threa
     if (thread->context)
     {
         thread->context->status = STATUS_ACCESS_DENIED;
-        signal_sync( thread->context->sync );
+        wake_up( &thread->context->obj, 0 );
         release_object( thread->context );
         thread->context = NULL;
     }
@@ -658,8 +646,9 @@ static void destroy_thread( struct objec
     release_object( thread->process );
     if (thread->id) free_ptid( thread->id );
     if (thread->token) release_object( thread->token );
-    if (thread->alert_sync) release_object( thread->alert_sync );
-    if (thread->sync) release_object( thread->sync );
+
+    if (do_esync())
+        close( thread->esync_fd );
 }
 
 /* dump a thread on stdout for debugging purposes */
@@ -672,11 +661,17 @@ static void dump_thread( struct object *
              thread->id, thread->unix_pid, thread->unix_tid, thread->state );
 }
 
-static struct object *thread_get_sync( struct object *obj )
+static int thread_signaled( struct object *obj, struct wait_queue_entry *entry )
+{
+    struct thread *mythread = (struct thread *)obj;
+    return (mythread->state == TERMINATED);
+}
+
+static int thread_get_esync_fd( struct object *obj, enum esync_type *type )
 {
     struct thread *thread = (struct thread *)obj;
-    assert( obj->ops == &thread_ops );
-    return grab_object( thread->sync );
+    *type = ESYNC_MANUAL_SERVER;
+    return thread->esync_fd;
 }
 
 static unsigned int thread_map_access( struct object *obj, unsigned int access )
@@ -695,11 +690,10 @@ static void dump_thread_apc( struct obje
     fprintf( stderr, "APC owner=%p type=%u\n", apc->owner, apc->call.type );
 }
 
-static struct object *thread_apc_get_sync( struct object *obj )
+static int thread_apc_signaled( struct object *obj, struct wait_queue_entry *entry )
 {
     struct thread_apc *apc = (struct thread_apc *)obj;
-    assert( obj->ops == &thread_apc_ops );
-    return grab_object( apc->sync );
+    return apc->executed;
 }
 
 static void thread_apc_destroy( struct object *obj )
@@ -715,7 +709,6 @@ static void thread_apc_destroy( struct o
             async_set_result( apc->owner, apc->call.async_io.status, 0 );
         release_object( apc->owner );
     }
-    if (apc->sync) release_object( apc->sync );
     reserve_obj_unbind( apc->reserve );
 }
 
@@ -726,7 +719,6 @@ static struct thread_apc *create_apc( st
 
     if ((apc = alloc_object( &thread_apc_ops )))
     {
-        apc->sync        = NULL;
         if (call_data) apc->call = *call_data;
         else apc->call.type = APC_NONE;
         apc->caller      = NULL;
@@ -735,12 +727,6 @@ static struct thread_apc *create_apc( st
         apc->executed    = 0;
         apc->result.type = APC_NONE;
         if (owner) grab_object( owner );
-
-        if (!(apc->sync = create_internal_sync( 1, 0 )))
-        {
-            release_object( apc );
-            return NULL;
-        }
     }
     return apc;
 }
@@ -987,6 +973,8 @@ int resume_thread( struct thread *thread
 /* add a thread to an object wait queue; return 1 if OK, 0 on error */
 int add_queue( struct object *obj, struct wait_queue_entry *entry )
 {
+    grab_object( obj );
+    entry->obj = obj;
     list_add_tail( &obj->wait_queue, &entry->entry );
     return 1;
 }
@@ -995,6 +983,7 @@ int add_queue( struct object *obj, struc
 void remove_queue( struct object *obj, struct wait_queue_entry *entry )
 {
     list_remove( &entry->entry );
+    release_object( obj );
 }
 
 struct thread *get_wait_queue_thread( struct wait_queue_entry *entry )
@@ -1022,46 +1011,6 @@ void set_wait_status( struct wait_queue_
     entry->wait->status = status;
 }
 
-static void object_sync_satisfied( struct object *obj, struct wait_queue_entry *entry )
-{
-    struct object *sync = get_obj_sync( obj );
-    sync->ops->satisfied( sync, entry );
-    release_object( sync );
-}
-
-static void object_sync_remove_queue( struct object *obj, struct wait_queue_entry *entry )
-{
-    struct object *sync = get_obj_sync( obj );
-    sync->ops->remove_queue( sync, entry );
-    release_object( sync );
-}
-
-static int object_sync_add_queue( struct object *obj, struct wait_queue_entry *entry )
-{
-    struct object *sync = get_obj_sync( obj );
-    int ret = sync->ops->add_queue( sync, entry );
-    release_object( sync );
-    return ret;
-}
-
-static int object_sync_signaled( struct object *obj, struct wait_queue_entry *entry )
-{
-    struct object *sync = get_obj_sync( obj );
-    int ret = sync->ops->signaled( sync, entry );
-    release_object( sync );
-    return ret;
-}
-
-void signal_sync( struct object *obj )
-{
-    obj->ops->signal( obj, 0, 1 );
-}
-
-void reset_sync( struct object *obj )
-{
-    obj->ops->signal( obj, 0, 0 );
-}
-
 /* finish waiting */
 static unsigned int end_wait( struct thread *thread, unsigned int status )
 {
@@ -1078,22 +1027,18 @@ static unsigned int end_wait( struct thr
         if (wait->select == SELECT_WAIT_ALL)
         {
             for (i = 0, entry = wait->queues; i < wait->count; i++, entry++)
-                object_sync_satisfied( entry->obj, entry );
+                entry->obj->ops->satisfied( entry->obj, entry );
         }
         else
         {
             entry = wait->queues + status;
-            object_sync_satisfied( entry->obj, entry );
+            entry->obj->ops->satisfied( entry->obj, entry );
         }
         status = wait->status;
         if (wait->abandoned) status += STATUS_ABANDONED_WAIT_0;
     }
     for (i = 0, entry = wait->queues; i < wait->count; i++, entry++)
-    {
-        object_sync_remove_queue( entry->obj, entry );
-        release_object( entry->obj );
-        entry->obj = NULL;
-    }
+        entry->obj->ops->remove_queue( entry->obj, entry );
     if (wait->user) remove_timeout_user( wait->user );
     free( wait );
     return status;
@@ -1123,14 +1068,13 @@ static int wait_on( const union select_o
     {
         struct object *obj = objects[i];
         entry->wait = wait;
-        if (!object_sync_add_queue( obj, entry ))
+        if (!obj->ops->add_queue( obj, entry ))
         {
             wait->count = i;
             end_wait( current, get_error() );
             return 0;
         }
 
-        entry->obj = grab_object( obj );
         if (obj == (struct object *)current->queue) idle = 1;
     }
 
@@ -1178,13 +1122,13 @@ static int check_wait( struct thread *th
         /* Note: we must check them all anyway, as some objects may
          * want to do something when signaled, even if others are not */
         for (i = 0, entry = wait->queues; i < wait->count; i++, entry++)
-            not_ok |= !object_sync_signaled( entry->obj, entry );
+            not_ok |= !entry->obj->ops->signaled( entry->obj, entry );
         if (!not_ok) return STATUS_WAIT_0;
     }
     else
     {
         for (i = 0, entry = wait->queues; i < wait->count; i++, entry++)
-            if (object_sync_signaled( entry->obj, entry )) return i;
+            if (entry->obj->ops->signaled( entry->obj, entry )) return i;
     }
 
     if ((wait->flags & SELECT_ALERTABLE) && !list_empty(&thread->user_apc)) return STATUS_USER_APC;
@@ -1300,7 +1244,7 @@ static int signal_object( obj_handle_t h
     obj = get_handle_obj( current->process, handle, 0, NULL );
     if (obj)
     {
-        ret = obj->ops->signal( obj, get_handle_access( current->process, handle ), -1 );
+        ret = obj->ops->signal( obj, get_handle_access( current->process, handle ));
         release_object( obj );
     }
     return ret;
@@ -1391,6 +1335,9 @@ void wake_up( struct object *obj, int ma
     struct list *ptr;
     int ret;
 
+    if (do_esync())
+        esync_wake_up( obj );
+
     LIST_FOR_EACH( ptr, &obj->wait_queue )
     {
         struct wait_queue_entry *entry = LIST_ENTRY( ptr, struct wait_queue_entry, entry );
@@ -1475,9 +1422,10 @@ static int queue_apc( struct process *pr
     list_add_tail( queue, &apc->entry );
     if (!list_prev( queue, &apc->entry ))  /* first one */
     {
-        if (apc->call.type == APC_USER && thread->alert_sync)
-            signal_inproc_sync( thread->alert_sync );
         wake_thread( thread );
+
+        if (do_esync() && queue == &thread->user_apc)
+            esync_wake_fd( thread->esync_apc_fd );
     }
 
     return 1;
@@ -1508,10 +1456,8 @@ void thread_cancel_apc( struct thread *t
         if (apc->owner != owner) continue;
         list_remove( &apc->entry );
         apc->executed = 1;
-        signal_sync( apc->sync );
+        wake_up( &apc->obj, 0 );
         release_object( apc );
-        if (list_empty( &thread->user_apc ) && thread->alert_sync)
-            reset_inproc_sync( thread->alert_sync );
         return;
     }
 }
@@ -1526,9 +1472,11 @@ static struct thread_apc *thread_dequeue
     {
         apc = LIST_ENTRY( ptr, struct thread_apc, entry );
         list_remove( ptr );
-        if (list_empty( &thread->user_apc ) && thread->alert_sync)
-            reset_inproc_sync( thread->alert_sync );
     }
+
+    if (do_esync() && list_empty( &thread->system_apc ) && list_empty( &thread->user_apc ))
+        esync_clear( thread->esync_apc_fd );
+
     return apc;
 }
 
@@ -1542,7 +1490,7 @@ static void clear_apc_queue( struct list
         struct thread_apc *apc = LIST_ENTRY( ptr, struct thread_apc, entry );
         list_remove( &apc->entry );
         apc->executed = 1;
-        signal_sync( apc->sync );
+        wake_up( &apc->obj, 0 );
         release_object( apc );
     }
 }
@@ -1624,7 +1572,9 @@ void kill_thread( struct thread *thread,
     }
     kill_console_processes( thread, 0 );
     abandon_mutexes( thread );
-    signal_sync( thread->sync );
+    wake_up( &thread->obj, 0 );
+    if (do_esync())
+        esync_abandon_mutexes( thread );
     if (violent_death) send_thread_signal( thread, SIGQUIT );
     cleanup_thread( thread );
     remove_process_thread( thread->process, thread );
@@ -1751,7 +1701,6 @@ static int init_thread( struct thread *t
 DECL_HANDLER(init_first_thread)
 {
     struct process *process = current->process;
-    int fd;
 
     if (!init_thread( current, req->reply_fd, req->wait_fd )) return;
 
@@ -1774,12 +1723,6 @@ DECL_HANDLER(init_first_thread)
     reply->server_start = server_start_time;
     set_reply_data( supported_machines,
                     min( supported_machines_count * sizeof(unsigned short), get_reply_max_size() ));
-
-    if ((fd = get_inproc_device_fd()) >= 0)
-    {
-        reply->inproc_device = get_process_id( process ) | 1;
-        send_client_fd( process, fd, reply->inproc_device );
-    }
 }
 
 /* initialize a new thread */
@@ -1988,7 +1931,7 @@ DECL_HANDLER(select)
         }
         ctx->status = STATUS_SUCCESS;
         current->suspend_cookie = req->cookie;
-        signal_sync( ctx->sync );
+        wake_up( &ctx->obj, 0 );
     }
 
     if (!req->cookie) goto invalid_param;
@@ -2012,7 +1955,7 @@ DECL_HANDLER(select)
             apc->result.create_thread.handle = handle;
             clear_error();  /* ignore errors from the above calls */
         }
-        signal_sync( apc->sync );
+        wake_up( &apc->obj, 0 );
         close_handle( current->process, req->prev_apc );
         release_object( apc );
     }
@@ -2035,7 +1978,7 @@ DECL_HANDLER(select)
         else
         {
             apc->executed = 1;
-            signal_sync( apc->sync );
+            wake_up( &apc->obj, 0 );
         }
         release_object( apc );
     }
@@ -2391,17 +2334,3 @@ DECL_HANDLER(get_next_thread)
     set_error( STATUS_NO_MORE_ENTRIES );
     release_object( process );
 }
-
-
-/* Get the in-process synchronization fd for the current thread user APC alerts */
-DECL_HANDLER(get_inproc_alert_fd)
-{
-    int fd;
-
-    if ((fd = get_inproc_sync_fd( current->alert_sync )) < 0) set_error( STATUS_INVALID_PARAMETER );
-    else
-    {
-        reply->handle = get_thread_id( current ) | 1; /* arbitrary token */
-        send_client_fd( current->process, fd, reply->handle );
-    }
-}
diff -ruN --show-c-function server/thread.h server/thread.h
--- server/thread.h	2025-10-21 17:44:36.357781284 -0700
+++ server/thread.h	2025-10-24 16:11:42.414329662 -0700
@@ -50,14 +50,14 @@ struct inflight_fd
 struct thread
 {
     struct object          obj;           /* object header */
-    struct object         *sync;          /* sync object for wait/signal */
-    struct inproc_sync    *alert_sync;    /* inproc sync for user apc alerts */
     struct list            entry;         /* entry in system-wide thread list */
     struct list            proc_entry;    /* entry in per-process thread list */
     struct list            desktop_entry; /* entry in per-desktop thread list */
     struct process        *process;
     thread_id_t            id;            /* thread id */
     struct list            mutex_list;    /* list of currently owned mutexes */
+    int                    esync_fd;      /* esync file descriptor (signalled on exit) */
+    int                    esync_apc_fd;  /* esync apc fd (signalled when APCs are present) */
     unsigned int           system_regs;   /* which system regs have been set */
     struct msg_queue      *queue;         /* message queue */
     struct thread_wait    *wait;          /* current wait condition if sleeping */
diff -ruN --show-c-function server/timer.c server/timer.c
--- server/timer.c	2025-10-21 17:44:36.357781284 -0700
+++ server/timer.c	2025-10-24 16:11:42.412351146 -0700
@@ -35,6 +35,7 @@
 #include "file.h"
 #include "handle.h"
 #include "request.h"
+#include "esync.h"
 
 static const WCHAR timer_name[] = {'T','i','m','e','r'};
 
@@ -53,7 +54,6 @@ struct type_descr timer_type =
 struct timer
 {
     struct object        obj;       /* object header */
-    struct object       *sync;      /* sync object for wait/signal */
     int                  manual;    /* manual reset */
     int                  signaled;  /* current signaled state */
     unsigned int         period;    /* timer period in ms */
@@ -62,10 +62,13 @@ struct timer
     struct thread       *thread;    /* thread that set the APC function */
     client_ptr_t         callback;  /* callback APC function */
     client_ptr_t         arg;       /* callback argument */
+    int                  esync_fd;  /* esync file descriptor */
 };
 
 static void timer_dump( struct object *obj, int verbose );
-static struct object *timer_get_sync( struct object *obj );
+static int timer_signaled( struct object *obj, struct wait_queue_entry *entry );
+static int timer_get_esync_fd( struct object *obj, enum esync_type *type );
+static void timer_satisfied( struct object *obj, struct wait_queue_entry *entry );
 static void timer_destroy( struct object *obj );
 
 static const struct object_ops timer_ops =
@@ -73,13 +76,13 @@ static const struct object_ops timer_ops
     sizeof(struct timer),      /* size */
     &timer_type,               /* type */
     timer_dump,                /* dump */
-    NULL,                      /* add_queue */
-    NULL,                      /* remove_queue */
-    NULL,                      /* signaled */
-    NULL,                      /* satisfied */
+    add_queue,                 /* add_queue */
+    remove_queue,              /* remove_queue */
+    timer_signaled,            /* signaled */
+    timer_get_esync_fd,        /* get_esync_fd */
+    timer_satisfied,           /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
-    timer_get_sync,            /* get_sync */
     default_map_access,        /* map_access */
     default_get_sd,            /* get_sd */
     default_set_sd,            /* set_sd */
@@ -105,19 +108,16 @@ static struct timer *create_timer( struc
         if (get_error() != STATUS_OBJECT_NAME_EXISTS)
         {
             /* initialize it if it didn't already exist */
-            timer->sync     = NULL;
             timer->manual   = manual;
             timer->signaled = 0;
             timer->when     = 0;
             timer->period   = 0;
             timer->timeout  = NULL;
             timer->thread   = NULL;
+            timer->esync_fd = -1;
 
-            if (!(timer->sync = create_internal_sync( manual, 0 )))
-            {
-                release_object( timer );
-                return NULL;
-            }
+            if (do_esync())
+                timer->esync_fd = esync_create_fd( 0, 0 );
         }
     }
     return timer;
@@ -157,8 +157,9 @@ static void timer_callback( void *privat
     }
     else timer->timeout = NULL;
 
+    /* wake up waiters */
     timer->signaled = 1;
-    signal_sync( timer->sync );
+    wake_up( &timer->obj, 0 );
 }
 
 /* cancel a running timer */
@@ -189,7 +190,9 @@ static int set_timer( struct timer *time
     {
         period = 0;  /* period doesn't make any sense for a manual timer */
         timer->signaled = 0;
-        reset_sync( timer->sync );
+
+        if (do_esync())
+            esync_clear( timer->esync_fd );
     }
     timer->when     = (expire <= 0) ? expire - monotonic_time : max( expire, current_time );
     timer->period   = period;
@@ -210,11 +213,25 @@ static void timer_dump( struct object *o
              timer->manual, get_timeout_str(timeout), timer->period );
 }
 
-static struct object *timer_get_sync( struct object *obj )
+static int timer_signaled( struct object *obj, struct wait_queue_entry *entry )
+{
+    struct timer *timer = (struct timer *)obj;
+    assert( obj->ops == &timer_ops );
+    return timer->signaled;
+}
+
+static int timer_get_esync_fd( struct object *obj, enum esync_type *type )
+{
+    struct timer *timer = (struct timer *)obj;
+    *type = timer->manual ? ESYNC_MANUAL_SERVER : ESYNC_AUTO_SERVER;
+    return timer->esync_fd;
+}
+
+static void timer_satisfied( struct object *obj, struct wait_queue_entry *entry )
 {
     struct timer *timer = (struct timer *)obj;
     assert( obj->ops == &timer_ops );
-    return grab_object( timer->sync );
+    if (!timer->manual) timer->signaled = 0;
 }
 
 static void timer_destroy( struct object *obj )
@@ -224,7 +241,7 @@ static void timer_destroy( struct object
 
     if (timer->timeout) remove_timeout_user( timer->timeout );
     if (timer->thread) release_object( timer->thread );
-    if (timer->sync) release_object( timer->sync );
+    if (do_esync()) close( timer->esync_fd );
 }
 
 /* create a timer */
diff -ruN --show-c-function server/token.c server/token.c
--- server/token.c	2025-10-21 17:44:36.357781284 -0700
+++ server/token.c	2025-10-24 16:11:42.402117021 -0700
@@ -145,10 +145,10 @@ static const struct object_ops token_ops
     no_add_queue,              /* add_queue */
     NULL,                      /* remove_queue */
     NULL,                      /* signaled */
+    NULL,                      /* get_esync_fd */
     NULL,                      /* satisfied */
     no_signal,                 /* signal */
     no_get_fd,                 /* get_fd */
-    default_get_sync,          /* get_sync */
     default_map_access,        /* map_access */
     default_get_sd,            /* get_sd */
     token_set_sd,              /* set_sd */
diff -ruN --show-c-function server/window.c server/window.c
--- server/window.c	2025-10-21 17:44:36.358781307 -0700
+++ server/window.c	2025-10-24 16:11:42.402348971 -0700
@@ -108,10 +108,10 @@ static const struct object_ops window_op
     no_add_queue,             /* add_queue */
     NULL,                     /* remove_queue */
     NULL,                     /* signaled */
+    NULL,                     /* get_esync_fd */
     NULL,                     /* satisfied */
     no_signal,                /* signal */
     no_get_fd,                /* get_fd */
-    default_get_sync,         /* get_sync */
     default_map_access,       /* map_access */
     default_get_sd,           /* get_sd */
     default_set_sd,           /* set_sd */
@@ -681,7 +681,7 @@ static struct window *create_window( str
     list_init( &win->children );
     list_init( &win->unlinked );
 
-    if (!(win->shared = alloc_shared_object( sizeof(*win->shared) ))) goto failed;
+    if (!(win->shared = alloc_shared_object())) goto failed;
     SHARED_WRITE_BEGIN( win->shared, window_shm_t )
     {
         shared->class       = class_locator;
diff -ruN --show-c-function server/winstation.c server/winstation.c
--- server/winstation.c	2025-10-21 17:44:36.358781307 -0700
+++ server/winstation.c	2025-10-24 16:11:42.402631838 -0700
@@ -76,10 +76,10 @@ static const struct object_ops winstatio
     no_add_queue,                 /* add_queue */
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
+    NULL,                         /* get_esync_fd */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-    default_get_sync,             /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
@@ -117,10 +117,10 @@ static const struct object_ops desktop_o
     no_add_queue,                 /* add_queue */
     NULL,                         /* remove_queue */
     NULL,                         /* signaled */
+    NULL,                         /* get_esync_fd */
     NULL,                         /* satisfied */
     no_signal,                    /* signal */
     no_get_fd,                    /* get_fd */
-    default_get_sync,             /* get_sync */
     default_map_access,           /* map_access */
     default_get_sd,               /* get_sd */
     default_set_sd,               /* set_sd */
@@ -308,7 +308,7 @@ static struct desktop *create_desktop( c
             list_init( &desktop->hotkeys );
             list_init( &desktop->pointers );
 
-            if (!(desktop->shared = alloc_shared_object( sizeof(*desktop->shared) )))
+            if (!(desktop->shared = alloc_shared_object()))
             {
                 release_object( desktop );
                 return NULL;
